{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About Polygon zkEVM Integrated seamlessly with the Ethereum ecosystem, Polygon zkEVM is a powerful, decentralized technology that provides Layer 2 scalability solutions to blockchain users. With the tremendous increase in the number of transactions taking place on-chain (i.e. base layer Ethereum), the Layer 1 solution is already facing blockchain trilemma: decentralization, scalability, and security. It is where Polygon zkEVM steps in. By providing zk-rollups (zero-knowledge rollups) that sit on the top of Ethereum Maninnet, the scalability and the transactions per second (TPS) can be dramatically improved. To prove that the off-chain computations are correct, Polygon zkEVM employs zero-knowledge proofs that can be verified easily. The Layer 2 zero-knowledge proofs are based on the complex polynomial computations that help in leveraging Ethereum scaling and provide fast finality to the off-chain transactions. What is Polygon zkEVM? Polygon Hermez 1.0 version was launched in March 2021. The goal of Polygon Hermez 1.0 was to scale payments and transfer ERC-20 tokens. It focussed mainly on decongesting Ethereum main chain by taking transactions off from the main chain and executing them off-chain; this resulted in an increase in the number of transactions that can be executed per second to up to 2000, which was a big improvement over Layer 1 Ethereum. See Ethereum Live TPS to keep track of Ethereum's live transactions per second. Polygon zkEVM, henceforth called zkEVM, has been developed to emulate Ethereum Virtual Machine(EVM) that executes Ethereum transactions with zero-knowledge proof validations. This has been accomplished by developing an EVM based on zero-knowledge; the machine is designed to recreate all the existing EVM opcodes that can be deployed as smart contracts. Although taking on this revolutionary design approach was a hard decision to make, the objective is to minimise the users and dApps friction when using the solution. It is an approach that requires the recreation of all EVM opcodes for the transparent deployment of existing Ethereum smart contracts. For this purpose, a new set of technologies and tools are being created and engineered by the team. This document presents a high-level description of the upcoming Polygon zkEVM solution including its main components and design. It also seeks to highlight how Polygon zkEVM departs from the original design of Polygon Hermez 1.0. Architecture Over and above what its predecessor was designed to do, the main functionality of zkEVM is to provide smart contract support. It performs the task of state transition resulting from the Ethereum Layer 2 transaction executions (transactions that users send to the network). Subsequently, by employing zero-knowledge functionality, it generates validity proofs that attest to the correctness of these state change computations carried out off-chain. The major components of zkEVM are: Proof of Efficiency Consensus Mechanism zkNode Software zkProver LX-to-LY Bridge Sequencers Aggregators Active users of the zkEVM network who create transactions. The skeletal architecture of zkEVM is shown below: Figure 1 : Skeletal Overview of zkEVM Consensus Algorithm: Proof of Efficiency Our earlier version, Polygon Hermez 1.0, is based on the Proof of Donation(PoD) consensus mechanism. This model decides who would be the next batch creator. PoD is a decentralised auction that is conducted automatically and the participants (coordinators) bid a number of tokens so that they have the chance to create the next batch. However, for the implementation of the current 2.0, PoD needed to be replaced with a much simpler Proof of Efficiency (PoE) model. Let us see why PoE is preferable to PoD. Why is PoD not the Best Option? The PoD model fell out of our preferable options for the reasons listed below: The PoD, being an auction model, has proved to be quite complex for both the coordinators and the validators. Besides, it has also proven to be less viable economically. This consensus mechanism is vulnerable to attacks, especially during the bootstrapping phases. At any given point in time, the network is controlled by a permissionless participant. This raises the risk for the network to suffer service level delays should such a third party turn malicious or experience operational issues. PoD assigns the right to produce batches in a specific timeframe and validators need to be very competitive if they are to gain any economic incentives. The efficacy of selecting \u201cthe best\u201d operator amounts to a \"winner-takes-all\" model, which turns out to be unfair to competitors with slightly less performance. Consequently, only a few select operators validate batches more often than others, defeating the concept of network decentralization. Another drawback is that the auction protocol is very costly and complex for validators. The auction requires bidding some time in advance. Why is PoE a Better Model? The Proof of Efficiency (PoE) model leverages the existing Proof of Donation mechanism and supports the permissionless participation of multiple coordinators to produce batches in Layer L2. These batches are created from the rolled-up transactions of Layer 1. As compared to PoD, PoE employs a much simpler mechanism and is preferred owing to its better efficiency to solve the problems inherent in PoD. The strategic implementation of PoE promises to ensure that the network: Maintains its \"permissionless\" feature to produce L2 batches Is efficient, a criterion which is key for the overall network performance Attains an acceptable degree of decentralization Is protected from malicious attacks, especially by validators Keeps a proportionate balance between the overall validation effort and the value in the network. Note: Possibilities of coupling PoE with a PoS (Proof of Stake) are currently being explored. A detailed description of zkEVM's PoE is found here . Hybrid Mode for On-Chain Data Availability A full zk-rollup schema requires that both the data (which is required by users to reconstruct the full state) and the validity proofs (zero-knowledge proofs) be published on-chain. However, given the Ethereum setting, publishing data on-chain incurs gas fees, which is an already-existing problem with Layer 1. This makes it difficult to choose between a full zk-rollup configuration and a hybrid one. Under a hybrid schema, either of the following is possible: - Validium : Data is stored off-chain and only the validity proofs are published on-chain. - Volition : For some transactions, both the data and the validity proofs remain on-chain while for the remaining ones, only proofs go on-chain. Unless, among other things, the proving module can be highly accelerated to mitigate costs for the validators, a hybrid schema remains viable. The team is yet to finalise the best consensus configuration. The PoE Smart Contract The underlying protocol in zkEVM ensures that the state transitions are correct by employing a validity proof. To ensure that a set of pre-determined rules have been followed for allowing transitioning of the state, a smart contract is employed. The verification of the validity proofs by a smart contract checks if each transition is done correctly. This is achieved by using zk-SNARK circuits. Such a mechanism entails two processes: batching of transactions and validation of the batched transactions. zkEVM uses two types of participants to carry out these processes: Sequencers and Aggregators. Under this two-layer model: Sequencers propose transaction batches to the network, i.e. they roll-up the transaction requests to batches and add them to the PoE smart contract. Aggregators check the validity of the transaction batches and provide validity proofs. Any permissionless Aggregator can submit the proof to demonstrate the correctness of the state transition computation. The PoE smart contract, therefore, makes two basic calls: A call to receive batches from Sequencers, and another call to Aggregators, requesting batches to be validated. See Figure 2 below: Figure 2: Simplified Proof of Efficiency Proof of Efficiency Tokenomics: Sequencers and Aggregators The PoE smart contract imposes a few requirements on Sequencers and Aggregators. Sequencers A Sequencer receives L2 transactions from the users, preprocesses them as a new L2 batch, and then proposes the batch to the PoE smart contract as a valid L2 transaction. Anyone with the software necessary for running a zkEVM node can be a Sequencer. Every Sequencer must pay a fee in form of MATIC tokens to earn the right to create and propose batches. A Sequencer that proposes valid batches (which consist of valid transactions), is incentivised with the fee paid by transaction-requestors or the users of the network. Aggregators An Aggregator receives all the transaction information from the Sequencer and sends it to the prover which provides a small zk-proof after complex polynomial computations. The smart contract validates this proof. This way, an aggregator collects the data, sends it to the prover, receives its output and finally, sends the information to the smart contract to check that the validity proof from the prover is correct. An Aggregator's task is to provide validity proofs for the L2 transactions proposed by Sequencers. In addition to running zkEVM's zkNode software, Aggregators need to have specialised hardware for creating the zero-knowledge validity proofs. We, herein, call it the zkProver. (You will read about it later in this document). For a given batch or batches, an Aggregator that submits a validity proof first earns the Matic fee (which is being paid by the Sequencer(s) of the batch(es)). The Aggregators need to indicate their intention to validate transactions and then they compete to produce the validity proofs based on their own strategy. zkNode A zkNode is the software needed to run a zkEVM node. It is a client that the network requires to implement the synchronization and govern the roles of the participants (Sequencers or Aggregators). zkNode Architecture The zkNode Architecture is composed of: Sequencers and Aggregators : Polygon zkEVM participants will choose how they participate; either as a node to know the state of the network; or as a participant in the process of batch production in any of the two roles: Sequencer or Aggregator. An Aggregator runs the zkNode but also performs validation using the core part of the zkEVM, called the zkProver (this is labelled Prover in Figure 3 below.) Synchronizer : Other than the sequencing and the validating processes, the zkNode also enables synchronisation of batches and their validity proofs, which happens only after these have been added to L1. This is accomplished using a subcomponent called the Synchronizer. A Synchronizer is in charge of getting all the data from smart contracts, which includes the data posted by the sequencers (transactions) and the data posted by the coordinators (which is the validity proof). All this data is stored in a huge database and served to third parties through a service called \"JSON-RPC\". The Synchronizer is responsible for reading the events from the Ethereum blockchain, including new batches to keep the state fully synced. The information read from these events must be stored in the database. The Synchronizer also handles possible reorgs, which will be detected by checking if the last ethBlockNum and the last ethBlockHash are synced. Figure 3: zkEVM zkNode Diagram The architecture of zkNode is modular and implements a set of functions as depicted in Figure 3 above. RPC : RPC (Remote Procedure Call) is a JSON RPC interface compatible with Ethereum. For a software application to interact with the Ethereum blockchain (by reading blockchain data and/or sending transactions to the network), it must connect to an Ethereum node. RPC enables integration of the zkEVM with existing tools, such as Metamask, Etherscan and Infura. It adds transactions to the Pool and interacts with the State using read-only methods. State : A subcomponent that implements the Merkle Tree and connects to the DB backend. It checks integrity at the block level (information related to gas and block size, among others) and some transaction-related information (signatures, sufficient balance). State also stores smart contract code into the Merkle tree and processes transactions using the EVM. zkProver : All the rules for a transaction to be valid are implemented and enforced in the zkProver. A zkProver performs complex mathematical computations in the form of polynomials and assembly language; these are then verified on a smart contract. Those rules could be seen as constraints that a transaction must accomplish in order to be able to modify the state tree or the exit tree. The zkProver is the most complex module; it required developing two new programming languages to implement the needed elements. Read below to know more about zkProver. zkProver zkEVM employs advanced zero-knowledge technology to create validity proofs. It uses a zero-knowledge prover (zkProver), which is intended to run on any server and is being engineered to be compatible with most consumer hardware. Every Aggregator will use this zkProver to validate batches and provide validity proofs. zkProver has its own detailed architecture which is outlined below. It consists of a Main State Machine Executor, a collection of secondary State Machines (each with its own executor), a STARK-proof builder, and a SNARK-proof builder. See Figure 4 below for a simplified diagram of the zkEVM zkProver: Figure 4: A Simplified zkProver Diagram In a nutshell, the zkEVM expresses state changes in a polynomial form. Therefore, the constraints that each proposed batch must satisfy are, in fact, polynomial constraints or polynomial identities. That is, all the valid batches must satisfy certain polynomial constraints. zkProver Architecture The zkNode Architecture is composed of: Main State Machine Executor : The Main Executor handles the execution of the zkEVM. This is where EVM Bytecodes are interpreted using a new zero-knowledge Assembly language (or zkASM), specially developed by the team. The executor also sets up the polynomial constraints that every valid batch of transactions must satisfy. Another language, specially developed by the team, called Polynomial Identity Language (or PIL), is used to encode all the polynomial constraints. Secondary State Machines : Every computation required in proving the correctness of transactions is represented in the zkEVM as a state machine. The zkProver, being the most complex part of the whole project, consists of several state machines; from those carrying out bitwise functionalities (e.g., XORing, padding, etc.) to those performing hashing (e.g., Keccak, Poseidon), even to verifying signatures (e.g., ECDSA). The collection of the secondary state machines, therefore, refers to a collection of all state machines in the zkProver. It is not a subcomponent per se, but a collection of various executors for individual secondary state machines. The set of state machines are: Binary SM Memory SM Storage SM Poseidon SM Keccak SM Arithmetic SM See Figure 5 below for dependencies among these SMs. While some SMs use both zkASM and PIL, others rely only on one of these languages depending upon the specific operations each SM is responsible for. Figure 5: zkEVM State Machines STARK Proof Builder : STARK, which stands for \"Scalable Transparent Argument of Knowledge\", is a proof system that enables provers to produce verifiable proofs without the need for a trusted setup. A STARK Proof Builder refers to the subcomponent used to produce zero-knowledge STARK proofs, which are zk-proofs attesting to the fact that all the polynomial constraints are satisfied. State machines generate polynomial constraints and zk-STARKs are used to prove that batches satisfy these constraints. In particular, zkProver utilises \"Fast Reed-Solomon Interactive Oracle Proofs of Proximity (RS-IOPP)\", colloquially called FRI , to facilitate fast zk-STARK proving. SNARK Proof Builder : SNARK, which stands for \"Succinct Non-interactive Argument of Knowledge\", is a proof system that produces verifiable proofs. Since STARK proofs are bigger than the SNARK proofs, zkEVM zkProver uses SNARK proofs to prove the correctness of these STARK proofs. Consequently, the SNARK proofs, which are much cheaper to verify on L1, are published as validity proofs. The aim is to generate a CIRCOM circuit which can be used to generate or verify a SNARK proof. Whether a PLONK or a GROTH16 SNARK proof will be used for zkEVM is a question that needs to be discussed. The LX-to-LY Bridge An LX-LY bridge is a smart contract that lets users transfer their assets between two layers, LX and LY. The L1-L2 in zkEVM is a decentralised bridge for secure deposits and withdrawal of assets; it is a combination of two smart contracts, one deployed on one chain and the second on the other. The L1 and L2 contracts in zkEVM are identical except for where each is deployed. Bridge L1 Contract is on the Ethereum mainnet in order to manage asset transfers between rollups, while Bridge L2 Contract is on a specific rollup and it is responsible for asset transfers between mainnet and the rollup (or rollups). Layer 2 Interoperability allows a native mechanism to migrate assets between different L2 networks. This solution is embedded in the bridge smart contract. Bridge L1 Contract Bridge L1 Contract carries out two operations: bridge and claim . The bridge operation transfers assets from one rollup to another, while the claim operation applies when the contract makes a claim from any rollup. Bridge L1 Contract requires two Merkle trees in order to perform the above operations: globalExitTree and mainnet exit tree . The globalExitTree contains all the information of exit trees of all rollups, whereas the mainnet exit tree has information on transactions made by users who interact with the mainnet. A contract named the global exit root manager L1 is responsible for managing exit roots across multiple networks. The exit tree structure is depicted in Figure 6 below: Figure 6: The Exit Tree Structure Bridge L2 Contract Bridge L2 Contract is deployed on Layer L2 with ether on it. The ether will be set on the genesis in order to enable the minting/burning of the native ether. Bridge L2 Contract also requires all the information of exit trees of all rollups contained in the globalExitTree Merkle tree. In this case, a smart contract named the global exit root manager L2 is responsible for managing the exit roots across multiple networks. Note: When a batch is verified in the PoE smart contract in L1, the rollup exit root is updated in the global exit root manager L1. Bridge L2 Contract handles the rollup side of the bridge and the claim operations, as well as interacting with the globalExitTree and the rollup exit tree , mainly to update exit roots. LX-to-LY Bridge Typically, a bridge smart contract is an L2-to-L1 Bridge, but the zkEVM Bridge is more flexible and interoperable. It can function as a bridge between any two arbitrary Layer 2 chains, L2_A and L2_B, or between any Layer 2 (say L2_X) and L1 (Ethereum blockchain). It consequently allows asset transfers among multiple rollups. Hence the term \"LX-to-LY Bridge\". zkEVM Design Characteristics The architectural details (for engineering and implementation) described in the sections above will help zkEVM attain its design goals. That would mean a network which is: permissionless, decentralized, secure, efficient and comes with verifiable block data. Development efforts aim at permissionless-ness , that is, allowing anyone with the zkEVM software to participate in the network. For instance, the consensus algorithm will give everyone the opportunity to be a Sequencer or an Aggregator. Data availability is most crucial for decentralization , where every user has sufficient data needed to rebuild the full state of a rollup. As discussed above, the team still has to decide on the best configuration for data availability. The aim is to ensure that there is no censorship and that no one party can control the network. zkEVM was designed with security in mind. As an L2 solution, most of the security is inherited from Ethereum. Smart contracts will warrant that anyone who executes state changes must, firstly, do it correctly; secondly, create a proof that attests to the validity of a state change; and thirdly, avail validity proofs on-chain for verification. Efficiency and Overall Strategy Efficiency is key to network performance. zkEVM, therefore, applies several implementation strategies to guarantee efficiency. A few of them are listed below: The first strategy is to deploy PoE, which incentivizes the most efficient aggregators to participate in the proof generation process. The second strategy is to carry out all computations off-chain while keeping only the necessary data and zk-proofs on-chain. There are other strategies too that are implemented within specific components of the zkEVM system. For instance: The way in which the bridge smart contract is implemented, such as settling accounts in a UTXO manner, by only using the Exit Tree Roots. Utilisation of specialised cryptographic primitives within the zkProver in order to speed up computations and minimise proof sizes, as seen in: (a) Running a special zero-knowledge Assembly language (zkASM) for interpretation of byte codes (b) Using zero-knowledge tools such as zk-STARKs for proving purposes; these proofs are very fast though they are bigger in size. See . So, instead of publishing the sizeable zk-STARK proofs as validity proofs, a zk-SNARK is used to attest to the correctness of the zk-STARK proofs. These zk-SNARKs are, in turn, published as the validity proofs to state changes. This helps in reducing the gas costs from 5M to 350K. Conclusion Given the EVM opcode compatibility, zkEVM is designed to process smart contracts seamlessly and verify state changes efficiently. It promises not only to be secure and efficient but also to accomplish competitive decentralization. In an effort to achieve high-speed proving and succinct proofs for quick verification, the team is focused on the optimization of the zkProver. The team also leverages the synergies among the different Polygon teams that are also looking into zk-rollup solutions for achieving Ethereum scalability. Although development is still underway, it was important for this document to be released early so as to align with the goal of transparency set by the open-source projects, as well as keep the Polygon community of developers and users of Polygon Hermez 1.0 updated with the upcoming changes. Our next step will be to develop a public testnet. Although it is difficult to set a fixed date for the same, our plan is to launch it by mid-2022.","title":"Home"},{"location":"#about-polygon-zkevm","text":"Integrated seamlessly with the Ethereum ecosystem, Polygon zkEVM is a powerful, decentralized technology that provides Layer 2 scalability solutions to blockchain users. With the tremendous increase in the number of transactions taking place on-chain (i.e. base layer Ethereum), the Layer 1 solution is already facing blockchain trilemma: decentralization, scalability, and security. It is where Polygon zkEVM steps in. By providing zk-rollups (zero-knowledge rollups) that sit on the top of Ethereum Maninnet, the scalability and the transactions per second (TPS) can be dramatically improved. To prove that the off-chain computations are correct, Polygon zkEVM employs zero-knowledge proofs that can be verified easily. The Layer 2 zero-knowledge proofs are based on the complex polynomial computations that help in leveraging Ethereum scaling and provide fast finality to the off-chain transactions.","title":"About Polygon zkEVM"},{"location":"#what-is-polygon-zkevm","text":"Polygon Hermez 1.0 version was launched in March 2021. The goal of Polygon Hermez 1.0 was to scale payments and transfer ERC-20 tokens. It focussed mainly on decongesting Ethereum main chain by taking transactions off from the main chain and executing them off-chain; this resulted in an increase in the number of transactions that can be executed per second to up to 2000, which was a big improvement over Layer 1 Ethereum. See Ethereum Live TPS to keep track of Ethereum's live transactions per second. Polygon zkEVM, henceforth called zkEVM, has been developed to emulate Ethereum Virtual Machine(EVM) that executes Ethereum transactions with zero-knowledge proof validations. This has been accomplished by developing an EVM based on zero-knowledge; the machine is designed to recreate all the existing EVM opcodes that can be deployed as smart contracts. Although taking on this revolutionary design approach was a hard decision to make, the objective is to minimise the users and dApps friction when using the solution. It is an approach that requires the recreation of all EVM opcodes for the transparent deployment of existing Ethereum smart contracts. For this purpose, a new set of technologies and tools are being created and engineered by the team. This document presents a high-level description of the upcoming Polygon zkEVM solution including its main components and design. It also seeks to highlight how Polygon zkEVM departs from the original design of Polygon Hermez 1.0.","title":"What is Polygon zkEVM?"},{"location":"#architecture","text":"Over and above what its predecessor was designed to do, the main functionality of zkEVM is to provide smart contract support. It performs the task of state transition resulting from the Ethereum Layer 2 transaction executions (transactions that users send to the network). Subsequently, by employing zero-knowledge functionality, it generates validity proofs that attest to the correctness of these state change computations carried out off-chain. The major components of zkEVM are: Proof of Efficiency Consensus Mechanism zkNode Software zkProver LX-to-LY Bridge Sequencers Aggregators Active users of the zkEVM network who create transactions. The skeletal architecture of zkEVM is shown below: Figure 1 : Skeletal Overview of zkEVM","title":"Architecture"},{"location":"#consensus-algorithm-proof-of-efficiency","text":"Our earlier version, Polygon Hermez 1.0, is based on the Proof of Donation(PoD) consensus mechanism. This model decides who would be the next batch creator. PoD is a decentralised auction that is conducted automatically and the participants (coordinators) bid a number of tokens so that they have the chance to create the next batch. However, for the implementation of the current 2.0, PoD needed to be replaced with a much simpler Proof of Efficiency (PoE) model. Let us see why PoE is preferable to PoD.","title":"Consensus Algorithm: Proof of Efficiency"},{"location":"#why-is-pod-not-the-best-option","text":"The PoD model fell out of our preferable options for the reasons listed below: The PoD, being an auction model, has proved to be quite complex for both the coordinators and the validators. Besides, it has also proven to be less viable economically. This consensus mechanism is vulnerable to attacks, especially during the bootstrapping phases. At any given point in time, the network is controlled by a permissionless participant. This raises the risk for the network to suffer service level delays should such a third party turn malicious or experience operational issues. PoD assigns the right to produce batches in a specific timeframe and validators need to be very competitive if they are to gain any economic incentives. The efficacy of selecting \u201cthe best\u201d operator amounts to a \"winner-takes-all\" model, which turns out to be unfair to competitors with slightly less performance. Consequently, only a few select operators validate batches more often than others, defeating the concept of network decentralization. Another drawback is that the auction protocol is very costly and complex for validators. The auction requires bidding some time in advance.","title":"Why is PoD not the Best Option?"},{"location":"#why-is-poe-a-better-model","text":"The Proof of Efficiency (PoE) model leverages the existing Proof of Donation mechanism and supports the permissionless participation of multiple coordinators to produce batches in Layer L2. These batches are created from the rolled-up transactions of Layer 1. As compared to PoD, PoE employs a much simpler mechanism and is preferred owing to its better efficiency to solve the problems inherent in PoD. The strategic implementation of PoE promises to ensure that the network: Maintains its \"permissionless\" feature to produce L2 batches Is efficient, a criterion which is key for the overall network performance Attains an acceptable degree of decentralization Is protected from malicious attacks, especially by validators Keeps a proportionate balance between the overall validation effort and the value in the network. Note: Possibilities of coupling PoE with a PoS (Proof of Stake) are currently being explored. A detailed description of zkEVM's PoE is found here .","title":"Why is PoE a Better Model?"},{"location":"#hybrid-mode-for-on-chain-data-availability","text":"A full zk-rollup schema requires that both the data (which is required by users to reconstruct the full state) and the validity proofs (zero-knowledge proofs) be published on-chain. However, given the Ethereum setting, publishing data on-chain incurs gas fees, which is an already-existing problem with Layer 1. This makes it difficult to choose between a full zk-rollup configuration and a hybrid one. Under a hybrid schema, either of the following is possible: - Validium : Data is stored off-chain and only the validity proofs are published on-chain. - Volition : For some transactions, both the data and the validity proofs remain on-chain while for the remaining ones, only proofs go on-chain. Unless, among other things, the proving module can be highly accelerated to mitigate costs for the validators, a hybrid schema remains viable. The team is yet to finalise the best consensus configuration.","title":"Hybrid Mode for On-Chain Data Availability"},{"location":"#the-poe-smart-contract","text":"The underlying protocol in zkEVM ensures that the state transitions are correct by employing a validity proof. To ensure that a set of pre-determined rules have been followed for allowing transitioning of the state, a smart contract is employed. The verification of the validity proofs by a smart contract checks if each transition is done correctly. This is achieved by using zk-SNARK circuits. Such a mechanism entails two processes: batching of transactions and validation of the batched transactions. zkEVM uses two types of participants to carry out these processes: Sequencers and Aggregators. Under this two-layer model: Sequencers propose transaction batches to the network, i.e. they roll-up the transaction requests to batches and add them to the PoE smart contract. Aggregators check the validity of the transaction batches and provide validity proofs. Any permissionless Aggregator can submit the proof to demonstrate the correctness of the state transition computation. The PoE smart contract, therefore, makes two basic calls: A call to receive batches from Sequencers, and another call to Aggregators, requesting batches to be validated. See Figure 2 below: Figure 2: Simplified Proof of Efficiency","title":"The PoE Smart Contract"},{"location":"#proof-of-efficiency-tokenomics-sequencers-and-aggregators","text":"The PoE smart contract imposes a few requirements on Sequencers and Aggregators. Sequencers A Sequencer receives L2 transactions from the users, preprocesses them as a new L2 batch, and then proposes the batch to the PoE smart contract as a valid L2 transaction. Anyone with the software necessary for running a zkEVM node can be a Sequencer. Every Sequencer must pay a fee in form of MATIC tokens to earn the right to create and propose batches. A Sequencer that proposes valid batches (which consist of valid transactions), is incentivised with the fee paid by transaction-requestors or the users of the network. Aggregators An Aggregator receives all the transaction information from the Sequencer and sends it to the prover which provides a small zk-proof after complex polynomial computations. The smart contract validates this proof. This way, an aggregator collects the data, sends it to the prover, receives its output and finally, sends the information to the smart contract to check that the validity proof from the prover is correct. An Aggregator's task is to provide validity proofs for the L2 transactions proposed by Sequencers. In addition to running zkEVM's zkNode software, Aggregators need to have specialised hardware for creating the zero-knowledge validity proofs. We, herein, call it the zkProver. (You will read about it later in this document). For a given batch or batches, an Aggregator that submits a validity proof first earns the Matic fee (which is being paid by the Sequencer(s) of the batch(es)). The Aggregators need to indicate their intention to validate transactions and then they compete to produce the validity proofs based on their own strategy.","title":"Proof of Efficiency Tokenomics: Sequencers and Aggregators"},{"location":"#zknode","text":"A zkNode is the software needed to run a zkEVM node. It is a client that the network requires to implement the synchronization and govern the roles of the participants (Sequencers or Aggregators).","title":"zkNode"},{"location":"#zknode-architecture","text":"The zkNode Architecture is composed of: Sequencers and Aggregators : Polygon zkEVM participants will choose how they participate; either as a node to know the state of the network; or as a participant in the process of batch production in any of the two roles: Sequencer or Aggregator. An Aggregator runs the zkNode but also performs validation using the core part of the zkEVM, called the zkProver (this is labelled Prover in Figure 3 below.) Synchronizer : Other than the sequencing and the validating processes, the zkNode also enables synchronisation of batches and their validity proofs, which happens only after these have been added to L1. This is accomplished using a subcomponent called the Synchronizer. A Synchronizer is in charge of getting all the data from smart contracts, which includes the data posted by the sequencers (transactions) and the data posted by the coordinators (which is the validity proof). All this data is stored in a huge database and served to third parties through a service called \"JSON-RPC\". The Synchronizer is responsible for reading the events from the Ethereum blockchain, including new batches to keep the state fully synced. The information read from these events must be stored in the database. The Synchronizer also handles possible reorgs, which will be detected by checking if the last ethBlockNum and the last ethBlockHash are synced. Figure 3: zkEVM zkNode Diagram The architecture of zkNode is modular and implements a set of functions as depicted in Figure 3 above. RPC : RPC (Remote Procedure Call) is a JSON RPC interface compatible with Ethereum. For a software application to interact with the Ethereum blockchain (by reading blockchain data and/or sending transactions to the network), it must connect to an Ethereum node. RPC enables integration of the zkEVM with existing tools, such as Metamask, Etherscan and Infura. It adds transactions to the Pool and interacts with the State using read-only methods. State : A subcomponent that implements the Merkle Tree and connects to the DB backend. It checks integrity at the block level (information related to gas and block size, among others) and some transaction-related information (signatures, sufficient balance). State also stores smart contract code into the Merkle tree and processes transactions using the EVM. zkProver : All the rules for a transaction to be valid are implemented and enforced in the zkProver. A zkProver performs complex mathematical computations in the form of polynomials and assembly language; these are then verified on a smart contract. Those rules could be seen as constraints that a transaction must accomplish in order to be able to modify the state tree or the exit tree. The zkProver is the most complex module; it required developing two new programming languages to implement the needed elements. Read below to know more about zkProver.","title":"zkNode Architecture"},{"location":"#zkprover","text":"zkEVM employs advanced zero-knowledge technology to create validity proofs. It uses a zero-knowledge prover (zkProver), which is intended to run on any server and is being engineered to be compatible with most consumer hardware. Every Aggregator will use this zkProver to validate batches and provide validity proofs. zkProver has its own detailed architecture which is outlined below. It consists of a Main State Machine Executor, a collection of secondary State Machines (each with its own executor), a STARK-proof builder, and a SNARK-proof builder. See Figure 4 below for a simplified diagram of the zkEVM zkProver: Figure 4: A Simplified zkProver Diagram In a nutshell, the zkEVM expresses state changes in a polynomial form. Therefore, the constraints that each proposed batch must satisfy are, in fact, polynomial constraints or polynomial identities. That is, all the valid batches must satisfy certain polynomial constraints.","title":"zkProver"},{"location":"#zkprover-architecture","text":"The zkNode Architecture is composed of: Main State Machine Executor : The Main Executor handles the execution of the zkEVM. This is where EVM Bytecodes are interpreted using a new zero-knowledge Assembly language (or zkASM), specially developed by the team. The executor also sets up the polynomial constraints that every valid batch of transactions must satisfy. Another language, specially developed by the team, called Polynomial Identity Language (or PIL), is used to encode all the polynomial constraints. Secondary State Machines : Every computation required in proving the correctness of transactions is represented in the zkEVM as a state machine. The zkProver, being the most complex part of the whole project, consists of several state machines; from those carrying out bitwise functionalities (e.g., XORing, padding, etc.) to those performing hashing (e.g., Keccak, Poseidon), even to verifying signatures (e.g., ECDSA). The collection of the secondary state machines, therefore, refers to a collection of all state machines in the zkProver. It is not a subcomponent per se, but a collection of various executors for individual secondary state machines. The set of state machines are: Binary SM Memory SM Storage SM Poseidon SM Keccak SM Arithmetic SM See Figure 5 below for dependencies among these SMs. While some SMs use both zkASM and PIL, others rely only on one of these languages depending upon the specific operations each SM is responsible for. Figure 5: zkEVM State Machines STARK Proof Builder : STARK, which stands for \"Scalable Transparent Argument of Knowledge\", is a proof system that enables provers to produce verifiable proofs without the need for a trusted setup. A STARK Proof Builder refers to the subcomponent used to produce zero-knowledge STARK proofs, which are zk-proofs attesting to the fact that all the polynomial constraints are satisfied. State machines generate polynomial constraints and zk-STARKs are used to prove that batches satisfy these constraints. In particular, zkProver utilises \"Fast Reed-Solomon Interactive Oracle Proofs of Proximity (RS-IOPP)\", colloquially called FRI , to facilitate fast zk-STARK proving. SNARK Proof Builder : SNARK, which stands for \"Succinct Non-interactive Argument of Knowledge\", is a proof system that produces verifiable proofs. Since STARK proofs are bigger than the SNARK proofs, zkEVM zkProver uses SNARK proofs to prove the correctness of these STARK proofs. Consequently, the SNARK proofs, which are much cheaper to verify on L1, are published as validity proofs. The aim is to generate a CIRCOM circuit which can be used to generate or verify a SNARK proof. Whether a PLONK or a GROTH16 SNARK proof will be used for zkEVM is a question that needs to be discussed.","title":"zkProver Architecture"},{"location":"#the-lx-to-ly-bridge","text":"An LX-LY bridge is a smart contract that lets users transfer their assets between two layers, LX and LY. The L1-L2 in zkEVM is a decentralised bridge for secure deposits and withdrawal of assets; it is a combination of two smart contracts, one deployed on one chain and the second on the other. The L1 and L2 contracts in zkEVM are identical except for where each is deployed. Bridge L1 Contract is on the Ethereum mainnet in order to manage asset transfers between rollups, while Bridge L2 Contract is on a specific rollup and it is responsible for asset transfers between mainnet and the rollup (or rollups). Layer 2 Interoperability allows a native mechanism to migrate assets between different L2 networks. This solution is embedded in the bridge smart contract.","title":"The LX-to-LY Bridge"},{"location":"#bridge-l1-contract","text":"Bridge L1 Contract carries out two operations: bridge and claim . The bridge operation transfers assets from one rollup to another, while the claim operation applies when the contract makes a claim from any rollup. Bridge L1 Contract requires two Merkle trees in order to perform the above operations: globalExitTree and mainnet exit tree . The globalExitTree contains all the information of exit trees of all rollups, whereas the mainnet exit tree has information on transactions made by users who interact with the mainnet. A contract named the global exit root manager L1 is responsible for managing exit roots across multiple networks. The exit tree structure is depicted in Figure 6 below: Figure 6: The Exit Tree Structure","title":"Bridge L1 Contract"},{"location":"#bridge-l2-contract","text":"Bridge L2 Contract is deployed on Layer L2 with ether on it. The ether will be set on the genesis in order to enable the minting/burning of the native ether. Bridge L2 Contract also requires all the information of exit trees of all rollups contained in the globalExitTree Merkle tree. In this case, a smart contract named the global exit root manager L2 is responsible for managing the exit roots across multiple networks. Note: When a batch is verified in the PoE smart contract in L1, the rollup exit root is updated in the global exit root manager L1. Bridge L2 Contract handles the rollup side of the bridge and the claim operations, as well as interacting with the globalExitTree and the rollup exit tree , mainly to update exit roots.","title":"Bridge L2 Contract"},{"location":"#lx-to-ly-bridge","text":"Typically, a bridge smart contract is an L2-to-L1 Bridge, but the zkEVM Bridge is more flexible and interoperable. It can function as a bridge between any two arbitrary Layer 2 chains, L2_A and L2_B, or between any Layer 2 (say L2_X) and L1 (Ethereum blockchain). It consequently allows asset transfers among multiple rollups. Hence the term \"LX-to-LY Bridge\".","title":"LX-to-LY Bridge"},{"location":"#zkevm-design-characteristics","text":"The architectural details (for engineering and implementation) described in the sections above will help zkEVM attain its design goals. That would mean a network which is: permissionless, decentralized, secure, efficient and comes with verifiable block data. Development efforts aim at permissionless-ness , that is, allowing anyone with the zkEVM software to participate in the network. For instance, the consensus algorithm will give everyone the opportunity to be a Sequencer or an Aggregator. Data availability is most crucial for decentralization , where every user has sufficient data needed to rebuild the full state of a rollup. As discussed above, the team still has to decide on the best configuration for data availability. The aim is to ensure that there is no censorship and that no one party can control the network. zkEVM was designed with security in mind. As an L2 solution, most of the security is inherited from Ethereum. Smart contracts will warrant that anyone who executes state changes must, firstly, do it correctly; secondly, create a proof that attests to the validity of a state change; and thirdly, avail validity proofs on-chain for verification.","title":"zkEVM Design Characteristics"},{"location":"#efficiency-and-overall-strategy","text":"Efficiency is key to network performance. zkEVM, therefore, applies several implementation strategies to guarantee efficiency. A few of them are listed below: The first strategy is to deploy PoE, which incentivizes the most efficient aggregators to participate in the proof generation process. The second strategy is to carry out all computations off-chain while keeping only the necessary data and zk-proofs on-chain. There are other strategies too that are implemented within specific components of the zkEVM system. For instance: The way in which the bridge smart contract is implemented, such as settling accounts in a UTXO manner, by only using the Exit Tree Roots. Utilisation of specialised cryptographic primitives within the zkProver in order to speed up computations and minimise proof sizes, as seen in: (a) Running a special zero-knowledge Assembly language (zkASM) for interpretation of byte codes (b) Using zero-knowledge tools such as zk-STARKs for proving purposes; these proofs are very fast though they are bigger in size. See . So, instead of publishing the sizeable zk-STARK proofs as validity proofs, a zk-SNARK is used to attest to the correctness of the zk-STARK proofs. These zk-SNARKs are, in turn, published as the validity proofs to state changes. This helps in reducing the gas costs from 5M to 350K.","title":"Efficiency and Overall Strategy"},{"location":"#conclusion","text":"Given the EVM opcode compatibility, zkEVM is designed to process smart contracts seamlessly and verify state changes efficiently. It promises not only to be secure and efficient but also to accomplish competitive decentralization. In an effort to achieve high-speed proving and succinct proofs for quick verification, the team is focused on the optimization of the zkProver. The team also leverages the synergies among the different Polygon teams that are also looking into zk-rollup solutions for achieving Ethereum scalability. Although development is still underway, it was important for this document to be released early so as to align with the goal of transparency set by the open-source projects, as well as keep the Polygon community of developers and users of Polygon Hermez 1.0 updated with the upcoming changes. Our next step will be to develop a public testnet. Although it is difficult to set a fixed date for the same, our plan is to launch it by mid-2022.","title":"Conclusion"},{"location":"Hermez_1.0/about/faq/","text":"FAQ TODO","title":"FAQ"},{"location":"Hermez_1.0/about/faq/#faq","text":"TODO","title":"FAQ"},{"location":"Hermez_1.0/about/model/","text":"Hermez Network Model Hermez Protocol Hermez provides the decentralized components in the form of smart contracts and open source tools (SDK, Block Explorer, Wallet,...) to enable a new ecosystem of actors to participate in the network. Hermez Network interacts with the rest of the ecosystem either via smart contracts or via a standardized REST API exported by all operative coordinators. Coordinators Coordinators are Hermez Network's version of block producers. This means they are the ones who effectively run the network by computing the zero-knowledge proof of validity of the transactions made by the users. Coordinators use systems infrastructure to: * Synchronize with the Hermez Network fetching data (historical and updates) from layer 1 * Receive transaction requests from users * Process transaction requests in order to build rollup batches * Save the Merkle root together with a ZK-proof of correctness and the data necessary to reconstruct the full Merkle tree on Ethereum. The boot coordinator is a special seed coordinator which will be assigned to create batches of transactions by default, until an alternative permissionless operator will place a bid in an attempt to obtain the right to run the network in a future slot of time. Auction Multiple coordinators can coexist in the network running Hermez nodes. They will compete in a continuous decentralized auction process managed by smart contract for the right to build rollup batches and collect the fees associated with each user transaction. The right to forge is structured in time slots, which are defined to be 10 minutes long. The winning bid is the one with the highest amount of HEZ, an ERC-20 utility token whose value is not pre-determined or pegged to a reference asset. All bids will be processed by the auction smart contract , and all of the HEZ tokens placed will be used as follows: 30% will be burned (permanently removed). 40% will be automatically and permanently transferred to a donations account controlled by the Ethereum Foundation. These donations will be initially sent to Gitcoin quadratic funding grants but with the future-proof ability to donate also to other quadratic funding matching pools as they become available; 30% will be allocated as Hermez Network usage incentives, compensating active engagement and network adoption, e.g. rewarding transaction and rewarding the holding of specific tokens in Hermez L2 addresses, instead of on L1 Ethereum addresses. The auction process incentivises efficiency, as coordinators need to include as many transactions as possible in each time slot to compensate for their bidding costs and operative expenses. To prevent bidders from buying up all the slots in one go, nobody will be able to bid on a specific slot more than one month in advance. And the auction will be closed two time slots before the time of creating the slot. The auction will be structured in a series of six time slots to cover one hour (%0-5), with 10 HEZ as the initial minimal bidding price for all of them. The first bid in each time slot must be over the minimum bidding price in order to be accepted as valid. Thereafter, any bid placed in the auction should outbid the previous bid by at least 10%. The minimum bidding amount for each slot in an auction series will be decided by the network governance (see section \"Hermez Governance\"), and it will be possible to change it dynamically, affecting future, even already open, auctions. Also, governance will be able to implement the effective decentralisation of the network by locking the price of specific slots of the auction to 0 HEZ and therefore wouldn't require any minimum bid, this being an irreversible configuration. Users Network users will be provided with easy-to-use interfaces to register their L1 Ethereum addresses as Hermez L2 accounts. They will then be able to deposit and withdraw their funds, ETH or ERC-20 tokens, into or out of these L2 accounts. Initially, users will access the Hermez Network through an interface based on a non-custodial individually owned wallet solution that relies on Metamask for the management of private keys. Through this interface, users will be able to: Register their Ethereum L1 address into the Hermez Network and obtain an internal address - one for each type of token they wish to deposit; Deposit L1 tokens into their Hermez Network addresses with a simple transaction; Transfer tokens between Hermez addresses much faster and for very low fees; Withdraw tokens from Hermez Network addresses back to their chosen L1 addresses. Hermez provides protection mechanisms (enforced in the smart contract) that guarantee all tokens locked in the L2 solution can always be recovered by the users, even in the unlikely event that the auction-winning coordinator is malicious \u2014 in other words, stealing, censoring or blocking transactions is impossible. The Hermez Network does not provide in any way custodial or exchange services. Hermez only and exclusively provides a L2 scaling solution for faster, low fee Ethereum tokens transfers. Third-Party Volume Aggregators Third-Party Exchanges and other volume aggregators will use an SDK to connect to the network to access L1 smart contracts and coordinator REST API endpoints and thus exploit Hermez's full potential. Hermez will provide an interesting feature of atomic transactions, which implements a link between transactions that need to be executed together, and it's very useful for token swaps.","title":"Polygon Hermez Network Model"},{"location":"Hermez_1.0/about/model/#hermez-network-model","text":"","title":"Hermez Network Model"},{"location":"Hermez_1.0/about/model/#hermez-protocol","text":"Hermez provides the decentralized components in the form of smart contracts and open source tools (SDK, Block Explorer, Wallet,...) to enable a new ecosystem of actors to participate in the network. Hermez Network interacts with the rest of the ecosystem either via smart contracts or via a standardized REST API exported by all operative coordinators.","title":"Hermez Protocol"},{"location":"Hermez_1.0/about/model/#coordinators","text":"Coordinators are Hermez Network's version of block producers. This means they are the ones who effectively run the network by computing the zero-knowledge proof of validity of the transactions made by the users. Coordinators use systems infrastructure to: * Synchronize with the Hermez Network fetching data (historical and updates) from layer 1 * Receive transaction requests from users * Process transaction requests in order to build rollup batches * Save the Merkle root together with a ZK-proof of correctness and the data necessary to reconstruct the full Merkle tree on Ethereum. The boot coordinator is a special seed coordinator which will be assigned to create batches of transactions by default, until an alternative permissionless operator will place a bid in an attempt to obtain the right to run the network in a future slot of time.","title":"Coordinators"},{"location":"Hermez_1.0/about/model/#auction","text":"Multiple coordinators can coexist in the network running Hermez nodes. They will compete in a continuous decentralized auction process managed by smart contract for the right to build rollup batches and collect the fees associated with each user transaction. The right to forge is structured in time slots, which are defined to be 10 minutes long. The winning bid is the one with the highest amount of HEZ, an ERC-20 utility token whose value is not pre-determined or pegged to a reference asset. All bids will be processed by the auction smart contract , and all of the HEZ tokens placed will be used as follows: 30% will be burned (permanently removed). 40% will be automatically and permanently transferred to a donations account controlled by the Ethereum Foundation. These donations will be initially sent to Gitcoin quadratic funding grants but with the future-proof ability to donate also to other quadratic funding matching pools as they become available; 30% will be allocated as Hermez Network usage incentives, compensating active engagement and network adoption, e.g. rewarding transaction and rewarding the holding of specific tokens in Hermez L2 addresses, instead of on L1 Ethereum addresses. The auction process incentivises efficiency, as coordinators need to include as many transactions as possible in each time slot to compensate for their bidding costs and operative expenses. To prevent bidders from buying up all the slots in one go, nobody will be able to bid on a specific slot more than one month in advance. And the auction will be closed two time slots before the time of creating the slot. The auction will be structured in a series of six time slots to cover one hour (%0-5), with 10 HEZ as the initial minimal bidding price for all of them. The first bid in each time slot must be over the minimum bidding price in order to be accepted as valid. Thereafter, any bid placed in the auction should outbid the previous bid by at least 10%. The minimum bidding amount for each slot in an auction series will be decided by the network governance (see section \"Hermez Governance\"), and it will be possible to change it dynamically, affecting future, even already open, auctions. Also, governance will be able to implement the effective decentralisation of the network by locking the price of specific slots of the auction to 0 HEZ and therefore wouldn't require any minimum bid, this being an irreversible configuration.","title":"Auction"},{"location":"Hermez_1.0/about/model/#users","text":"Network users will be provided with easy-to-use interfaces to register their L1 Ethereum addresses as Hermez L2 accounts. They will then be able to deposit and withdraw their funds, ETH or ERC-20 tokens, into or out of these L2 accounts. Initially, users will access the Hermez Network through an interface based on a non-custodial individually owned wallet solution that relies on Metamask for the management of private keys. Through this interface, users will be able to: Register their Ethereum L1 address into the Hermez Network and obtain an internal address - one for each type of token they wish to deposit; Deposit L1 tokens into their Hermez Network addresses with a simple transaction; Transfer tokens between Hermez addresses much faster and for very low fees; Withdraw tokens from Hermez Network addresses back to their chosen L1 addresses. Hermez provides protection mechanisms (enforced in the smart contract) that guarantee all tokens locked in the L2 solution can always be recovered by the users, even in the unlikely event that the auction-winning coordinator is malicious \u2014 in other words, stealing, censoring or blocking transactions is impossible. The Hermez Network does not provide in any way custodial or exchange services. Hermez only and exclusively provides a L2 scaling solution for faster, low fee Ethereum tokens transfers.","title":"Users"},{"location":"Hermez_1.0/about/model/#third-party-volume-aggregators","text":"Third-Party Exchanges and other volume aggregators will use an SDK to connect to the network to access L1 smart contracts and coordinator REST API endpoints and thus exploit Hermez's full potential. Hermez will provide an interesting feature of atomic transactions, which implements a link between transactions that need to be executed together, and it's very useful for token swaps.","title":"Third-Party Volume Aggregators"},{"location":"Hermez_1.0/about/scalability/","text":"Ethereum Scalability and ZK-Rollups Background During the last year, it has become clear that rollups will be the dominant scaling paradigm on the Ethereum public blockchain: with this in mind, Iden3 has developed and recently launched Hermez, a ZK-Rollup focused on scaling payments and token transfers on Ethereum. Why the focus on transfers? It turns out that more than 50% of transactions on the Ethereum network are transfers, and a large percent of these are deposits and withdrawals from exchanges. Demand could be reduced by a significant amount if exchanges started using rollups, or (in the ideal case) even agreed to meet on the same rollup. In addition to significantly reducing transaction costs for users, this could have the added benefit of greatly reducing gas prices, and freeing up the base chain for more complex contracts. Zero-Knowledge Rollups A ZK-Rollup, such as Hermez, is a layer 2 construction which uses the Ethereum blockchain for data storage instead of computation: - All funds are held by a smart contract on the main-chain. For every batch of transactions, a ZK-SNARK cryptographic proof is generated off-chain. This ZK-SNARK proves the validity of every transaction in the batch which means it is not necessary to rely on the Ethereum main-chain to verify each signature transaction. The significance of this is that it allows verification to be carried out in constant time regardless of the number of transactions. This ability to verify proofs both efficiently and in constant time is at the heart of all ZK-Rollups . In addition to this, all transaction data is published cheaply on-chain, without signatures \u2014 under call data. Since the data is published on-chain, there are no data availability problems that have plagued other L2 solutions such as Plasma. Anyone can reconstruct the current state and history from this on-chain data. This prevents censorship and avoids the centralization of coordinators (rollup batch producers) \u2014 since anyone can build the state tree from scratch (and therefore become a coordinator). Why the Need for ZK-Rollups? Trust-minimised blockchain scaling mechanisms are sorely needed if blockchain applications are ever to achieve mass adoption. For context, the Ethereum network can handle approximately 15 transactions per second (tps), while the Visa network averages around 2,000 tps. This limitation in throughput directly affects the price paid for each transaction and constraints its adoption. As outlined in an earlier Iden3 post , ZK-Rollups have the potential to increase the Ethereum network\u2019s maximum tps by two orders of magnitude, making it comparable to the Visa network\u2019s average. How is 2000 tps Possible? Blockchain scalability is improved by compressing each transaction to ~10 bytes: instead of including signatures on-chain, we send a ZK-SNARK which proves that 1000\u2019s of signature verifications and other transaction validation checks have been correctly carried out off-chain. Since signatures make up a large percentage of transaction costs (gas), in practice ZK-Rollups have the effect of significantly reducing the average cost per transaction. This allows Hermez to fit more transactions per batch, which results in a greater overall throughput. Bytes breakdown: vanilla Eth transaction (109+ bytes) vs ZK-Rollup transaction (8 bytes)","title":"Ethereum Scalability and zk-Rollups"},{"location":"Hermez_1.0/about/scalability/#ethereum-scalability-and-zk-rollups","text":"","title":"Ethereum Scalability and ZK-Rollups"},{"location":"Hermez_1.0/about/scalability/#background","text":"During the last year, it has become clear that rollups will be the dominant scaling paradigm on the Ethereum public blockchain: with this in mind, Iden3 has developed and recently launched Hermez, a ZK-Rollup focused on scaling payments and token transfers on Ethereum. Why the focus on transfers? It turns out that more than 50% of transactions on the Ethereum network are transfers, and a large percent of these are deposits and withdrawals from exchanges. Demand could be reduced by a significant amount if exchanges started using rollups, or (in the ideal case) even agreed to meet on the same rollup. In addition to significantly reducing transaction costs for users, this could have the added benefit of greatly reducing gas prices, and freeing up the base chain for more complex contracts.","title":"Background"},{"location":"Hermez_1.0/about/scalability/#zero-knowledge-rollups","text":"A ZK-Rollup, such as Hermez, is a layer 2 construction which uses the Ethereum blockchain for data storage instead of computation: - All funds are held by a smart contract on the main-chain. For every batch of transactions, a ZK-SNARK cryptographic proof is generated off-chain. This ZK-SNARK proves the validity of every transaction in the batch which means it is not necessary to rely on the Ethereum main-chain to verify each signature transaction. The significance of this is that it allows verification to be carried out in constant time regardless of the number of transactions. This ability to verify proofs both efficiently and in constant time is at the heart of all ZK-Rollups . In addition to this, all transaction data is published cheaply on-chain, without signatures \u2014 under call data. Since the data is published on-chain, there are no data availability problems that have plagued other L2 solutions such as Plasma. Anyone can reconstruct the current state and history from this on-chain data. This prevents censorship and avoids the centralization of coordinators (rollup batch producers) \u2014 since anyone can build the state tree from scratch (and therefore become a coordinator).","title":"Zero-Knowledge Rollups"},{"location":"Hermez_1.0/about/scalability/#why-the-need-for-zk-rollups","text":"Trust-minimised blockchain scaling mechanisms are sorely needed if blockchain applications are ever to achieve mass adoption. For context, the Ethereum network can handle approximately 15 transactions per second (tps), while the Visa network averages around 2,000 tps. This limitation in throughput directly affects the price paid for each transaction and constraints its adoption. As outlined in an earlier Iden3 post , ZK-Rollups have the potential to increase the Ethereum network\u2019s maximum tps by two orders of magnitude, making it comparable to the Visa network\u2019s average.","title":"Why the Need for ZK-Rollups?"},{"location":"Hermez_1.0/about/scalability/#how-is-2000-tps-possible","text":"Blockchain scalability is improved by compressing each transaction to ~10 bytes: instead of including signatures on-chain, we send a ZK-SNARK which proves that 1000\u2019s of signature verifications and other transaction validation checks have been correctly carried out off-chain. Since signatures make up a large percentage of transaction costs (gas), in practice ZK-Rollups have the effect of significantly reducing the average cost per transaction. This allows Hermez to fit more transactions per batch, which results in a greater overall throughput. Bytes breakdown: vanilla Eth transaction (109+ bytes) vs ZK-Rollup transaction (8 bytes)","title":"How is 2000 tps Possible?"},{"location":"Hermez_1.0/about/security/","text":"Security Hermez relies on certain assumptions that guarantee users can always recover their assets deposited on the network. These assumptions are based on several design and architectural decisions that we will review here. Hermez is a Layer2 solution running on top of Ethereum 1.0. This means that the security of Hermez depends on the security assumptions and guarantees provided by Ethereum. In addition, Hermez is a ZK-Rollup protocol: on top of Ethereum blockchain, Hermez adds another layer of security borrowed from Zcash. Following their work, Hermez integrates a ZK-SNARK prover/verifier module to validate in constant time the execution of a series of transactions. These ZK-SNARKs make use of certain cryptographic primitives such as hashes and signatures that make further security assumptions as it will be reviewed later. Finally, Hermez embeds operating rules in different smart contracts to guarantee that user's transactions cannot be blocked by operators and can withdraw their assets at all times. As a summary, Hermez makes the following security assumptions: 1. Security assumptions of Ethereum. 2. Groth16 assumptions (knowledge of exponent assumption). 3. Certain cryptographic assumptions from primitives such as signatures and hashes 4. Software security assumptions that rely on correct design and implementation. Ethereum Hermez runs on top of Ethereum. All Hermez data is available on Ethereum and borrows layer 1 security too. ZK-Proofs User transactions are always verified by an Ethereum smart contract by verifying the ZK-Proof supplied by the coordinator. The specific ZK-SNARK that is used in these ZK-Proofs is Groth16 . This protocol has been widely used and tested by the Zcash team of researchers and it is currently considered mature enough to be used in production. At this time, Ethereum precompiled smart contracts only support BN254 elliptic curve operations for zk-SNARK proofs validation. For this reason, Hermez uses this curve for generating and validating proofs and Baby Jubjub here and here for implementing elliptic curve cryptography inside circuits. In place of BN254, which offers 100 bits of security, Zcash uses BLS12-381 , with 128 bits of security see here . Hermez will likely migrate to [ BLS12-381 ] curve as soon as it is available for Ethereum. Among other benefits, BLS12-381 provides 128 bits of security instead of the 100 bits provided by BN256. The EIP that implements BLS12-381 curve was already approved and the migration is very likely to happen by the next planned Berlin Hard Fork. This change will improve the security level. At this point Baby Jubjub will be substituted by Jubjub curve . Baby Jubjub curve satisfies security standards as shown here and here . Multi-party Computation for the Trusted Setup The proving and verification keys of the ZK-SNARK protocol require the generation of some random values that need to be eliminated. This elimination process is a crucial step: if these values are ever exposed, the security of the whole scheme is compromised. To construct the setting, Hermez uses a Multi-party computation (MPC) ceremony that allows multiple independent parties to collaboratively construct the parameters or trusted setup. With MPC, it is enough that one single participant deletes its secret counterpart of the contribution in order to keep the whole scheme secure. The construction of the trusted setup has two phases: 1. General MPC ceremony that is valid for any circuit (also known as Powers of Tau ceremony) 2. Phase 2 that is constructed for each specific circuit. Anyone can contribute with their randomness to the MPC ceremonies and typically, before getting the final parameters, a random beacon is applied. To contribute to the robustness of the setup, Hermez implemented an independent snarkjs module for computing and validating the MPC ceremonies. The software is compatible with current Powers of Tau , and it allows one to see the list of contributions of a given setup, to import a response, export a challenge of the ceremony, or to verify if the whole process has been correctly computed. Hermez\u2019 contribution can be found here ). Cryptography Hermez makes use of two main cryptographic primitives inside circuits: a signature and a hash function. 1. The signature schema is the Edwards Digital Signature Algorithm (EdDSA) on Baby Jubjub (after the migration, it will use EdDSA on Jubjub). This protocol was implemented making use of the circuit language circom and following the circuit design of Zcash. 2. The hash function used is Poseidon , a similar hash to MiMC but with a mixing layer. These hash functions have been used in projects such as TornadoCash (MiMC) and Semaphore (Poseidon) Assumptions made on Poseidon hash function include that it is collision and preimage resistant. Design Hermez attempts to decentralize the role of coordinators while simultaneously enforcing some rules or guidelines on the coordinators to ensure user transactions cannot be blocked. Some of these features are: Coordinators are required to process L1 user transactions periodically as established in the smart contract. Since L1 transactions are concatenated together, a coordinator must process all pending L1 transactions, thus preventing it from blocking specific users or L1 operations. Note that withdrawal of funds is a L1 transaction so it cannot be blocked by a coordinator. If a coordinator doesn't process (or forge) transactions during its allotted time, any online coordinator can forge transactions. This mechanism is known as Coordinator override. HermezDAO foundation controls a last resort coordinator called Boot coordinator. If there are no coordinators available to forge any batches, the boot coordinator will forge transactions. The HermezDAO foundation is a non-profit organization created for the maintenance and operation of the Hermez Network, registered under BVI 2043757 in Wickhams Cay II, Road Town, Tortola, VG1110, British Virgin Islands. Bidding process format allows the governance to set different minimum bidding prices to different sots to increase the chances that transactions are forged by Boot coordinator. Security Audits Smart contracts and circuits designed for ZK-proof system are being audited by different entities. The results will be published here as soon as they are available. Results from the first audit performed by Solidified can be found here Results from the second audit performed by Trail of Bits can be found here","title":"Security"},{"location":"Hermez_1.0/about/security/#security","text":"Hermez relies on certain assumptions that guarantee users can always recover their assets deposited on the network. These assumptions are based on several design and architectural decisions that we will review here. Hermez is a Layer2 solution running on top of Ethereum 1.0. This means that the security of Hermez depends on the security assumptions and guarantees provided by Ethereum. In addition, Hermez is a ZK-Rollup protocol: on top of Ethereum blockchain, Hermez adds another layer of security borrowed from Zcash. Following their work, Hermez integrates a ZK-SNARK prover/verifier module to validate in constant time the execution of a series of transactions. These ZK-SNARKs make use of certain cryptographic primitives such as hashes and signatures that make further security assumptions as it will be reviewed later. Finally, Hermez embeds operating rules in different smart contracts to guarantee that user's transactions cannot be blocked by operators and can withdraw their assets at all times. As a summary, Hermez makes the following security assumptions: 1. Security assumptions of Ethereum. 2. Groth16 assumptions (knowledge of exponent assumption). 3. Certain cryptographic assumptions from primitives such as signatures and hashes 4. Software security assumptions that rely on correct design and implementation.","title":"Security"},{"location":"Hermez_1.0/about/security/#ethereum","text":"Hermez runs on top of Ethereum. All Hermez data is available on Ethereum and borrows layer 1 security too.","title":"Ethereum"},{"location":"Hermez_1.0/about/security/#zk-proofs","text":"User transactions are always verified by an Ethereum smart contract by verifying the ZK-Proof supplied by the coordinator. The specific ZK-SNARK that is used in these ZK-Proofs is Groth16 . This protocol has been widely used and tested by the Zcash team of researchers and it is currently considered mature enough to be used in production. At this time, Ethereum precompiled smart contracts only support BN254 elliptic curve operations for zk-SNARK proofs validation. For this reason, Hermez uses this curve for generating and validating proofs and Baby Jubjub here and here for implementing elliptic curve cryptography inside circuits. In place of BN254, which offers 100 bits of security, Zcash uses BLS12-381 , with 128 bits of security see here . Hermez will likely migrate to [ BLS12-381 ] curve as soon as it is available for Ethereum. Among other benefits, BLS12-381 provides 128 bits of security instead of the 100 bits provided by BN256. The EIP that implements BLS12-381 curve was already approved and the migration is very likely to happen by the next planned Berlin Hard Fork. This change will improve the security level. At this point Baby Jubjub will be substituted by Jubjub curve . Baby Jubjub curve satisfies security standards as shown here and here .","title":"ZK-Proofs"},{"location":"Hermez_1.0/about/security/#multi-party-computation-for-the-trusted-setup","text":"The proving and verification keys of the ZK-SNARK protocol require the generation of some random values that need to be eliminated. This elimination process is a crucial step: if these values are ever exposed, the security of the whole scheme is compromised. To construct the setting, Hermez uses a Multi-party computation (MPC) ceremony that allows multiple independent parties to collaboratively construct the parameters or trusted setup. With MPC, it is enough that one single participant deletes its secret counterpart of the contribution in order to keep the whole scheme secure. The construction of the trusted setup has two phases: 1. General MPC ceremony that is valid for any circuit (also known as Powers of Tau ceremony) 2. Phase 2 that is constructed for each specific circuit. Anyone can contribute with their randomness to the MPC ceremonies and typically, before getting the final parameters, a random beacon is applied. To contribute to the robustness of the setup, Hermez implemented an independent snarkjs module for computing and validating the MPC ceremonies. The software is compatible with current Powers of Tau , and it allows one to see the list of contributions of a given setup, to import a response, export a challenge of the ceremony, or to verify if the whole process has been correctly computed. Hermez\u2019 contribution can be found here ).","title":"Multi-party Computation for the Trusted Setup"},{"location":"Hermez_1.0/about/security/#cryptography","text":"Hermez makes use of two main cryptographic primitives inside circuits: a signature and a hash function. 1. The signature schema is the Edwards Digital Signature Algorithm (EdDSA) on Baby Jubjub (after the migration, it will use EdDSA on Jubjub). This protocol was implemented making use of the circuit language circom and following the circuit design of Zcash. 2. The hash function used is Poseidon , a similar hash to MiMC but with a mixing layer. These hash functions have been used in projects such as TornadoCash (MiMC) and Semaphore (Poseidon) Assumptions made on Poseidon hash function include that it is collision and preimage resistant.","title":"Cryptography"},{"location":"Hermez_1.0/about/security/#design","text":"Hermez attempts to decentralize the role of coordinators while simultaneously enforcing some rules or guidelines on the coordinators to ensure user transactions cannot be blocked. Some of these features are: Coordinators are required to process L1 user transactions periodically as established in the smart contract. Since L1 transactions are concatenated together, a coordinator must process all pending L1 transactions, thus preventing it from blocking specific users or L1 operations. Note that withdrawal of funds is a L1 transaction so it cannot be blocked by a coordinator. If a coordinator doesn't process (or forge) transactions during its allotted time, any online coordinator can forge transactions. This mechanism is known as Coordinator override. HermezDAO foundation controls a last resort coordinator called Boot coordinator. If there are no coordinators available to forge any batches, the boot coordinator will forge transactions. The HermezDAO foundation is a non-profit organization created for the maintenance and operation of the Hermez Network, registered under BVI 2043757 in Wickhams Cay II, Road Town, Tortola, VG1110, British Virgin Islands. Bidding process format allows the governance to set different minimum bidding prices to different sots to increase the chances that transactions are forged by Boot coordinator.","title":"Design"},{"location":"Hermez_1.0/about/security/#security-audits","text":"Smart contracts and circuits designed for ZK-proof system are being audited by different entities. The results will be published here as soon as they are available. Results from the first audit performed by Solidified can be found here Results from the second audit performed by Trail of Bits can be found here","title":"Security Audits"},{"location":"Hermez_1.0/about/value-proposition/","text":"Hermez Value Proposition Hermez network project has some properties that will provide value to the users and the community: Production Ready Solution Hermez will launch in mainnet a project which is intended to be a usable token transfers network from day one. This product will have support, maintenance, and technological evolution to provide users with the most updated functionalities with the right risk management. The first release starts with the specific scope of token transfers implemented with a technological stack and cryptography setup considered the most tested so far. Decentralized Hermez is called a network because the model is natively decentralized. It is a layer 2 construction and intends to transact at thousands per second, so the consensus algorithm has to be simple for one agent (coordinator) to process this amount of transactions at any given time. With this model, it still keeps the properties of being permissionless to participate and censorship resistant for user transactions. Efficient The decentralized model is implemented through a permissionless auction system for potential coordinators of the network to earn the right to process transactions during a slot of time. This auction model incentivises the efficiency of coordinators since they need to process as many transactions as they can to collect the fees and compensate their investment and their operation expenses (and make money out of it). Hermez implements a ZK-Rollup based on ZK-SNARK proofs, the most efficient in terms of batch cost in Ethereum. Since the batches of transactions are a maximum of 2,000 in size, users will benefit from the scale and the underlying technology for nominal maximum savings up to 97% compared to the Ethereum cost for a single token transfer. Security in Mind Scalability can be achieved in different ways. Hermez is a layer 2 construction because it leverages Ethereum not only by using its native tokens but by also borrowing Ethereum's security as a strong public blockchain. The implementation of Hermez is based on iden3's own technology (Circom and SnarkJS libraries) and the cryptographic technology which has been proven as the most robust so far, as used in the ZCash blockchain. As a new network with a bootstrap period, Hermez has transitory security measures to protect the system with the objective to remove them and leave it fully decentralized. Part of the Community Hermez is designed to contribute to the community, since the project wouldn\u2019t be possible without it. Innovations in scalability are a rare opportunity to realign incentives around the community and the public goods they provide. 40% of the generated value in the network will be sent to a donation process where the ecosystem projects will benefit from the donations. It will start with Gitcoin but other pools might be enabled in the future. Hermez will open source all the protocol and coordinator code, is open to contributions, and has committed to contribute to the creation of a L2 ecosystem for initiatives such as a better L2 interoperability . Focused on Usability ZK-Rollups provide the technology for instant finality of transactions, which Hermez understands is a key feature for usability. Hermez Protocol also provides a guarantee that user transactions can not be censored and that all funds can always be sent back to layer 1. Layer 2 solutions increase complexity for the users, but the Hermez project focus is to provide the best possible usability for user onboarding, transactions and reduce friction and confusion between layers. With a Vision Hermez project derives from the iden3 initiative, where a highly qualified team work to implement the vision of a universal and private by default self-sovereign identity. Scalability was required for the identity protocol to be universal and individuals could issue claims on other identities for (almost) free. Symbiotically, Hermez Network is expected to benefit from the advancements in identity infrastructure such as validation, private credentials and reputation for improved usability and extend the range of potential use cases of a high throughput transaction network. Hermez will guide its efforts in becoming an infrastructure which can serve the maximum number of users.","title":"Polygon Hermez Value Proposition"},{"location":"Hermez_1.0/about/value-proposition/#hermez-value-proposition","text":"Hermez network project has some properties that will provide value to the users and the community:","title":"Hermez Value Proposition"},{"location":"Hermez_1.0/about/value-proposition/#production-ready-solution","text":"Hermez will launch in mainnet a project which is intended to be a usable token transfers network from day one. This product will have support, maintenance, and technological evolution to provide users with the most updated functionalities with the right risk management. The first release starts with the specific scope of token transfers implemented with a technological stack and cryptography setup considered the most tested so far.","title":"Production Ready Solution"},{"location":"Hermez_1.0/about/value-proposition/#decentralized","text":"Hermez is called a network because the model is natively decentralized. It is a layer 2 construction and intends to transact at thousands per second, so the consensus algorithm has to be simple for one agent (coordinator) to process this amount of transactions at any given time. With this model, it still keeps the properties of being permissionless to participate and censorship resistant for user transactions.","title":"Decentralized"},{"location":"Hermez_1.0/about/value-proposition/#efficient","text":"The decentralized model is implemented through a permissionless auction system for potential coordinators of the network to earn the right to process transactions during a slot of time. This auction model incentivises the efficiency of coordinators since they need to process as many transactions as they can to collect the fees and compensate their investment and their operation expenses (and make money out of it). Hermez implements a ZK-Rollup based on ZK-SNARK proofs, the most efficient in terms of batch cost in Ethereum. Since the batches of transactions are a maximum of 2,000 in size, users will benefit from the scale and the underlying technology for nominal maximum savings up to 97% compared to the Ethereum cost for a single token transfer.","title":"Efficient"},{"location":"Hermez_1.0/about/value-proposition/#security-in-mind","text":"Scalability can be achieved in different ways. Hermez is a layer 2 construction because it leverages Ethereum not only by using its native tokens but by also borrowing Ethereum's security as a strong public blockchain. The implementation of Hermez is based on iden3's own technology (Circom and SnarkJS libraries) and the cryptographic technology which has been proven as the most robust so far, as used in the ZCash blockchain. As a new network with a bootstrap period, Hermez has transitory security measures to protect the system with the objective to remove them and leave it fully decentralized.","title":"Security in Mind"},{"location":"Hermez_1.0/about/value-proposition/#part-of-the-community","text":"Hermez is designed to contribute to the community, since the project wouldn\u2019t be possible without it. Innovations in scalability are a rare opportunity to realign incentives around the community and the public goods they provide. 40% of the generated value in the network will be sent to a donation process where the ecosystem projects will benefit from the donations. It will start with Gitcoin but other pools might be enabled in the future. Hermez will open source all the protocol and coordinator code, is open to contributions, and has committed to contribute to the creation of a L2 ecosystem for initiatives such as a better L2 interoperability .","title":"Part of the Community"},{"location":"Hermez_1.0/about/value-proposition/#focused-on-usability","text":"ZK-Rollups provide the technology for instant finality of transactions, which Hermez understands is a key feature for usability. Hermez Protocol also provides a guarantee that user transactions can not be censored and that all funds can always be sent back to layer 1. Layer 2 solutions increase complexity for the users, but the Hermez project focus is to provide the best possible usability for user onboarding, transactions and reduce friction and confusion between layers.","title":"Focused on Usability"},{"location":"Hermez_1.0/about/value-proposition/#with-a-vision","text":"Hermez project derives from the iden3 initiative, where a highly qualified team work to implement the vision of a universal and private by default self-sovereign identity. Scalability was required for the identity protocol to be universal and individuals could issue claims on other identities for (almost) free. Symbiotically, Hermez Network is expected to benefit from the advancements in identity infrastructure such as validation, private credentials and reputation for improved usability and extend the range of potential use cases of a high throughput transaction network. Hermez will guide its efforts in becoming an infrastructure which can serve the maximum number of users.","title":"With a Vision"},{"location":"Hermez_1.0/developers/api/","text":"REST API The API is the layer that allows 3rd party apps and services to interface with the coordinator to explore, monitor and use the Hermez rollup. Example of these apps include: * Wallet: send L2 transactions, check balance, ... * Explorer: List transactions, slots, batches, ... * Exchange integrations The documentation of the API can be found here Hermez Testnet API can be found here Hermez Mainnet API can be found here","title":"API"},{"location":"Hermez_1.0/developers/api/#rest-api","text":"The API is the layer that allows 3rd party apps and services to interface with the coordinator to explore, monitor and use the Hermez rollup. Example of these apps include: * Wallet: send L2 transactions, check balance, ... * Explorer: List transactions, slots, batches, ... * Exchange integrations The documentation of the API can be found here Hermez Testnet API can be found here Hermez Mainnet API can be found here","title":"REST API"},{"location":"Hermez_1.0/developers/batch-explorer/","text":"Batch Explorer What is Hermez Block Explorer Hermez Block Explorer, as the name suggests is a block explorer for the Hermez Network. It is a tool that allows anyone to search and lookup details about transactions, batches, coordinators, accounts or slots. It also provides basic information on the network performance. Batches By searching for a particular batch number, or simply navigating to one, user is able to see the details of a given batch. Among other information the page displays: * block hash * status of a batch * timestamp * collected fees * link to the coordinator in question * link to the given slot, and * a full list of transactions included in that batch Transactions By searching for a transaction id, or simply clicking on one of the transaction links users land on a page showing all important details of that transaction. Such as: * status of a batch * timestamp * transaction type * for an L1 transaction: * Exit * Transfer * Deposit * CreateAccountDeposit * CreateAccountDepositTransfer * DepositTransfer * ForceTransfer * ForceExit * TransferToEthAddr * TransferToBJJ * for an L2 transaction: * Exit * Transfer * TransferToEthAddr * TransferToBJJ * id of a batch that transaction is part of User address User address page is displaying basic information about the given Hermez Ethereum or BJJ address. That information includes the addresses themselves as well as a total number of token accounts. Apart from that, basic information for each token as well as each related transaction is listed in two separate views. Slots By navigating through a corresponding link, users land on the slot details page. Here are shown all relevant information for a slot, as: * slot status (whether the auction of the slot is open or not) * total number of bids * bids details (including coordinator and the bid amount) If a given slot auction is closed, the following information will be shown as well: * list of batches included in that slot (with some details about each batch) Coordinator By searching for the Ethereum address of an existing coordinator, or by navigating through the app the user lands on the page listing details of that coordinator. Those details include: * forger and withdrawal addresses * full list of forged batches * full list of winner bids (including slot, total bids and bid amount) Searching through Hermez Batch Explorer There are limited options available for search and navigation in the app itself. Those include: * Ethereum address * HEZ Ethereum address * BJJ address * Batch number * Id of a Transaction * Account index","title":"Batch Explorer"},{"location":"Hermez_1.0/developers/batch-explorer/#batch-explorer","text":"","title":"Batch Explorer"},{"location":"Hermez_1.0/developers/batch-explorer/#what-is-hermez-block-explorer","text":"Hermez Block Explorer, as the name suggests is a block explorer for the Hermez Network. It is a tool that allows anyone to search and lookup details about transactions, batches, coordinators, accounts or slots. It also provides basic information on the network performance.","title":"What is Hermez Block Explorer"},{"location":"Hermez_1.0/developers/batch-explorer/#batches","text":"By searching for a particular batch number, or simply navigating to one, user is able to see the details of a given batch. Among other information the page displays: * block hash * status of a batch * timestamp * collected fees * link to the coordinator in question * link to the given slot, and * a full list of transactions included in that batch","title":"Batches"},{"location":"Hermez_1.0/developers/batch-explorer/#transactions","text":"By searching for a transaction id, or simply clicking on one of the transaction links users land on a page showing all important details of that transaction. Such as: * status of a batch * timestamp * transaction type * for an L1 transaction: * Exit * Transfer * Deposit * CreateAccountDeposit * CreateAccountDepositTransfer * DepositTransfer * ForceTransfer * ForceExit * TransferToEthAddr * TransferToBJJ * for an L2 transaction: * Exit * Transfer * TransferToEthAddr * TransferToBJJ * id of a batch that transaction is part of","title":"Transactions"},{"location":"Hermez_1.0/developers/batch-explorer/#user-address","text":"User address page is displaying basic information about the given Hermez Ethereum or BJJ address. That information includes the addresses themselves as well as a total number of token accounts. Apart from that, basic information for each token as well as each related transaction is listed in two separate views.","title":"User address"},{"location":"Hermez_1.0/developers/batch-explorer/#slots","text":"By navigating through a corresponding link, users land on the slot details page. Here are shown all relevant information for a slot, as: * slot status (whether the auction of the slot is open or not) * total number of bids * bids details (including coordinator and the bid amount) If a given slot auction is closed, the following information will be shown as well: * list of batches included in that slot (with some details about each batch)","title":"Slots"},{"location":"Hermez_1.0/developers/batch-explorer/#coordinator","text":"By searching for the Ethereum address of an existing coordinator, or by navigating through the app the user lands on the page listing details of that coordinator. Those details include: * forger and withdrawal addresses * full list of forged batches * full list of winner bids (including slot, total bids and bid amount)","title":"Coordinator"},{"location":"Hermez_1.0/developers/batch-explorer/#searching-through-hermez-batch-explorer","text":"There are limited options available for search and navigation in the app itself. Those include: * Ethereum address * HEZ Ethereum address * BJJ address * Batch number * Id of a Transaction * Account index","title":"Searching through Hermez Batch Explorer"},{"location":"Hermez_1.0/developers/coordinator/","text":"Hermez Node This tutorial describes how to launch a Hermez node. It starts by explaining how to launch a Boot Coordinator in localhost. Next, it describes how to initialize a Proof Server and how to connect it to the Boot Coordinator. The next section describes how to spin up a second Hermez node in synchronizer mode to track the rollup status independently from the Boot Coordinator. This second node will be launched in Rinkeby testnet. The last part of the tutorial includes an explanation on how to add a second Coordinator node to Hermez testnet Rinkeby that bids for the right to forge batches. Preparing the Environment Launching the Boot Coordinator Launching a Proof Server Launching a Price Updater Launching a Synchronizer Node Launching a Second Coordinator Preparing the Environment Hermez node requires a PostgreSQL database and connectivity to an Ethereum node. In this part, we describe how you can set this environment up using docker containers. Dependencies golang 1.16+ golangci-lint packr utility to bundle the database migrations. Make sure your $PATH contains $GOPATH/bin , otherwise the packr utility will not be found. cd /tmp && go get -u github.com/gobuffalo/packr/v2/packr2 && cd - docker and docker-compose without sudo permission (optional if you want to use the provided PostgreSQL and Geth containers) docker docker-compose aws cli 2 (optional if you want to use the provided Geth container) Setup Clone hermez-node repository git clone https://github.com/hermeznetwork/hermez-node.git Build hermez-node executable cd hermez-node make The executable can be found in dist/heznode Deploy PostgreSQL database and Geth node containers. For this step we provide a docker-compose file example. Copy file to docker-compose.sandbox.yaml . Login to AWS public ECR to be able to download the Geth docker image: export AWS_REGION=eu-west-3 aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws/r7d5k1t8 Ensure that port 5432 is not being used. Otherwise, PostgreSQL docker will fail. To start start database and Geth node containers: DEV_PERIOD=3 docker-compose -f docker-compose.sandbox.yaml up -d This command will start a Geth node mining a block every 3 seconds. Database is available at port 5432. Geth node is available at port 8545. To stop containers: docker-compose -f docker-compose.sandbox.yaml down The Geth container comes with pre-deployed Hermez contracts and with 200 funded accounts. The relevant information about the contract deployment can be found below \"hermezAuctionProtocolAddress\": \"0x317113D2593e3efF1FfAE0ba2fF7A61861Df7ae5\" \"hermezAddress\": \"0x10465b16615ae36F350268eb951d7B0187141D3B\" \"withdrawalDelayeAddress\": \"0x8EEaea23686c319133a7cC110b840d1591d9AeE0\" \"HEZTokenAddress\": \"0x5E0816F0f8bC560cB2B9e9C87187BeCac8c2021F\" \"hermezGovernanceIndex\": 1 \"hermezGovernanceAddress\": \"0x8401Eb5ff34cc943f096A32EF3d5113FEbE8D4Eb\" \"emergencyCouncilIndex\": 2 \"emergencyCouncilAddress\": \"0x306469457266CBBe7c0505e8Aad358622235e768\" \"donationIndex\": 3 \"donationAddress\": \"0xd873F6DC68e3057e4B7da74c6b304d0eF0B484C7\" \"bootCoordinatorIndex\": 4 \"mnemonic\": \"explain tackle mirror kit van hammer degree position ginger unfair soup bonus\" \"chainId\" : 1337 } Customize Hermez Node configuration file. For this example, we can use this configuration file . Just copy this file to cmd/heznode/cfg.sandbox.boot.coordinator.toml For more information on the parameters in the configuration file, read the configuration parameters description . Ensure correct permissions are granted to /var/hermez folder sudo mkdir -p /var/hermez sudo chown $USER:$USER /var/hermez Launching the Boot Coordinator It is recommended to run the Coordinator node in a server with 8+ cores, 16 GB+ of RAM and 250GB of disk (AWS c5a.2xlarge or equivalent). Import the Coordinator and Fee Ethereum accounts private keys into the keystore. ./dist/heznode importkey --mode coord --cfg ./cmd/heznode/cfg.sandbox.boot-coordinator.toml --privatekey 0x705df2ae707e25fa37ca84461ac6eb83eb4921b653e98fdc594b60bea1bb4e52 ./dist/heznode importkey --mode coord --cfg ./cmd/heznode/cfg.sandbox.boot-coordinator.toml --privatekey 0xfdb75ceb9f3e0a6c1721e98b94ae451ecbcb9e8c09f9fc059938cb5ab8cc8a7c The Coordinator account is used to pay the gas required to forge batches. The Fee account is used to collect the fees paid by users submitting transactions to Hermez Network. You only need to import these keys once. Start a mock proof server. cd test/proofserver/cmd go build -o proof-server ./proof-server -d 15s -a 0.0.0.0:3000 The hermez-node repository provides a mock proof server that generates proofs every 15 seconds. The mock prover is launched at http://localhost:3000, and it exports two endpoints: - GET /api/status: Queries the prover's status. - POST /api/input: Starts the generation of a new proof. Wipe SQL database Before starting the Coordinator node, you may want to wipe the pre-existing SQL database. This command will wipe the pre-existing database if it exists, and it will force the Coordinator to resynchronize the full state. ./dist/heznode wipedbs --mode coord --cfg cmd/heznode/cfg.sandbox.boot-coordinator.toml Launch the Hermez Node ./dist/heznode run --mode coord --cfg cmd/heznode/cfg.sandbox.boot-coordinator.toml Once the Hermez Node is launched, the API can be queried at localhost:8086/v1 . You can find more information on the API here Launching a Proof Server We will use rapidsnark as the Hermez proof server. rapidsnarks is a zkSnark proof generator written in C++. It is recommended to run the proof server in servers with 48+ cores, 96 GB+ of RAM and 250GB of disk (AWS c5a.12xlarge or equivalent). rapidsnark requires a host CPU that supports ADX extensions. You can check this with cat /proc/cpuinfo | grep adx Dependencies node v16+ npm apt install npm npx npm i -g npx Install gcc, libsodium, gmp, cmake sudo apt install build-essential sudo apt-get install libgmp-dev libsodium-dev nasm cmake Circuit Files Download circuit and auxiliary files. These files are extremely large (20GB+), so make sure you have enough bandwidth and disk space. There are two Hermez circuits that have undergone the Trusted Setup Ceremony. - circuit-2048-32-256-64 with 2048 transactions per batch (~2^27 constraints) - circuit-400-32-256-64 with 400 transactions per batch (~2^25 constraints) For each type of circuit, you will need the following files: - C++ source file (extension .cpp) - Data file (extension .dat) - Verification and Proving Key files (extension .zkey) circuit-400-32-256-64.cpp circuit-400-32-256-64.dat circuit-400-32-256-64_hez4_final.zkey circuit-2048-32-256-64.cpp circuit-2048-32-256-64.dat circuit-2048-32-256-64_hez4_final.zkey More information on Trusted Setup can be found here . Setup Clone rapidsnark repository git clone https://github.com/iden3/rapidsnark.git Compile the prover. In this example we are building the 400 transactions prover. cd rapidsnark npm install git submodule init git submodule update npx task createFieldSources npx task buildPistche npx task buildProverServer ../circuit-400-32-256-64.cpp Launch prover cd .. ./rapidsnark/build/proverServer circuit-400-32-256-64.dat circuit-400-32-256-64_hez4_final.zkey Prover is deployed at port 9080. Check prover status curl -i -H \"Accept: application/json\" -H \"Content-Type: application/json\" -X GET http://localhost:9080/status Generate a Prover Input File Clone circuits repository git clone https://github.com/hermeznetwork/circuits.git Install dependencies cd circuits npm install cd tools In this example we are working with circuit-400-32-236-64_hez1.zkey , which corresponds to a circuit with 400 transactions, 32 levels, 256 maxL1Tx and 64 maxFeeTx. Generate Input file To generate a new input file with empty transactions: node build-circuit.js input 400 32 256 64 This command generates a new input file rollup-400-32-256-64/input-400-32-256-64.json To generate a new input file with random transactions node generate-input.js 256 144 400 32 256 64 This will create a new input file called inputs-256.json Generate a New Proof You can use curl to post any of the inputs generated in the previous step. curl -X POST -d @inputs-256.json http://localhost:9080/input or curl -X POST -d @input-400-32-256-64.json http://localhost:9080/input You check the status of the prover by querying the /status endpoint. curl -i -H \"Accept: application/json\" -H \"Content-Type: application/json\" -X GET http://localhost:9080/status /status returns if the prover is ready to accept a new input as well as the proof result and input data of the previous iteration. An example is shown below. {\"proof\":\"{\\\"pi_a\\\":[\\\"15669797899330531899539165505099185328127025552675136844487912123159422688332\\\",\\\"4169184787514663864223014515796569609423571145125431603092380267213494033234\\\",\\\"1\\\"],\\\"pi_b\\\":[[\\\"15897268173694161686615535760524608158592057931378775361036549860571955196024\\\",\\\"7259544064908843863227076126721939493856845778102643664527079112408898332246\\\"],[\\\"11114029940357001415257752309672127606595008143716611566922301064883221118673\\\",\\\"11641375208941828855753998380661873329613421331584366604363069099895897057080\\\"],[\\\"1\\\",\\\"0\\\"]],\\\"pi_c\\\":[\\\"3069279014559805068186938831761517403137936718184152637949316506268770388068\\\",\\\"17615095679439987436388060423042830905459966122501664486007177405315943656120\\\",\\\"1\\\"],\\\"protocol\\\":\\\"groth16\\\"}\",\"pubData\":\"[\\\"18704199975058268984020790304481139232906477725400223723702831520660895945049\\\"]\",\"status\":\"success\"} Connect Prover to Coordinator Node Once you have verified the prover is working, you can connect it to the Hermez Coordinator by configuring the cfg.sandbox.boot-coordinator.toml configuration file. You need to substitute sections ServerProofs with the updated URLs where prover is deployed, and the Circuit section where the verifier smart contract is specified. [Coordinator.ServerProofs] #TODO: Add Prover URL #URLs = [\"http://localhost:9080\"] [Coordinator.Circuit] MaxTx = 400 NLevels = 32 At this point, you can stop the mock server if it is still running, and re-launch the coordinator as we saw in the previous section. The new prover will be running at http://localhost:9080 (or at the configured URL), and the two endpoints are /status and /input Launching a Price Updater Price Updater service is used to consult and updater the tokens and fiat currency used by Hermez Node. Once Hermez Node has been deployed, the Price Updater service can be deployed. Follow these instructions to set up the Price Updater service. Launching a Synchronizer Node In synchronizer mode, the node is capable of keeping track of the rollup and consensus smart contracts, storing all the history of events, and keeping the rollup state updated, handling reorgs when they happen. This mode is intended for entities that want to gather all the rollup data by themselves and not rely on third party APIs. For this part of the tutorial, we are going to deploy the syncrhonizer node in testnet on Rinkeby. Stop Coordinator node launched in localhost in previous steps. Stop prover, coordinator node and containers from previous phases as you will be working in testnet with a real Boot Coordinator node. docker-compose -f docker-compose.sandbox.yaml down Launch PostgreSQL database. The Hermez node in synchronizer mode needs to run on a separate database docker run --rm --name hermez-db -p 5432:5432 -e POSTGRES_DB=hermez -e POSTGRES_USER=hermez -e POSTGRES_PASSWORD=\"yourpasswordhere\" -d postgres Start an Ethereum node in Rinkeby You will need to run your own Ethreum node on Rinkeby. We recommend using Geth. - Pre-built binaries for all platforms on our downloads page (https://geth.ethereum.org/downloads/). - Ubuntu packages in our Launchpad PPA repository (https://launchpad.net/~ethereum/+archive/ubuntu/ethereum). - OSX packages in our Homebrew Tap repository (https://github.com/ethereum/homebrew-ethereum). Sync this node with Rinkeby testnet where all of Hermez's smart contracts are deployed. Get contract addresses Query Testnet API for the addresses of the Hermez smart contracts. You can use a web browser or the command below. curl -i -H \"Accept: application/json\" -H \"Content-Type: application/json\" -X GET api.testnet.hermez.io/v1/config At this moment, Hermez Network is deployed in this address: \"Rollup\":\"0x679b11e0229959c1d3d27c9d20529e4c5df7997c\" Copy configuration file to hermez-node/cmd/heznode/cfg.testnet.sync.toml . You will need to edit the following sections: PostgreSQL Values provided are valid for docker postgreSQL container. You will need to supply the actual values for your database. Web3 URL of your Rinkeby Ethereum node SmartContracts Double check that the address provided in the configuration file corresponds to the current Hermez Network contract deployed in Rinkeby Launch hermez-node in synchronizer mode ./dist/heznode run --mode sync --cfg cmd/heznode/cfg.testnet.sync.toml Kill and relaunch Price Updater service in testnet Follow instructions to set up the Price Updater service. Once the Hermez node is launched, the API can be queried at the location specified in the configuration file in API.Address section, as well as at https://api.testnet.hermez.io/v1/ serviced by the Boot Coordinator node. Launching a Second Coordinator Node In this part of the tutorial we will start a second Coordinator Node in testnet that will bid for the right to forge batches. Dependencies node 14+ Start Coordinator in Testnet Stop Synchronizer node and PostgreSQL container launched in previous steps. Launch PostgreSQL database docker run --rm --name hermez-db -p 5432:5432 -e POSTGRES_DB=hermez -e POSTGRES_USER=hermez -e POSTGRES_PASSWORD=\"yourpasswordhere\" -d postgres Launch Prover as shown here Create two Ethereum accounts in Rinkeby using Metamask wallet. One account is the forger account (needs to pay for gas to forge batches in Ethereum and for bids in auction in HEZ), and the second is the fee account (receives the HEZ fees). The fees are collected in L2. You can convert from ETH to HEZ in Uniswap Create a Wallet with fee account Ethereum Private Key. This wallet is needed to generate a Baby JubJub address where fees will be collected. There is an example code in the SDK that can be used. Simply substitute EXAMPLES_WEB3_URL by your Rinkeby Node URL and EXAMPLES_PRIVATE_KEY1 by fee account private key. This script will generate a similar output: { privateKey: <Buffer 3e 12 35 91 e9 99 61 98 24 74 dc 9c 09 70 0a cb d1 a5 c9 6f 34 2f ab 35 ca 44 90 01 31 f4 dc 19>, publicKey: [ '554747587236068008597553797728983628103889817758448212785555888433332778905', '5660923625742030187027289840534366342931920530664475168036204263114974152564' ], publicKeyHex: [ '139f9dba06599c54e09934b242161b80041cda4be9192360b997e4751b07799', 'c83f81f4fce3e2ccc78530099830e29bf69713fa11c546ad152bf5226cfc774' ], publicKeyCompressed: '5660923625742030187027289840534366342931920530664475168036204263114974152564', publicKeyCompressedHex: '0c83f81f4fce3e2ccc78530099830e29bf69713fa11c546ad152bf5226cfc774', publicKeyBase64: 'hez:dMfPJlK_UtFqVByhP3FpvykOg5kAU3jMLD7OTx_4gwzO', hermezEthereumAddress: 'hez:0x74d5531A3400f9b9d63729bA9C0E5172Ab0FD0f6' } The Baby JubJub address is publicKeyCompressedHex . In this case, 0x0c83f81f4fce3e2ccc78530099830e29bf69713fa11c546ad152bf5226cfc774 . Copy configuration file to hermez-node/cmd/heznode/cfg.testnet.coord.toml . You will need to edit the following sections: PostgreSQL Values provided are valid for docker postgreSQL container. You will need to supply the actual values for your database. Web3 URL of your Rinkeby Ethereum node SmartContracts Double check that the address provided in the configuration file corresponds to the current Hermez Network contract deployed in Rinkeby Coordinator.ForgerAddress Ethereum account in Ethereum Rinkeby. This account is used to bid during the slots auction and to pay the gas to forge batches in Ethereum Coordinator.FeeAccount You need to supply the Fee account in Ethereum Rinkeby and the Baby JubJub address computed in previous step. This account is used to colled the fees paid by transactions. Coordinator.ServerProofs Provide a valid URL for the proof server. Coordinator.Circuit Ensure the MaxTx parameters matches with the circuit size configed in the proof server. Import the forger and fee Ethereum private keys into the keystore. ./dist/heznode importkey --mode coord --cfg cmd/heznode/cfg.coord.toml --privatekey <FORGER ACCOUNT_PRIVATE KEY> ./dist/heznode importkey --mode coord --cfg cmd/heznode/cfg.coord.toml --privatekey <FEE_ACCOUNT PRIVATE KEY> This private key corresponds to the new Coordinator node Launch New Coordinator Node ./dist/heznode run --mode coord --cfg cmd/heznode/cfg.testnet.coord.toml The node will start synchronizing with the Hermez Network in testnet. This may take a while. Launch new Price Updater service and connect it to the newly launched Hermez node Follow instructions to set up the Price Updater service. Bidding Process Once the node is synchronized, you can start bidding for the right to forge a batch. Install cli-bidding cli-bidding is a tool that allows to register a Coordinator in Hermez Network and place bids in the auction. git clone https://github.com/hermeznetwork/cli-bidding.git Once downloaded, follow the installation steps in the README . NOTE that PRIVATE_KEY_CLI_BIDDING corresponds to the forger private key. Approve HEZ transfers. Before the coordinator can start bidding, it needs to approve the use of HEZ tokens. To do this go to HEZ address in Etherscan , select Contract -> Write Contract -> Approve and set spender address to Coordinator address and value to quantity you want to approve. The recommendation is to set this quantity value very high. Register Forger Using cli-bidding , you need to register the new Coordinator API URL. In our case, we have the Coordinator node running at http://134.255.190.114:8086 node src/biddingCLI.js register --url http://134.255.190.114:8086 NOTE. In order for the wallet-ui to be able to forward transactions to this coordinator, the API needs to be accessible from a https domain. Get Current Slot and Minimum Bid in Hermez bid Take a look at the current slot being bid in Hermez. When bidding, you need to bid at least 2 slots after the curent slot node src/biddingCLI.js slotinfo In our case, minimum bidding is set to 11.0 HEZ, and first biddable slot is 4200. Bidding Process Send a simple bid of \\(11 \\times 10^{18}\\) HEZ for slot 4200. node src/biddingCLI.js bid --amount 11 --slot 4200 --bidAmount 11 Parameter amount is the quantity to be transferred to the auction smart contract, and bidAmount is the actual bid amount. If the bidding process is successful, an Etherscan URL with the transaction id is returned to verify transaction. You can check the allocated nextForgers using /v1/state endpoint cli-bidding provides additional mechanisms to bid in multple slots at once. Check the README file","title":"Hermez Node"},{"location":"Hermez_1.0/developers/coordinator/#hermez-node","text":"This tutorial describes how to launch a Hermez node. It starts by explaining how to launch a Boot Coordinator in localhost. Next, it describes how to initialize a Proof Server and how to connect it to the Boot Coordinator. The next section describes how to spin up a second Hermez node in synchronizer mode to track the rollup status independently from the Boot Coordinator. This second node will be launched in Rinkeby testnet. The last part of the tutorial includes an explanation on how to add a second Coordinator node to Hermez testnet Rinkeby that bids for the right to forge batches. Preparing the Environment Launching the Boot Coordinator Launching a Proof Server Launching a Price Updater Launching a Synchronizer Node Launching a Second Coordinator","title":"Hermez Node"},{"location":"Hermez_1.0/developers/coordinator/#preparing-the-environment","text":"Hermez node requires a PostgreSQL database and connectivity to an Ethereum node. In this part, we describe how you can set this environment up using docker containers.","title":"Preparing the Environment"},{"location":"Hermez_1.0/developers/coordinator/#dependencies","text":"golang 1.16+ golangci-lint packr utility to bundle the database migrations. Make sure your $PATH contains $GOPATH/bin , otherwise the packr utility will not be found. cd /tmp && go get -u github.com/gobuffalo/packr/v2/packr2 && cd - docker and docker-compose without sudo permission (optional if you want to use the provided PostgreSQL and Geth containers) docker docker-compose aws cli 2 (optional if you want to use the provided Geth container)","title":"Dependencies"},{"location":"Hermez_1.0/developers/coordinator/#setup","text":"Clone hermez-node repository git clone https://github.com/hermeznetwork/hermez-node.git Build hermez-node executable cd hermez-node make The executable can be found in dist/heznode Deploy PostgreSQL database and Geth node containers. For this step we provide a docker-compose file example. Copy file to docker-compose.sandbox.yaml . Login to AWS public ECR to be able to download the Geth docker image: export AWS_REGION=eu-west-3 aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws/r7d5k1t8 Ensure that port 5432 is not being used. Otherwise, PostgreSQL docker will fail. To start start database and Geth node containers: DEV_PERIOD=3 docker-compose -f docker-compose.sandbox.yaml up -d This command will start a Geth node mining a block every 3 seconds. Database is available at port 5432. Geth node is available at port 8545. To stop containers: docker-compose -f docker-compose.sandbox.yaml down The Geth container comes with pre-deployed Hermez contracts and with 200 funded accounts. The relevant information about the contract deployment can be found below \"hermezAuctionProtocolAddress\": \"0x317113D2593e3efF1FfAE0ba2fF7A61861Df7ae5\" \"hermezAddress\": \"0x10465b16615ae36F350268eb951d7B0187141D3B\" \"withdrawalDelayeAddress\": \"0x8EEaea23686c319133a7cC110b840d1591d9AeE0\" \"HEZTokenAddress\": \"0x5E0816F0f8bC560cB2B9e9C87187BeCac8c2021F\" \"hermezGovernanceIndex\": 1 \"hermezGovernanceAddress\": \"0x8401Eb5ff34cc943f096A32EF3d5113FEbE8D4Eb\" \"emergencyCouncilIndex\": 2 \"emergencyCouncilAddress\": \"0x306469457266CBBe7c0505e8Aad358622235e768\" \"donationIndex\": 3 \"donationAddress\": \"0xd873F6DC68e3057e4B7da74c6b304d0eF0B484C7\" \"bootCoordinatorIndex\": 4 \"mnemonic\": \"explain tackle mirror kit van hammer degree position ginger unfair soup bonus\" \"chainId\" : 1337 } Customize Hermez Node configuration file. For this example, we can use this configuration file . Just copy this file to cmd/heznode/cfg.sandbox.boot.coordinator.toml For more information on the parameters in the configuration file, read the configuration parameters description . Ensure correct permissions are granted to /var/hermez folder sudo mkdir -p /var/hermez sudo chown $USER:$USER /var/hermez","title":"Setup"},{"location":"Hermez_1.0/developers/coordinator/#launching-the-boot-coordinator","text":"It is recommended to run the Coordinator node in a server with 8+ cores, 16 GB+ of RAM and 250GB of disk (AWS c5a.2xlarge or equivalent). Import the Coordinator and Fee Ethereum accounts private keys into the keystore. ./dist/heznode importkey --mode coord --cfg ./cmd/heznode/cfg.sandbox.boot-coordinator.toml --privatekey 0x705df2ae707e25fa37ca84461ac6eb83eb4921b653e98fdc594b60bea1bb4e52 ./dist/heznode importkey --mode coord --cfg ./cmd/heznode/cfg.sandbox.boot-coordinator.toml --privatekey 0xfdb75ceb9f3e0a6c1721e98b94ae451ecbcb9e8c09f9fc059938cb5ab8cc8a7c The Coordinator account is used to pay the gas required to forge batches. The Fee account is used to collect the fees paid by users submitting transactions to Hermez Network. You only need to import these keys once. Start a mock proof server. cd test/proofserver/cmd go build -o proof-server ./proof-server -d 15s -a 0.0.0.0:3000 The hermez-node repository provides a mock proof server that generates proofs every 15 seconds. The mock prover is launched at http://localhost:3000, and it exports two endpoints: - GET /api/status: Queries the prover's status. - POST /api/input: Starts the generation of a new proof. Wipe SQL database Before starting the Coordinator node, you may want to wipe the pre-existing SQL database. This command will wipe the pre-existing database if it exists, and it will force the Coordinator to resynchronize the full state. ./dist/heznode wipedbs --mode coord --cfg cmd/heznode/cfg.sandbox.boot-coordinator.toml Launch the Hermez Node ./dist/heznode run --mode coord --cfg cmd/heznode/cfg.sandbox.boot-coordinator.toml Once the Hermez Node is launched, the API can be queried at localhost:8086/v1 . You can find more information on the API here","title":"Launching the Boot Coordinator"},{"location":"Hermez_1.0/developers/coordinator/#launching-a-proof-server","text":"We will use rapidsnark as the Hermez proof server. rapidsnarks is a zkSnark proof generator written in C++. It is recommended to run the proof server in servers with 48+ cores, 96 GB+ of RAM and 250GB of disk (AWS c5a.12xlarge or equivalent). rapidsnark requires a host CPU that supports ADX extensions. You can check this with cat /proc/cpuinfo | grep adx","title":"Launching a Proof Server"},{"location":"Hermez_1.0/developers/coordinator/#dependencies_1","text":"node v16+ npm apt install npm npx npm i -g npx Install gcc, libsodium, gmp, cmake sudo apt install build-essential sudo apt-get install libgmp-dev libsodium-dev nasm cmake","title":"Dependencies"},{"location":"Hermez_1.0/developers/coordinator/#circuit-files","text":"Download circuit and auxiliary files. These files are extremely large (20GB+), so make sure you have enough bandwidth and disk space. There are two Hermez circuits that have undergone the Trusted Setup Ceremony. - circuit-2048-32-256-64 with 2048 transactions per batch (~2^27 constraints) - circuit-400-32-256-64 with 400 transactions per batch (~2^25 constraints) For each type of circuit, you will need the following files: - C++ source file (extension .cpp) - Data file (extension .dat) - Verification and Proving Key files (extension .zkey) circuit-400-32-256-64.cpp circuit-400-32-256-64.dat circuit-400-32-256-64_hez4_final.zkey circuit-2048-32-256-64.cpp circuit-2048-32-256-64.dat circuit-2048-32-256-64_hez4_final.zkey More information on Trusted Setup can be found here .","title":"Circuit Files"},{"location":"Hermez_1.0/developers/coordinator/#setup_1","text":"Clone rapidsnark repository git clone https://github.com/iden3/rapidsnark.git Compile the prover. In this example we are building the 400 transactions prover. cd rapidsnark npm install git submodule init git submodule update npx task createFieldSources npx task buildPistche npx task buildProverServer ../circuit-400-32-256-64.cpp Launch prover cd .. ./rapidsnark/build/proverServer circuit-400-32-256-64.dat circuit-400-32-256-64_hez4_final.zkey Prover is deployed at port 9080. Check prover status curl -i -H \"Accept: application/json\" -H \"Content-Type: application/json\" -X GET http://localhost:9080/status","title":"Setup"},{"location":"Hermez_1.0/developers/coordinator/#generate-a-prover-input-file","text":"Clone circuits repository git clone https://github.com/hermeznetwork/circuits.git Install dependencies cd circuits npm install cd tools In this example we are working with circuit-400-32-236-64_hez1.zkey , which corresponds to a circuit with 400 transactions, 32 levels, 256 maxL1Tx and 64 maxFeeTx. Generate Input file To generate a new input file with empty transactions: node build-circuit.js input 400 32 256 64 This command generates a new input file rollup-400-32-256-64/input-400-32-256-64.json To generate a new input file with random transactions node generate-input.js 256 144 400 32 256 64 This will create a new input file called inputs-256.json","title":"Generate a Prover Input File"},{"location":"Hermez_1.0/developers/coordinator/#generate-a-new-proof","text":"You can use curl to post any of the inputs generated in the previous step. curl -X POST -d @inputs-256.json http://localhost:9080/input or curl -X POST -d @input-400-32-256-64.json http://localhost:9080/input You check the status of the prover by querying the /status endpoint. curl -i -H \"Accept: application/json\" -H \"Content-Type: application/json\" -X GET http://localhost:9080/status /status returns if the prover is ready to accept a new input as well as the proof result and input data of the previous iteration. An example is shown below. {\"proof\":\"{\\\"pi_a\\\":[\\\"15669797899330531899539165505099185328127025552675136844487912123159422688332\\\",\\\"4169184787514663864223014515796569609423571145125431603092380267213494033234\\\",\\\"1\\\"],\\\"pi_b\\\":[[\\\"15897268173694161686615535760524608158592057931378775361036549860571955196024\\\",\\\"7259544064908843863227076126721939493856845778102643664527079112408898332246\\\"],[\\\"11114029940357001415257752309672127606595008143716611566922301064883221118673\\\",\\\"11641375208941828855753998380661873329613421331584366604363069099895897057080\\\"],[\\\"1\\\",\\\"0\\\"]],\\\"pi_c\\\":[\\\"3069279014559805068186938831761517403137936718184152637949316506268770388068\\\",\\\"17615095679439987436388060423042830905459966122501664486007177405315943656120\\\",\\\"1\\\"],\\\"protocol\\\":\\\"groth16\\\"}\",\"pubData\":\"[\\\"18704199975058268984020790304481139232906477725400223723702831520660895945049\\\"]\",\"status\":\"success\"}","title":"Generate a New Proof"},{"location":"Hermez_1.0/developers/coordinator/#connect-prover-to-coordinator-node","text":"Once you have verified the prover is working, you can connect it to the Hermez Coordinator by configuring the cfg.sandbox.boot-coordinator.toml configuration file. You need to substitute sections ServerProofs with the updated URLs where prover is deployed, and the Circuit section where the verifier smart contract is specified. [Coordinator.ServerProofs] #TODO: Add Prover URL #URLs = [\"http://localhost:9080\"] [Coordinator.Circuit] MaxTx = 400 NLevels = 32 At this point, you can stop the mock server if it is still running, and re-launch the coordinator as we saw in the previous section. The new prover will be running at http://localhost:9080 (or at the configured URL), and the two endpoints are /status and /input","title":"Connect Prover to Coordinator Node"},{"location":"Hermez_1.0/developers/coordinator/#launching-a-price-updater","text":"Price Updater service is used to consult and updater the tokens and fiat currency used by Hermez Node. Once Hermez Node has been deployed, the Price Updater service can be deployed. Follow these instructions to set up the Price Updater service.","title":"Launching a Price Updater"},{"location":"Hermez_1.0/developers/coordinator/#launching-a-synchronizer-node","text":"In synchronizer mode, the node is capable of keeping track of the rollup and consensus smart contracts, storing all the history of events, and keeping the rollup state updated, handling reorgs when they happen. This mode is intended for entities that want to gather all the rollup data by themselves and not rely on third party APIs. For this part of the tutorial, we are going to deploy the syncrhonizer node in testnet on Rinkeby. Stop Coordinator node launched in localhost in previous steps. Stop prover, coordinator node and containers from previous phases as you will be working in testnet with a real Boot Coordinator node. docker-compose -f docker-compose.sandbox.yaml down Launch PostgreSQL database. The Hermez node in synchronizer mode needs to run on a separate database docker run --rm --name hermez-db -p 5432:5432 -e POSTGRES_DB=hermez -e POSTGRES_USER=hermez -e POSTGRES_PASSWORD=\"yourpasswordhere\" -d postgres Start an Ethereum node in Rinkeby You will need to run your own Ethreum node on Rinkeby. We recommend using Geth. - Pre-built binaries for all platforms on our downloads page (https://geth.ethereum.org/downloads/). - Ubuntu packages in our Launchpad PPA repository (https://launchpad.net/~ethereum/+archive/ubuntu/ethereum). - OSX packages in our Homebrew Tap repository (https://github.com/ethereum/homebrew-ethereum). Sync this node with Rinkeby testnet where all of Hermez's smart contracts are deployed. Get contract addresses Query Testnet API for the addresses of the Hermez smart contracts. You can use a web browser or the command below. curl -i -H \"Accept: application/json\" -H \"Content-Type: application/json\" -X GET api.testnet.hermez.io/v1/config At this moment, Hermez Network is deployed in this address: \"Rollup\":\"0x679b11e0229959c1d3d27c9d20529e4c5df7997c\" Copy configuration file to hermez-node/cmd/heznode/cfg.testnet.sync.toml . You will need to edit the following sections: PostgreSQL Values provided are valid for docker postgreSQL container. You will need to supply the actual values for your database. Web3 URL of your Rinkeby Ethereum node SmartContracts Double check that the address provided in the configuration file corresponds to the current Hermez Network contract deployed in Rinkeby Launch hermez-node in synchronizer mode ./dist/heznode run --mode sync --cfg cmd/heznode/cfg.testnet.sync.toml Kill and relaunch Price Updater service in testnet Follow instructions to set up the Price Updater service. Once the Hermez node is launched, the API can be queried at the location specified in the configuration file in API.Address section, as well as at https://api.testnet.hermez.io/v1/ serviced by the Boot Coordinator node.","title":"Launching a Synchronizer Node"},{"location":"Hermez_1.0/developers/coordinator/#launching-a-second-coordinator-node","text":"In this part of the tutorial we will start a second Coordinator Node in testnet that will bid for the right to forge batches.","title":"Launching a Second Coordinator Node"},{"location":"Hermez_1.0/developers/coordinator/#dependencies_2","text":"node 14+","title":"Dependencies"},{"location":"Hermez_1.0/developers/coordinator/#start-coordinator-in-testnet","text":"Stop Synchronizer node and PostgreSQL container launched in previous steps. Launch PostgreSQL database docker run --rm --name hermez-db -p 5432:5432 -e POSTGRES_DB=hermez -e POSTGRES_USER=hermez -e POSTGRES_PASSWORD=\"yourpasswordhere\" -d postgres Launch Prover as shown here Create two Ethereum accounts in Rinkeby using Metamask wallet. One account is the forger account (needs to pay for gas to forge batches in Ethereum and for bids in auction in HEZ), and the second is the fee account (receives the HEZ fees). The fees are collected in L2. You can convert from ETH to HEZ in Uniswap Create a Wallet with fee account Ethereum Private Key. This wallet is needed to generate a Baby JubJub address where fees will be collected. There is an example code in the SDK that can be used. Simply substitute EXAMPLES_WEB3_URL by your Rinkeby Node URL and EXAMPLES_PRIVATE_KEY1 by fee account private key. This script will generate a similar output: { privateKey: <Buffer 3e 12 35 91 e9 99 61 98 24 74 dc 9c 09 70 0a cb d1 a5 c9 6f 34 2f ab 35 ca 44 90 01 31 f4 dc 19>, publicKey: [ '554747587236068008597553797728983628103889817758448212785555888433332778905', '5660923625742030187027289840534366342931920530664475168036204263114974152564' ], publicKeyHex: [ '139f9dba06599c54e09934b242161b80041cda4be9192360b997e4751b07799', 'c83f81f4fce3e2ccc78530099830e29bf69713fa11c546ad152bf5226cfc774' ], publicKeyCompressed: '5660923625742030187027289840534366342931920530664475168036204263114974152564', publicKeyCompressedHex: '0c83f81f4fce3e2ccc78530099830e29bf69713fa11c546ad152bf5226cfc774', publicKeyBase64: 'hez:dMfPJlK_UtFqVByhP3FpvykOg5kAU3jMLD7OTx_4gwzO', hermezEthereumAddress: 'hez:0x74d5531A3400f9b9d63729bA9C0E5172Ab0FD0f6' } The Baby JubJub address is publicKeyCompressedHex . In this case, 0x0c83f81f4fce3e2ccc78530099830e29bf69713fa11c546ad152bf5226cfc774 . Copy configuration file to hermez-node/cmd/heznode/cfg.testnet.coord.toml . You will need to edit the following sections: PostgreSQL Values provided are valid for docker postgreSQL container. You will need to supply the actual values for your database. Web3 URL of your Rinkeby Ethereum node SmartContracts Double check that the address provided in the configuration file corresponds to the current Hermez Network contract deployed in Rinkeby Coordinator.ForgerAddress Ethereum account in Ethereum Rinkeby. This account is used to bid during the slots auction and to pay the gas to forge batches in Ethereum Coordinator.FeeAccount You need to supply the Fee account in Ethereum Rinkeby and the Baby JubJub address computed in previous step. This account is used to colled the fees paid by transactions. Coordinator.ServerProofs Provide a valid URL for the proof server. Coordinator.Circuit Ensure the MaxTx parameters matches with the circuit size configed in the proof server. Import the forger and fee Ethereum private keys into the keystore. ./dist/heznode importkey --mode coord --cfg cmd/heznode/cfg.coord.toml --privatekey <FORGER ACCOUNT_PRIVATE KEY> ./dist/heznode importkey --mode coord --cfg cmd/heznode/cfg.coord.toml --privatekey <FEE_ACCOUNT PRIVATE KEY> This private key corresponds to the new Coordinator node Launch New Coordinator Node ./dist/heznode run --mode coord --cfg cmd/heznode/cfg.testnet.coord.toml The node will start synchronizing with the Hermez Network in testnet. This may take a while. Launch new Price Updater service and connect it to the newly launched Hermez node Follow instructions to set up the Price Updater service.","title":"Start Coordinator in Testnet"},{"location":"Hermez_1.0/developers/coordinator/#bidding-process","text":"Once the node is synchronized, you can start bidding for the right to forge a batch. Install cli-bidding cli-bidding is a tool that allows to register a Coordinator in Hermez Network and place bids in the auction. git clone https://github.com/hermeznetwork/cli-bidding.git Once downloaded, follow the installation steps in the README . NOTE that PRIVATE_KEY_CLI_BIDDING corresponds to the forger private key. Approve HEZ transfers. Before the coordinator can start bidding, it needs to approve the use of HEZ tokens. To do this go to HEZ address in Etherscan , select Contract -> Write Contract -> Approve and set spender address to Coordinator address and value to quantity you want to approve. The recommendation is to set this quantity value very high. Register Forger Using cli-bidding , you need to register the new Coordinator API URL. In our case, we have the Coordinator node running at http://134.255.190.114:8086 node src/biddingCLI.js register --url http://134.255.190.114:8086 NOTE. In order for the wallet-ui to be able to forward transactions to this coordinator, the API needs to be accessible from a https domain. Get Current Slot and Minimum Bid in Hermez bid Take a look at the current slot being bid in Hermez. When bidding, you need to bid at least 2 slots after the curent slot node src/biddingCLI.js slotinfo In our case, minimum bidding is set to 11.0 HEZ, and first biddable slot is 4200. Bidding Process Send a simple bid of \\(11 \\times 10^{18}\\) HEZ for slot 4200. node src/biddingCLI.js bid --amount 11 --slot 4200 --bidAmount 11 Parameter amount is the quantity to be transferred to the auction smart contract, and bidAmount is the actual bid amount. If the bidding process is successful, an Etherscan URL with the transaction id is returned to verify transaction. You can check the allocated nextForgers using /v1/state endpoint cli-bidding provides additional mechanisms to bid in multple slots at once. Check the README file","title":"Bidding Process"},{"location":"Hermez_1.0/developers/dev-guide/","text":"Developer Guide This document is an overview of the Hermez Protocol. Its objective is to provide an introduction to developers on the Hermez Protocol so that the use of the tools which interact with Hermez Network, such as HermezJS (javascript SDK) and the REST API , become simpler. This document assumes you are familiar with the Ethereum ecosystem and L2 Rollups (in particular ZK-Rollups). For a more in depth analysis, read the protocol section. Hermez smart contracts can be downloaded from here . Overview Hermez is a zk-rollup solution that allows scaling payments and token transfers on top of the Ethereum public blockchain. It uses Ethereum for data storage but not for computation. In addition, by using zero-knowledge proofs, it is easy to verify on-chain that computations have been carried out correctly. All accounts and balances in Hermez Network are stored off-chain in a state tree . Incoming user transactions are batched together, and through a zk-SNARK that proves that those transactions meet certain rules specified in a smart contract, the state tree transitions to a new verifiable valid state. The coordinator is the entity that collects and codifies these transactions, calculates the ZK-SNARK proof and submits the result to the smart contract that validates the transition. Transactions are made public to provide data availability to the protocol so that anyone can rebuild the state tree from on-chain data. Users typically send transactions to Hermez via a wallet. The purpose of this tool is to improve the experience of using Hermez by hiding the internal interactions between the different Hermez components and simplifying the usage. The governance is the entity that oversees the sustainability and evolution of the network. Some functions delegated to the governance include the upgrade of smart contracts, the modification of system parameters , or the execution of the withdrawal delay mechanism among others. Hermez deploys three main smart contracts: 1. Hermez smart contract : Manages the forging stage by checking the zk-proofs provided by the selected coordinator, and updates the state and exit trees. It also interacts with users by collecting L1 transactions and adding them to the transaction queue. 2. Consensus smart contract : Manages the selection of a coordinator node via an auction process. 3. WithdrawalDelayer smart contract : Manages a withdrawal protection mechanism embedded into the system. The overall picture of Hermez can be seen in the diagram below. Users send L1 transactions (such as Create account, Deposit or Withdrawal requests) using a UI. These transactions are collected by the Hermez smart contract and added into a queue of pending transactions. Users may also send L2 transactions (Transfer, Exit) directly to the coordinator node. The UI hides all the unnecessary complexities from the user, who just selects the type of operation and the input data for a given operation (source account, destination account, amount to transfer,...). At the time of processing a batch, the coordinator takes the pending L1 transactions from the Hermez smart contract and the received L2 transactions, and generates a proof showing that these transactions have been carried out correctly. This proof is given to the smart contract that verifies it and updates the state of the network. In the meantime, an auction process is ongoing to select the coordinator node for a given amount of time. In this auction, nodes bid for the right to forge upcoming batches and thus collecting the fees associated to those transactions. The proceedings of these bids will be sent to different accounts, including a Gitcoin grants account. Hermez functionalities can be summarized in 4 major groups: 1. Handling L1-user and L2-user transactions 2. Forging batches 3. Reaching consensus to select a coordinator 4. Withdrawal of funds. Accounts Hermez stores accounts as leaves in the Hermez state tree. Each account stores a single type of token. A user may own multiple rollup accounts. There are two types of accounts to operate in Hermez Network: 1. Regular : Regular accounts can be used in both L1 and L2 transactions. Regular accounts include an Ethereum and a babyjubjub public key. An Ethereum key is used to authorize L1 transactions and the Baby Jubjub key is used to authorize L2 transactions. An Ethereum address may authorize the creation of a Regular account containing that same Ethereum address plus a Baby Jubjub public key. Typically, this is done via a UI. Internal : Internal accounts only have a Baby Jubjub key, and thus may only be used in L2 transactions. Since there is no Ethereum address, the account creation does not require an authorization and will only require a Baby Jubjub key. Transactions There are two types of Hermez transactions: - L1 transactions are those that are executed through the smart contract. These transactions may be started by the user or by the coordinator. - L2 transactions are those that are executed exclusively on L2. L1 Transactions L1 transactions can be divided in two groups depending the originator of the transaction: - L1 User Transactions : originate from an Hermez end-user using some form of UI. - L1 Coordinator Transactions : originate from the coordinator. L1 User Transactions L1 user transactions (L1UserTxs) are received by the smart contract. These transactions are concatenated and added in queues to force the coordinator to process them as part of the batch. The queue that will be forged in the next L1L2-batch is always frozen, and the L1 Transactions will be added in the following queues. In case a transaction is invalid (e.g. attempts to send an amount greater than the account balance) it will be processed by the circuit but will be nullified. This system allows the L1 transactions to be uncensorable Examples of L1 User transactions include CreateAccountDeposit , Deposit , DepositTransfer ... All the transactions details are handled by the UI. L1 Coordinator Transactions L1 Coordinator Transactions (L1CoordinatorTxs) allow the coordinator to create regular or internal accounts when forging a batch so that a user can transfer funds to another user that doesn't own an account yet. L2 Transactions L2 transactions (L2Txs) are executed exclusively on L2. Examples of L2 transactions include Transfer of funds between rollup accounts or Exit to transfer funds to the exit tree. All L2 transactions are initiated by the user, who sends the transactions directly to the coordinator via a REST API . Depending on the UI capabilities, the user may be able to select among a number of coordinators (the one currently forging, the ones that have already won the right to forge in upcoming slots,...). Fees are payed on L2 transactions in the same token used in the transaction. The coordinator collects these fees from up to 64 different tokens per batch. If more than 64 tokens are used in the same batch, no fees will be collected for the excess number of tokens. Transaction ID Transaction ID (TxID) allows tracking transactions from the time they are sent to the coordinator to the time they are made available on chain. TxID is computed differently depending on the type of transaction (L1UserTxs, L1CoordinatorTxs or L2Txs). Padding is used to make all TxID (no matter which type) have the same length of 33 bytes. TxID on L1UserTx: bytes: | 1 byte | 32 bytes | SHA256( 8 bytes | 2 bytes ) content: | 0 | SHA256([ToForgeL1TxsNum | Position ]) TxID on L1CoordinatorTx: bytes: | 1 byte | 32 bytes | SHA256( 8 bytes | 2 bytes ) content: | 1 | SHA256([BatchNum | Position ]) TxID on L2Tx: bytes: | 1 byte | 32 bytes | SHA256( 6 bytes | 4 bytes | 2 bytes| 5 bytes | 1 byte ) content: | 2 | SHA256([FromIdx | TokenID | Amount | Nonce | Fee ]) Forging In this section we will describe how consensus to select a coordinator with the permission to forge batches and collect fees from the processed transactions is reached. We will also describe some of the embedded security mechanisms that discourage these coordinators from acting maliciously. Consensus In Hermez zkRollup, time is divided into slots of a certain duration: - Ethereum Block = ~ 15s. - Slot = 40 Ethereum Blocks ~ 10 min. Hermez reaches a consensus on who will play the role of coordinator by running an auction managed by a smart contract. This auction is held among the existing nodes for every slot. The node that places the highest bid for a given slot while the auction is open will claim the role of coordinator for that slot. The coordinator node is allowed to forge batches during the awarded slot, which is the mechanism by which an authorized coordinator processes a batch of transactions, produces a ZK-SNARK attesting to the correctness of the operation and is able to reclaim the processing fees. Auction bids are placed only in HEZ . The auction of future slots opens up to S1 slots in advance. Auction closes S2 slots before the beginning the slot. Tentative S1 and S2 values are 1 month and 2 slots respectively. Additionally, these parameters can be changed by governance at any time. Bids placed during the auction should be at least greater than the minimal bidding price if it's the first bid in a slot, or a premium bid factor P % higher than the previous bid. Both the minimum bidding price and the premium bid factor( P ) can be modified by the network governance. Tentative values for minimum bid and premium factor are 10 HEZ and 10% respectively. Bids not meeting these conditions will not be valid and bidders will receive their HEZ when the slot is forged. Allocation of Bids All bids are deposited in the consensus smart contract the moment they are placed. Once the slot is forged, the tokens bid are assigned to three different accounts: - Part will be burnt . - Part will be assigned to a donations account with Gitcoin grants, which will decide how to allocate this funds into different projects. - Remaining tokens will be allocated to an incentives account , compensation active engagement and network adoption. Protection Mechanisms There are some rules on how coordinators must process transactions. These rules ensure that a coordinator will behave correctly and efficiently, attempting to forge as many transactions as possible during its allocated slots. L1/L2 Batches There are 2 types of batches: - L2-batch : Only L2 transactions are mined. - L1L2-batch : Both L1 and L2 transactions can be mined. In these batches, the coordinator must forge the last L1 queue. In both cases the coordinator may include L1-coordinator-transactions. Coordinators must process L1 user transactions periodically. The smart contract establishes a deadline for the L1L2-batches. This deadline indicates the maximum time between two consecutive L1L2 batches. Once this deadline is reached, the coordinator cannot forge any L2 batches until the deadline is reset which only happens after a L1L2 batch is forged. This mechanism is summarized in the diagram below. Coordinator Override If for some reason the coordinator of the current slot doesn't forge any batch in the N first available blocks inside the slot, any available coordinator may forge batches without bidding. This maximum idle time is called Slot deadline , and defines the amount of time that any coordinator must wait to start forging without bidding, provided that the coordinator that won the current slot action hasn't forged anything during that time. This mechanism ensures that as long as there is one honest working coordinator, Hermez Network will be running and all funds will be recoverable. Boot Coordinator Hermez includes the role of Boot coordinator managed by the network. The Boot coordinator acts as the bootstrap mechanism and its mission is to guarantee that there is always coordinator available in the early stages of the project. Slot Grouping Auction is structured in groups of 6 slots (i.e, slots are sequentially indexed 0,1,2,3,4,5,0,1,...). Each slot index has an independent minimum bidding price. This grouping allows certain flexibility to the governance to influence behavior of coordinators. If slots are frequently wasted (meaning that elected coordinators chose not to forge batches), governance may increase the minimum bid amount for certain slots to make slot wasting less efficient for coordinators, and thus allowing the boot coordinator to forge the batches. When the minimum bidding price is set to 0 HEZ value for a given slot index, the value will be locked and governance will not be able to modify it anymore for that slot. Withdrawal Funds are recovered from Hermez network by executing two transactions back-to-back: 1. Exit transaction : Funds are transferred from the state tree to the exit tree. 2. Withdrawal : Funds are transferred from Hermez smart contract to the user Ethereum address. The limit and rate at which funds can be transferred from the smart contract is regulated by a leaky bucket algorithm. Depending on the amount of available credits in the smart contract, withdrawal may be instantaneous or delayed. Hermez Withdrawal Limit Withdrawals are classified in one of several buckets depending on the USD amount to be withdrawn. Every bucket contains some amount of credits indicating the maximum amount that can be withdrawn at any point in time. Buckets are re-filled with credits at a specific rate (depending on bucket). When a user attempts to withdraw funds, credits in the selected bucket are subtracted. If the withdrawal amount exceeds the existing value of credits, the instant withdrawal cannot be performed and a delayed withdrawal will be done instead. Delayed withdrawal is handled by the WithdrawalDelayer smart contract. Figure below depicts how the different buckets are structured depending on the amount. Withdrawal Resolution The amount above the withdrawal limit set by the available credits wont be withdrawn instantly. In this case, excess tokens will be sent to the WithdrawalDelayer smart contract. The WithdrawalDelayer smart contract can be in one of two states: 1. Normal Mode : Amount above withdrawal limit is available for withdrawal, but with a delay D. This is the standard state. 2. Emergency Mode : The Hermez Foundation is the only body that may change the WithdrawalDelayer mode to Emergency in case of an attack. In this scenario, funds can only be withdrawn by the governance under the tutelage of an emergency council that will return the funds to the users. Adding New Tokens Hermez contains a list with all tokens supported. The following list includes some requirements on the token listing: - Tokens must be ERC20 - Governance can decide the fee cost of adding tokens and therefore can regulate the token listing. - There can be up to 2^{32} different tokens. - Contracts maintain a list of all tokens registered in the rollup and each token needs to be listed before using it. - The token 0 will be reserved for ether - A token only can be added once The list of supported tokens can be retrieved though the REST API","title":"Developer Guide"},{"location":"Hermez_1.0/developers/dev-guide/#developer-guide","text":"This document is an overview of the Hermez Protocol. Its objective is to provide an introduction to developers on the Hermez Protocol so that the use of the tools which interact with Hermez Network, such as HermezJS (javascript SDK) and the REST API , become simpler. This document assumes you are familiar with the Ethereum ecosystem and L2 Rollups (in particular ZK-Rollups). For a more in depth analysis, read the protocol section. Hermez smart contracts can be downloaded from here .","title":"Developer Guide"},{"location":"Hermez_1.0/developers/dev-guide/#overview","text":"Hermez is a zk-rollup solution that allows scaling payments and token transfers on top of the Ethereum public blockchain. It uses Ethereum for data storage but not for computation. In addition, by using zero-knowledge proofs, it is easy to verify on-chain that computations have been carried out correctly. All accounts and balances in Hermez Network are stored off-chain in a state tree . Incoming user transactions are batched together, and through a zk-SNARK that proves that those transactions meet certain rules specified in a smart contract, the state tree transitions to a new verifiable valid state. The coordinator is the entity that collects and codifies these transactions, calculates the ZK-SNARK proof and submits the result to the smart contract that validates the transition. Transactions are made public to provide data availability to the protocol so that anyone can rebuild the state tree from on-chain data. Users typically send transactions to Hermez via a wallet. The purpose of this tool is to improve the experience of using Hermez by hiding the internal interactions between the different Hermez components and simplifying the usage. The governance is the entity that oversees the sustainability and evolution of the network. Some functions delegated to the governance include the upgrade of smart contracts, the modification of system parameters , or the execution of the withdrawal delay mechanism among others. Hermez deploys three main smart contracts: 1. Hermez smart contract : Manages the forging stage by checking the zk-proofs provided by the selected coordinator, and updates the state and exit trees. It also interacts with users by collecting L1 transactions and adding them to the transaction queue. 2. Consensus smart contract : Manages the selection of a coordinator node via an auction process. 3. WithdrawalDelayer smart contract : Manages a withdrawal protection mechanism embedded into the system. The overall picture of Hermez can be seen in the diagram below. Users send L1 transactions (such as Create account, Deposit or Withdrawal requests) using a UI. These transactions are collected by the Hermez smart contract and added into a queue of pending transactions. Users may also send L2 transactions (Transfer, Exit) directly to the coordinator node. The UI hides all the unnecessary complexities from the user, who just selects the type of operation and the input data for a given operation (source account, destination account, amount to transfer,...). At the time of processing a batch, the coordinator takes the pending L1 transactions from the Hermez smart contract and the received L2 transactions, and generates a proof showing that these transactions have been carried out correctly. This proof is given to the smart contract that verifies it and updates the state of the network. In the meantime, an auction process is ongoing to select the coordinator node for a given amount of time. In this auction, nodes bid for the right to forge upcoming batches and thus collecting the fees associated to those transactions. The proceedings of these bids will be sent to different accounts, including a Gitcoin grants account. Hermez functionalities can be summarized in 4 major groups: 1. Handling L1-user and L2-user transactions 2. Forging batches 3. Reaching consensus to select a coordinator 4. Withdrawal of funds.","title":"Overview"},{"location":"Hermez_1.0/developers/dev-guide/#accounts","text":"Hermez stores accounts as leaves in the Hermez state tree. Each account stores a single type of token. A user may own multiple rollup accounts. There are two types of accounts to operate in Hermez Network: 1. Regular : Regular accounts can be used in both L1 and L2 transactions. Regular accounts include an Ethereum and a babyjubjub public key. An Ethereum key is used to authorize L1 transactions and the Baby Jubjub key is used to authorize L2 transactions. An Ethereum address may authorize the creation of a Regular account containing that same Ethereum address plus a Baby Jubjub public key. Typically, this is done via a UI. Internal : Internal accounts only have a Baby Jubjub key, and thus may only be used in L2 transactions. Since there is no Ethereum address, the account creation does not require an authorization and will only require a Baby Jubjub key.","title":"Accounts"},{"location":"Hermez_1.0/developers/dev-guide/#transactions","text":"There are two types of Hermez transactions: - L1 transactions are those that are executed through the smart contract. These transactions may be started by the user or by the coordinator. - L2 transactions are those that are executed exclusively on L2.","title":"Transactions"},{"location":"Hermez_1.0/developers/dev-guide/#l1-transactions","text":"L1 transactions can be divided in two groups depending the originator of the transaction: - L1 User Transactions : originate from an Hermez end-user using some form of UI. - L1 Coordinator Transactions : originate from the coordinator.","title":"L1 Transactions"},{"location":"Hermez_1.0/developers/dev-guide/#l1-user-transactions","text":"L1 user transactions (L1UserTxs) are received by the smart contract. These transactions are concatenated and added in queues to force the coordinator to process them as part of the batch. The queue that will be forged in the next L1L2-batch is always frozen, and the L1 Transactions will be added in the following queues. In case a transaction is invalid (e.g. attempts to send an amount greater than the account balance) it will be processed by the circuit but will be nullified. This system allows the L1 transactions to be uncensorable Examples of L1 User transactions include CreateAccountDeposit , Deposit , DepositTransfer ... All the transactions details are handled by the UI.","title":"L1 User Transactions"},{"location":"Hermez_1.0/developers/dev-guide/#l1-coordinator-transactions","text":"L1 Coordinator Transactions (L1CoordinatorTxs) allow the coordinator to create regular or internal accounts when forging a batch so that a user can transfer funds to another user that doesn't own an account yet.","title":"L1 Coordinator Transactions"},{"location":"Hermez_1.0/developers/dev-guide/#l2-transactions","text":"L2 transactions (L2Txs) are executed exclusively on L2. Examples of L2 transactions include Transfer of funds between rollup accounts or Exit to transfer funds to the exit tree. All L2 transactions are initiated by the user, who sends the transactions directly to the coordinator via a REST API . Depending on the UI capabilities, the user may be able to select among a number of coordinators (the one currently forging, the ones that have already won the right to forge in upcoming slots,...). Fees are payed on L2 transactions in the same token used in the transaction. The coordinator collects these fees from up to 64 different tokens per batch. If more than 64 tokens are used in the same batch, no fees will be collected for the excess number of tokens.","title":"L2 Transactions"},{"location":"Hermez_1.0/developers/dev-guide/#transaction-id","text":"Transaction ID (TxID) allows tracking transactions from the time they are sent to the coordinator to the time they are made available on chain. TxID is computed differently depending on the type of transaction (L1UserTxs, L1CoordinatorTxs or L2Txs). Padding is used to make all TxID (no matter which type) have the same length of 33 bytes. TxID on L1UserTx: bytes: | 1 byte | 32 bytes | SHA256( 8 bytes | 2 bytes ) content: | 0 | SHA256([ToForgeL1TxsNum | Position ]) TxID on L1CoordinatorTx: bytes: | 1 byte | 32 bytes | SHA256( 8 bytes | 2 bytes ) content: | 1 | SHA256([BatchNum | Position ]) TxID on L2Tx: bytes: | 1 byte | 32 bytes | SHA256( 6 bytes | 4 bytes | 2 bytes| 5 bytes | 1 byte ) content: | 2 | SHA256([FromIdx | TokenID | Amount | Nonce | Fee ])","title":"Transaction ID"},{"location":"Hermez_1.0/developers/dev-guide/#forging","text":"In this section we will describe how consensus to select a coordinator with the permission to forge batches and collect fees from the processed transactions is reached. We will also describe some of the embedded security mechanisms that discourage these coordinators from acting maliciously.","title":"Forging"},{"location":"Hermez_1.0/developers/dev-guide/#consensus","text":"In Hermez zkRollup, time is divided into slots of a certain duration: - Ethereum Block = ~ 15s. - Slot = 40 Ethereum Blocks ~ 10 min. Hermez reaches a consensus on who will play the role of coordinator by running an auction managed by a smart contract. This auction is held among the existing nodes for every slot. The node that places the highest bid for a given slot while the auction is open will claim the role of coordinator for that slot. The coordinator node is allowed to forge batches during the awarded slot, which is the mechanism by which an authorized coordinator processes a batch of transactions, produces a ZK-SNARK attesting to the correctness of the operation and is able to reclaim the processing fees. Auction bids are placed only in HEZ . The auction of future slots opens up to S1 slots in advance. Auction closes S2 slots before the beginning the slot. Tentative S1 and S2 values are 1 month and 2 slots respectively. Additionally, these parameters can be changed by governance at any time. Bids placed during the auction should be at least greater than the minimal bidding price if it's the first bid in a slot, or a premium bid factor P % higher than the previous bid. Both the minimum bidding price and the premium bid factor( P ) can be modified by the network governance. Tentative values for minimum bid and premium factor are 10 HEZ and 10% respectively. Bids not meeting these conditions will not be valid and bidders will receive their HEZ when the slot is forged.","title":"Consensus"},{"location":"Hermez_1.0/developers/dev-guide/#allocation-of-bids","text":"All bids are deposited in the consensus smart contract the moment they are placed. Once the slot is forged, the tokens bid are assigned to three different accounts: - Part will be burnt . - Part will be assigned to a donations account with Gitcoin grants, which will decide how to allocate this funds into different projects. - Remaining tokens will be allocated to an incentives account , compensation active engagement and network adoption.","title":"Allocation of Bids"},{"location":"Hermez_1.0/developers/dev-guide/#protection-mechanisms","text":"There are some rules on how coordinators must process transactions. These rules ensure that a coordinator will behave correctly and efficiently, attempting to forge as many transactions as possible during its allocated slots.","title":"Protection Mechanisms"},{"location":"Hermez_1.0/developers/dev-guide/#l1l2-batches","text":"There are 2 types of batches: - L2-batch : Only L2 transactions are mined. - L1L2-batch : Both L1 and L2 transactions can be mined. In these batches, the coordinator must forge the last L1 queue. In both cases the coordinator may include L1-coordinator-transactions. Coordinators must process L1 user transactions periodically. The smart contract establishes a deadline for the L1L2-batches. This deadline indicates the maximum time between two consecutive L1L2 batches. Once this deadline is reached, the coordinator cannot forge any L2 batches until the deadline is reset which only happens after a L1L2 batch is forged. This mechanism is summarized in the diagram below.","title":"L1/L2 Batches"},{"location":"Hermez_1.0/developers/dev-guide/#coordinator-override","text":"If for some reason the coordinator of the current slot doesn't forge any batch in the N first available blocks inside the slot, any available coordinator may forge batches without bidding. This maximum idle time is called Slot deadline , and defines the amount of time that any coordinator must wait to start forging without bidding, provided that the coordinator that won the current slot action hasn't forged anything during that time. This mechanism ensures that as long as there is one honest working coordinator, Hermez Network will be running and all funds will be recoverable.","title":"Coordinator Override"},{"location":"Hermez_1.0/developers/dev-guide/#boot-coordinator","text":"Hermez includes the role of Boot coordinator managed by the network. The Boot coordinator acts as the bootstrap mechanism and its mission is to guarantee that there is always coordinator available in the early stages of the project.","title":"Boot Coordinator"},{"location":"Hermez_1.0/developers/dev-guide/#slot-grouping","text":"Auction is structured in groups of 6 slots (i.e, slots are sequentially indexed 0,1,2,3,4,5,0,1,...). Each slot index has an independent minimum bidding price. This grouping allows certain flexibility to the governance to influence behavior of coordinators. If slots are frequently wasted (meaning that elected coordinators chose not to forge batches), governance may increase the minimum bid amount for certain slots to make slot wasting less efficient for coordinators, and thus allowing the boot coordinator to forge the batches. When the minimum bidding price is set to 0 HEZ value for a given slot index, the value will be locked and governance will not be able to modify it anymore for that slot.","title":"Slot Grouping"},{"location":"Hermez_1.0/developers/dev-guide/#withdrawal","text":"Funds are recovered from Hermez network by executing two transactions back-to-back: 1. Exit transaction : Funds are transferred from the state tree to the exit tree. 2. Withdrawal : Funds are transferred from Hermez smart contract to the user Ethereum address. The limit and rate at which funds can be transferred from the smart contract is regulated by a leaky bucket algorithm. Depending on the amount of available credits in the smart contract, withdrawal may be instantaneous or delayed.","title":"Withdrawal"},{"location":"Hermez_1.0/developers/dev-guide/#hermez-withdrawal-limit","text":"Withdrawals are classified in one of several buckets depending on the USD amount to be withdrawn. Every bucket contains some amount of credits indicating the maximum amount that can be withdrawn at any point in time. Buckets are re-filled with credits at a specific rate (depending on bucket). When a user attempts to withdraw funds, credits in the selected bucket are subtracted. If the withdrawal amount exceeds the existing value of credits, the instant withdrawal cannot be performed and a delayed withdrawal will be done instead. Delayed withdrawal is handled by the WithdrawalDelayer smart contract. Figure below depicts how the different buckets are structured depending on the amount.","title":"Hermez Withdrawal Limit"},{"location":"Hermez_1.0/developers/dev-guide/#withdrawal-resolution","text":"The amount above the withdrawal limit set by the available credits wont be withdrawn instantly. In this case, excess tokens will be sent to the WithdrawalDelayer smart contract. The WithdrawalDelayer smart contract can be in one of two states: 1. Normal Mode : Amount above withdrawal limit is available for withdrawal, but with a delay D. This is the standard state. 2. Emergency Mode : The Hermez Foundation is the only body that may change the WithdrawalDelayer mode to Emergency in case of an attack. In this scenario, funds can only be withdrawn by the governance under the tutelage of an emergency council that will return the funds to the users.","title":"Withdrawal Resolution"},{"location":"Hermez_1.0/developers/dev-guide/#adding-new-tokens","text":"Hermez contains a list with all tokens supported. The following list includes some requirements on the token listing: - Tokens must be ERC20 - Governance can decide the fee cost of adding tokens and therefore can regulate the token listing. - There can be up to 2^{32} different tokens. - Contracts maintain a list of all tokens registered in the rollup and each token needs to be listed before using it. - The token 0 will be reserved for ether - A token only can be added once The list of supported tokens can be retrieved though the REST API","title":"Adding New Tokens"},{"location":"Hermez_1.0/developers/getting-started/","text":"Getting Started TODO","title":"Getting Started"},{"location":"Hermez_1.0/developers/getting-started/#getting-started","text":"TODO","title":"Getting Started"},{"location":"Hermez_1.0/developers/glossary/","text":"Glossary Auction Selection of the coordinator is done via an auction process managed by a smart contract. The node with the highest bid in an open slot will earn the right to forge new batches and collect the fees from the transactions included in the batch. This auction is the process by which Hermez Network reaches a consensus on which node shall play the role of coordinator in an upcoming slot. BabyJubJub BabyJubJub is an elliptic curve defined over a large prime field. It's useful in zk-SNARKs proofs. Batch A batch is a rollup block. It is formed by a set of transactions that determines a state transition of the Hermez accounts and sets an exit tree. Batches can be: - L2-Batch: The set of transactions are only L2 - L1-L2 Batch: The set of transactions are L1 or L2 Coordinator A coordinator is our term for rollup block producer. At any one time there is one coordinator responsible for collecting transactions and creating blocks on the rollup chain. Data Availability Hermez approach determines that anyone can reconstruct the full tree state by just collecting data from the mainnet. This is done by not having any dependency of third parties holding essential data to reconstruct the full state. This feature ensures liveness of the system, meaning that no third party needs to be active in order to provide data to rebuild the state tree. Forging Forging refers to the creation of a batch of layer 2 transactions (off-chain), creation of the proof and the subsequent (on-chain) verification of the attached zk-SNARK. Governance The Hermez Network community intends to follow a strategy of \u201cGovernance minimization\u201d. This model is intended to initially be a bootstrap governance mechanism to adjust and manage some network parameters mainly for security and stability purposes until the network reaches a sufficient degree of maturity to become fully decentralized; at that stage, the initial bootstrap Governance model will no longer be necessary and will eventually disappear. The network will start with a governance based on a Community Council formed by some distributed and known Ethereum community members. This council will delegate some specific network parameters adjustments into a reduced Bootstrap Council, which is non custodial, in order to be more operationally effective in the initial phase. Some decisions that the initial Community Council will be able to make will be: Governance and policies related changes Upgrade, maintenance and updates of the smart contracts code and/or circuits. The bootstrap Council will be enabled to change some of the initial parameters of the Hermez smart contracts such as: Minimum bidding amount for the slots auction series; Days an auction is open for and slots before closing auction; Value of the outbidding variable; Boot Coordinator maximum cap reward reduction. HEZ Hermez has its own network token: HEZ. HEZ is an ERC-20 utility token used to place bids in the Coordinators auction. Every time a rollup batch is created, a fraction of HEZ tokens placed during the proof-of-donation auction will be burned, and therefore permanently removed. L1 Ethereum Layer-1 blockchain L2 Hermez Layer-2 blockchain Proof of Donation Bidding mechanism to select the coordinator for upcoming batches. A fraction of the winning bid goes back to be reinvested in the protocols and services that run on top of Ethereum. System Parameters Set of parameters defined in the system that allow certain configuration from governance in order to modify the behavior of the network. Transactions Transactions is the generic name given to every operation in the Hermez Network. Transactions may be initiated by a user or by the coordinator. Transactions may also happen on L1 or L2. The coordinator node is in charge of collecting and processing transactions in batches generating a ZK-SNARK to prove that the transactions have been carried out according to some rules. Atomic Transactions Hermez provides the capability for some transactions to be processed together. This feature is called Atomic Transactions. Trees Hermez uses Sparse Merkle Trees to store the state of the Hermez Network. There are two main tree structures: - State Tree - Exit Tree State Tree Merkle tree used to represent the whole zkRollup state which is summarized by its root. Each leaf of the state tree represents an account, and contains data such us balance, ethereum Address or type of token stored in this account. Exit Tree Each batch has an associated exit tree with all the exits performed by the user (either L1 or L2 exit transactions). User needs to prove that it owns a leaf in the exit tree in order to perform a withdrawal and get the tokens back. This verification could be done either by submitting a Merkle tree proof or by submitting a zkProof. Exit & Withdrawal In order to transfer funds from the L2 account to the Ethereum account, two separate transactions are invoked. The first transaction is Exit, where funds are transferred to a smart contract. The second transaction is Withdrawal. If conditions are met, Withdrawal can be instant. If funds to be withdrawn exceed certain limits, the Withdrawal is delayed until the transaction is cleared. zk-Rollup A zk-Rollup is a layer 2 construction\u200a\u200awhich uses the Ethereum blockchain for data storage instead of computation. All funds are held by a smart contract on the main-chain. For every batch, a zk-snark is generated off-chain and verified by this contract. This snark proves the validity of every transaction in the batch. zk-SNARK A zk-SNARK is a short (and efficiently checkable) cryptographic proof that allows to prove something specific without revealing any extra information.","title":"Glossary"},{"location":"Hermez_1.0/developers/glossary/#glossary","text":"","title":"Glossary"},{"location":"Hermez_1.0/developers/glossary/#auction","text":"Selection of the coordinator is done via an auction process managed by a smart contract. The node with the highest bid in an open slot will earn the right to forge new batches and collect the fees from the transactions included in the batch. This auction is the process by which Hermez Network reaches a consensus on which node shall play the role of coordinator in an upcoming slot.","title":"Auction"},{"location":"Hermez_1.0/developers/glossary/#babyjubjub","text":"BabyJubJub is an elliptic curve defined over a large prime field. It's useful in zk-SNARKs proofs.","title":"BabyJubJub"},{"location":"Hermez_1.0/developers/glossary/#batch","text":"A batch is a rollup block. It is formed by a set of transactions that determines a state transition of the Hermez accounts and sets an exit tree. Batches can be: - L2-Batch: The set of transactions are only L2 - L1-L2 Batch: The set of transactions are L1 or L2","title":"Batch"},{"location":"Hermez_1.0/developers/glossary/#coordinator","text":"A coordinator is our term for rollup block producer. At any one time there is one coordinator responsible for collecting transactions and creating blocks on the rollup chain.","title":"Coordinator"},{"location":"Hermez_1.0/developers/glossary/#data-availability","text":"Hermez approach determines that anyone can reconstruct the full tree state by just collecting data from the mainnet. This is done by not having any dependency of third parties holding essential data to reconstruct the full state. This feature ensures liveness of the system, meaning that no third party needs to be active in order to provide data to rebuild the state tree.","title":"Data Availability"},{"location":"Hermez_1.0/developers/glossary/#forging","text":"Forging refers to the creation of a batch of layer 2 transactions (off-chain), creation of the proof and the subsequent (on-chain) verification of the attached zk-SNARK.","title":"Forging"},{"location":"Hermez_1.0/developers/glossary/#governance","text":"The Hermez Network community intends to follow a strategy of \u201cGovernance minimization\u201d. This model is intended to initially be a bootstrap governance mechanism to adjust and manage some network parameters mainly for security and stability purposes until the network reaches a sufficient degree of maturity to become fully decentralized; at that stage, the initial bootstrap Governance model will no longer be necessary and will eventually disappear. The network will start with a governance based on a Community Council formed by some distributed and known Ethereum community members. This council will delegate some specific network parameters adjustments into a reduced Bootstrap Council, which is non custodial, in order to be more operationally effective in the initial phase. Some decisions that the initial Community Council will be able to make will be: Governance and policies related changes Upgrade, maintenance and updates of the smart contracts code and/or circuits. The bootstrap Council will be enabled to change some of the initial parameters of the Hermez smart contracts such as: Minimum bidding amount for the slots auction series; Days an auction is open for and slots before closing auction; Value of the outbidding variable; Boot Coordinator maximum cap reward reduction.","title":"Governance"},{"location":"Hermez_1.0/developers/glossary/#hez","text":"Hermez has its own network token: HEZ. HEZ is an ERC-20 utility token used to place bids in the Coordinators auction. Every time a rollup batch is created, a fraction of HEZ tokens placed during the proof-of-donation auction will be burned, and therefore permanently removed.","title":"HEZ"},{"location":"Hermez_1.0/developers/glossary/#l1","text":"Ethereum Layer-1 blockchain","title":"L1"},{"location":"Hermez_1.0/developers/glossary/#l2","text":"Hermez Layer-2 blockchain","title":"L2"},{"location":"Hermez_1.0/developers/glossary/#proof-of-donation","text":"Bidding mechanism to select the coordinator for upcoming batches. A fraction of the winning bid goes back to be reinvested in the protocols and services that run on top of Ethereum.","title":"Proof of Donation"},{"location":"Hermez_1.0/developers/glossary/#system-parameters","text":"Set of parameters defined in the system that allow certain configuration from governance in order to modify the behavior of the network.","title":"System Parameters"},{"location":"Hermez_1.0/developers/glossary/#transactions","text":"Transactions is the generic name given to every operation in the Hermez Network. Transactions may be initiated by a user or by the coordinator. Transactions may also happen on L1 or L2. The coordinator node is in charge of collecting and processing transactions in batches generating a ZK-SNARK to prove that the transactions have been carried out according to some rules.","title":"Transactions"},{"location":"Hermez_1.0/developers/glossary/#atomic-transactions","text":"Hermez provides the capability for some transactions to be processed together. This feature is called Atomic Transactions.","title":"Atomic Transactions"},{"location":"Hermez_1.0/developers/glossary/#trees","text":"Hermez uses Sparse Merkle Trees to store the state of the Hermez Network. There are two main tree structures: - State Tree - Exit Tree","title":"Trees"},{"location":"Hermez_1.0/developers/glossary/#state-tree","text":"Merkle tree used to represent the whole zkRollup state which is summarized by its root. Each leaf of the state tree represents an account, and contains data such us balance, ethereum Address or type of token stored in this account.","title":"State Tree"},{"location":"Hermez_1.0/developers/glossary/#exit-tree","text":"Each batch has an associated exit tree with all the exits performed by the user (either L1 or L2 exit transactions). User needs to prove that it owns a leaf in the exit tree in order to perform a withdrawal and get the tokens back. This verification could be done either by submitting a Merkle tree proof or by submitting a zkProof.","title":"Exit Tree"},{"location":"Hermez_1.0/developers/glossary/#exit-withdrawal","text":"In order to transfer funds from the L2 account to the Ethereum account, two separate transactions are invoked. The first transaction is Exit, where funds are transferred to a smart contract. The second transaction is Withdrawal. If conditions are met, Withdrawal can be instant. If funds to be withdrawn exceed certain limits, the Withdrawal is delayed until the transaction is cleared.","title":"Exit &amp; Withdrawal"},{"location":"Hermez_1.0/developers/glossary/#zk-rollup","text":"A zk-Rollup is a layer 2 construction\u200a\u200awhich uses the Ethereum blockchain for data storage instead of computation. All funds are held by a smart contract on the main-chain. For every batch, a zk-snark is generated off-chain and verified by this contract. This snark proves the validity of every transaction in the batch.","title":"zk-Rollup"},{"location":"Hermez_1.0/developers/glossary/#zk-snark","text":"A zk-SNARK is a short (and efficiently checkable) cryptographic proof that allows to prove something specific without revealing any extra information.","title":"zk-SNARK"},{"location":"Hermez_1.0/developers/price-updater/","text":"Price Updater Price Updater is a web service used to consult and update the tokens and fiat currency used by Hermez Node. Installation $ git clone git@github.com:hermeznetwork/price-updater-service.git $ cd price-updater-service/ $ go build -o priceupdater # or other name that you want Pre-requirements It is necessary to have write access to a Hermez node database. The Price updater will update the prices and write them to the database. You need an API Key from https://exchangeratesapi.io/ Usage Configure .env file in the price-updater main folder. Below there is an example of and .env file. HTTP_HOST=\"0.0.0.0\" HTTP_PORT=8037 # POSTGRES information POSTGRES_USER=\"hermez\" POSTGRES_PASSWORD=\"yourpasswordhere\" POSTGRES_HOST=\"localhost\" POSTGRES_PORT=5432 POSTGRES_DATABASE=\"hermez\" POSTGRES_SSL_ENABLED=false POSTGRES_MAX_ID_CONNS=10 POSTGRES_MAX_OPEN_CONNS=10 # ETHEREUM NODE URL ETH_NETWORK=\"http://localhost:8545\" # ROLLUP SMART CONTRACT ADDRESS ETH_HEZ_ROLLUP=\"0xA68D85dF56E733A06443306A095646317B5Fa633\" ETH_USDT_ADDRESS=\"0xa1A31DE489C9b977fa78c70C7f001da181e126FB\" # API KEY from https://exchangeratesapi.io/`. FIAT_API_KEY=\"ffffffffffffffffffffffffffff\" BBOLT_LOCATION=\"priceupdater.db\" MAIN_TIME_TO_UPDATE_PRICES=1m POSTGRES_USER , POSTGRES_PASSWORD , POSTGRES_HOST and POSTGRES_PORT can be extracted from the Hermez node configuration file Configure provider priority. Providers are selected in order. ./priceupdater change-priority --priority \"bitfinex,coingecko,uniswap\" Price Updater provides configurations files to use Bitfinex, Coingecko and Uniswap as providers depending on the network. 3. Update provided configuration ./priceupdater update-config --provider bitfinex --configFile assets/testnet/bitfinex.json ./priceupdater update-config --provider coingecko --configFile assets/testnet/coingecko.json ./priceupdater update-config --provider uniswap --configFile assets/testnet/uniswap.json Set up an apiKey to accept incoming requests ./priceupdater setup-apikey --apiKey \"pr1c3upd4t3rw Start server ./priceupdater server If everything went well, you should see the following output: 2021-08-16T14:41:32Z INFO cli/server.go:33 connection established with postgresql server \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Fiber v2.14.0 \u2502 \u2502 http://127.0.0.1:8037 \u2502 \u2502 (bound on host 0.0.0.0 and port 8037) \u2502 \u2502 \u2502 \u2502 Handlers ............ 12 Processes ........... 1 \u2502 \u2502 Prefork ....... Disabled PID ............ 120438 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Polygon Hermez NodePrice Updater"},{"location":"Hermez_1.0/developers/price-updater/#price-updater","text":"Price Updater is a web service used to consult and update the tokens and fiat currency used by Hermez Node.","title":"Price Updater"},{"location":"Hermez_1.0/developers/price-updater/#installation","text":"$ git clone git@github.com:hermeznetwork/price-updater-service.git $ cd price-updater-service/ $ go build -o priceupdater # or other name that you want","title":"Installation"},{"location":"Hermez_1.0/developers/price-updater/#pre-requirements","text":"It is necessary to have write access to a Hermez node database. The Price updater will update the prices and write them to the database. You need an API Key from https://exchangeratesapi.io/","title":"Pre-requirements"},{"location":"Hermez_1.0/developers/price-updater/#usage","text":"Configure .env file in the price-updater main folder. Below there is an example of and .env file. HTTP_HOST=\"0.0.0.0\" HTTP_PORT=8037 # POSTGRES information POSTGRES_USER=\"hermez\" POSTGRES_PASSWORD=\"yourpasswordhere\" POSTGRES_HOST=\"localhost\" POSTGRES_PORT=5432 POSTGRES_DATABASE=\"hermez\" POSTGRES_SSL_ENABLED=false POSTGRES_MAX_ID_CONNS=10 POSTGRES_MAX_OPEN_CONNS=10 # ETHEREUM NODE URL ETH_NETWORK=\"http://localhost:8545\" # ROLLUP SMART CONTRACT ADDRESS ETH_HEZ_ROLLUP=\"0xA68D85dF56E733A06443306A095646317B5Fa633\" ETH_USDT_ADDRESS=\"0xa1A31DE489C9b977fa78c70C7f001da181e126FB\" # API KEY from https://exchangeratesapi.io/`. FIAT_API_KEY=\"ffffffffffffffffffffffffffff\" BBOLT_LOCATION=\"priceupdater.db\" MAIN_TIME_TO_UPDATE_PRICES=1m POSTGRES_USER , POSTGRES_PASSWORD , POSTGRES_HOST and POSTGRES_PORT can be extracted from the Hermez node configuration file Configure provider priority. Providers are selected in order. ./priceupdater change-priority --priority \"bitfinex,coingecko,uniswap\" Price Updater provides configurations files to use Bitfinex, Coingecko and Uniswap as providers depending on the network. 3. Update provided configuration ./priceupdater update-config --provider bitfinex --configFile assets/testnet/bitfinex.json ./priceupdater update-config --provider coingecko --configFile assets/testnet/coingecko.json ./priceupdater update-config --provider uniswap --configFile assets/testnet/uniswap.json Set up an apiKey to accept incoming requests ./priceupdater setup-apikey --apiKey \"pr1c3upd4t3rw Start server ./priceupdater server If everything went well, you should see the following output: 2021-08-16T14:41:32Z INFO cli/server.go:33 connection established with postgresql server \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Fiber v2.14.0 \u2502 \u2502 http://127.0.0.1:8037 \u2502 \u2502 (bound on host 0.0.0.0 and port 8037) \u2502 \u2502 \u2502 \u2502 Handlers ............ 12 Processes ........... 1 \u2502 \u2502 Prefork ....... Disabled PID ............ 120438 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Usage"},{"location":"Hermez_1.0/developers/sdk/","text":"Examples Some Golang and Javascript integration examples are provided as a reference. They can be found at: - Hermez Golang examples - Hermez Javascript examples Additionally, Hermez Mobile SDK example provides an example of how to import and use the Mobile SDK. SDK A full Javascript SDK and a Flutter Plugin for Hermez Mobile SDK are provided as part of the tools for integration with Hermez Network. HermezJS is an open-source SDK to interact with Hermez Rollup network. It can be downloaded as an npm package , or via github . Hermez Flutter SDK is a Flutter Plugin for Hermez Mobile SDK, and provides a cross-platform tool (iOS, Android) to communicate with the Hermez API and network. There is an additional Golang SDK to interact with Hermez using Golang. SDK How-To (Javascript) In this tutorial we will walk through the process of using the SDK to: 1. Installing Hermezjs 2. Initializing Hermezjs 3. Check registered tokens 4. Creating a wallet 5. Making a deposit from Ethereum into the Hermez Network 6. Verifying the balance in a Hermez account 7. Withdrawing funds back to Ethereum network 8. Making transfers 9. Verifying transaction status 10. Authorizing the creation of Hermez accounts 11. Internal accounts Install Hermezjs npm i @hermeznetwork/hermezjs Import modules Load Hermezjs library const hermez = require('@hermeznetwork/hermezjs') Initialization Create Transaction Pool Initialize the storage where user transactions are stored. This needs to be initialized at the start of your application. hermez.TxPool.initializeTransactionPool() Configure Hermez Environment In these examples, we are going to connect to Hermez Testnet which is deployed in Rinkeby Ethereum Network. To configure Hermezjs to work with the Testnet, we need to configure a Rinkeby Ethereum node, the Hermez API URL, and the addresses of the Hermez and Withdrawal Delayer smart contracts. Hermez Testnet API URL is deployed at https://api.testnet.hermez.io/v1. NOTE: In order to interact with Hermez Testnet, you will need to supply your own Rinkeby Ethereum node. You can check these links to help you set up a Rinkeby node (https://blog.infura.io/getting-started-with-infura-28e41844cc89, https://blog.infura.io/getting-started-with-infuras-ethereum-api). Currently, Testnet Hermez smart contract is deployed at address 0x14a3b6f3328766c7421034e14472f5c14c5ba090 and Withdrawal Delayer contract is deployed at address 0x6ea0abf3ef52d24427043cad3ec26aa4f2c8e8fd . These addresses could change in the future, so please check these addresses with a query of the API using the browser. For the remainder of the examples, we will configure the basic Hermezjs parameters const EXAMPLES_WEB3_URL = 'https://rinkeby.infura.io/v3/80496a41d0a134ccbc6e856ffd034696' const EXAMPLES_HERMEZ_API_URL = 'https://api.testnet.hermez.io' const EXAMPLES_HERMEZ_ROLLUP_ADDRESS = '0x14a3b6f3328766c7421034e14472f5c14c5ba090' const EXAMPLES_HERMEZ_WDELAYER_ADDRESS = '0x6ea0abf3ef52d24427043cad3ec26aa4f2c8e8fd' hermez.Providers.setProvider(EXAMPLES_WEB3_URL) hermez.Environment.setEnvironment({ baseApiUrl: EXAMPLES_HERMEZ_API_URL, contractAddresses: { [hermez.Constants.ContractNames.Hermez]: EXAMPLES_HERMEZ_ROLLUP_ADDRESS, [hermez.Constants.ContractNames.WithdrawalDelayer]: EXAMPLES_HERMEZ_WDELAYER_ADDRESS } }) Check token exists in Hermez Network Before being able to operate on the Hermez Network, we must ensure that the token we want to operate with is listed. For that we make a call to the Hermez Coordinator API that will list all available tokens. All tokens in Hermez Network must be ERC20. We can see there are 2 tokens registered. ETH will always be configured at index 0. The second token is HEZ . For the rest of the examples we will work with ETH . In the future, more tokens will be included in Hermez. const token = await hermez.CoordinatorAPI.getTokens() const tokenERC20 = token.tokens[0] console.log(token) >>>> { tokens: [ { itemId: 1, id: 0, ethereumBlockNum: 0, ethereumAddress: '0x0000000000000000000000000000000000000000', name: 'Ether', symbol: 'ETH', decimals: 18, USD: 1787, fiatUpdate: '2021-02-28T18:55:17.372008Z' }, { itemId: 2, id: 1, ethereumBlockNum: 8153596, ethereumAddress: '0x2521bc90b4f5fb9a8d61278197e5ff5cdbc4fbf2', name: 'Hermez Network Token', symbol: 'HEZ', decimals: 18, USD: 5.365, fiatUpdate: '2021-02-28T18:55:17.386805Z' } ], pendingItems: 0 Create a Wallet We can create a new Hermez wallet by providing the Ethereum private key of an Ethereum account. This wallet will store the Ethereum and Baby JubJub keys for the Hermez account. The Ethereum address is used to authorize L1 transactions, and the Baby JubJub key is used to authorize L2 transactions. We will create two wallets. NOTE You will need to supply two Rinkeby private keys to initialize both accounts. The keys provided here are invalid and are shown as an example. const EXAMPLES_PRIVATE_KEY1 = 0x705d123e707e25fa37ca84461ac6eb83eb4921b65680cfdc594b60bea1bb4e52 const EXAMPLES_PRIVATE_KEY2 = 0x3a9270c05ac169097808da4b02e8f9146be0f8a38cfad3dcfc0b398076381fdd // load first account const wallet = await hermez.HermezWallet.createWalletFromEtherAccount(EXAMPLES_WEB3_URL, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY1 }) const hermezWallet = wallet.hermezWallet const hermezEthereumAddress = wallet.hermezEthereumAddress // load second account const wallet2 = await hermez.HermezWallet.createWalletFromEtherAccount(EXAMPLES_WEB3_URL, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY2 }) const hermezWallet2 = wallet2.hermezWallet const hermezEthereumAddress2 = wallet2.hermezEthereumAddress Deposit Tokens from Ethereum into Hermez Network Creating a Hermez account and depositing tokens is done simultaneously as an L1 transaction. In this example we are going to deposit 1 ETH tokens into the newly created Hermez accounts. // set amount to deposit const amountDepositString = '1.0' const amountDeposit = hermez.Utils.getTokenAmountBigInt(amountDepositString, 18) const compressedDepositAmount = hermez.HermezCompressedAmount.compressAmount(amountDeposit) // perform deposit account 1 await hermez.Tx.deposit( compressedDepositAmount, hermezEthereumAddress, tokenERC20, hermezWallet.publicKeyCompressedHex, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY1 } ) // perform deposit account 2 await hermez.Tx.deposit( compressedDepositAmount, hermezEthereumAddress2, tokenERC20, hermezWallet2.publicKeyCompressedHex, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY2 } ) Internally, the deposit funcion calls the Hermez smart contract to add the L1 transaction. Verify Balance A token balance can be obtained by querying the API and passing the hermezEthereumAddress of the Hermez account. // get sender account information const infoAccountSender = (await hermez.CoordinatorAPI.getAccounts(hermezEthereumAddress, [tokenERC20.id])) .accounts[0] // get receiver account information const infoAccountReceiver = (await hermez.CoordinatorAPI.getAccounts(hermezEthereumAddress2, [tokenERC20.id])) .accounts[0] console.log(infoAccountSender) console.log(infoAccountReceiver) >>>>> { accountIndex: 'hez:ETH:4253', balance: '1099600000000000000', bjj: 'hez:dMfPJlK_UtFqVByhP3FpvykOg5kAU3jMLD7OTx_4gwzO', hezEthereumAddress: 'hez:0x74d5531A3400f9b9d63729bA9C0E5172Ab0FD0f6', itemId: 4342, nonce: 1, token: { USD: 1789, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' } } { accountIndex: 'hez:ETH:4254', balance: '1097100000000000000', bjj: 'hez:HESLP_6Kp_nn5ANmSGiOnhhYvF3wF5Davf7xGi6lwh3U', hezEthereumAddress: 'hez:0x12FfCe7D5d6d09564768d0FFC0774218458162d4', itemId: 4343, nonce: 6, token: { USD: 1789, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' } } We can see that the field accountIndex is formed by the token symbol it holds and an index. A Hermez account can only hold one type of token. Account indexes start at 256. Indexes 0-255 are reserved for internal use. Note that the balances do not match with the ammount deposited of 1 ETH because accounts already existed in Hermez Network before the deposit, so we performed a deposit on top instead. Alternatively, an account query can be filtered using the assigned accountIndex const account1ByIdx = await hermez.CoordinatorAPI.getAccount(infoAccountSender.accountIndex) const account2ByIdx = await hermez.CoordinatorAPI.getAccount(infoAccountReceiver.accountIndex) console.log(account1ByIdx) console.log(account2ByIdx) >>>>> { accountIndex: 'hez:ETH:4253', balance: '1099600000000000000', bjj: 'hez:dMfPJlK_UtFqVByhP3FpvykOg5kAU3jMLD7OTx_4gwzO', hezEthereumAddress: 'hez:0x74d5531A3400f9b9d63729bA9C0E5172Ab0FD0f6', itemId: 4342, nonce: 1, token: { USD: 1789, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' } } { accountIndex: 'hez:ETH:4254', balance: '1097100000000000000', bjj: 'hez:HESLP_6Kp_nn5ANmSGiOnhhYvF3wF5Davf7xGi6lwh3U', hezEthereumAddress: 'hez:0x12FfCe7D5d6d09564768d0FFC0774218458162d4', itemId: 4343, nonce: 6, token: { USD: 1789, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' } } Withdrawing Withdrawing funds is a two step process: 1. Exit 2. Withdrawal Exit The Exit transaction is used as a first step to retrieve the funds from Hermez Network back to Ethereum. There are two types of Exit transactions: - Normal Exit, referred as Exit from now on. This is a L2 transaction type. - Force Exit , an L1 transaction type which has extended guarantees that will be processed by the Coordinator. We will talk more about Force Exit here The Exit is requested as follows: // set amount to exit const amountExit = hermez.HermezCompressedAmount.compressAmount(hermez.Utils.getTokenAmountBigInt('1.0', 18)) // set fee in transaction const state = await hermez.CoordinatorAPI.getState() const userFee = state.recommendedFee.existingAccount // generate L2 transaction const l2ExitTx = { type: 'Exit', from: infoAccountSender.accountIndex, amount: amountExit, fee: userFee } const exitResponse = await hermez.Tx.generateAndSendL2Tx(l2ExitTx, hermezWallet, infoAccountSender.token) console.log(exitResponse) >>>> { status: 200, id: '0x0257305cdc43060a754a5c2ea6b0e0f6e28735ea8e75d841ca4a7377aa099d91b7', nonce: 2 } After submitting our Exit request to the Coordinator, we can check the status of the transaction by calling the Coordinator's Transaction Pool. The Coordinator's transaction pool stores all those transactions that are waiting to be forged. const txPool = await hermez.CoordinatorAPI.getPoolTransaction(exitResponse.id) console.log(txPool) >>>>> { amount: '1000000000000000000', fee: 204, fromAccountIndex: 'hez:ETH:4253', fromBJJ: 'hez:dMfPJlK_UtFqVByhP3FpvykOg5kAU3jMLD7OTx_4gwzO', fromHezEthereumAddress: 'hez:0x74d5531A3400f9b9d63729bA9C0E5172Ab0FD0f6', id: '0x0257305cdc43060a754a5c2ea6b0e0f6e28735ea8e75d841ca4a7377aa099d91b7', info: null, nonce: 2, requestAmount: null, requestFee: null, requestFromAccountIndex: null, requestNonce: null, requestToAccountIndex: null, requestToBJJ: null, requestToHezEthereumAddress: null, requestTokenId: null, signature: '38f23d06826be8ea5a0893ee67f4ede885a831523c0c626c102edb05e1cf890e418b5820e3e6d4b530386d0bc84b3c3933d655527993ad77a55bb735d5a67c03', state: 'pend', timestamp: '2021-03-16T12:31:50.407428Z', toAccountIndex: 'hez:ETH:1', toBjj: null, toHezEthereumAddress: null, token: { USD: 1781.9, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' }, type: 'Exit' } We can see the state field is set to pend (meaning pending). There are 4 possible states: 1. pend : Pending 2. fging : Forging 3. fged : Forged 4. invl : Invalid If we continue polling the Coordinator about the status of the transaction, the state will eventually be set to fged . We can also query the Coordinator to check whether or not our transaction has been forged. getHistoryTransaction reports those transactions that have been forged by the Coordinator. const txExitConf = await hermez.CoordinatorAPI.getHistoryTransaction(txExitPool.id) console.log(txExitConf) And we can confirm our account status and check that the correct amount has been transfered out of the account. console.log((await hermez.CoordinatorAPI.getAccounts(hermezEthereumAddress, [tokenERC20.id])) .accounts[0]) Withdrawing Funds from Hermez After doing any type of Exit transaction, which moves the user's funds from their token account to a specific Exit Merkle tree, one needs to do a Withdraw of those funds to an Ethereum L1 account. To do a Withdraw we need to indicate the accountIndex that includes the Ethereum address where the funds will be transferred, the amount and type of tokens, and some information to verify the ownership of those tokens. Additionally, there is one boolean flag. If set to true, the Withdraw will be instantaneous. const exitInfoN = (await hermez.CoordinatorAPI.getExits(infoAccountSender.hezEthereumAddress, true)).exits const exitInfo = exitInfoN[exitInfoN.length - 1] // set to perform instant withdraw const isInstant = true // perform withdraw await hermez.Tx.withdraw( exitInfo.balance, exitInfo.accountIndex, exitInfo.token, hermezWallet.publicKeyCompressedHex, exitInfo.batchNum, exitInfo.merkleProof.siblings, isInstant, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY1 } ) The funds should now appear in the Ethereum account that made the withdrawal. Force Exit This is the L1 equivalent of an Exit. With this option, the smart contract forces Coordinators to pick up L1 transactions before they pick up L2 transactions to ensure that L1 transactions will eventually be picked up. This is a security measure. We don't expect users to need to make a Force Exit. // set amount to force-exit const amountForceExit = hermez.HermezCompressedAmount.compressAmount(hermez.Utils.getTokenAmountBigInt('1.0', 18)) // perform force-exit await hermez.Tx.forceExit( amountForceExit, infoAccountSender.accountIndex, tokenERC20, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY1 } ) The last step to recover the funds will be to send a new Withdraw request to the smart contract as we did after the regular Exit request. ```js const exitInfoN = (await hermez.CoordinatorAPI.getExits(infoAccountSender.hezEthereumAddress, true)).exits const exitInfo = exitInfoN[exitInfoN.length - 1] // set to perform instant withdraw const isInstant = true // perform withdraw await hermez.Tx.withdraw( exitInfo.balance, exitInfo.accountIndex, exitInfo.token, hermezWallet.publicKeyCompressedHex, exitInfo.batchNum, exitInfo.merkleProof.siblings, isInstant, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY1 } ) Transfers First, we compute the fees for the transaction. For this we consult the recommended fees from the Coordinator. // fee computation const state = await hermez.CoordinatorAPI.getState() console.log(state.recommendedFee) >>>> { existingAccount: 96.34567219671051, createAccount: 192.69134439342102, createAccountInternal: 240.86418049177627 } The returned fees are the suggested fees for different transactions: - existingAccount : Make a transfer to an existing account - createAccount : Make a transfer to a non-existent account, and create a regular account - createAccountInternal : Make a transfer to an non-existent account and create internal account The fee amounts are given in USD. However, fees are payed in the token of the transaction. So, we need to do a conversion. const usdTokenExchangeRate = tokenERC20.USD const fee = fees.existingAccount / usdTokenExchangeRate Finally we make the final transfer transaction. // set amount to transfer const amountTransfer = hermez.HermezCompressedAmount.compressAmount(hermez.Utils.getTokenAmountBigInt('1.0', 18)) // generate L2 transaction const l2TxTransfer = { from: infoAccountSender.accountIndex, to: infoAccountReceiver.accountIndex, amount: amountTransfer, fee: fee } const transferResponse = await hermez.Tx.generateAndSendL2Tx(l2TxTransfer, hermezWallet, infoAccountSender.token) console.log(transferResponse) >>>>> { status: 200, id: '0x02e7c2c293173f21249058b1d71afd5b1f3c0de4f1a173bac9b9aa4a2d149483a2', nonce: 3 } The result status 200 shows that transaction has been correctly received. Additionally, we receive the nonce matching the transaction we sent, and an id that we can use to verify the status of the transaction either using hermez.CoordinatorAPI.getHistoryTransaction() or hermez.CoordinatorAPI.getPoolTransaction() . As we saw with the Exit transaction, every transaction includes a \u00b4nonce\u00b4. This nonce is a protection mechanism to avoid replay attacks. Every L2 transaction will increase the nonce by 1. Verifying Transaction Status Transactions received by the Coordinator will be stored in its transaction pool while they haven't been processed. To check a transaction in the transaction pool we make a query to the Coordinator node. const txXferPool = await hermez.CoordinatorAPI.getPoolTransaction(transferResponse.id) console.log(txXferPool) >>>>> { amount: '100000000000000', fee: 202, fromAccountIndex: 'hez:ETH:4253', fromBJJ: 'hez:dMfPJlK_UtFqVByhP3FpvykOg5kAU3jMLD7OTx_4gwzO', fromHezEthereumAddress: 'hez:0x74d5531A3400f9b9d63729bA9C0E5172Ab0FD0f6', id: '0x02e7c2c293173f21249058b1d71afd5b1f3c0de4f1a173bac9b9aa4a2d149483a2', info: null, nonce: 3, requestAmount: null, requestFee: null, requestFromAccountIndex: null, requestNonce: null, requestToAccountIndex: null, requestToBJJ: null, requestToHezEthereumAddress: null, requestTokenId: null, signature: 'c9e1a61ce2c3c728c6ec970ae646b444a7ab9d30aa6015eb10fb729078c1302978fe9fb0419b4d944d4f11d83582043a48546dff7dda22de7c1e1da004cd5401', state: 'pend', timestamp: '2021-03-16T13:20:33.336469Z', toAccountIndex: 'hez:ETH:4254', toBjj: 'hez:HESLP_6Kp_nn5ANmSGiOnhhYvF3wF5Davf7xGi6lwh3U', toHezEthereumAddress: 'hez:0x12FfCe7D5d6d09564768d0FFC0774218458162d4', token: { USD: 1786, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' }, type: 'Transfer' } We can also check directly with the Coordinator in the database of forged transactions. const transferConf = await hermez.CoordinatorAPI.getHistoryTransaction(transferResponse.id) console.log(transferConf) >>>>> { L1Info: null, L1orL2: 'L2', L2Info: { fee: 202, historicFeeUSD: 182.8352, nonce: 3 }, amount: '100000000000000', batchNum: 4724, fromAccountIndex: 'hez:ETH:4253', fromBJJ: 'hez:dMfPJlK_UtFqVByhP3FpvykOg5kAU3jMLD7OTx_4gwzO', fromHezEthereumAddress: 'hez:0x74d5531A3400f9b9d63729bA9C0E5172Ab0FD0f6', historicUSD: 0.17855, id: '0x02e7c2c293173f21249058b1d71afd5b1f3c0de4f1a173bac9b9aa4a2d149483a2', itemId: 14590, position: 1, timestamp: '2021-03-16T13:24:48Z', toAccountIndex: 'hez:ETH:4254', toBJJ: 'hez:HESLP_6Kp_nn5ANmSGiOnhhYvF3wF5Davf7xGi6lwh3U', toHezEthereumAddress: 'hez:0x12FfCe7D5d6d09564768d0FFC0774218458162d4', token: { USD: 1787.2, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' }, type: 'Transfer' } At this point, the balances in both accounts will be updated with the result of the transfer // check balances console.log((await hermez.CoordinatorAPI.getAccounts(wallet.hermezEthereumAddress, [tokenERC20.id])).accounts[0]) console.log((await hermez.CoordinatorAPI.getAccounts(wallet2.hermezEthereumAddress2, [tokenERC20.id])).accounts[0]) >>>>> { accountIndex: 'hez:ETH:4253', balance: '477700000000000000', bjj: 'hez:dMfPJlK_UtFqVByhP3FpvykOg5kAU3jMLD7OTx_4gwzO', hezEthereumAddress: 'hez:0x74d5531A3400f9b9d63729bA9C0E5172Ab0FD0f6', itemId: 4342, nonce: 4, token: { USD: 1793, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' } } { accountIndex: 'hez:ETH:256', balance: '1874280899837791518', bjj: 'hez:YN2DmRh0QgDrxz3NLDqH947W5oNys7YWqkxsQmFVeI_m', hezEthereumAddress: 'hez:0x9F255048EC1141831A28019e497F3f76e559356E', itemId: 1, nonce: 2, token: { USD: 1793, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' } } Create Account Authorization Imagine that Bob wants to send a transfer of Ether to Mary using Hermez, but Mary only has an Ethereum account but no Hermez account. To complete this transfer, Mary could open a Hermez account and proceed as the previous transfer example. Alternatively, Mary could authorize the Coordinator to create a Hermez account on her behalf so that she can receive Bob's transfer. First we create a wallet for Mary: // load second account const wallet3 = await hermez.HermezWallet.createWalletFromEtherAccount(EXAMPLES_WEB3_URL, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY3 }) const hermezWallet3 = wallet3.hermezWallet const hermezEthereumAddress3 = wallet3.hermezEthereumAddress The authorization for the creation of a Hermez account is done using the private key stored in the newly created Hermez wallet. Note that the account is not created at this moment. The account will be created when Bob performs the transfer. Also, it is Bob that pays for the fees associated with the account creation. const EXAMPLES_PRIVATE_KEY3 = '0x3d228fed4dc371f56b8f82f66ff17cd6bf1da7806d7eabb21810313dee819a53' const signature = await hermezWallet3.signCreateAccountAuthorization(EXAMPLES_WEB3_URL, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY3 }) const res = await hermez.CoordinatorAPI.postCreateAccountAuthorization( hermezWallet3.hermezEthereumAddress, hermezWallet3.publicKeyBase64, signature ) We can find out if the Coordinator has been authorized to create a Hermez account on behalf of a user by: const authResponse = await hermez.CoordinatorAPI.getCreateAccountAuthorization(wallet3.hermezEthereumAddress) console.log(authResponse) >>>> { hezEthereumAddress: 'hez:0xd3B6DcfCA7Eb3207905Be27Ddfa69453625ffbf9', bjj: 'hez:ct0ml6FjdUN6uGUHZ70qOq5-58cZ19SJDeldMH021oOk', signature: '0x22ffc6f8d569a92c48a4e784a11a9e57b840fac21eaa7fedc9dc040c4a45d502744a35eeb0ab173234c0f687b252bd0364647bff8db270ffcdf1830257de28e41c', timestamp: '2021-03-16T14:56:05.295946Z' } Once we verify the receiving Ethereum account has authorized the creation of a Hermez account, we can proceed with the transfer from Bob's account to Mary's account. For this, we set the destination address to Mary's Ethereum address and set the fee using the createAccount value. // set amount to transfer const amountTransferAuth = hermez.HermezCompressedAmount.compressAmount(hermez.Utils.getTokenAmountBigInt('1.0', 18)) // generate L2 transaction const l2AuthTxTransfer = { from: infoAccountSender.accountIndex, to: hermezWallet3.hermezEthereumAddress amount: amountTransferAuth, fee: state.recommendedFee.createAccount / usdTokenExchangeRate } const accountAuthTransferResponse = await hermez.Tx.generateAndSendL2Tx(l2AuthTxTransfer, hermezWallet, infoAccountSender.token) console.log(accountAuthTransferResponse) >>>>> { status: 200, id: '0x025398af5b69f132d8c2c5b7b225df1436baf7d1774a6b017a233bf273b4675c8f', nonce: 0 } After the transfer has been forged, we can check Mary's account on Hermez // get receiver account information const infoAccountAuth = (await hermez.CoordinatorAPI.getAccounts(hermezWallet3.hermezEthereumAddress, [tokenERC20.id])) .accounts[0] console.log(infoAccountAuth) >>>>> { accountIndex: 'hez:ETH:265', balance: '1000000000000000', bjj: 'hez:ct0ml6FjdUN6uGUHZ70qOq5-58cZ19SJDeldMH021oOk', hezEthereumAddress: 'hez:0xd3B6DcfCA7Eb3207905Be27Ddfa69453625ffbf9', itemId: 10, nonce: 0, token: { USD: 1795.94, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-03-16T14:56:57.460862Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' } } Create Internal Accounts Until now we have seen that accounts have an Ethereum address and a Baby JubJub key. This is the case for normal accounts. However, there is a second type of account that only requires a Baby JubJub key. These accounts are called internal accounts . The advantage of these accounts is that they are much more inexpensive to create than a normal account , since these accounts only exist on Hermez. The downside is that one cannot perform deposits or withdrawals from this type of account. However, there are some scenarios where these accounts are useful. For example, in those scenarios where one requires a temporary account. (for example, Exchanges could use these accounts to receive a transfer from users). // Create Internal Account // create new bjj private key to receive user transactions const pvtBjjKey = Buffer.allocUnsafe(32).fill('1') // create rollup internal account from bjj private key const wallet4 = await hermez.HermezWallet.createWalletFromBjjPvtKey(pvtBjjKey) const hermezWallet4 = wallet4.hermezWallet // set amount to transfer const amountTransferInternal = hermez.HermezCompressedAmount.compressAmount(hermez.Utils.getTokenAmountBigInt('1.0', 18)) // generate L2 transaction const transferToInternal = { from: infoAccountSender.accountIndex, to: hermezWallet4.publicKeyBase64, amount: amountTransferInternal, fee: state.recommendedFee.createAccountInternal / usdTokenExchangeRate } const internalAccountResponse = await hermez.Tx.generateAndSendL2Tx(transferToInternal, hermezWallet, tokenERC20) console.log(internalAccountResponse) >>>>> { status: 200, id: '0x02ac000f39eee60b198c85348443002991753de912337720b9ef85d48e9dcfe83e', nonce: 0 } Once the transaction is forged, we can check the account information // get internal account information const infoAccountInternal = (await hermez.CoordinatorAPI.getAccounts(hermezWallet4.publicKeyBase64, [tokenERC20.id])) .accounts[0] console.log(infoAccountInternal) >>>>>> { accountIndex: 'hez:ETH:259', balance: '1000000000000000000', bjj: 'hez:KmbnR34pOUhSaaPOkeWbaeZVjMqojfyYy8sYIHRSlaKx', hezEthereumAddress: 'hez:0xFFfFfFffFFfffFFfFFfFFFFFffFFFffffFfFFFfF', itemId: 4, nonce: 0, token: { USD: 1798.51, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-03-16T15:44:08.33507Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' } } We can verify it is in fact an internal account because the associated hezEthereumAddress is hez:0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF .","title":"Examples/SDK"},{"location":"Hermez_1.0/developers/sdk/#examples","text":"Some Golang and Javascript integration examples are provided as a reference. They can be found at: - Hermez Golang examples - Hermez Javascript examples Additionally, Hermez Mobile SDK example provides an example of how to import and use the Mobile SDK.","title":"Examples"},{"location":"Hermez_1.0/developers/sdk/#sdk","text":"A full Javascript SDK and a Flutter Plugin for Hermez Mobile SDK are provided as part of the tools for integration with Hermez Network. HermezJS is an open-source SDK to interact with Hermez Rollup network. It can be downloaded as an npm package , or via github . Hermez Flutter SDK is a Flutter Plugin for Hermez Mobile SDK, and provides a cross-platform tool (iOS, Android) to communicate with the Hermez API and network. There is an additional Golang SDK to interact with Hermez using Golang.","title":"SDK"},{"location":"Hermez_1.0/developers/sdk/#sdk-how-to-javascript","text":"In this tutorial we will walk through the process of using the SDK to: 1. Installing Hermezjs 2. Initializing Hermezjs 3. Check registered tokens 4. Creating a wallet 5. Making a deposit from Ethereum into the Hermez Network 6. Verifying the balance in a Hermez account 7. Withdrawing funds back to Ethereum network 8. Making transfers 9. Verifying transaction status 10. Authorizing the creation of Hermez accounts 11. Internal accounts","title":"SDK How-To (Javascript)"},{"location":"Hermez_1.0/developers/sdk/#install-hermezjs","text":"npm i @hermeznetwork/hermezjs","title":"Install Hermezjs"},{"location":"Hermez_1.0/developers/sdk/#import-modules","text":"Load Hermezjs library const hermez = require('@hermeznetwork/hermezjs')","title":"Import modules"},{"location":"Hermez_1.0/developers/sdk/#initialization","text":"","title":"Initialization"},{"location":"Hermez_1.0/developers/sdk/#create-transaction-pool","text":"Initialize the storage where user transactions are stored. This needs to be initialized at the start of your application. hermez.TxPool.initializeTransactionPool()","title":"Create Transaction Pool"},{"location":"Hermez_1.0/developers/sdk/#configure-hermez-environment","text":"In these examples, we are going to connect to Hermez Testnet which is deployed in Rinkeby Ethereum Network. To configure Hermezjs to work with the Testnet, we need to configure a Rinkeby Ethereum node, the Hermez API URL, and the addresses of the Hermez and Withdrawal Delayer smart contracts. Hermez Testnet API URL is deployed at https://api.testnet.hermez.io/v1. NOTE: In order to interact with Hermez Testnet, you will need to supply your own Rinkeby Ethereum node. You can check these links to help you set up a Rinkeby node (https://blog.infura.io/getting-started-with-infura-28e41844cc89, https://blog.infura.io/getting-started-with-infuras-ethereum-api). Currently, Testnet Hermez smart contract is deployed at address 0x14a3b6f3328766c7421034e14472f5c14c5ba090 and Withdrawal Delayer contract is deployed at address 0x6ea0abf3ef52d24427043cad3ec26aa4f2c8e8fd . These addresses could change in the future, so please check these addresses with a query of the API using the browser. For the remainder of the examples, we will configure the basic Hermezjs parameters const EXAMPLES_WEB3_URL = 'https://rinkeby.infura.io/v3/80496a41d0a134ccbc6e856ffd034696' const EXAMPLES_HERMEZ_API_URL = 'https://api.testnet.hermez.io' const EXAMPLES_HERMEZ_ROLLUP_ADDRESS = '0x14a3b6f3328766c7421034e14472f5c14c5ba090' const EXAMPLES_HERMEZ_WDELAYER_ADDRESS = '0x6ea0abf3ef52d24427043cad3ec26aa4f2c8e8fd' hermez.Providers.setProvider(EXAMPLES_WEB3_URL) hermez.Environment.setEnvironment({ baseApiUrl: EXAMPLES_HERMEZ_API_URL, contractAddresses: { [hermez.Constants.ContractNames.Hermez]: EXAMPLES_HERMEZ_ROLLUP_ADDRESS, [hermez.Constants.ContractNames.WithdrawalDelayer]: EXAMPLES_HERMEZ_WDELAYER_ADDRESS } })","title":"Configure Hermez Environment"},{"location":"Hermez_1.0/developers/sdk/#check-token-exists-in-hermez-network","text":"Before being able to operate on the Hermez Network, we must ensure that the token we want to operate with is listed. For that we make a call to the Hermez Coordinator API that will list all available tokens. All tokens in Hermez Network must be ERC20. We can see there are 2 tokens registered. ETH will always be configured at index 0. The second token is HEZ . For the rest of the examples we will work with ETH . In the future, more tokens will be included in Hermez. const token = await hermez.CoordinatorAPI.getTokens() const tokenERC20 = token.tokens[0] console.log(token) >>>> { tokens: [ { itemId: 1, id: 0, ethereumBlockNum: 0, ethereumAddress: '0x0000000000000000000000000000000000000000', name: 'Ether', symbol: 'ETH', decimals: 18, USD: 1787, fiatUpdate: '2021-02-28T18:55:17.372008Z' }, { itemId: 2, id: 1, ethereumBlockNum: 8153596, ethereumAddress: '0x2521bc90b4f5fb9a8d61278197e5ff5cdbc4fbf2', name: 'Hermez Network Token', symbol: 'HEZ', decimals: 18, USD: 5.365, fiatUpdate: '2021-02-28T18:55:17.386805Z' } ], pendingItems: 0","title":"Check token exists in Hermez Network"},{"location":"Hermez_1.0/developers/sdk/#create-a-wallet","text":"We can create a new Hermez wallet by providing the Ethereum private key of an Ethereum account. This wallet will store the Ethereum and Baby JubJub keys for the Hermez account. The Ethereum address is used to authorize L1 transactions, and the Baby JubJub key is used to authorize L2 transactions. We will create two wallets. NOTE You will need to supply two Rinkeby private keys to initialize both accounts. The keys provided here are invalid and are shown as an example. const EXAMPLES_PRIVATE_KEY1 = 0x705d123e707e25fa37ca84461ac6eb83eb4921b65680cfdc594b60bea1bb4e52 const EXAMPLES_PRIVATE_KEY2 = 0x3a9270c05ac169097808da4b02e8f9146be0f8a38cfad3dcfc0b398076381fdd // load first account const wallet = await hermez.HermezWallet.createWalletFromEtherAccount(EXAMPLES_WEB3_URL, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY1 }) const hermezWallet = wallet.hermezWallet const hermezEthereumAddress = wallet.hermezEthereumAddress // load second account const wallet2 = await hermez.HermezWallet.createWalletFromEtherAccount(EXAMPLES_WEB3_URL, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY2 }) const hermezWallet2 = wallet2.hermezWallet const hermezEthereumAddress2 = wallet2.hermezEthereumAddress","title":"Create a Wallet"},{"location":"Hermez_1.0/developers/sdk/#deposit-tokens-from-ethereum-into-hermez-network","text":"Creating a Hermez account and depositing tokens is done simultaneously as an L1 transaction. In this example we are going to deposit 1 ETH tokens into the newly created Hermez accounts. // set amount to deposit const amountDepositString = '1.0' const amountDeposit = hermez.Utils.getTokenAmountBigInt(amountDepositString, 18) const compressedDepositAmount = hermez.HermezCompressedAmount.compressAmount(amountDeposit) // perform deposit account 1 await hermez.Tx.deposit( compressedDepositAmount, hermezEthereumAddress, tokenERC20, hermezWallet.publicKeyCompressedHex, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY1 } ) // perform deposit account 2 await hermez.Tx.deposit( compressedDepositAmount, hermezEthereumAddress2, tokenERC20, hermezWallet2.publicKeyCompressedHex, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY2 } ) Internally, the deposit funcion calls the Hermez smart contract to add the L1 transaction.","title":"Deposit Tokens from Ethereum into Hermez Network"},{"location":"Hermez_1.0/developers/sdk/#verify-balance","text":"A token balance can be obtained by querying the API and passing the hermezEthereumAddress of the Hermez account. // get sender account information const infoAccountSender = (await hermez.CoordinatorAPI.getAccounts(hermezEthereumAddress, [tokenERC20.id])) .accounts[0] // get receiver account information const infoAccountReceiver = (await hermez.CoordinatorAPI.getAccounts(hermezEthereumAddress2, [tokenERC20.id])) .accounts[0] console.log(infoAccountSender) console.log(infoAccountReceiver) >>>>> { accountIndex: 'hez:ETH:4253', balance: '1099600000000000000', bjj: 'hez:dMfPJlK_UtFqVByhP3FpvykOg5kAU3jMLD7OTx_4gwzO', hezEthereumAddress: 'hez:0x74d5531A3400f9b9d63729bA9C0E5172Ab0FD0f6', itemId: 4342, nonce: 1, token: { USD: 1789, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' } } { accountIndex: 'hez:ETH:4254', balance: '1097100000000000000', bjj: 'hez:HESLP_6Kp_nn5ANmSGiOnhhYvF3wF5Davf7xGi6lwh3U', hezEthereumAddress: 'hez:0x12FfCe7D5d6d09564768d0FFC0774218458162d4', itemId: 4343, nonce: 6, token: { USD: 1789, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' } } We can see that the field accountIndex is formed by the token symbol it holds and an index. A Hermez account can only hold one type of token. Account indexes start at 256. Indexes 0-255 are reserved for internal use. Note that the balances do not match with the ammount deposited of 1 ETH because accounts already existed in Hermez Network before the deposit, so we performed a deposit on top instead. Alternatively, an account query can be filtered using the assigned accountIndex const account1ByIdx = await hermez.CoordinatorAPI.getAccount(infoAccountSender.accountIndex) const account2ByIdx = await hermez.CoordinatorAPI.getAccount(infoAccountReceiver.accountIndex) console.log(account1ByIdx) console.log(account2ByIdx) >>>>> { accountIndex: 'hez:ETH:4253', balance: '1099600000000000000', bjj: 'hez:dMfPJlK_UtFqVByhP3FpvykOg5kAU3jMLD7OTx_4gwzO', hezEthereumAddress: 'hez:0x74d5531A3400f9b9d63729bA9C0E5172Ab0FD0f6', itemId: 4342, nonce: 1, token: { USD: 1789, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' } } { accountIndex: 'hez:ETH:4254', balance: '1097100000000000000', bjj: 'hez:HESLP_6Kp_nn5ANmSGiOnhhYvF3wF5Davf7xGi6lwh3U', hezEthereumAddress: 'hez:0x12FfCe7D5d6d09564768d0FFC0774218458162d4', itemId: 4343, nonce: 6, token: { USD: 1789, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' } }","title":"Verify Balance"},{"location":"Hermez_1.0/developers/sdk/#withdrawing","text":"Withdrawing funds is a two step process: 1. Exit 2. Withdrawal","title":"Withdrawing"},{"location":"Hermez_1.0/developers/sdk/#exit","text":"The Exit transaction is used as a first step to retrieve the funds from Hermez Network back to Ethereum. There are two types of Exit transactions: - Normal Exit, referred as Exit from now on. This is a L2 transaction type. - Force Exit , an L1 transaction type which has extended guarantees that will be processed by the Coordinator. We will talk more about Force Exit here The Exit is requested as follows: // set amount to exit const amountExit = hermez.HermezCompressedAmount.compressAmount(hermez.Utils.getTokenAmountBigInt('1.0', 18)) // set fee in transaction const state = await hermez.CoordinatorAPI.getState() const userFee = state.recommendedFee.existingAccount // generate L2 transaction const l2ExitTx = { type: 'Exit', from: infoAccountSender.accountIndex, amount: amountExit, fee: userFee } const exitResponse = await hermez.Tx.generateAndSendL2Tx(l2ExitTx, hermezWallet, infoAccountSender.token) console.log(exitResponse) >>>> { status: 200, id: '0x0257305cdc43060a754a5c2ea6b0e0f6e28735ea8e75d841ca4a7377aa099d91b7', nonce: 2 } After submitting our Exit request to the Coordinator, we can check the status of the transaction by calling the Coordinator's Transaction Pool. The Coordinator's transaction pool stores all those transactions that are waiting to be forged. const txPool = await hermez.CoordinatorAPI.getPoolTransaction(exitResponse.id) console.log(txPool) >>>>> { amount: '1000000000000000000', fee: 204, fromAccountIndex: 'hez:ETH:4253', fromBJJ: 'hez:dMfPJlK_UtFqVByhP3FpvykOg5kAU3jMLD7OTx_4gwzO', fromHezEthereumAddress: 'hez:0x74d5531A3400f9b9d63729bA9C0E5172Ab0FD0f6', id: '0x0257305cdc43060a754a5c2ea6b0e0f6e28735ea8e75d841ca4a7377aa099d91b7', info: null, nonce: 2, requestAmount: null, requestFee: null, requestFromAccountIndex: null, requestNonce: null, requestToAccountIndex: null, requestToBJJ: null, requestToHezEthereumAddress: null, requestTokenId: null, signature: '38f23d06826be8ea5a0893ee67f4ede885a831523c0c626c102edb05e1cf890e418b5820e3e6d4b530386d0bc84b3c3933d655527993ad77a55bb735d5a67c03', state: 'pend', timestamp: '2021-03-16T12:31:50.407428Z', toAccountIndex: 'hez:ETH:1', toBjj: null, toHezEthereumAddress: null, token: { USD: 1781.9, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' }, type: 'Exit' } We can see the state field is set to pend (meaning pending). There are 4 possible states: 1. pend : Pending 2. fging : Forging 3. fged : Forged 4. invl : Invalid If we continue polling the Coordinator about the status of the transaction, the state will eventually be set to fged . We can also query the Coordinator to check whether or not our transaction has been forged. getHistoryTransaction reports those transactions that have been forged by the Coordinator. const txExitConf = await hermez.CoordinatorAPI.getHistoryTransaction(txExitPool.id) console.log(txExitConf) And we can confirm our account status and check that the correct amount has been transfered out of the account. console.log((await hermez.CoordinatorAPI.getAccounts(hermezEthereumAddress, [tokenERC20.id])) .accounts[0])","title":"Exit"},{"location":"Hermez_1.0/developers/sdk/#withdrawing-funds-from-hermez","text":"After doing any type of Exit transaction, which moves the user's funds from their token account to a specific Exit Merkle tree, one needs to do a Withdraw of those funds to an Ethereum L1 account. To do a Withdraw we need to indicate the accountIndex that includes the Ethereum address where the funds will be transferred, the amount and type of tokens, and some information to verify the ownership of those tokens. Additionally, there is one boolean flag. If set to true, the Withdraw will be instantaneous. const exitInfoN = (await hermez.CoordinatorAPI.getExits(infoAccountSender.hezEthereumAddress, true)).exits const exitInfo = exitInfoN[exitInfoN.length - 1] // set to perform instant withdraw const isInstant = true // perform withdraw await hermez.Tx.withdraw( exitInfo.balance, exitInfo.accountIndex, exitInfo.token, hermezWallet.publicKeyCompressedHex, exitInfo.batchNum, exitInfo.merkleProof.siblings, isInstant, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY1 } ) The funds should now appear in the Ethereum account that made the withdrawal.","title":"Withdrawing Funds from Hermez"},{"location":"Hermez_1.0/developers/sdk/#force-exit","text":"This is the L1 equivalent of an Exit. With this option, the smart contract forces Coordinators to pick up L1 transactions before they pick up L2 transactions to ensure that L1 transactions will eventually be picked up. This is a security measure. We don't expect users to need to make a Force Exit. // set amount to force-exit const amountForceExit = hermez.HermezCompressedAmount.compressAmount(hermez.Utils.getTokenAmountBigInt('1.0', 18)) // perform force-exit await hermez.Tx.forceExit( amountForceExit, infoAccountSender.accountIndex, tokenERC20, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY1 } ) The last step to recover the funds will be to send a new Withdraw request to the smart contract as we did after the regular Exit request. ```js const exitInfoN = (await hermez.CoordinatorAPI.getExits(infoAccountSender.hezEthereumAddress, true)).exits const exitInfo = exitInfoN[exitInfoN.length - 1] // set to perform instant withdraw const isInstant = true // perform withdraw await hermez.Tx.withdraw( exitInfo.balance, exitInfo.accountIndex, exitInfo.token, hermezWallet.publicKeyCompressedHex, exitInfo.batchNum, exitInfo.merkleProof.siblings, isInstant, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY1 } )","title":"Force Exit"},{"location":"Hermez_1.0/developers/sdk/#transfers","text":"First, we compute the fees for the transaction. For this we consult the recommended fees from the Coordinator. // fee computation const state = await hermez.CoordinatorAPI.getState() console.log(state.recommendedFee) >>>> { existingAccount: 96.34567219671051, createAccount: 192.69134439342102, createAccountInternal: 240.86418049177627 } The returned fees are the suggested fees for different transactions: - existingAccount : Make a transfer to an existing account - createAccount : Make a transfer to a non-existent account, and create a regular account - createAccountInternal : Make a transfer to an non-existent account and create internal account The fee amounts are given in USD. However, fees are payed in the token of the transaction. So, we need to do a conversion. const usdTokenExchangeRate = tokenERC20.USD const fee = fees.existingAccount / usdTokenExchangeRate Finally we make the final transfer transaction. // set amount to transfer const amountTransfer = hermez.HermezCompressedAmount.compressAmount(hermez.Utils.getTokenAmountBigInt('1.0', 18)) // generate L2 transaction const l2TxTransfer = { from: infoAccountSender.accountIndex, to: infoAccountReceiver.accountIndex, amount: amountTransfer, fee: fee } const transferResponse = await hermez.Tx.generateAndSendL2Tx(l2TxTransfer, hermezWallet, infoAccountSender.token) console.log(transferResponse) >>>>> { status: 200, id: '0x02e7c2c293173f21249058b1d71afd5b1f3c0de4f1a173bac9b9aa4a2d149483a2', nonce: 3 } The result status 200 shows that transaction has been correctly received. Additionally, we receive the nonce matching the transaction we sent, and an id that we can use to verify the status of the transaction either using hermez.CoordinatorAPI.getHistoryTransaction() or hermez.CoordinatorAPI.getPoolTransaction() . As we saw with the Exit transaction, every transaction includes a \u00b4nonce\u00b4. This nonce is a protection mechanism to avoid replay attacks. Every L2 transaction will increase the nonce by 1.","title":"Transfers"},{"location":"Hermez_1.0/developers/sdk/#verifying-transaction-status","text":"Transactions received by the Coordinator will be stored in its transaction pool while they haven't been processed. To check a transaction in the transaction pool we make a query to the Coordinator node. const txXferPool = await hermez.CoordinatorAPI.getPoolTransaction(transferResponse.id) console.log(txXferPool) >>>>> { amount: '100000000000000', fee: 202, fromAccountIndex: 'hez:ETH:4253', fromBJJ: 'hez:dMfPJlK_UtFqVByhP3FpvykOg5kAU3jMLD7OTx_4gwzO', fromHezEthereumAddress: 'hez:0x74d5531A3400f9b9d63729bA9C0E5172Ab0FD0f6', id: '0x02e7c2c293173f21249058b1d71afd5b1f3c0de4f1a173bac9b9aa4a2d149483a2', info: null, nonce: 3, requestAmount: null, requestFee: null, requestFromAccountIndex: null, requestNonce: null, requestToAccountIndex: null, requestToBJJ: null, requestToHezEthereumAddress: null, requestTokenId: null, signature: 'c9e1a61ce2c3c728c6ec970ae646b444a7ab9d30aa6015eb10fb729078c1302978fe9fb0419b4d944d4f11d83582043a48546dff7dda22de7c1e1da004cd5401', state: 'pend', timestamp: '2021-03-16T13:20:33.336469Z', toAccountIndex: 'hez:ETH:4254', toBjj: 'hez:HESLP_6Kp_nn5ANmSGiOnhhYvF3wF5Davf7xGi6lwh3U', toHezEthereumAddress: 'hez:0x12FfCe7D5d6d09564768d0FFC0774218458162d4', token: { USD: 1786, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' }, type: 'Transfer' } We can also check directly with the Coordinator in the database of forged transactions. const transferConf = await hermez.CoordinatorAPI.getHistoryTransaction(transferResponse.id) console.log(transferConf) >>>>> { L1Info: null, L1orL2: 'L2', L2Info: { fee: 202, historicFeeUSD: 182.8352, nonce: 3 }, amount: '100000000000000', batchNum: 4724, fromAccountIndex: 'hez:ETH:4253', fromBJJ: 'hez:dMfPJlK_UtFqVByhP3FpvykOg5kAU3jMLD7OTx_4gwzO', fromHezEthereumAddress: 'hez:0x74d5531A3400f9b9d63729bA9C0E5172Ab0FD0f6', historicUSD: 0.17855, id: '0x02e7c2c293173f21249058b1d71afd5b1f3c0de4f1a173bac9b9aa4a2d149483a2', itemId: 14590, position: 1, timestamp: '2021-03-16T13:24:48Z', toAccountIndex: 'hez:ETH:4254', toBJJ: 'hez:HESLP_6Kp_nn5ANmSGiOnhhYvF3wF5Davf7xGi6lwh3U', toHezEthereumAddress: 'hez:0x12FfCe7D5d6d09564768d0FFC0774218458162d4', token: { USD: 1787.2, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' }, type: 'Transfer' } At this point, the balances in both accounts will be updated with the result of the transfer // check balances console.log((await hermez.CoordinatorAPI.getAccounts(wallet.hermezEthereumAddress, [tokenERC20.id])).accounts[0]) console.log((await hermez.CoordinatorAPI.getAccounts(wallet2.hermezEthereumAddress2, [tokenERC20.id])).accounts[0]) >>>>> { accountIndex: 'hez:ETH:4253', balance: '477700000000000000', bjj: 'hez:dMfPJlK_UtFqVByhP3FpvykOg5kAU3jMLD7OTx_4gwzO', hezEthereumAddress: 'hez:0x74d5531A3400f9b9d63729bA9C0E5172Ab0FD0f6', itemId: 4342, nonce: 4, token: { USD: 1793, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' } } { accountIndex: 'hez:ETH:256', balance: '1874280899837791518', bjj: 'hez:YN2DmRh0QgDrxz3NLDqH947W5oNys7YWqkxsQmFVeI_m', hezEthereumAddress: 'hez:0x9F255048EC1141831A28019e497F3f76e559356E', itemId: 1, nonce: 2, token: { USD: 1793, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-02-28T18:55:17.372008Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' } }","title":"Verifying Transaction Status"},{"location":"Hermez_1.0/developers/sdk/#create-account-authorization","text":"Imagine that Bob wants to send a transfer of Ether to Mary using Hermez, but Mary only has an Ethereum account but no Hermez account. To complete this transfer, Mary could open a Hermez account and proceed as the previous transfer example. Alternatively, Mary could authorize the Coordinator to create a Hermez account on her behalf so that she can receive Bob's transfer. First we create a wallet for Mary: // load second account const wallet3 = await hermez.HermezWallet.createWalletFromEtherAccount(EXAMPLES_WEB3_URL, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY3 }) const hermezWallet3 = wallet3.hermezWallet const hermezEthereumAddress3 = wallet3.hermezEthereumAddress The authorization for the creation of a Hermez account is done using the private key stored in the newly created Hermez wallet. Note that the account is not created at this moment. The account will be created when Bob performs the transfer. Also, it is Bob that pays for the fees associated with the account creation. const EXAMPLES_PRIVATE_KEY3 = '0x3d228fed4dc371f56b8f82f66ff17cd6bf1da7806d7eabb21810313dee819a53' const signature = await hermezWallet3.signCreateAccountAuthorization(EXAMPLES_WEB3_URL, { type: 'WALLET', privateKey: EXAMPLES_PRIVATE_KEY3 }) const res = await hermez.CoordinatorAPI.postCreateAccountAuthorization( hermezWallet3.hermezEthereumAddress, hermezWallet3.publicKeyBase64, signature ) We can find out if the Coordinator has been authorized to create a Hermez account on behalf of a user by: const authResponse = await hermez.CoordinatorAPI.getCreateAccountAuthorization(wallet3.hermezEthereumAddress) console.log(authResponse) >>>> { hezEthereumAddress: 'hez:0xd3B6DcfCA7Eb3207905Be27Ddfa69453625ffbf9', bjj: 'hez:ct0ml6FjdUN6uGUHZ70qOq5-58cZ19SJDeldMH021oOk', signature: '0x22ffc6f8d569a92c48a4e784a11a9e57b840fac21eaa7fedc9dc040c4a45d502744a35eeb0ab173234c0f687b252bd0364647bff8db270ffcdf1830257de28e41c', timestamp: '2021-03-16T14:56:05.295946Z' } Once we verify the receiving Ethereum account has authorized the creation of a Hermez account, we can proceed with the transfer from Bob's account to Mary's account. For this, we set the destination address to Mary's Ethereum address and set the fee using the createAccount value. // set amount to transfer const amountTransferAuth = hermez.HermezCompressedAmount.compressAmount(hermez.Utils.getTokenAmountBigInt('1.0', 18)) // generate L2 transaction const l2AuthTxTransfer = { from: infoAccountSender.accountIndex, to: hermezWallet3.hermezEthereumAddress amount: amountTransferAuth, fee: state.recommendedFee.createAccount / usdTokenExchangeRate } const accountAuthTransferResponse = await hermez.Tx.generateAndSendL2Tx(l2AuthTxTransfer, hermezWallet, infoAccountSender.token) console.log(accountAuthTransferResponse) >>>>> { status: 200, id: '0x025398af5b69f132d8c2c5b7b225df1436baf7d1774a6b017a233bf273b4675c8f', nonce: 0 } After the transfer has been forged, we can check Mary's account on Hermez // get receiver account information const infoAccountAuth = (await hermez.CoordinatorAPI.getAccounts(hermezWallet3.hermezEthereumAddress, [tokenERC20.id])) .accounts[0] console.log(infoAccountAuth) >>>>> { accountIndex: 'hez:ETH:265', balance: '1000000000000000', bjj: 'hez:ct0ml6FjdUN6uGUHZ70qOq5-58cZ19SJDeldMH021oOk', hezEthereumAddress: 'hez:0xd3B6DcfCA7Eb3207905Be27Ddfa69453625ffbf9', itemId: 10, nonce: 0, token: { USD: 1795.94, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-03-16T14:56:57.460862Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' } }","title":"Create Account Authorization"},{"location":"Hermez_1.0/developers/sdk/#create-internal-accounts","text":"Until now we have seen that accounts have an Ethereum address and a Baby JubJub key. This is the case for normal accounts. However, there is a second type of account that only requires a Baby JubJub key. These accounts are called internal accounts . The advantage of these accounts is that they are much more inexpensive to create than a normal account , since these accounts only exist on Hermez. The downside is that one cannot perform deposits or withdrawals from this type of account. However, there are some scenarios where these accounts are useful. For example, in those scenarios where one requires a temporary account. (for example, Exchanges could use these accounts to receive a transfer from users). // Create Internal Account // create new bjj private key to receive user transactions const pvtBjjKey = Buffer.allocUnsafe(32).fill('1') // create rollup internal account from bjj private key const wallet4 = await hermez.HermezWallet.createWalletFromBjjPvtKey(pvtBjjKey) const hermezWallet4 = wallet4.hermezWallet // set amount to transfer const amountTransferInternal = hermez.HermezCompressedAmount.compressAmount(hermez.Utils.getTokenAmountBigInt('1.0', 18)) // generate L2 transaction const transferToInternal = { from: infoAccountSender.accountIndex, to: hermezWallet4.publicKeyBase64, amount: amountTransferInternal, fee: state.recommendedFee.createAccountInternal / usdTokenExchangeRate } const internalAccountResponse = await hermez.Tx.generateAndSendL2Tx(transferToInternal, hermezWallet, tokenERC20) console.log(internalAccountResponse) >>>>> { status: 200, id: '0x02ac000f39eee60b198c85348443002991753de912337720b9ef85d48e9dcfe83e', nonce: 0 } Once the transaction is forged, we can check the account information // get internal account information const infoAccountInternal = (await hermez.CoordinatorAPI.getAccounts(hermezWallet4.publicKeyBase64, [tokenERC20.id])) .accounts[0] console.log(infoAccountInternal) >>>>>> { accountIndex: 'hez:ETH:259', balance: '1000000000000000000', bjj: 'hez:KmbnR34pOUhSaaPOkeWbaeZVjMqojfyYy8sYIHRSlaKx', hezEthereumAddress: 'hez:0xFFfFfFffFFfffFFfFFfFFFFFffFFFffffFfFFFfF', itemId: 4, nonce: 0, token: { USD: 1798.51, decimals: 18, ethereumAddress: '0x0000000000000000000000000000000000000000', ethereumBlockNum: 0, fiatUpdate: '2021-03-16T15:44:08.33507Z', id: 0, itemId: 1, name: 'Ether', symbol: 'ETH' } } We can verify it is in fact an internal account because the associated hezEthereumAddress is hez:0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF .","title":"Create Internal Accounts"},{"location":"Hermez_1.0/developers/coord-files/cfg.sandbox.boot-coordinator/","text":"#[API] ### Url and port where the API will listen #Address = \"0.0.0.0:8086\" ### Enables the Explorer API endpoints #Explorer = true ### Interval between updates of the API metrics #UpdateMetricsInterval = \"10s\" ### Interval between updates of the recommended fees #UpdateRecommendedFeeInterval = \"10s\" ### Maximum concurrent connections allowed between API and SQL #MaxSQLConnections = 100 ### Maximum amount of time that an API request can wait to establish a SQL connection #SQLConnectionTimeout = \"2s\" [Debug] ### If it is set, the debug api will listen in this address and port APIAddress = \"0.0.0.0:12345\" ### Enables meddler debug mode, where unused columns and struct fields will be logged MeddlerLogs = true ### Sets the web framework Gin-Gonic to run in debug mode GinDebugMode = true [StateDB] ### Path where the synchronizer StateDB is stored Path = \"/tmp/hermez/statedb\" ### Number of checkpoints to keep #Keep = 256 [PostgreSQL] ## Port of the PostgreSQL write server PortWrite = 5432 ## Host of the PostgreSQL write server HostWrite = \"localhost\" ## User of the PostgreSQL write server UserWrite = \"hermez\" ## Password of the PostgreSQL write server PasswordWrite = \"yourpasswordhere\" ## Name of the PostgreSQL write server database NameWrite = \"hermez\" [Web3] ## Url of the web3 Ethereum-node RPC server. Only geth is officially supported URL = \"http://localhost:8545\" #[Synchronizer] ### Interval between attempts to synchronize a new block from an Ethereum node #SyncLoopInterval = \"1s\" ### Threshold of a number of Ethereum blocks left to synchronize, such that if there are more blocks to sync than the defined value synchronizer can aggressively skip calling UpdateEth to save network bandwidth and time. After reaching the threshold UpdateEth is called on each block. This value only affects the reported % of synchronization of blocks and batches, nothing else. #StatsUpdateBlockNumDiffThreshold = 100 ### While having more blocks to sync than updateEthBlockNumThreshold, UpdateEth will be called once in a defined number of blocks. This value only affects the reported % of synchronization of blocks and batches, nothing else #StatsUpdateFrequencyDivider = 100 [SmartContracts] ## Smart contract address of the rollup Hermez.sol Rollup = \"0x10465b16615ae36F350268eb951d7B0187141D3B\" [Coordinator] ## Ethereum address that the Coordinator is using to forge batches ForgerAddress = \"0xDcC5dD922fb1D0fd0c450a0636a8cE827521f0eD\" # Non-Boot Coordinator # ForgerAddressPrivateKey = \"0x705df2ae707e25fa37ca84461ac6eb83eb4921b653e98fdc594b60bea1bb4e52\" ### Minimum balance the forger address needs to start the Coordinator in Wei. If it is set to 0, the Coordinator will not check the balance #MinimumForgeAddressBalance = \"0\" ### Number of confirmation blocks to be sure that the tx has been mined correctly #ConfirmBlocks = 5 ### Portion of the range before the L1Batch timeout that will trigger a schedule to forge an L1Batch #L1BatchTimeoutPerc = 0.00001 ### Number of delay blocks to wait before starting the pipeline when a slot in which the Coordinator can forge is reached #StartSlotBlocksDelay = 0 ### Number of blocks ahead used to decide when to stop scheduling new batches #ScheduleBatchBlocksAheadCheck = 0 ### Number of margin blocks used to decide when to stop sending batches to the smart contract #SendBatchBlocksMarginCheck = 0 ### Interval between calls to the ProofServer to check the status #ProofServerPollInterval = \"1s\" ### Interval between forge retries after an error #ForgeRetryInterval = \"10s\" ### Interval between calls to the main handler of a synced block after an error #SyncRetryInterval = \"1s\" #Delay after which a batch is forged if the slot is already committed. If It is set to \"0s\", the Coordinator will continuously forge at the maximum rate ForgeDelay = \"0s\" ### Delay after a forged batch if there are no txs to forge. If It is set to 0s, the Coordinator will continuously forge even if the batches are empty ForgeNoTxsDelay = \"1s\" ### Interval between calls to the PurgeByExternalDelete function of the l2db which deletes pending txs externally marked by the column `external_delete` #PurgeByExtDelInterval = \"1m\" ### Enables the Coordinator to forge in slots if the empty slots reach the slot deadline #MustForgeAtSlotDeadline = true ### It will make the Coordinator forge at most one batch per slot, only if there are included txs in that batch, or pending l1UserTxs in the smart contract. Setting this parameter overrides `ForgeDelay`, `ForgeNoTxsDelay`, `MustForgeAtSlotDeadline` and `IgnoreSlotCommitment`. #IgnoreSlotCommitment = true ### This parameter will make the Coordinator forge at most one batch per slot, only if there are included txs in that batch, or pending l1UserTxs in the smart contract. Setting this parameter overrides `ForgeDelay`, `ForgeNoTxsDelay`, `MustForgeAtSlotDeadline` and `IgnoreSlotCommitment`. #ForgeOncePerSlotIfTxs = false [Coordinator.FeeAccount] ## Ethereum address of the account that will receive the fees Address = \"0xCfDe8f47215a147e3876efa0c059771159c4FC70\" # PrivateKey = \"0xfdb75ceb9f3e0a6c1721e98b94ae451ecbcb9e8c09f9fc059938cb5ab8cc8a7c\" ## BJJ is the baby jub jub public key of the account that will receive the fees BJJ = \"0x1b176232f78ba0d388ecc5f4896eca2d3b3d4f272092469f559247297f5c0c13\" # BJJPrivateKey = \"0xb556862fb60e7cf4c0a8a7f44baf2ab06a4c90ac39decc4eef363b6142d07a34\" [Coordinator.L2DB] ### Number of batches after which non-pending L2Txs are deleted from the pool #SafetyPeriod = 10 ### Maximum number of pending L2Txs that can be stored in the pool #MaxTxs = 1000000 ### Minimum fee in USD that a tx must pay in order to be accepted into the pool MinFeeUSD = 0.0 ### Maximum fee in USD that a tx must pay in order to be accepted into the pool #MaxFeeUSD = 10.00 ### Time To Live for L2Txs in the pool. L2Txs older than TTL will be deleted. #TTL = \"24h\" ### Delay between batches to purge outdated transactions. Outdated L2Txs are those that have been forged or marked as invalid for longer than the SafetyPeriod and pending L2Txs that have been in the pool for longer than TTL once there are MaxTxs #PurgeBatchDelay = 10 ### Delay between batches to mark invalid transactions due to nonce lower than the account nonce #InvalidateBatchDelay = 20 ### Delay between blocks to purge outdated transactions. Outdated L2Txs are those that have been forged or marked as invalid for longer than the SafetyPeriod and pending L2Txs that have been in the pool for longer than TTL once there are MaxTxs. #PurgeBlockDelay = 10 ### Delay between blocks to mark invalid transactions due to nonce lower than the account nonce #InvalidateBlockDelay = 20 [Coordinator.TxSelector] ### Path where the TxSelector StateDB is stored Path = \"/tmp/hermez/txselector\" [Coordinator.BatchBuilder] ### Path where the BatchBuilder StateDB is stored Path = \"/tmp/hermez/batchbuilder\" [Coordinator.ServerProofs] ## Server proof API URLs URLs = [\"http://localhost:3000/api\"] [Coordinator.Circuit] ## Maximum number of txs supported by the circuit MaxTx = 512 ## Maximum number of merkle tree levels supported by the circuit NLevels = 32 #[Coordinator.EthClient] ### Interval between receipt checks of Ethereum transactions in the TxManager #CheckLoopInterval = \"500ms\" ### Number of attempts to do an Eth client RPC call before giving up #Attempts = 4 ### Delay between attempts do do an Eth client RPC call #AttemptsDelay = \"500ms\" ### Timeout after which a non-mined Ethereum transaction will be resent (reusing the nonce) with a newly calculated gas price #TxResendTimeout = \"2m\" ### Disables reusing nonces of pending transactions for new replacement transactions #NoReuseNonce = false ### Maximum gas price allowed for Ethereum transactions in Gwei #MaxGasPrice = 500 ### Minimum gas price allowed for Ethereum transactions in Gwei #MinGasPrice = 5 ### Percentage increased of gas price set in an Ethereum transaction from the suggested gas price by the Ethereum node #GasPriceIncPerc = 5 [Coordinator.EthClient.Keystore] ### Path where the keystore is stored Path = \"/tmp/hermez/ethkeystore\" ## Password used to decrypt the keys in the keystore Password = \"yourpasswordhere\" #[Coordinator.EthClient.ForgeBatchGasCost] ### Gas needed to forge an empty batch #Fixed = 900000 ### Gas needed per L1 tx #L1UserTx = 15000 ### Gas needed for a Coordinator L1 tx #L1CoordTx = 7000 ### Gas needed for an L2 tx #L2Tx = 600 #[Coordinator.API] ### Enables Coordinator API endpoints #Coordinator = true [Coordinator.Debug] ## If this parameter is set, specifies the path where batchInfo is stored in JSON in every step/update of the pipeline BatchPath = \"/tmp/hermez/batchesdebug\" ## If lightScrypt is set, uses light parameters for the Ethereum keystore encryption algorithm LightScrypt = false ## RollupVerifierIndex is the index of the verifier to use in the Rollup smart contract. The verifier chosen by index must match with the Circuit parameters. Only for debug purposes. It can't be used as env variable # RollupVerifierIndex = 0 [Coordinator.Etherscan] ## If this parameter is set, specifies the Etherscan endpoint to get the gas estimations for that momment URL = \"https://api.etherscan.io\" ## APIKey parameter allows access to Etherscan services APIKey = \"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\" #[RecommendedFeePolicy] ### Strategy used to calculate the recommended fee that the API will expose. ### Available options: ### - Static: always return the same value (StaticValue) in USD ### - AvgLastHour: calculate using the average fee of the forged transactions during the last hour ### Selects the mode. \"Static\" or \"AvgLastHour\" #PolicyType = \"Static\" ### If PolicyType is \"static\" defines the recommended fee value #StaticValue = 0.10","title":"Cfg.sandbox.boot coordinator"},{"location":"Hermez_1.0/developers/coord-files/cfg.testnet.coord/","text":"[API] ### Url and port where the API will listen #Address = \"0.0.0.0:8086\" ### Enables the Explorer API endpoints #Explorer = true ### Interval between updates of the API metrics #UpdateMetricsInterval = \"10s\" ### Interval between updates of the recommended fees #UpdateRecommendedFeeInterval = \"10s\" ### Maximum concurrent connections allowed between API and SQL #MaxSQLConnections = 100 ### Maximum amount of time that an API request can wait to establish a SQL connection #SQLConnectionTimeout = \"2s\" [Debug] ### If it is set, the debug api will listen in this address and port APIAddress = \"0.0.0.0:12345\" ### Enables meddler debug mode, where unused columns and struct fields will be logged MeddlerLogs = true ### Sets the web framework Gin-Gonic to run in debug mode GinDebugMode = true [StateDB] ### Path where the synchronizer StateDB is stored Path = \"/tmp/hermez/statedb\" ### Number of checkpoints to keep #Keep = 256 [PostgreSQL] # TODO: Add user, pwd and host for pg database ## Port of the PostgreSQL write server PortWrite = 5432 ## Host of the PostgreSQL write server HostWrite = \"localhost\" ## User of the PostgreSQL write server UserWrite = \"hermez\" ## Password of the PostgreSQL write server PasswordWrite = \"yourpasswordhere\" ## Name of the PostgreSQL write server database NameWrite = \"hermez\" [Web3] ## Url of the web3 Ethereum-node RPC server. Only geth is officially supported # TODO - Add you Ethereum node URL here #URL = \"http://10.48.1.224:8545\" #[Synchronizer] ### Interval between attempts to synchronize a new block from an Ethereum node #SyncLoopInterval = \"1s\" ### Threshold of a number of Ethereum blocks left to synchronize, such that if there are more blocks to sync than the defined value synchronizer can aggressively skip calling UpdateEth to save network bandwidth and time. After reaching the threshold UpdateEth is called on each block. This value only affects the reported % of synchronization of blocks and batches, nothing else. #StatsUpdateBlockNumDiffThreshold = 100 ### While having more blocks to sync than updateEthBlockNumThreshold, UpdateEth will be called once in a defined number of blocks. This value only affects the reported % of synchronization of blocks and batches, nothing else #StatsUpdateFrequencyDivider = 100 [SmartContracts] ## Smart contract address of the rollup Hermez.sol #TODO - Check that Rollup address matches the one displayed at https://api.testnet.hermez.io/v1/state Rollup = \"0x679b11E0229959C1D3D27C9d20529E4C5DF7997c\" [Coordinator] ## Ethereum address that the Coordinator is using to forge batches #TODO - Add your Coordinator's Ethereum Address #ForgerAddress = \"0xaFd6e65bdB854732f39e2F577c67Ea6e83a4C2c2\" # Coordinator ### Minimum balance the forger address needs to start the Coordinator in Wei. If It is set to 0, the Coordinator will not check the balance #MinimumForgeAddressBalance = \"0\" ### Number of confirmation blocks to be sure that the tx has been mined correctly #ConfirmBlocks = 5 ### Portion of the range before the L1Batch timeout that will trigger a schedule to forge an L1Batch #L1BatchTimeoutPerc = 0.00001 ### Number of delay blocks to wait before starting the pipeline when a slot in which the Coordinator can forge is reached #StartSlotBlocksDelay = 0 ### Number of blocks ahead used to decide when to stop scheduling new batches #ScheduleBatchBlocksAheadCheck = 0 ### Number of margin blocks used to decide when to stop sending batches to the smart contract #SendBatchBlocksMarginCheck = 0 ### Interval between calls to the ProofServer to check the status #ProofServerPollInterval = \"1s\" ### Interval between forge retries after an error #ForgeRetryInterval = \"10s\" ### Interval between calls to the main handler of a synced block after an error #SyncRetryInterval = \"1s\" #Delay after which a batch is forged if the slot is already committed. If It is set to \"0s\", the Coordinator will continuously forge at the maximum rate ForgeDelay = \"0s\" ### Delay after a forged batch if there are no txs to forge. If It is set to 0s, the Coordinator will continuously forge even if the batches are empty ForgeNoTxsDelay = \"1s\" ### Interval between calls to the PurgeByExternalDelete function of the l2db which deletes pending txs externally marked by the column `external_delete` #PurgeByExtDelInterval = \"1m\" ### Enables the Coordinator to forge in slots if the empty slots reach the slot deadline #MustForgeAtSlotDeadline = true ### It will make the Coordinator forge at most one batch per slot, only if there are included txs in that batch, or pending l1UserTxs in the smart contract. Setting this parameter overrides `ForgeDelay`, `ForgeNoTxsDelay`, `MustForgeAtSlotDeadline` and `IgnoreSlotCommitment`. #IgnoreSlotCommitment = true ### This parameter will make the Coordinator forge at most one batch per slot, only if there are included txs in that batch, or pending l1UserTxs in the smart contract. Setting this parameter overrides `ForgeDelay`, `ForgeNoTxsDelay`, `MustForgeAtSlotDeadline` and `IgnoreSlotCommitment`. #ForgeOncePerSlotIfTxs = false [Coordinator.FeeAccount] ## Ethereum address of the account that will receive the fees # TODO - Add Fee account Ethereum address #Address = \"0xbDF0C0f0B367Ade948545140788FE2db319B7B61\" ## BJJ is the baby jub jub public key of the account that will receive the fees #BJJ = \"Add Fee account internal address\" TODO #BJJ = \"0x8f785561426c4caa16b6b37283e6d68ef7873a2ccd3dc7eb004274189983dd60\" [Coordinator.L2DB] ### Number of batches after which non-pending L2Txs are deleted from the pool #SafetyPeriod = 10 ### Maximum number of pending L2Txs that can be stored in the pool #MaxTxs = 1000000 ### Minimum fee in USD that a tx must pay in order to be accepted into the pool MinFeeUSD = 0.0 ### Maximum fee in USD that a tx must pay in order to be accepted into the pool #MaxFeeUSD = 10.00 ### Time To Live for L2Txs in the pool. L2Txs older than TTL will be deleted. #TTL = \"24h\" ### Delay between batches to purge outdated transactions. Outdated L2Txs are those that have been forged or marked as invalid for longer than the SafetyPeriod and pending L2Txs that have been in the pool for longer than TTL once there are MaxTxs #PurgeBatchDelay = 10 ### Delay between batches to mark invalid transactions due to nonce lower than the account nonce #InvalidateBatchDelay = 20 ### Delay between blocks to purge outdated transactions. Outdated L2Txs are those that have been forged or marked as invalid for longer than the SafetyPeriod and pending L2Txs that have been in the pool for longer than TTL once there are MaxTxs. #PurgeBlockDelay = 10 ### Delay between blocks to mark invalid transactions due to nonce lower than the account nonce #InvalidateBlockDelay = 20 [Coordinator.TxSelector] ### Path where the TxSelector StateDB is stored Path = \"/tmp/hermez/txselector\" [Coordinator.BatchBuilder] ### Path where the BatchBuilder StateDB is stored Path = \"/tmp/hermez/batchbuilder\" [Coordinator.ServerProofs] ## Server proof API URLs # TODO - Add Prover server URL #URLs = [\"http://10.48.11.153:9080\"] [Coordinator.Circuit] ## Maximum number of txs supported by the circuit # TODO - Check circuit size (2048/400) MaxTx = 2048 NLevels = 32 #[Coordinator.EthClient] ### Interval between receipt checks of Ethereum transactions in the TxManager #CheckLoopInterval = \"500ms\" ### Number of attempts to do an Eth client RPC call before giving up #Attempts = 4 ### Delay between attempts do do an Eth client RPC call #AttemptsDelay = \"500ms\" ### Timeout after which a non-mined Ethereum transaction will be resent (reusing the nonce) with a newly calculated gas price #TxResendTimeout = \"2m\" ### Disables reusing nonces of pending transactions for new replacement transactions #NoReuseNonce = false ### Maximum gas price allowed for Ethereum transactions in Gwei #MaxGasPrice = 500 ### Minimum gas price allowed for Ethereum transactions in Gwei #MinGasPrice = 5 ### Percentage increased of gas price set in an Ethereum transaction from the suggested gas price by the Ethereum node #GasPriceIncPerc = 5 [Coordinator.EthClient.Keystore] ### Path where the keystore is stored Path = \"/home/ubuntu/keystore\" ## Password used to decrypt the keys in the keystore Password = \"yourpasswordhere\" #[Coordinator.EthClient.ForgeBatchGasCost] ### Gas needed to forge an empty batch #Fixed = 900000 ### Gas needed per L1 tx #L1UserTx = 15000 ### Gas needed for a Coordinator L1 tx #L1CoordTx = 7000 ### Gas needed for an L2 tx #L2Tx = 600 #[Coordinator.API] ### Enables Coordinator API endpoints #Coordinator = true [Coordinator.Debug] ## If this parameter is set, specifies the path where batchInfo is stored in JSON in every step/update of the pipeline BatchPath = \"/tmp/hermez/batchesdebug\" ## If lightScrypt is set, uses light parameters for the Ethereum keystore encryption algorithm LightScrypt = false ## RollupVerifierIndex is the index of the verifier to use in the Rollup smart contract. The verifier chosen by index must match with the Circuit parameters. Only for debug purposes. It can't be used as env variable #RollupVerifierIndex = 0 [Coordinator.Etherscan] ## If this parameter is set, specifies the Etherscan endpoint to get the gas estimations for that momment URL = \"https://api.etherscan.io\" ## APIKey parameter allows access to Etherscan services # TODO - Set true API Key APIKey = \"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\" #[RecommendedFeePolicy] # Strategy used to calculate the recommended fee that the API will expose. # Available options: # - Static: always return the same value (StaticValue) in USD # - AvgLastHour: calculate using the average fee of the forged transactions during the last hour ### Selects the mode. \"Static\" or \"AvgLastHour\" #PolicyType = \"Static\" ### If PolicyType is \"static\" defines the recommended fee value #StaticValue = 0.10","title":"Cfg.testnet.coord"},{"location":"Hermez_1.0/developers/coord-files/docker-compose.sandbox/","text":"version: \"3.3\" services: hermez-db-test: image: postgres ports: - \"5432:5432\" environment: POSTGRES_USER: \"hermez\" POSTGRES_PASSWORD: \"yourpasswordhere\" privatebc: image: public.ecr.aws/r7d5k1t8/hermez-geth:latest ports: - \"8545:8545\" environment: - DEV_PERIOD entrypoint: [\"geth\", \"--http\", \"--http.addr\", \"0.0.0.0\",\"--http.corsdomain\", \"*\", \"--http.vhosts\" ,\"*\", \"--ws\", \"--ws.origins\", \"*\", \"--ws.addr\", \"0.0.0.0\", \"--dev\", \"--datadir\", \"/geth_data$DEV_PERIOD\"]","title":"Docker compose.sandbox"},{"location":"Hermez_1.0/developers/protocol/consensus/consensus/","text":"Forging Consensus Protocol Hermez will run an auction to incentivize the efficiency of coordinators, meaning that they need to be very effective and include as many transactions as they can in the slots in order to compensate for their bidding costs, gas costs and operations costs. The general purpose of this protocol is to describe the rules to coordinate the auction where the bids will be placed only in HEZ utility token. General Goals Select a single coordinator for a given slot to forge a batch Avoid stops of ZK-Rollup Incentivize coordinators to participate in the ZK-Rollup Scenario ZK-Rollup is divided into slots of a certain duration: Ethereum Block = ~ 15s Slot = 40 Ethereum Blocks = 40 * 15s = 600s = 10 min Slot deadline = 20 Note: The number of blocks per slot is a parameter that is hardcoded on the smart contracts, so in order to change this parameter we need to make an upgrade on consensus smart contracts Auction Bids in the Auction will be placed only in HEZ. The auction of future slots will be open up to 1 month (system parameter), the opening is a sliding window that opens a new slot every 40 blocks. Auction will be closed 2 slots (system parameter) before the start time of the forging in the slot. A bid will not pay a premium on top of the previous bid, but a bid placed in the auction should be at least 1.1 times (system parameter) the previous bid or over the minimum bidding price (if it's the first one) to be accepted as valid. Auction will be structured in series of 6 slots slots[5] , with 10 HEZ as initial minimal bidding price for all the slots. The governance can change this value slots[i] independently at any time and affecting open auctions , in such a way that all the slots whose slot % 6 = i will have the same minimum bid. Bids under the new minimal bidding price will not be considered as valid bids anymore and bidders (if no new bids outbid theirs) will be sent back their HEZ in the event that the slot is fully processed (forge). When a slot number in the series gets 0 HEZ value , it will be locked and governance will not be able to modify the minimal bidding price anymore, so it will become decentralized . HEZ Token Bidding Allocation In the moment of placement, all bids in form of HEZ token placed in the auction will be stored in the smart contract, and will pay the gas to send the previous bidder their HEZ back. Once the slot is forged, the tokens are assigned to three different accounts: A part of the tokens will be burnt . So they will not be at 0x0 address, but reduced from the total token amount. A part will be assigned to the donations account . Governance process will decide how to allocate these funds into different projects. The rest will be allocated as Hermez Network usage incentives, compensating active engagement and network adoption, e.g. rewarding transaction and rewarding the holding of specific tokens in Hermez L2 addresses, instead of on L1 Ethereum addresses. Boot Coordinator This element has the mission to support the network bootstrap and at some moment will disappear when the network gains traction. Removal of the boot coordinator will be a governance decision. Basically, its role is to forge any slot where there is no winner in the auction without the need to make a bid. Free Coordinator Override There is a situation where any coordinator can forge batches without bidding. This happens when the coordinator of the current slot doesn't forge any batch in the N first available inside the slot. This mechanism responds to the need of the network for the efficiency of coordinators, and cover from potential technical problems or attacks. It also provides a guarantee to users that all funds will be recoverable from the L2 network because there is a deadline after which a batch MUST include L1 pending transactions, which includes L2 (funds) exit operations. System Parameters slotDeadline Number of blocks after the beginning of a slot after which any coordinator can forge if the winner has not forged any batch in that slot Default Value: 20 closedAuctionSlots Distance (#slots) to the closest slot to which you can bid Default value: 2 (2 Slots = 2 * 40 Blocks = 2 * 40 * 15s = 20 min ) openAuctionSlots Distance (#slots) to the farthest slot to which you can bid Default value: 4320 slots (30 days) INITIAL_MINIMAL_BIDDING Minimum bid when no one has bid yet Default value: 10 * (1e18) outbidding Minimum outbid (percentage, two decimal precision) over the previous one to consider it valid Default value: 1000 donationAddress Default value: Pending to be defined governanceAddress Default value: Pending to be defined bootCoordinator Default value: Pending to be defined ALLOCATION_RATIO How the HEZ tokens deposited by the slot winner are distributed Default values: Burn: 40.00% - Donation: 40.00% - HGT: 20.00% Note: All this parameters are managed by the governance, this means that they can change it at any time without any delay","title":"Forging consensus protocol"},{"location":"Hermez_1.0/developers/protocol/consensus/consensus/#forging-consensus-protocol","text":"Hermez will run an auction to incentivize the efficiency of coordinators, meaning that they need to be very effective and include as many transactions as they can in the slots in order to compensate for their bidding costs, gas costs and operations costs. The general purpose of this protocol is to describe the rules to coordinate the auction where the bids will be placed only in HEZ utility token.","title":"Forging Consensus Protocol"},{"location":"Hermez_1.0/developers/protocol/consensus/consensus/#general-goals","text":"Select a single coordinator for a given slot to forge a batch Avoid stops of ZK-Rollup Incentivize coordinators to participate in the ZK-Rollup","title":"General Goals"},{"location":"Hermez_1.0/developers/protocol/consensus/consensus/#scenario","text":"ZK-Rollup is divided into slots of a certain duration: Ethereum Block = ~ 15s Slot = 40 Ethereum Blocks = 40 * 15s = 600s = 10 min Slot deadline = 20 Note: The number of blocks per slot is a parameter that is hardcoded on the smart contracts, so in order to change this parameter we need to make an upgrade on consensus smart contracts","title":"Scenario"},{"location":"Hermez_1.0/developers/protocol/consensus/consensus/#auction","text":"Bids in the Auction will be placed only in HEZ. The auction of future slots will be open up to 1 month (system parameter), the opening is a sliding window that opens a new slot every 40 blocks. Auction will be closed 2 slots (system parameter) before the start time of the forging in the slot. A bid will not pay a premium on top of the previous bid, but a bid placed in the auction should be at least 1.1 times (system parameter) the previous bid or over the minimum bidding price (if it's the first one) to be accepted as valid. Auction will be structured in series of 6 slots slots[5] , with 10 HEZ as initial minimal bidding price for all the slots. The governance can change this value slots[i] independently at any time and affecting open auctions , in such a way that all the slots whose slot % 6 = i will have the same minimum bid. Bids under the new minimal bidding price will not be considered as valid bids anymore and bidders (if no new bids outbid theirs) will be sent back their HEZ in the event that the slot is fully processed (forge). When a slot number in the series gets 0 HEZ value , it will be locked and governance will not be able to modify the minimal bidding price anymore, so it will become decentralized .","title":"Auction"},{"location":"Hermez_1.0/developers/protocol/consensus/consensus/#hez-token-bidding-allocation","text":"In the moment of placement, all bids in form of HEZ token placed in the auction will be stored in the smart contract, and will pay the gas to send the previous bidder their HEZ back. Once the slot is forged, the tokens are assigned to three different accounts: A part of the tokens will be burnt . So they will not be at 0x0 address, but reduced from the total token amount. A part will be assigned to the donations account . Governance process will decide how to allocate these funds into different projects. The rest will be allocated as Hermez Network usage incentives, compensating active engagement and network adoption, e.g. rewarding transaction and rewarding the holding of specific tokens in Hermez L2 addresses, instead of on L1 Ethereum addresses.","title":"HEZ Token Bidding Allocation"},{"location":"Hermez_1.0/developers/protocol/consensus/consensus/#boot-coordinator","text":"This element has the mission to support the network bootstrap and at some moment will disappear when the network gains traction. Removal of the boot coordinator will be a governance decision. Basically, its role is to forge any slot where there is no winner in the auction without the need to make a bid.","title":"Boot Coordinator"},{"location":"Hermez_1.0/developers/protocol/consensus/consensus/#free-coordinator-override","text":"There is a situation where any coordinator can forge batches without bidding. This happens when the coordinator of the current slot doesn't forge any batch in the N first available inside the slot. This mechanism responds to the need of the network for the efficiency of coordinators, and cover from potential technical problems or attacks. It also provides a guarantee to users that all funds will be recoverable from the L2 network because there is a deadline after which a batch MUST include L1 pending transactions, which includes L2 (funds) exit operations.","title":"Free Coordinator Override"},{"location":"Hermez_1.0/developers/protocol/consensus/consensus/#system-parameters","text":"slotDeadline Number of blocks after the beginning of a slot after which any coordinator can forge if the winner has not forged any batch in that slot Default Value: 20 closedAuctionSlots Distance (#slots) to the closest slot to which you can bid Default value: 2 (2 Slots = 2 * 40 Blocks = 2 * 40 * 15s = 20 min ) openAuctionSlots Distance (#slots) to the farthest slot to which you can bid Default value: 4320 slots (30 days) INITIAL_MINIMAL_BIDDING Minimum bid when no one has bid yet Default value: 10 * (1e18) outbidding Minimum outbid (percentage, two decimal precision) over the previous one to consider it valid Default value: 1000 donationAddress Default value: Pending to be defined governanceAddress Default value: Pending to be defined bootCoordinator Default value: Pending to be defined ALLOCATION_RATIO How the HEZ tokens deposited by the slot winner are distributed Default values: Burn: 40.00% - Donation: 40.00% - HGT: 20.00% Note: All this parameters are managed by the governance, this means that they can change it at any time without any delay","title":"System Parameters"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/fee-table/","text":"Transaction Fee Table Fees in L2 transaction apply a factor encoded by an index, as shown in the table above and the formula below: \\(0 \\quad \\text{ if } i = 0\\) \\(2^{-60 + i\u00b7(\\frac{-8-(-60)}{32})} \\quad \\text{if} \\quad 1 \\leq i \\leq 31\\) \\(2^{-8 + (i-32)\u00b7(\\frac{0-(-8)}{160})} \\quad \\text{if} \\quad 32 \\leq i \\leq 191\\) \\(2^{(i-192)\u00b7(\\frac{63-0}{63})} \\quad \\text{if} \\quad 192 \\leq i \\leq 255\\) This is the complete table of the fees factors by fee index: feeIndex feeExponent feeFactor 0 0 0,00E+00 1 -58,375 2,68E-18 2 -56,75 8,25E-18 3 -55,125 2,55E-17 4 -53,5 7,85E-17 5 -51,875 2,42E-16 6 -50,25 7,47E-16 7 -48,625 2,30E-15 8 -47 7,11E-15 9 -45,375 2,19E-14 10 -43,75 6,76E-14 11 -42,125 2,09E-13 12 -40,5 6,43E-13 13 -38,875 1,98E-12 14 -37,25 6,12E-12 15 -35,625 1,89E-11 16 -34 5,82E-11 17 -32,375 1,80E-10 18 -30,75 5,54E-10 19 -29,125 1,71E-09 20 -27,5 5,27E-09 21 -25,875 1,62E-08 22 -24,25 5,01E-08 23 -22,625 1,55E-07 24 -21 4,77E-07 25 -19,375 1,47E-06 26 -17,75 4,54E-06 27 -16,125 1,40E-05 28 -14,5 4,32E-05 29 -12,875 1,33E-04 30 -11,25 4,11E-04 31 -9,625 1,27E-03 32 -8 3,91E-03 33 -7,95 4,04E-03 34 -7,9 4,19E-03 35 -7,85 4,33E-03 36 -7,8 4,49E-03 37 -7,75 4,65E-03 38 -7,7 4,81E-03 39 -7,65 4,98E-03 40 -7,6 5,15E-03 41 -7,55 5,34E-03 42 -7,5 5,52E-03 43 -7,45 5,72E-03 44 -7,4 5,92E-03 45 -7,35 6,13E-03 46 -7,3 6,35E-03 47 -7,25 6,57E-03 48 -7,2 6,80E-03 49 -7,15 7,04E-03 50 -7,1 7,29E-03 51 -7,05 7,55E-03 52 -7 7,81E-03 53 -6,95 8,09E-03 54 -6,9 8,37E-03 55 -6,85 8,67E-03 56 -6,8 8,97E-03 57 -6,75 9,29E-03 58 -6,7 9,62E-03 59 -6,65 9,96E-03 60 -6,6 1,03E-02 61 -6,55 1,07E-02 62 -6,5 1,10E-02 63 -6,45 1,14E-02 64 -6,4 1,18E-02 65 -6,35 1,23E-02 66 -6,3 1,27E-02 67 -6,25 1,31E-02 68 -6,2 1,36E-02 69 -6,15 1,41E-02 70 -6,1 1,46E-02 71 -6,05 1,51E-02 72 -6 1,56E-02 73 -5,95 1,62E-02 74 -5,9 1,67E-02 75 -5,85 1,73E-02 76 -5,8 1,79E-02 77 -5,75 1,86E-02 78 -5,7 1,92E-02 79 -5,65 1,99E-02 80 -5,6 2,06E-02 81 -5,55 2,13E-02 82 -5,5 2,21E-02 83 -5,45 2,29E-02 84 -5,4 2,37E-02 85 -5,35 2,45E-02 86 -5,3 2,54E-02 87 -5,25 2,63E-02 88 -5,2 2,72E-02 89 -5,15 2,82E-02 90 -5,1 2,92E-02 91 -5,05 3,02E-02 92 -5 3,13E-02 93 -4,95 3,24E-02 94 -4,9 3,35E-02 95 -4,85 3,47E-02 96 -4,8 3,59E-02 97 -4,75 3,72E-02 98 -4,7 3,85E-02 99 -4,65 3,98E-02 100 -4,6 4,12E-02 101 -4,55 4,27E-02 102 -4,5 4,42E-02 103 -4,45 4,58E-02 104 -4,4 4,74E-02 105 -4,35 4,90E-02 106 -4,3 5,08E-02 107 -4,25 5,26E-02 108 -4,2 5,44E-02 109 -4,15 5,63E-02 110 -4,1 5,83E-02 111 -4,05 6,04E-02 112 -4 6,25E-02 113 -3,95 6,47E-02 114 -3,9 6,70E-02 115 -3,85 6,93E-02 116 -3,8 7,18E-02 117 -3,75 7,43E-02 118 -3,7 7,69E-02 119 -3,65 7,97E-02 120 -3,6 8,25E-02 121 -3,55 8,54E-02 122 -3,5 8,84E-02 123 -3,45 9,15E-02 124 -3,4 9,47E-02 125 -3,35 9,81E-02 126 -3,3 1,02E-01 127 -3,25 1,05E-01 128 -3,2 1,09E-01 129 -3,15 1,13E-01 130 -3,1 1,17E-01 131 -3,05 1,21E-01 132 -3 1,25E-01 133 -2,95 1,29E-01 134 -2,9 1,34E-01 135 -2,85 1,39E-01 136 -2,8 1,44E-01 137 -2,75 1,49E-01 138 -2,7 1,54E-01 139 -2,65 1,59E-01 140 -2,6 1,65E-01 141 -2,55 1,71E-01 142 -2,5 1,77E-01 143 -2,45 1,83E-01 144 -2,4 1,89E-01 145 -2,35 1,96E-01 146 -2,3 2,03E-01 147 -2,25 2,10E-01 148 -2,2 2,18E-01 149 -2,15 2,25E-01 150 -2,1 2,33E-01 151 -2,05 2,41E-01 152 -2 2,50E-01 153 -1,95 2,59E-01 154 -1,9 2,68E-01 155 -1,85 2,77E-01 156 -1,8 2,87E-01 157 -1,75 2,97E-01 158 -1,7 3,08E-01 159 -1,65 3,19E-01 160 -1,6 3,30E-01 161 -1,55 3,42E-01 162 -1,5 3,54E-01 163 -1,45 3,66E-01 164 -1,4 3,79E-01 165 -1,35 3,92E-01 166 -1,3 4,06E-01 167 -1,25 4,20E-01 168 -1,2 4,35E-01 169 -1,15 4,51E-01 170 -1,1 4,67E-01 171 -1,05 4,83E-01 172 -1 5,00E-01 173 -0,95 5,18E-01 174 -0,9 5,36E-01 175 -0,85 5,55E-01 176 -0,8 5,74E-01 177 -0,75 5,95E-01 178 -0,7 6,16E-01 179 -0,65 6,37E-01 180 -0,6 6,60E-01 181 -0,55 6,83E-01 182 -0,5 7,07E-01 183 -0,45 7,32E-01 184 -0,4 7,58E-01 185 -0,35 7,85E-01 186 -0,3 8,12E-01 187 -0,25 8,41E-01 188 -0,2 8,71E-01 189 -0,15 9,01E-01 190 -0,1 9,33E-01 191 -0,05 9,66E-01 192 0 1,00E+00 193 1 2,00E+00 194 2 4,00E+00 195 3 8,00E+00 196 4 1,60E+01 197 5 3,20E+01 198 6 6,40E+01 199 7 1,28E+02 200 8 2,56E+02 201 9 5,12E+02 202 10 1,02E+03 203 11 2,05E+03 204 12 4,10E+03 205 13 8,19E+03 206 14 1,64E+04 207 15 3,28E+04 208 16 6,55E+04 209 17 1,31E+05 210 18 2,62E+05 211 19 5,24E+05 212 20 1,05E+06 213 21 2,10E+06 214 22 4,19E+06 215 23 8,39E+06 216 24 1,68E+07 217 25 3,36E+07 218 26 6,71E+07 219 27 1,34E+08 220 28 2,68E+08 221 29 5,37E+08 222 30 1,07E+09 223 31 2,15E+09 224 32 4,29E+09 225 33 8,59E+09 226 34 1,72E+10 227 35 3,44E+10 228 36 6,87E+10 229 37 1,37E+11 230 38 2,75E+11 231 39 5,50E+11 232 40 1,10E+12 233 41 2,20E+12 234 42 4,40E+12 235 43 8,80E+12 236 44 1,76E+13 237 45 3,52E+13 238 46 7,04E+13 239 47 1,41E+14 240 48 2,81E+14 241 49 5,63E+14 242 50 1,13E+15 243 51 2,25E+15 244 52 4,50E+15 245 53 9,01E+15 246 54 1,80E+16 247 55 3,60E+16 248 56 7,21E+16 249 57 1,44E+17 250 58 2,88E+17 251 59 5,76E+17 252 60 1,15E+18 253 61 2,31E+18 254 62 4,61E+18 255 63 9,22E+18 FeeFactor left shifted Fee factor is shifted according: - \\(\\text{bitsShiftPrecision} = 60\\) - \\(\\text{feeFactorShifted} = (\\text{feeFactor} << \\text{bitsShiftPrecison}) \\quad \\text{if} \\quad i < 192\\) - \\(\\text{feeFactorShifted} = \\text{feeFactor} \\quad \\text{if} \\quad i \\geq 192\\) feeIndex feeFactorShifted 0 0 1 3 2 9 3 29 4 90 5 279 6 861 7 2655 8 8192 9 25267 10 77935 11 240387 12 741455 13 2286960 14 7053950 15 21757357 16 67108864 17 206992033 18 638450708 19 1969251187 20 6074000999 21 18734780191 22 57785961645 23 178236271212 24 549755813888 25 1695678735018 26 5230188203117 27 16132105731538 28 49758216191607 29 153475319327371 30 473382597799226 31 1460111533771401 32 4503599627370496 33 4662418725241772 34 4826838566504035 35 4997056660946426 36 5173277483525749 37 5355712719992597 38 5544581521179432 39 5740110766256133 40 5942535335269230 41 6152098391292193 42 6369051672525772 43 6593655794699191 44 6826180564135515 45 7066905301857248 46 7316119179121470 47 7574121564787630 48 7841222384935199 49 8117742495163242 50 8404014066019092 51 8700380982019120 52 9007199254740992 53 9324837450483544 54 9653677133008070 55 9994113321892852 56 10346554967051498 57 10711425439985194 58 11089163042358864 59 11480221532512266 60 11885070670538460 61 12304196782584386 62 12738103345051544 63 13187311589398382 64 13652361128271030 65 14133810603714496 66 14632238358242940 67 15148243129575260 68 15682444769870398 69 16235484990326484 70 16808028132038184 71 17400761964038240 72 18014398509481984 73 18649674900967100 74 19307354266016140 75 19988226643785704 76 20693109934102996 77 21422850879970388 78 22178326084717744 79 22960443065024532 80 23770141341076920 81 24608393565168772 82 25476206690103088 83 26374623178796784 84 27304722256542060 85 28267621207428992 86 29264476716485880 87 30296486259150520 88 31364889539740816 89 32470969980652968 90 33616056264076368 91 34801523928076480 92 36028797018963968 93 37299349801934200 94 38614708532032280 95 39976453287571408 96 41386219868205992 97 42845701759940776 98 44356652169435488 99 45920886130049064 100 47540282682153840 101 49216787130337544 102 50952413380206176 103 52749246357593568 104 54609444513084120 105 56535242414857984 106 58528953432971760 107 60592972518301040 108 62729779079481632 109 64941939961305936 110 67232112528152736 111 69603047856152960 112 72057594037927936 113 74598699603868352 114 77229417064064608 115 79952906575142816 116 82772439736411984 117 85691403519881552 118 88713304338870912 119 91841772260098192 120 95080565364307680 121 98433574260675088 122 101904826760412352 123 105498492715187056 124 109218889026168304 125 113070484829715968 126 117057906865943520 127 121185945036602080 128 125459558158963264 129 129883879922611968 130 134464225056305472 131 139206095712305920 132 144115188075855872 133 149197399207736800 134 154458834128129216 135 159905813150285632 136 165544879472823968 137 171382807039763104 138 177426608677741952 139 183683544520196384 140 190161130728615360 141 196867148521350176 142 203809653520824704 143 210996985430374272 144 218437778052336608 145 226140969659431936 146 234115813731887040 147 242371890073204160 148 250919116317926528 149 259767759845223936 150 268928450112610944 151 278412191424611840 152 288230376151711744 153 298394798415473600 154 308917668256258432 155 319811626300571264 156 331089758945647936 157 342765614079526208 158 354853217355483904 159 367367089040392768 160 380322261457230720 161 393734297042700352 162 407619307041649408 163 421993970860748544 164 436875556104673216 165 452281939318863872 166 468231627463774080 167 484743780146408320 168 501838232635853056 169 519535519690447872 170 537856900225221888 171 556824382849223680 172 576460752303423488 173 596789596830947200 174 617835336512516864 175 639623252601142528 176 662179517891295872 177 685531228159052416 178 709706434710967808 179 734734178080785536 180 760644522914461440 181 787468594085400704 182 815238614083298816 183 843987941721497088 184 873751112209346432 185 904563878637727744 186 936463254927548160 187 969487560292816640 188 1003676465271706112 189 1039071039380895744 190 1075713800450443776 191 1113648765698447360 192 1 193 2 194 4 195 8 196 16 197 32 198 64 199 128 200 256 201 512 202 1024 203 2048 204 4096 205 8192 206 16384 207 32768 208 65536 209 131072 210 262144 211 524288 212 1048576 213 2097152 214 4194304 215 8388608 216 16777216 217 33554432 218 67108864 219 134217728 220 268435456 221 536870912 222 1073741824 223 2147483648 224 4294967296 225 8589934592 226 17179869184 227 34359738368 228 68719476736 229 137438953472 230 274877906944 231 549755813888 232 1099511627776 233 2199023255552 234 4398046511104 235 8796093022208 236 17592186044416 237 35184372088832 238 70368744177664 239 140737488355328 240 281474976710656 241 562949953421312 242 1125899906842624 243 2251799813685248 244 4503599627370496 245 9007199254740992 246 18014398509481984 247 36028797018963968 248 72057594037927936 249 144115188075855872 250 288230376151711744 251 576460752303423488 252 1152921504606846976 253 2305843009213693952 254 4611686018427387904 255 9223372036854775808","title":"Transaction Fee Table"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/fee-table/#transaction-fee-table","text":"Fees in L2 transaction apply a factor encoded by an index, as shown in the table above and the formula below: \\(0 \\quad \\text{ if } i = 0\\) \\(2^{-60 + i\u00b7(\\frac{-8-(-60)}{32})} \\quad \\text{if} \\quad 1 \\leq i \\leq 31\\) \\(2^{-8 + (i-32)\u00b7(\\frac{0-(-8)}{160})} \\quad \\text{if} \\quad 32 \\leq i \\leq 191\\) \\(2^{(i-192)\u00b7(\\frac{63-0}{63})} \\quad \\text{if} \\quad 192 \\leq i \\leq 255\\) This is the complete table of the fees factors by fee index: feeIndex feeExponent feeFactor 0 0 0,00E+00 1 -58,375 2,68E-18 2 -56,75 8,25E-18 3 -55,125 2,55E-17 4 -53,5 7,85E-17 5 -51,875 2,42E-16 6 -50,25 7,47E-16 7 -48,625 2,30E-15 8 -47 7,11E-15 9 -45,375 2,19E-14 10 -43,75 6,76E-14 11 -42,125 2,09E-13 12 -40,5 6,43E-13 13 -38,875 1,98E-12 14 -37,25 6,12E-12 15 -35,625 1,89E-11 16 -34 5,82E-11 17 -32,375 1,80E-10 18 -30,75 5,54E-10 19 -29,125 1,71E-09 20 -27,5 5,27E-09 21 -25,875 1,62E-08 22 -24,25 5,01E-08 23 -22,625 1,55E-07 24 -21 4,77E-07 25 -19,375 1,47E-06 26 -17,75 4,54E-06 27 -16,125 1,40E-05 28 -14,5 4,32E-05 29 -12,875 1,33E-04 30 -11,25 4,11E-04 31 -9,625 1,27E-03 32 -8 3,91E-03 33 -7,95 4,04E-03 34 -7,9 4,19E-03 35 -7,85 4,33E-03 36 -7,8 4,49E-03 37 -7,75 4,65E-03 38 -7,7 4,81E-03 39 -7,65 4,98E-03 40 -7,6 5,15E-03 41 -7,55 5,34E-03 42 -7,5 5,52E-03 43 -7,45 5,72E-03 44 -7,4 5,92E-03 45 -7,35 6,13E-03 46 -7,3 6,35E-03 47 -7,25 6,57E-03 48 -7,2 6,80E-03 49 -7,15 7,04E-03 50 -7,1 7,29E-03 51 -7,05 7,55E-03 52 -7 7,81E-03 53 -6,95 8,09E-03 54 -6,9 8,37E-03 55 -6,85 8,67E-03 56 -6,8 8,97E-03 57 -6,75 9,29E-03 58 -6,7 9,62E-03 59 -6,65 9,96E-03 60 -6,6 1,03E-02 61 -6,55 1,07E-02 62 -6,5 1,10E-02 63 -6,45 1,14E-02 64 -6,4 1,18E-02 65 -6,35 1,23E-02 66 -6,3 1,27E-02 67 -6,25 1,31E-02 68 -6,2 1,36E-02 69 -6,15 1,41E-02 70 -6,1 1,46E-02 71 -6,05 1,51E-02 72 -6 1,56E-02 73 -5,95 1,62E-02 74 -5,9 1,67E-02 75 -5,85 1,73E-02 76 -5,8 1,79E-02 77 -5,75 1,86E-02 78 -5,7 1,92E-02 79 -5,65 1,99E-02 80 -5,6 2,06E-02 81 -5,55 2,13E-02 82 -5,5 2,21E-02 83 -5,45 2,29E-02 84 -5,4 2,37E-02 85 -5,35 2,45E-02 86 -5,3 2,54E-02 87 -5,25 2,63E-02 88 -5,2 2,72E-02 89 -5,15 2,82E-02 90 -5,1 2,92E-02 91 -5,05 3,02E-02 92 -5 3,13E-02 93 -4,95 3,24E-02 94 -4,9 3,35E-02 95 -4,85 3,47E-02 96 -4,8 3,59E-02 97 -4,75 3,72E-02 98 -4,7 3,85E-02 99 -4,65 3,98E-02 100 -4,6 4,12E-02 101 -4,55 4,27E-02 102 -4,5 4,42E-02 103 -4,45 4,58E-02 104 -4,4 4,74E-02 105 -4,35 4,90E-02 106 -4,3 5,08E-02 107 -4,25 5,26E-02 108 -4,2 5,44E-02 109 -4,15 5,63E-02 110 -4,1 5,83E-02 111 -4,05 6,04E-02 112 -4 6,25E-02 113 -3,95 6,47E-02 114 -3,9 6,70E-02 115 -3,85 6,93E-02 116 -3,8 7,18E-02 117 -3,75 7,43E-02 118 -3,7 7,69E-02 119 -3,65 7,97E-02 120 -3,6 8,25E-02 121 -3,55 8,54E-02 122 -3,5 8,84E-02 123 -3,45 9,15E-02 124 -3,4 9,47E-02 125 -3,35 9,81E-02 126 -3,3 1,02E-01 127 -3,25 1,05E-01 128 -3,2 1,09E-01 129 -3,15 1,13E-01 130 -3,1 1,17E-01 131 -3,05 1,21E-01 132 -3 1,25E-01 133 -2,95 1,29E-01 134 -2,9 1,34E-01 135 -2,85 1,39E-01 136 -2,8 1,44E-01 137 -2,75 1,49E-01 138 -2,7 1,54E-01 139 -2,65 1,59E-01 140 -2,6 1,65E-01 141 -2,55 1,71E-01 142 -2,5 1,77E-01 143 -2,45 1,83E-01 144 -2,4 1,89E-01 145 -2,35 1,96E-01 146 -2,3 2,03E-01 147 -2,25 2,10E-01 148 -2,2 2,18E-01 149 -2,15 2,25E-01 150 -2,1 2,33E-01 151 -2,05 2,41E-01 152 -2 2,50E-01 153 -1,95 2,59E-01 154 -1,9 2,68E-01 155 -1,85 2,77E-01 156 -1,8 2,87E-01 157 -1,75 2,97E-01 158 -1,7 3,08E-01 159 -1,65 3,19E-01 160 -1,6 3,30E-01 161 -1,55 3,42E-01 162 -1,5 3,54E-01 163 -1,45 3,66E-01 164 -1,4 3,79E-01 165 -1,35 3,92E-01 166 -1,3 4,06E-01 167 -1,25 4,20E-01 168 -1,2 4,35E-01 169 -1,15 4,51E-01 170 -1,1 4,67E-01 171 -1,05 4,83E-01 172 -1 5,00E-01 173 -0,95 5,18E-01 174 -0,9 5,36E-01 175 -0,85 5,55E-01 176 -0,8 5,74E-01 177 -0,75 5,95E-01 178 -0,7 6,16E-01 179 -0,65 6,37E-01 180 -0,6 6,60E-01 181 -0,55 6,83E-01 182 -0,5 7,07E-01 183 -0,45 7,32E-01 184 -0,4 7,58E-01 185 -0,35 7,85E-01 186 -0,3 8,12E-01 187 -0,25 8,41E-01 188 -0,2 8,71E-01 189 -0,15 9,01E-01 190 -0,1 9,33E-01 191 -0,05 9,66E-01 192 0 1,00E+00 193 1 2,00E+00 194 2 4,00E+00 195 3 8,00E+00 196 4 1,60E+01 197 5 3,20E+01 198 6 6,40E+01 199 7 1,28E+02 200 8 2,56E+02 201 9 5,12E+02 202 10 1,02E+03 203 11 2,05E+03 204 12 4,10E+03 205 13 8,19E+03 206 14 1,64E+04 207 15 3,28E+04 208 16 6,55E+04 209 17 1,31E+05 210 18 2,62E+05 211 19 5,24E+05 212 20 1,05E+06 213 21 2,10E+06 214 22 4,19E+06 215 23 8,39E+06 216 24 1,68E+07 217 25 3,36E+07 218 26 6,71E+07 219 27 1,34E+08 220 28 2,68E+08 221 29 5,37E+08 222 30 1,07E+09 223 31 2,15E+09 224 32 4,29E+09 225 33 8,59E+09 226 34 1,72E+10 227 35 3,44E+10 228 36 6,87E+10 229 37 1,37E+11 230 38 2,75E+11 231 39 5,50E+11 232 40 1,10E+12 233 41 2,20E+12 234 42 4,40E+12 235 43 8,80E+12 236 44 1,76E+13 237 45 3,52E+13 238 46 7,04E+13 239 47 1,41E+14 240 48 2,81E+14 241 49 5,63E+14 242 50 1,13E+15 243 51 2,25E+15 244 52 4,50E+15 245 53 9,01E+15 246 54 1,80E+16 247 55 3,60E+16 248 56 7,21E+16 249 57 1,44E+17 250 58 2,88E+17 251 59 5,76E+17 252 60 1,15E+18 253 61 2,31E+18 254 62 4,61E+18 255 63 9,22E+18","title":"Transaction Fee Table"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/fee-table/#feefactor-left-shifted","text":"Fee factor is shifted according: - \\(\\text{bitsShiftPrecision} = 60\\) - \\(\\text{feeFactorShifted} = (\\text{feeFactor} << \\text{bitsShiftPrecison}) \\quad \\text{if} \\quad i < 192\\) - \\(\\text{feeFactorShifted} = \\text{feeFactor} \\quad \\text{if} \\quad i \\geq 192\\) feeIndex feeFactorShifted 0 0 1 3 2 9 3 29 4 90 5 279 6 861 7 2655 8 8192 9 25267 10 77935 11 240387 12 741455 13 2286960 14 7053950 15 21757357 16 67108864 17 206992033 18 638450708 19 1969251187 20 6074000999 21 18734780191 22 57785961645 23 178236271212 24 549755813888 25 1695678735018 26 5230188203117 27 16132105731538 28 49758216191607 29 153475319327371 30 473382597799226 31 1460111533771401 32 4503599627370496 33 4662418725241772 34 4826838566504035 35 4997056660946426 36 5173277483525749 37 5355712719992597 38 5544581521179432 39 5740110766256133 40 5942535335269230 41 6152098391292193 42 6369051672525772 43 6593655794699191 44 6826180564135515 45 7066905301857248 46 7316119179121470 47 7574121564787630 48 7841222384935199 49 8117742495163242 50 8404014066019092 51 8700380982019120 52 9007199254740992 53 9324837450483544 54 9653677133008070 55 9994113321892852 56 10346554967051498 57 10711425439985194 58 11089163042358864 59 11480221532512266 60 11885070670538460 61 12304196782584386 62 12738103345051544 63 13187311589398382 64 13652361128271030 65 14133810603714496 66 14632238358242940 67 15148243129575260 68 15682444769870398 69 16235484990326484 70 16808028132038184 71 17400761964038240 72 18014398509481984 73 18649674900967100 74 19307354266016140 75 19988226643785704 76 20693109934102996 77 21422850879970388 78 22178326084717744 79 22960443065024532 80 23770141341076920 81 24608393565168772 82 25476206690103088 83 26374623178796784 84 27304722256542060 85 28267621207428992 86 29264476716485880 87 30296486259150520 88 31364889539740816 89 32470969980652968 90 33616056264076368 91 34801523928076480 92 36028797018963968 93 37299349801934200 94 38614708532032280 95 39976453287571408 96 41386219868205992 97 42845701759940776 98 44356652169435488 99 45920886130049064 100 47540282682153840 101 49216787130337544 102 50952413380206176 103 52749246357593568 104 54609444513084120 105 56535242414857984 106 58528953432971760 107 60592972518301040 108 62729779079481632 109 64941939961305936 110 67232112528152736 111 69603047856152960 112 72057594037927936 113 74598699603868352 114 77229417064064608 115 79952906575142816 116 82772439736411984 117 85691403519881552 118 88713304338870912 119 91841772260098192 120 95080565364307680 121 98433574260675088 122 101904826760412352 123 105498492715187056 124 109218889026168304 125 113070484829715968 126 117057906865943520 127 121185945036602080 128 125459558158963264 129 129883879922611968 130 134464225056305472 131 139206095712305920 132 144115188075855872 133 149197399207736800 134 154458834128129216 135 159905813150285632 136 165544879472823968 137 171382807039763104 138 177426608677741952 139 183683544520196384 140 190161130728615360 141 196867148521350176 142 203809653520824704 143 210996985430374272 144 218437778052336608 145 226140969659431936 146 234115813731887040 147 242371890073204160 148 250919116317926528 149 259767759845223936 150 268928450112610944 151 278412191424611840 152 288230376151711744 153 298394798415473600 154 308917668256258432 155 319811626300571264 156 331089758945647936 157 342765614079526208 158 354853217355483904 159 367367089040392768 160 380322261457230720 161 393734297042700352 162 407619307041649408 163 421993970860748544 164 436875556104673216 165 452281939318863872 166 468231627463774080 167 484743780146408320 168 501838232635853056 169 519535519690447872 170 537856900225221888 171 556824382849223680 172 576460752303423488 173 596789596830947200 174 617835336512516864 175 639623252601142528 176 662179517891295872 177 685531228159052416 178 709706434710967808 179 734734178080785536 180 760644522914461440 181 787468594085400704 182 815238614083298816 183 843987941721497088 184 873751112209346432 185 904563878637727744 186 936463254927548160 187 969487560292816640 188 1003676465271706112 189 1039071039380895744 190 1075713800450443776 191 1113648765698447360 192 1 193 2 194 4 195 8 196 16 197 32 198 64 199 128 200 256 201 512 202 1024 203 2048 204 4096 205 8192 206 16384 207 32768 208 65536 209 131072 210 262144 211 524288 212 1048576 213 2097152 214 4194304 215 8388608 216 16777216 217 33554432 218 67108864 219 134217728 220 268435456 221 536870912 222 1073741824 223 2147483648 224 4294967296 225 8589934592 226 17179869184 227 34359738368 228 68719476736 229 137438953472 230 274877906944 231 549755813888 232 1099511627776 233 2199023255552 234 4398046511104 235 8796093022208 236 17592186044416 237 35184372088832 238 70368744177664 239 140737488355328 240 281474976710656 241 562949953421312 242 1125899906842624 243 2251799813685248 244 4503599627370496 245 9007199254740992 246 18014398509481984 247 36028797018963968 248 72057594037927936 249 144115188075855872 250 288230376151711744 251 576460752303423488 252 1152921504606846976 253 2305843009213693952 254 4611686018427387904 255 9223372036854775808","title":"FeeFactor left shifted"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/","text":"Hermez ZK-Rollup Protocol Overview The core protocol ensures that state transitions are valid through a validity proof which will assure that certain rules have been fulfilled. This collection of rules are determined by a smart contract which will validate a proof of state transition. This verification will check that each state transitioning is made correctly. This is achieved by using a ZK-SNARK circuit and it will make sure that all rules for state transition are being followed. Any prover must submit a proof in order to demonstrate the correctness of the state transition computation. A prover (aka coordinator) is in charge of computing all state changes and calculating the ZK-SNARK proof. The coordinator will be in charge of submitting the ZK-SNARK to the verifier (smart contract) which will ensure state transition validation. A sparse-Merkle-tree is used to keep the state data where all accounts and balances are stored. This information is kept on L2 and users will sign transactions in order to spend their balances between L2 accounts. These L2 transactions are collected together to create a batch. Afterward, batch data is compressed through a ZK-SNARK and it will prove that the state transitions of all those L2 transactions are correct. This collection of transactions are made public on L1 in order to provide data-availability to the protocol, meaning that anyone can re-build the L2 state just depending on L1 data. Hence, there is no need to rely on third parties to provide or store this data. The system is composed of L1 and L2 transactions: L1 transactions are the ones that are executed through the smart contract and affect the L2 state tree L2 transactions are the ones that are executed exclusively on L2 and affect the L2 state tree L1 transactions are forced to be executed by the coordinator in the protocol. Therefore, these kinds of transactions will be always forged at some time. L2 transactions are generated off-chain by the users and they are sent to the coordinators. Coordinators will be in charge of gathering them. Some of the rollup functionality depends on a consensus mechanism to decide who can be the coordinator of a given batch. Separate from the rollup smart contract (which mainly handles the queue of L1UserTxs and the forging of batches), there is an external smart contract that implements the consensus mechanism and maintains its own state. During a forge call in the rollup smart contract, a call is made to the consensus smart contract to validate if the caller coordinator is allowed to forge and also to allow the consensus smart contract to update its own state and perform consensus actions if necessary. Assumptions L1 (Ethereum): integrity and immutability of data Hashes Poseidon is unbreakable and collision-resistant SHA256 is unbreakable and collision-resistant Elliptic curves: L1: secp256k1 signature scheme is ecdsa L2: BabyJubjub signature scheme is eddsa State tree transitions are always valid L1 transactions are forced to be processed Notation H : is the poseidon hash function elements are always encoded in big endian Big endian encoding is used since it fits better with EVM encoding Field Element the value encoded in a field element must be smaller than the field order first value corresponds to a less significant part of the field dataField: [16 bits] tokenID [16 bits] nonce [1 bit ] sign Example: dataFieldExample: [16 bits] tokenID = 5 [16 bits] nonce = 4 [1 bit ] sign = 1 dataFieldExample (large integer) = 4295229445; dataFieldExample (hexadecimal padded 32 bytes) = 0x0000000000000000000000000000000000000000000000000000000100040005; Buffer Bytes first value corresponds to the first byte of the array dataBuffer: [48 bits] fromIdx [32 bits] tokenID [16 bit ] amountFloat Example: dataBufferExample: [48 bits] fromIdx = 5 [32 bits] tokenID = 4 [16 bit ] amountFloat = 20 dataBufferExample (hexadecimal) = 0x000000000005000000040014; Global Settings Circuit MAX_NLEVELS : absolute maximum of Merkle tree depth (48 bits) determines the maximum number of accounts that can exist in the ZK-Rollup: \\(MAX\\_ACCOUNTS=2^{MAX\\_NLEVELS}\\) MAX_TX : absolute maximum L1 or L2 transactions allowed to process in one batch MAX_L1_TXS : absolute maximum of L1 transactions allowed to process in one batch MAX_FEE_TX : maximum number of tokens that the coordinator is able to collect fees from in a batch from the included transactions NLevels : Merkle tree depth It should be noted that NLevels is always a multiple of 8 Contracts MAX_L1_USER_TXS : absolute maximum of L1 user transactions allowed to be queued for a batch MAX_AMOUNT_DEPOSIT : maximum amount of tokens that can be added when creating a new account INITIAL_IDX : first Merkle tree index to populate if a new account is created Some indexes are reserved in order to specify special transactions IDX 0 : null index IDX 1 : exit 2 <= IDX < 256 : reserved Idx values for future uses 256 <= IDX < 2^MAX_NLEVELS : available Idx values for rollup accounts MAX_TOKENS : maximum amount of tokens allowed to be registered in the ZK-Rollup Data Types Floating Point Format (Float40) A custom floating point, 40 bits, codification internally called Float40 has been adopted to encode large integers. This is done in order to save bits when L2 transactions are published. Formula is as follows: \\(v = m \\times 10^e\\) where: v : large integer value to encode m : mantissa (35 bits) e : exponent (5 bits) bit position: [ e | m ] [ 5 bits | 35 bits] Account idx : integer, path in the sparse Merkle tree (NLevels bits) sign : Baby Jubjub sign (1 bit) ay : Baby Jubjub public key Y coordinate (253 bits) ethAddr : Ethereum address (160 bits) tokenID : token identifier (32 bits) balance : balance (192 bits) nonce : nonce (40 bits) Transaction Fields All transactions fields are required to build the ZK-SNARK proof but depending on the transaction type not all of them are used. Detailed transaction types can be seen in transaction type section Below is a summary of each transaction field and its explaination: signature_constant : hardcoded transaction constant that indicates that the user is signing a Hermez rollup transaction. Used to avoid transaction replay in case other rollup are deployed (32 bits) signature_constant = sha256(\"I authorize this hermez rollup transaction\")[:32/8] chainId : Ethereum chain identifier in order to prevent replay attacks in case of hardforks, we use only 2 bytes since Hermez is only expected to be deployed in the Ethereum mainnet or one of its tesnets, so only 2 bytes are needed (16 bits) amountFloat40 : number of tokens to transfer inside the ZK-Rollup (40 bits) tokenID : token identifier (32 bits) nonce : nonce (40 bits) feeSelector : select %fee to apply (8 bits) maxNumBatch : maximum allowed batch number when the transaction can be processed (32 bits) onChain : mark transaction as L1 transaction (1 bit) newAccount : mark transaction to create new account (1 bit) fromIdx : sender account index (NLevels bits) fromBjjCompressed : sender Baby Jubjub public key compressed (256 bits) fromEthAddr : sender Ethereum address (160 bits) toIdx : recipient account index (NLevels bits) toEthAddr : recipient Ethereum address (160 bits) toBjjSign : recipient Baby Jubjub sign (1 bits) toAy : recipient Baby Jubjub public key Y coordinate (253 bits) loadAmountFloat40 : L1 amount transfered to L2 (40 bits) txCompressedData : transaction fields joined together that fit into a single field element (253 bits) See L2Tx specification txCompressedDataV2 : transaction fields joined together used for other transactions when using atomic transactions feature (193 bits) See L2Tx specification rqOffset : relative transaction position to be linked. Used to perform atomic transactions (3 bits) rqTxCompressedDataV2 : requested txCompressedDataV2 rqToEthAddr : requested toEthAddr rqToBjjAy : requested toBjj Fields to perform atomic transactions: rqTxCompressedDataV2 rqToEthAddr rqToBjjAy rqOffset Trees It is assured by protocol a unique idx for each account. Therefore, a given idx identifies uniquely a ZK-Rollup account idx is incremented sequentially and it is assured by protocol State tree Sparse Merkle tree is used to represent the whole ZK-Rollup state which is identified by its root. Each leaf of the state tree (account) contains the following data: Key: Merkle tree index ( idx ) Value: Hash(state) **field element notation** State hash = H(e0, e1, e2, e3) e_0: [ 32 bits ] tokenID [ 40 bits ] nonce [ 1 bit ] sign e_1: [ 192 bits ] balance e_2: [ 253 bits ] ay e_3: [ 160 bits ] ethAddr All data is hashed with Poseidon hash function and inserted into the sparse Merkle tree as a key-value pair. This approach implies a balanced Merkle tree: path is traversed from the root starting with the least significant bit out of the NLevels bits. This allows to have as many accounts as the tree levels: \\(MAX\\_ACCOUNTS\\) = \\(2^{MAX\\_NLEVELS}\\) Exit Tree Each batch would have an associated exit tree with all the exits performed by the user, either L1 or L2 exit transactions. The exit tree has the same leaf structure as the state tree with some particularities: nonce is always set to 0 if several exits are done in the same batch for the same account, the balance is just added on top of the account User will need to prove that it owns a leaf in the exit tree in order to perform its withdraw and get back the tokens from the contract. This verification could be done either by submitting a Merkle tree proof or by submitting a ZK Proof. Account Types Regular Rollup Account Regular accounts contain an Ethereum address and a Baby Jubjub public key. Accounts are always indexed by Ethereum address in the UX, so it is a requirement that the Ethereum address authorizes the account keys. Once the account is created, the Ethereum key is used to authorize L1 txs and the Baby Jubjub key is used to authorize L2 txs. There are two ways to authorize an account creation (that is, an Ethereum address authorizes the creation of an account containing that same Ethereum address and a Baby Jubjub public key): Via Ethereum transaction, which has an implicit signature of the Ethereum address. This requires the owner of the Ethereum address to sign the smart contract transaction call Via an authorization signature ( AccountCreationAuthSig ) that can be used by any party to create accounts on behalf of the user AccountCreationAuthSig specification (follows ethereum eip712 ): domain: { name: \"Hermez Network\", version: \"1\", chainId: chainID, verifyingContract: rollupContractAddress } structured typed data: { Authorise: [ { name: \"Provider\", type: \"string\" }, { name: \"Authorisation\", type: \"string\" }, { name: \"BJJKey\", type: \"bytes32\" } ] } structured data: { Provider: \"Hermez Network\", Authorisation: \"Account creation\", BJJKey: compressed-bjj } where: chainID : refers to the ethereum chain identifier rollupContractAddress : rollup contract ethereum address compressed-bjj : babyjubjub public key in its compressed format represented as hexadecimal string signature = eth_signTypedData(domain, types, value) Further details on eth_signTypedData can be found here Internal Rollup Account An internal rollup account does not use an Ethereum address, and thus can only operate via L2 txs. Since no Ethereum address is involved, the account creation does not require an authorization and will only specify the Baby Jubjub public key. Internally, this account will have the ethAddr = 0xffff.. . Transaction Types Table of possible combinations of actions in an L1User transaction: CreateAccount Deposit Transfer Exit Valid Name NO X YES ForceExit X YES ForceTransfer X X NO X YES Deposit X X NO X X YES DepositTransfer X X X NO X NO X X NO X X NO X X X NO X X YES CreateAccountDeposit X X X NO X X X YES CreateAccountDepositTransfer X X X X NO Summary: RollupTx L1 User CreateAccountDeposit CreateAccountDepositTransfer Deposit DepositTransfer ForceTransfer ForceExit Coordinator CreateAccountEth CreateAccountBjj L2 Transfer Exit TransferToEthAddr TransferToBjj HermezWithdraw RollupTx is any transaction that is processed in the rollup state through a ZK-SNARK proof. HermezWithdraw is a transaction performed through the smart contract to get funds back from the smart contract to Ethereum address. This is done by demonstrating the existence of a leaf in the exit tree. NOP transaction is an empty transaction that does not perform any action. Used in the circuit inputs when the coordinator does not have enough transactions to fill maximum number of transactions in a batch. NULL transaction is a transaction that is forced to use the value 0 for amount or loadAmount. Used to nullify an L1UserTx that is found to be invalid, so that it does not do any update to the state tree. L1 user transactions All L1 data transactions are concatenated together and hashed in order to force the coordinator to process them. Since the operator is forced to process L1 transactions, those transactions have to accomplish certain rules to be processed by the circuit. If any of those rules are not fulfilled the transaction will be considered as a NULL transaction. If any user tries to flood L1 transactions with invalid transactions, it will have to pay fees associated to L1 transactions Data of the transaction that is concatenated, hashed with sha256 and used as a public input in the circuit: **Buffer bytes notation** L1TxFullData: [ 160 bits ] fromEthAddr [ 256 bits ] fromBjj-compressed [ MAX_NLEVELS bits ] fromIdx [ 40 bits ] loadAmountFloat40 [ 40 bits ] amountFloat40 [ 32 bits ] tokenID [ MAX_NLEVELS bits ] toIdx L1TxFullData length: 624 bits / 78 bytes L1TxsFullData = L1TxFullData[0] || L1TxFullData[1] || ... || L1TxFullData[len(L1Txs) - 1] || zero[(len(L1Txs)] || ... || zero[MAX_L1_TX - 1] All L1 txs that perform a transfer or exit must be approved by the Ethereum address of the account. This is indicated by setting the fromEthAddr as the message.sender , which is the address that signs the L1 tx. CreateAccountDeposit Inputs: fromEthAddr : message.sender fromBjj-compressed : user parameter fromIdx : 0 loadAmountFloat40 : user parameter amountFloat40 : 0 tokenId : user parameter toIdx : 0 Actions: new account inserted into the state tree with idx = auxFromIdx deposit loadAmountFloat40 into the sender auxFromIdx new account data: ax : fromBjj-compressed -> ax ay : fromBjj-compressed -> ay ethAddr : fromEthAddr tokenID : tokenId balance : loadAmount nonce : 0 Requirements: CreateAccountDepositTransfer Inputs: fromEthAddr : message.sender fromBjj-compressed : user parameter fromIdx : 0 loadAmountFloat40 : user parameter amountFloat40 : user parameter tokenId : user parameter toIdx : user parameter Actions: new account inserted into the state tree with idx = auxFromIdx deposit loadAmountFloat40 into the sender auxFromIdx new account data: ax : fromBjj-compressed -> ax ay : fromBjj-compressed -> ay ethAddr : fromEthAddr tokenID : tokenId balance : loadAmount nonce : 0 subtract amountFloat40 from sender auxFromIdx add amountFloat40 to recipient toIdx Requirements: receiver toIdx account must exist Checks NULL: sender fromIdx and receiver should have the same tokenID tokenID should match state1 update account tokenID should match state2 update account sender fromIdx should have enough balance Deposit Inputs: fromEthAddr : 0 fromBjj-compressed : 0 fromIdx : user parameter loadAmountFloat40 : user parameter amountFloat40 : 0 tokenId : user parameter toIdx : 0 Actions: deposit loadAmountFloat40 into the account Requirements: recipient fromIdx account to receive L1 funds must exist Checks NULL: tokenID should match state1 update account DepositTransfer Inputs: fromEthAddr : message.sender fromBjj-compressed : 0 fromIdx : user parameter loadAmountFloat40 : user parameter amountFloat40 : user parameter tokenId : user parameter toIdx : user parameter Actions: deposit loadAmountFloat40 into the account subtract amountFloat40 from sender fromIdx add amountFloat40 to recipient toIdx Requirements: recipient fromIdx account to receive L1 funds must exist receiver toIdx account must exist Checks NULL: tokenID should match state1 update account tokenID should match state2 update account sender fromIdx should have enough balance fromEthAddr should match state1 update account ForceTransfer Inputs: fromEthAddr : message.sender fromBjj-compressed : 0 fromIdx : user parameter loadAmountFloat40 : 0 amountFloat40 : user parameter tokenId : user parameter toIdx : user parameter Actions: subtract amountFloat40 from sender fromIdx add amountFloat40 to recipient toIdx Requirements: sender fromIdx must exist receiver toIdx account must exist Checks NULL: sender fromIdx and receiver should have the same tokenID tokenID should match state1 update account tokenID should match state2 update account sender fromIdx should have enough balance fromEthAddr should match state1 update account ForceExit Inputs: fromEthAddr : message.sender fromBjj-compressed : 0 fromIdx : user parameter loadAmountFloat40 : 0 amountFloat40 : user parameter tokenId : user parameter toIdx : 1 Actions: subtract amountFloat40 from sender fromIdx If it does not exit fromIdx account on the exit tree: new account fromIdx inserted into the exit tree add amountFloat40 to the exit tree recipient fromIdx Requirements: sender fromIdx must exist Checks NULL: tokenID should match state1 update account sender should have enough balance fromEthAddr should match state1 update account L1 Coordinator Coordinator has the ability to create accounts at the time to forge a batch. These transactions are also included in the L1TxsData . Account could be created for a given: Ethereum address - Baby Jubjub key pair (regular rollup account) Baby Jubjub public key (internal rollup account) CreateAccountEth Inputs: fromEthAddr : coordinator parameter fromBjj-compressed : coordinator parameter (from ecdsa signed message) fromIdx : 0 loadAmountFloat40 : 0 amountFloat40 : 0 tokenId : coordinator parameter toIdx : 0 Actions: new account inserted into the state tree account data: sign : fromBjj-compressed -> sign ay : fromBjj-compressed -> ay ethAddr : fromEthAddr tokenID : tokenId balance : 0 nonce : 0 Requirements: coordinator must submit: ecdsa signature : R,S,V signature of AccountCreationAuthMsg CreateAccountBjj Inputs: fromEthAddr : 0xffff.. fromBjj-compressed : coordinator parameter fromIdx : 0 loadAmountFloat40 : 0 amountFloat40 : 0 tokenId : coordinator parameter toIdx : 0 Actions: new account inserted into the state tree account data: sign : fromBjj-compressed -> sign ay : fromBjj-compressed -> ay ethAddr : 0 tokenID : tokenId balance : 0 nonce : 0 L2 All L2 transactions are sent to the coordinators by the users. The coordinator collects them into a batch in order to forge it. The coordinator must check that it collects valid transactions that must not perform an invalid transition state. Otherwise, the proof computed by the coordinator will not be valid. The user could submit any transaction data to the coordinator, but it will be rejected if the transaction could not be processed. Therefore, it is in the users' benefit to provide a valid transaction if they want it to be inserted in the ZK-Rollup. Signature used for L2 transactions is eddsa with Baby Jubjub key. L2 transaction data in the signature: **Field element notation** txCompressedData: [ 32 bits ] signatureConstant [ 16 bits ] chainId [ MAX_NLEVELS bits ] fromIdx [ MAX_NLEVELS bits ] toIdx [ 32 bits ] tokenID [ 40 bits ] nonce [ 8 bits ] userFee [ 1 bits ] toBjjSign Total bits compressed data: 225 toEthAddr toBjjAy **Field element notation** txCompressedDataV2: [ MAX_NLEVELS bits ] fromIdx [ MAX_NLEVELS bits ] toIdx [ 40 bits ] amountFloat40 [ 32 bits ] tokenID [ 40 bits ] nonce [ 8 bits ] userFee [ 1 bits ] toBjjSign Total bits txCompressedDataV2: 217 **Field element notation** element_1:[ 160 bits ] toEthAddr [ 40 bits ] amountFloat40 [ 32 bits ] maxNumBatch Total bits element_1: 232 rqToEthAddr rqToBjjAy messageToSign = H(e_0, e_1, e_2, e_3, e_4, e_5) e_0: [ 225 bits ] txCompressedData e_1: [ 232 bits ] element_1 e_2: [ 253 bits ] toBjjAy e_3: [ 217 bits ] rqTxCompressedDataV2 e_4: [ 160 bits ] rqToEthAddr e_5: [ 253 bits ] rqToBjjAy Transfer Standard transaction of tokens between two accounts inside the rollup, L2 --> L2. It is assumed that this transaction has a recipient toIdx > INITIAL_IDX Actions: subtract amountFloat40 from sender fromIdx add amountFloat40 to recipient toIdx Valid transaction: sender fromIdx exist on the state tree recipient toIdx exist on the state tree tokenID match with fromIdx and toIdx token sender fromIdx has enough funds sender fromIdx has the correct nonce Exit Transfer tokens from an account to the exit tree , L2 --> L2 Actions: subtract amountFloat40 from sender fromIdx If it does not exit fromIdx account on the exit tree: new account fromIdx inserted into the exit tree add amountFloat40 to the exit tree recipient fromIdx Valid transaction: sender fromIdx exist on the state tree tokenID match with fromIdx token sender fromIdx has enough funds sender fromIdx has the correct nonce TransferToEthAddr The sender sends the transaction to an Ethereum address recipient in the state tree. If the recipient does not exist and the coordinator wants to process the transaction, coordinator should create a new account with the recipient's Ethereum address. It is assumed that the toIdx is set to the special index 0. toEthAddr would be used to choose a recipient to transfer the amountFloat40 . Hence, coordinator would select the recipient idx to add amountFloat40 (called auxToIdx ). Note that this transaction encourages the coordinator to create new accounts through the L1 coordinator transaction CreateAccountEth . It is important to mention that this kind of transaction allows for the creation of new accounts in the state tree without needing to have any ether on L1. Hence, users could create new accounts and deposit tokens just through an L2 transaction. Actions: subtract amountFloat40 from sender fromIdx add amountFloat40 to the recipient auxToIdx it must match with toEthAddr and tokenID signed by sender Valid transaction: sender fromIdx exist on the state tree tokenID match with fromIdx and auxToIdx token sender fromIdx has enough funds sender fromIdx has the correct nonce TransferToBjj Sender sends the transaction to a Baby Jubjub address recipient in the state tree. If the recipient does not exist and coordinator wants to process the transaction, coordinator should create a new account with the recipient Baby Jubjub address. It is assumed that the toIdx is set to the special index 0. toBjjAy + toBjjSign would be used to choose the recipient to transfer the amountFloat40 . toEthAddr will be set to 0xff..fff which is a special case of an Ethereum address that no one can control and it will check that the recipient account has its Ethereum address set to 0xff..ff . This value allows account creation without Ethereum address authorization. Hence, coordinator would select the recipient idx to add amountFloat40 (called auxToIdx ). Note that this transaction encourages the coordinator to create new accounts through the L1 coordinator transaction CreateAccountBjj . It is important to mention that this kind of transaction allows for the creation of new accounts in the state tree without the needing to have any ether on L1. Hence, users could create new accounts and deposit tokens just through an L2 transaction. Actions: subtract amountFloat40 from sender fromIdx add amountFloat40 to the recipient auxToIdx it must match with toBjjAy + toBjjSign and tokenID signed by sender it must match ethAddr with 0xff..ff Valid transaction: sender fromIdx exist on the state tree tokenID match with fromIdx and auxToIdx token sender fromIdx has enough funds sender fromIdx has the correct nonce HermezWithdraw Funds are held on Hermez contract once the user has perform an exit transaction . The withdrawal data will contain unique data (nullifier) which identifies the withdrawal. Hence, the smart contract will store that data to avoid performing withdrawals multiple times. Each withdrawal could be identified uniquely by: Merkle tree index number exit root // numExitRoot => (idx => true/false) mapping(uint64 => mapping(uint48 => bool)) public exitNullifierMap; In order to perform withdraw with a ZK Proof, all pretended public inputs are hashed with sha256 into one single public input in order to optimize number of public inputs and therefore save gas at the time to do the verification in the smart contract. Pretended public inputs are hashed following the next specification: **Buffer bytes notation** globalInputsData: [ 256 bits ] rootExit [ 160 bits ] ethAddr [ 32 bits ] tokenID [ 192 bits ] balance [ 48 bits ] idx hashGlobalInputs = SHA256(globalInputsData) % rField Example: rootExit = 0x1230000000000000000000000000000000000000000000000000000000000456 ethAddr = 0xAB000000000000000000000000000000000000CD tokenID = 0x700000007 balance = 0xEE00000000000000000000000000000000000000000000EE idx = 0xF0000000000F globalInputsData = 0x1230000000000000000000000000000000000000000000000000000000000456AB000000000000000000000000000000000000CD700000007EE00000000000000000000000000000000000000000000EEF0000000000F Data Availability ZK-Rollup approach determines that anyone can reconstruct the full tree state by just collecting data from the L1 chain. This is done by not having any dependency of third parties holding essential data to reconstruct the full state. This feature ensures liveness of the system, meaning that no third party needs to be active in order to provide data to rebuild the state tree. Transaction types: txs l1_txs: layer 1 transactions l1_user_txs: queued asynchronously by users via smart contract call l1_coordinator_txs: added by coordinator in forge smart contract call l2_txs: layer 2 transactions \\(len(txs) = len(l1\\_txs) + len(l2\\_txs)\\) \\(len(l1\\_txs) = len(l1\\_user\\_txs) + len(l1\\_coordinator\\_txs)\\) \\(len(txs) \\leq MAX\\_TXS\\) \\(len(l1\\_txs) \\leq MAX\\_L1\\_TXS < MAX\\_TXS\\) \\(len(l1\\_user\\_txs) \\leq MAX\\_L1\\_USER\\_TXS < MAX\\_L1\\_TXS\\) L1 User Transactions All transaction data triggered by a smart contract function can be directly retrieved since it will be stored on the blockchain, but it's harder when this data happens in internal transactions, not all nodes support that functionality. That's why all the L1 user transactions emit an L1UserTx event to facilitate the data retrieval. When a user calls a function that adds an L1UserTx , the following happens: Storage Add the L1UserTx data at the end of the last non-frozen non-full queue of L1UserTxs ( L1UserTxs[lastL1UserTxs] ). Each queue is identified by a toForgeL1TxsNumber that grows incrementally The queue in which this data is added is identified by a particular toForgeL1TxsNumber (which is lastL1UserTxs at the moment the L1UserTx is added) The L1UserTxs has a position in this queue: L1UserTxs[lastL1UserTxs][position] Event toForgeL1TxsNumber L1UserTx data (78 bytes) position L1 Coordinator Transactions Coordinator could perform some special transactions to trigger L1 transactions. These transactions are processed in the forgeBatch smart contract method, and all the necessary data is provided in the method inputs. This means that like L2 transactions, the data availability can be retrieved by inspecting the Ethereum transaction. Data needed to perform these transactions will be encoded as: **Buffer bytes notation** L1CoordinatorTx: [ 8 bits ] V (ecdsa signature) [ 256 bits ] S (ecdsa signature) [ 256 bits ] R (ecdsa signature) [ 256 bits ] Bjj compressed [ 32 bits ] tokenID L1CoordinatorTxs = L1CoordinatorTx[0] || L1CoordinatorTx[1] || ... || L1CoordinatorTx[N - 1] || L1CoordinatorTx[N] There two types of L1CoordinatorTx: CreateAccountEth: Ethereum address is recovered from the ecdsa signature Coordinator should create an account with an Ethereum address equal to the toEthAddr in the L2 transaction in order to process the L2 transaction Contract will have to build the AccountCreationAuthMsg , hash it and retrieve Ethereum account from signed message and the signature ( r , s and v ). CreateAccountBjj: Coordinator should create an account with a Baby Jubjub key equal to the toAx and toAy in the L2 transaction in order to process the L2 transaction ecdsa signature fields are set to 0 L1 - L2 Transactions All transactions processed in a batch must be posted on L1. This is assured by hashing all data-availability and forces the coordinator to match all his processed transactions with his posted L1 data-availability. L2 transactions data-availability struct L2TxData : finalToIdx is equal to toIdx except when toIdx == IDX 0 where it will be equal to auxToIdx **Buffer bytes notation** L2TxData: [ NLevels bits ] fromIdx [ NLevels bits ] finalToIdx [ 40 bits ] amountF [ 8 bits ] fee note that nopTxData is a L2TxData struct where all the fields are set to 0 L1 transactions data-availability struct L1TxData : note that effectiveAmount is the amount that will be transferred on L1 transaction once all the nullifiers are applied **Buffer bytes notation** L1TxData: [ NLevels bits ] fromIdx [ NLevels bits ] toIdx [ 40 bits ] effectiveAmountF = amounF * (1 - isNullified) [ 8 bits ] fee = 0 Example: considering NLevels = 32 bits , each L2Tx data-availability is 32 + 32 + 40 + 8 = 112 bits = 14 bytes L1L2TxsData is the all the L1-L2 transaction data concatenated: L1L2TxsData = L1TxData[0] || L1TxData[1] || ... || L1TxData[len(L1Txs) - 1] || L2TxData[0] || L2TxData[1] || ... || L2TxData[len(L2Txs) - 1] || nopTxData[len(Txs)] || ... || nopTxData[MAX_TXS - 1] Fee Tx All indexes that will receive the fees accumulated. Further information can be found in this section . feeTxsData is all the indexes that will receive the fees concatenated: feeTxsData = idx[0] || ... || ... || L2Tx[MAX_FEE_TX - 1] Forging When the coordinator calls the forging function, the L1CoordinatorTxs, L2Txs and feeTxsData data is sent as input to the smart contract function. This data can be retrieved by querying the arguments of the function call. To allow this data retrieval from a regular Ethereum node, we must force that the call is not made from a smart contract: assert(msg.sender == tx.origin) For every forging call, an event will be sent with the following information: BatchNum The rollup forging function will be private, and will be called internally in the smart contract by a wrapper that adds a consensus mechanism to decide if the caller is allowed to forge or not at that Ethereum block. Contract will compute the hash of all pretended public inputs of the circuit in order to force these private signals to be processed by the coordinator. List parameters in hashGlobalData : oldLastIdx : old last merkle tree index created newLastIdx : new last merkle tree index created oldStateRoot : ols state root newStateRoot : new state root newExitRoot : new exit root L1TxsFullData : bits L2 full data L1L2TxsData : bits L1-L2 transaction data-availability feeTxsData : all index accounts to receive accumulated fees chainId : global chain identifier currentNumBatch : current batch number processed **Buffer bytes notation** hashGlobalData: [ MAX_NLEVELS bits ] oldLastIdx [ MAX_NLEVELS bits ] newLastIdx [ 256 bits ] oldStRoot [ 256 bits ] newStRoot [ 256 bits ] newExitRoot [ MAX_L1_TX*(2*MAX_NLEVELS + 528) bits ] L1TxsFullData [ MAX_TX*(2*NLevels + 48) bits ] L1L2TxsData [ NLevels * MAX_TOKENS_FEE ] feeTxsData [ 16 bits ] chainID [ 32 bits ] currentNumBatch hashGlobalInputs = SHA256(hashGlobalData) % rField Fee Model User Fees are paid on L2 transactions in the same token that they are done. So, if the user sends \"Token A\", the fees will be paid in \"Token A\". Fee is represented as a percentage of the total amount sent: \\(Fee_{amount} = amount * Fee_{percentage}\\) \\(TotalTxCost = amount + Fee_{amount}\\) Since there are 8 reserved bits for this field, there will be 256 different fee percentages that the user could choose to perform its transaction. See the table showing the 256 values for each fee index Compute Fees Procedure to compute fees must remain equal across protocol implementations. The following procedure has been adopted: given feeUser bits selects feeFactor shifted large integer 60 bits has been chosen in order to optimize precision at the time to compute fees. 60 bits is the minimum bits to achieve enough precision among all fee factor values \\(\\text{bitsShiftPrecision} = 60\\) \\(Fee_{amount} = amount * feeFactor_{shifted}\\) \\(Fee_{amount} = Fee_{amount} >> \\text{bitsShiftPrecision} \\quad \\text{if} \\quad i < 192\\) \\(Fee_{amount} = Fee_{amount} \\quad \\text{if} \\quad i \\geq 192\\) \\(assert(Fee_{amount} < 2^{128})\\) Coordinator L2 transactions are collected by the coordinator and it will receive all the fees collected by the L2 transactions. In order to optimize protocol speed, it has been defined a maximum number of tokens that the coordinator can collect fees from MAX_FEE_TX = 64 . It does not mean that the coordinator could forge as many transactions with more than 64 tokenID . The coordinator could do so, but it will only be available to collect fees from 64 different tokenID . The rest of tokenID that appear in the forged transactions will be processed but fees would not be collected. In order to ensure that the coordinator receives the correct amount of fees, the ZK-SNARK circuit will compute all the collected fees for all the L2 transactions processed. Then, the coordinator must submit in which leafs it wants to receive the fees collected. Token Listing ERC20 tokens are supported by the rollup and it could be added up to \\(2^{32}\\) different tokens Ether is supported by the rollup and it has an assigned tokenID = 0 Contracts maintain a list of all tokens registered in the rollup and each token needs to be listed before using it tokenID is assigned (sequentially) each time a token is listed in the system and this identifier will be used for any rollup transaction, either L1 or L2, that modifies the state tree TokenInfo: TokenID Address Each time a new token is registered: Storage The TokenInfo is added to a mapping Event TokenInfo Constraints: A fee will be applied at the time to register tokens in order to prevent flooding attack this fee could be modified by the governance and it is paid in HEZ tokens Two tokens with the same Ethereum address cannot be added twice in the system Emergency Mechanism This logic is implemented in order to mitigate attacks that could potentially steal funds from Hermez Network. The aim of this method is to mitigate funds stolen while preserving decentralization. The core mechanism is to set a withdrawal limit in order to avoid infinite withdrawal in case of stolen funds. Therefore, it is assured that the attacker can only steal a certain amount of tokens. This logic is implemented in a smart contract: WithdrawalDelayer . This contract is for use completely independent of the Hermez Network but it meets the objective we need to mitigate attacks. The purpose of this smart contract is to delay the withdraw. Hence, tokens will be held by the smart contract for a period of D and only afterwards tokens could be really withdrawn. Hermez emergency mechanism Withdrawal delayer mechanism","title":"Core protocol"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#hermez-zk-rollup-protocol","text":"","title":"Hermez ZK-Rollup Protocol"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#overview","text":"The core protocol ensures that state transitions are valid through a validity proof which will assure that certain rules have been fulfilled. This collection of rules are determined by a smart contract which will validate a proof of state transition. This verification will check that each state transitioning is made correctly. This is achieved by using a ZK-SNARK circuit and it will make sure that all rules for state transition are being followed. Any prover must submit a proof in order to demonstrate the correctness of the state transition computation. A prover (aka coordinator) is in charge of computing all state changes and calculating the ZK-SNARK proof. The coordinator will be in charge of submitting the ZK-SNARK to the verifier (smart contract) which will ensure state transition validation. A sparse-Merkle-tree is used to keep the state data where all accounts and balances are stored. This information is kept on L2 and users will sign transactions in order to spend their balances between L2 accounts. These L2 transactions are collected together to create a batch. Afterward, batch data is compressed through a ZK-SNARK and it will prove that the state transitions of all those L2 transactions are correct. This collection of transactions are made public on L1 in order to provide data-availability to the protocol, meaning that anyone can re-build the L2 state just depending on L1 data. Hence, there is no need to rely on third parties to provide or store this data. The system is composed of L1 and L2 transactions: L1 transactions are the ones that are executed through the smart contract and affect the L2 state tree L2 transactions are the ones that are executed exclusively on L2 and affect the L2 state tree L1 transactions are forced to be executed by the coordinator in the protocol. Therefore, these kinds of transactions will be always forged at some time. L2 transactions are generated off-chain by the users and they are sent to the coordinators. Coordinators will be in charge of gathering them. Some of the rollup functionality depends on a consensus mechanism to decide who can be the coordinator of a given batch. Separate from the rollup smart contract (which mainly handles the queue of L1UserTxs and the forging of batches), there is an external smart contract that implements the consensus mechanism and maintains its own state. During a forge call in the rollup smart contract, a call is made to the consensus smart contract to validate if the caller coordinator is allowed to forge and also to allow the consensus smart contract to update its own state and perform consensus actions if necessary.","title":"Overview"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#assumptions","text":"L1 (Ethereum): integrity and immutability of data Hashes Poseidon is unbreakable and collision-resistant SHA256 is unbreakable and collision-resistant Elliptic curves: L1: secp256k1 signature scheme is ecdsa L2: BabyJubjub signature scheme is eddsa State tree transitions are always valid L1 transactions are forced to be processed","title":"Assumptions"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#notation","text":"H : is the poseidon hash function elements are always encoded in big endian Big endian encoding is used since it fits better with EVM encoding","title":"Notation"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#field-element","text":"the value encoded in a field element must be smaller than the field order first value corresponds to a less significant part of the field dataField: [16 bits] tokenID [16 bits] nonce [1 bit ] sign Example: dataFieldExample: [16 bits] tokenID = 5 [16 bits] nonce = 4 [1 bit ] sign = 1 dataFieldExample (large integer) = 4295229445; dataFieldExample (hexadecimal padded 32 bytes) = 0x0000000000000000000000000000000000000000000000000000000100040005;","title":"Field Element"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#buffer-bytes","text":"first value corresponds to the first byte of the array dataBuffer: [48 bits] fromIdx [32 bits] tokenID [16 bit ] amountFloat Example: dataBufferExample: [48 bits] fromIdx = 5 [32 bits] tokenID = 4 [16 bit ] amountFloat = 20 dataBufferExample (hexadecimal) = 0x000000000005000000040014;","title":"Buffer Bytes"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#global-settings","text":"","title":"Global Settings"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#circuit","text":"MAX_NLEVELS : absolute maximum of Merkle tree depth (48 bits) determines the maximum number of accounts that can exist in the ZK-Rollup: \\(MAX\\_ACCOUNTS=2^{MAX\\_NLEVELS}\\) MAX_TX : absolute maximum L1 or L2 transactions allowed to process in one batch MAX_L1_TXS : absolute maximum of L1 transactions allowed to process in one batch MAX_FEE_TX : maximum number of tokens that the coordinator is able to collect fees from in a batch from the included transactions NLevels : Merkle tree depth It should be noted that NLevels is always a multiple of 8","title":"Circuit"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#contracts","text":"MAX_L1_USER_TXS : absolute maximum of L1 user transactions allowed to be queued for a batch MAX_AMOUNT_DEPOSIT : maximum amount of tokens that can be added when creating a new account INITIAL_IDX : first Merkle tree index to populate if a new account is created Some indexes are reserved in order to specify special transactions IDX 0 : null index IDX 1 : exit 2 <= IDX < 256 : reserved Idx values for future uses 256 <= IDX < 2^MAX_NLEVELS : available Idx values for rollup accounts MAX_TOKENS : maximum amount of tokens allowed to be registered in the ZK-Rollup","title":"Contracts"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#data-types","text":"","title":"Data Types"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#floating-point-format-float40","text":"A custom floating point, 40 bits, codification internally called Float40 has been adopted to encode large integers. This is done in order to save bits when L2 transactions are published. Formula is as follows: \\(v = m \\times 10^e\\) where: v : large integer value to encode m : mantissa (35 bits) e : exponent (5 bits) bit position: [ e | m ] [ 5 bits | 35 bits]","title":"Floating Point Format (Float40)"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#account","text":"idx : integer, path in the sparse Merkle tree (NLevels bits) sign : Baby Jubjub sign (1 bit) ay : Baby Jubjub public key Y coordinate (253 bits) ethAddr : Ethereum address (160 bits) tokenID : token identifier (32 bits) balance : balance (192 bits) nonce : nonce (40 bits)","title":"Account"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#transaction-fields","text":"All transactions fields are required to build the ZK-SNARK proof but depending on the transaction type not all of them are used. Detailed transaction types can be seen in transaction type section Below is a summary of each transaction field and its explaination: signature_constant : hardcoded transaction constant that indicates that the user is signing a Hermez rollup transaction. Used to avoid transaction replay in case other rollup are deployed (32 bits) signature_constant = sha256(\"I authorize this hermez rollup transaction\")[:32/8] chainId : Ethereum chain identifier in order to prevent replay attacks in case of hardforks, we use only 2 bytes since Hermez is only expected to be deployed in the Ethereum mainnet or one of its tesnets, so only 2 bytes are needed (16 bits) amountFloat40 : number of tokens to transfer inside the ZK-Rollup (40 bits) tokenID : token identifier (32 bits) nonce : nonce (40 bits) feeSelector : select %fee to apply (8 bits) maxNumBatch : maximum allowed batch number when the transaction can be processed (32 bits) onChain : mark transaction as L1 transaction (1 bit) newAccount : mark transaction to create new account (1 bit) fromIdx : sender account index (NLevels bits) fromBjjCompressed : sender Baby Jubjub public key compressed (256 bits) fromEthAddr : sender Ethereum address (160 bits) toIdx : recipient account index (NLevels bits) toEthAddr : recipient Ethereum address (160 bits) toBjjSign : recipient Baby Jubjub sign (1 bits) toAy : recipient Baby Jubjub public key Y coordinate (253 bits) loadAmountFloat40 : L1 amount transfered to L2 (40 bits) txCompressedData : transaction fields joined together that fit into a single field element (253 bits) See L2Tx specification txCompressedDataV2 : transaction fields joined together used for other transactions when using atomic transactions feature (193 bits) See L2Tx specification rqOffset : relative transaction position to be linked. Used to perform atomic transactions (3 bits) rqTxCompressedDataV2 : requested txCompressedDataV2 rqToEthAddr : requested toEthAddr rqToBjjAy : requested toBjj Fields to perform atomic transactions: rqTxCompressedDataV2 rqToEthAddr rqToBjjAy rqOffset","title":"Transaction Fields"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#trees","text":"It is assured by protocol a unique idx for each account. Therefore, a given idx identifies uniquely a ZK-Rollup account idx is incremented sequentially and it is assured by protocol","title":"Trees"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#state-tree","text":"Sparse Merkle tree is used to represent the whole ZK-Rollup state which is identified by its root. Each leaf of the state tree (account) contains the following data: Key: Merkle tree index ( idx ) Value: Hash(state) **field element notation** State hash = H(e0, e1, e2, e3) e_0: [ 32 bits ] tokenID [ 40 bits ] nonce [ 1 bit ] sign e_1: [ 192 bits ] balance e_2: [ 253 bits ] ay e_3: [ 160 bits ] ethAddr All data is hashed with Poseidon hash function and inserted into the sparse Merkle tree as a key-value pair. This approach implies a balanced Merkle tree: path is traversed from the root starting with the least significant bit out of the NLevels bits. This allows to have as many accounts as the tree levels: \\(MAX\\_ACCOUNTS\\) = \\(2^{MAX\\_NLEVELS}\\)","title":"State tree"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#exit-tree","text":"Each batch would have an associated exit tree with all the exits performed by the user, either L1 or L2 exit transactions. The exit tree has the same leaf structure as the state tree with some particularities: nonce is always set to 0 if several exits are done in the same batch for the same account, the balance is just added on top of the account User will need to prove that it owns a leaf in the exit tree in order to perform its withdraw and get back the tokens from the contract. This verification could be done either by submitting a Merkle tree proof or by submitting a ZK Proof.","title":"Exit Tree"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#account-types","text":"","title":"Account Types"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#regular-rollup-account","text":"Regular accounts contain an Ethereum address and a Baby Jubjub public key. Accounts are always indexed by Ethereum address in the UX, so it is a requirement that the Ethereum address authorizes the account keys. Once the account is created, the Ethereum key is used to authorize L1 txs and the Baby Jubjub key is used to authorize L2 txs. There are two ways to authorize an account creation (that is, an Ethereum address authorizes the creation of an account containing that same Ethereum address and a Baby Jubjub public key): Via Ethereum transaction, which has an implicit signature of the Ethereum address. This requires the owner of the Ethereum address to sign the smart contract transaction call Via an authorization signature ( AccountCreationAuthSig ) that can be used by any party to create accounts on behalf of the user AccountCreationAuthSig specification (follows ethereum eip712 ): domain: { name: \"Hermez Network\", version: \"1\", chainId: chainID, verifyingContract: rollupContractAddress } structured typed data: { Authorise: [ { name: \"Provider\", type: \"string\" }, { name: \"Authorisation\", type: \"string\" }, { name: \"BJJKey\", type: \"bytes32\" } ] } structured data: { Provider: \"Hermez Network\", Authorisation: \"Account creation\", BJJKey: compressed-bjj } where: chainID : refers to the ethereum chain identifier rollupContractAddress : rollup contract ethereum address compressed-bjj : babyjubjub public key in its compressed format represented as hexadecimal string signature = eth_signTypedData(domain, types, value) Further details on eth_signTypedData can be found here","title":"Regular Rollup Account"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#internal-rollup-account","text":"An internal rollup account does not use an Ethereum address, and thus can only operate via L2 txs. Since no Ethereum address is involved, the account creation does not require an authorization and will only specify the Baby Jubjub public key. Internally, this account will have the ethAddr = 0xffff.. .","title":"Internal Rollup Account"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#transaction-types","text":"Table of possible combinations of actions in an L1User transaction: CreateAccount Deposit Transfer Exit Valid Name NO X YES ForceExit X YES ForceTransfer X X NO X YES Deposit X X NO X X YES DepositTransfer X X X NO X NO X X NO X X NO X X X NO X X YES CreateAccountDeposit X X X NO X X X YES CreateAccountDepositTransfer X X X X NO Summary: RollupTx L1 User CreateAccountDeposit CreateAccountDepositTransfer Deposit DepositTransfer ForceTransfer ForceExit Coordinator CreateAccountEth CreateAccountBjj L2 Transfer Exit TransferToEthAddr TransferToBjj HermezWithdraw RollupTx is any transaction that is processed in the rollup state through a ZK-SNARK proof. HermezWithdraw is a transaction performed through the smart contract to get funds back from the smart contract to Ethereum address. This is done by demonstrating the existence of a leaf in the exit tree. NOP transaction is an empty transaction that does not perform any action. Used in the circuit inputs when the coordinator does not have enough transactions to fill maximum number of transactions in a batch. NULL transaction is a transaction that is forced to use the value 0 for amount or loadAmount. Used to nullify an L1UserTx that is found to be invalid, so that it does not do any update to the state tree.","title":"Transaction Types"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#l1-user-transactions","text":"All L1 data transactions are concatenated together and hashed in order to force the coordinator to process them. Since the operator is forced to process L1 transactions, those transactions have to accomplish certain rules to be processed by the circuit. If any of those rules are not fulfilled the transaction will be considered as a NULL transaction. If any user tries to flood L1 transactions with invalid transactions, it will have to pay fees associated to L1 transactions Data of the transaction that is concatenated, hashed with sha256 and used as a public input in the circuit: **Buffer bytes notation** L1TxFullData: [ 160 bits ] fromEthAddr [ 256 bits ] fromBjj-compressed [ MAX_NLEVELS bits ] fromIdx [ 40 bits ] loadAmountFloat40 [ 40 bits ] amountFloat40 [ 32 bits ] tokenID [ MAX_NLEVELS bits ] toIdx L1TxFullData length: 624 bits / 78 bytes L1TxsFullData = L1TxFullData[0] || L1TxFullData[1] || ... || L1TxFullData[len(L1Txs) - 1] || zero[(len(L1Txs)] || ... || zero[MAX_L1_TX - 1] All L1 txs that perform a transfer or exit must be approved by the Ethereum address of the account. This is indicated by setting the fromEthAddr as the message.sender , which is the address that signs the L1 tx.","title":"L1 user transactions"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#createaccountdeposit","text":"Inputs: fromEthAddr : message.sender fromBjj-compressed : user parameter fromIdx : 0 loadAmountFloat40 : user parameter amountFloat40 : 0 tokenId : user parameter toIdx : 0 Actions: new account inserted into the state tree with idx = auxFromIdx deposit loadAmountFloat40 into the sender auxFromIdx new account data: ax : fromBjj-compressed -> ax ay : fromBjj-compressed -> ay ethAddr : fromEthAddr tokenID : tokenId balance : loadAmount nonce : 0 Requirements:","title":"CreateAccountDeposit"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#createaccountdeposittransfer","text":"Inputs: fromEthAddr : message.sender fromBjj-compressed : user parameter fromIdx : 0 loadAmountFloat40 : user parameter amountFloat40 : user parameter tokenId : user parameter toIdx : user parameter Actions: new account inserted into the state tree with idx = auxFromIdx deposit loadAmountFloat40 into the sender auxFromIdx new account data: ax : fromBjj-compressed -> ax ay : fromBjj-compressed -> ay ethAddr : fromEthAddr tokenID : tokenId balance : loadAmount nonce : 0 subtract amountFloat40 from sender auxFromIdx add amountFloat40 to recipient toIdx Requirements: receiver toIdx account must exist Checks NULL: sender fromIdx and receiver should have the same tokenID tokenID should match state1 update account tokenID should match state2 update account sender fromIdx should have enough balance","title":"CreateAccountDepositTransfer"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#deposit","text":"Inputs: fromEthAddr : 0 fromBjj-compressed : 0 fromIdx : user parameter loadAmountFloat40 : user parameter amountFloat40 : 0 tokenId : user parameter toIdx : 0 Actions: deposit loadAmountFloat40 into the account Requirements: recipient fromIdx account to receive L1 funds must exist Checks NULL: tokenID should match state1 update account","title":"Deposit"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#deposittransfer","text":"Inputs: fromEthAddr : message.sender fromBjj-compressed : 0 fromIdx : user parameter loadAmountFloat40 : user parameter amountFloat40 : user parameter tokenId : user parameter toIdx : user parameter Actions: deposit loadAmountFloat40 into the account subtract amountFloat40 from sender fromIdx add amountFloat40 to recipient toIdx Requirements: recipient fromIdx account to receive L1 funds must exist receiver toIdx account must exist Checks NULL: tokenID should match state1 update account tokenID should match state2 update account sender fromIdx should have enough balance fromEthAddr should match state1 update account","title":"DepositTransfer"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#forcetransfer","text":"Inputs: fromEthAddr : message.sender fromBjj-compressed : 0 fromIdx : user parameter loadAmountFloat40 : 0 amountFloat40 : user parameter tokenId : user parameter toIdx : user parameter Actions: subtract amountFloat40 from sender fromIdx add amountFloat40 to recipient toIdx Requirements: sender fromIdx must exist receiver toIdx account must exist Checks NULL: sender fromIdx and receiver should have the same tokenID tokenID should match state1 update account tokenID should match state2 update account sender fromIdx should have enough balance fromEthAddr should match state1 update account","title":"ForceTransfer"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#forceexit","text":"Inputs: fromEthAddr : message.sender fromBjj-compressed : 0 fromIdx : user parameter loadAmountFloat40 : 0 amountFloat40 : user parameter tokenId : user parameter toIdx : 1 Actions: subtract amountFloat40 from sender fromIdx If it does not exit fromIdx account on the exit tree: new account fromIdx inserted into the exit tree add amountFloat40 to the exit tree recipient fromIdx Requirements: sender fromIdx must exist Checks NULL: tokenID should match state1 update account sender should have enough balance fromEthAddr should match state1 update account","title":"ForceExit"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#l1-coordinator","text":"Coordinator has the ability to create accounts at the time to forge a batch. These transactions are also included in the L1TxsData . Account could be created for a given: Ethereum address - Baby Jubjub key pair (regular rollup account) Baby Jubjub public key (internal rollup account)","title":"L1 Coordinator"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#createaccounteth","text":"Inputs: fromEthAddr : coordinator parameter fromBjj-compressed : coordinator parameter (from ecdsa signed message) fromIdx : 0 loadAmountFloat40 : 0 amountFloat40 : 0 tokenId : coordinator parameter toIdx : 0 Actions: new account inserted into the state tree account data: sign : fromBjj-compressed -> sign ay : fromBjj-compressed -> ay ethAddr : fromEthAddr tokenID : tokenId balance : 0 nonce : 0 Requirements: coordinator must submit: ecdsa signature : R,S,V signature of AccountCreationAuthMsg","title":"CreateAccountEth"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#createaccountbjj","text":"Inputs: fromEthAddr : 0xffff.. fromBjj-compressed : coordinator parameter fromIdx : 0 loadAmountFloat40 : 0 amountFloat40 : 0 tokenId : coordinator parameter toIdx : 0 Actions: new account inserted into the state tree account data: sign : fromBjj-compressed -> sign ay : fromBjj-compressed -> ay ethAddr : 0 tokenID : tokenId balance : 0 nonce : 0","title":"CreateAccountBjj"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#l2","text":"All L2 transactions are sent to the coordinators by the users. The coordinator collects them into a batch in order to forge it. The coordinator must check that it collects valid transactions that must not perform an invalid transition state. Otherwise, the proof computed by the coordinator will not be valid. The user could submit any transaction data to the coordinator, but it will be rejected if the transaction could not be processed. Therefore, it is in the users' benefit to provide a valid transaction if they want it to be inserted in the ZK-Rollup. Signature used for L2 transactions is eddsa with Baby Jubjub key. L2 transaction data in the signature: **Field element notation** txCompressedData: [ 32 bits ] signatureConstant [ 16 bits ] chainId [ MAX_NLEVELS bits ] fromIdx [ MAX_NLEVELS bits ] toIdx [ 32 bits ] tokenID [ 40 bits ] nonce [ 8 bits ] userFee [ 1 bits ] toBjjSign Total bits compressed data: 225 toEthAddr toBjjAy **Field element notation** txCompressedDataV2: [ MAX_NLEVELS bits ] fromIdx [ MAX_NLEVELS bits ] toIdx [ 40 bits ] amountFloat40 [ 32 bits ] tokenID [ 40 bits ] nonce [ 8 bits ] userFee [ 1 bits ] toBjjSign Total bits txCompressedDataV2: 217 **Field element notation** element_1:[ 160 bits ] toEthAddr [ 40 bits ] amountFloat40 [ 32 bits ] maxNumBatch Total bits element_1: 232 rqToEthAddr rqToBjjAy messageToSign = H(e_0, e_1, e_2, e_3, e_4, e_5) e_0: [ 225 bits ] txCompressedData e_1: [ 232 bits ] element_1 e_2: [ 253 bits ] toBjjAy e_3: [ 217 bits ] rqTxCompressedDataV2 e_4: [ 160 bits ] rqToEthAddr e_5: [ 253 bits ] rqToBjjAy","title":"L2"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#transfer","text":"Standard transaction of tokens between two accounts inside the rollup, L2 --> L2. It is assumed that this transaction has a recipient toIdx > INITIAL_IDX Actions: subtract amountFloat40 from sender fromIdx add amountFloat40 to recipient toIdx Valid transaction: sender fromIdx exist on the state tree recipient toIdx exist on the state tree tokenID match with fromIdx and toIdx token sender fromIdx has enough funds sender fromIdx has the correct nonce","title":"Transfer"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#exit","text":"Transfer tokens from an account to the exit tree , L2 --> L2 Actions: subtract amountFloat40 from sender fromIdx If it does not exit fromIdx account on the exit tree: new account fromIdx inserted into the exit tree add amountFloat40 to the exit tree recipient fromIdx Valid transaction: sender fromIdx exist on the state tree tokenID match with fromIdx token sender fromIdx has enough funds sender fromIdx has the correct nonce","title":"Exit"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#transfertoethaddr","text":"The sender sends the transaction to an Ethereum address recipient in the state tree. If the recipient does not exist and the coordinator wants to process the transaction, coordinator should create a new account with the recipient's Ethereum address. It is assumed that the toIdx is set to the special index 0. toEthAddr would be used to choose a recipient to transfer the amountFloat40 . Hence, coordinator would select the recipient idx to add amountFloat40 (called auxToIdx ). Note that this transaction encourages the coordinator to create new accounts through the L1 coordinator transaction CreateAccountEth . It is important to mention that this kind of transaction allows for the creation of new accounts in the state tree without needing to have any ether on L1. Hence, users could create new accounts and deposit tokens just through an L2 transaction. Actions: subtract amountFloat40 from sender fromIdx add amountFloat40 to the recipient auxToIdx it must match with toEthAddr and tokenID signed by sender Valid transaction: sender fromIdx exist on the state tree tokenID match with fromIdx and auxToIdx token sender fromIdx has enough funds sender fromIdx has the correct nonce","title":"TransferToEthAddr"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#transfertobjj","text":"Sender sends the transaction to a Baby Jubjub address recipient in the state tree. If the recipient does not exist and coordinator wants to process the transaction, coordinator should create a new account with the recipient Baby Jubjub address. It is assumed that the toIdx is set to the special index 0. toBjjAy + toBjjSign would be used to choose the recipient to transfer the amountFloat40 . toEthAddr will be set to 0xff..fff which is a special case of an Ethereum address that no one can control and it will check that the recipient account has its Ethereum address set to 0xff..ff . This value allows account creation without Ethereum address authorization. Hence, coordinator would select the recipient idx to add amountFloat40 (called auxToIdx ). Note that this transaction encourages the coordinator to create new accounts through the L1 coordinator transaction CreateAccountBjj . It is important to mention that this kind of transaction allows for the creation of new accounts in the state tree without the needing to have any ether on L1. Hence, users could create new accounts and deposit tokens just through an L2 transaction. Actions: subtract amountFloat40 from sender fromIdx add amountFloat40 to the recipient auxToIdx it must match with toBjjAy + toBjjSign and tokenID signed by sender it must match ethAddr with 0xff..ff Valid transaction: sender fromIdx exist on the state tree tokenID match with fromIdx and auxToIdx token sender fromIdx has enough funds sender fromIdx has the correct nonce","title":"TransferToBjj"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#hermezwithdraw","text":"Funds are held on Hermez contract once the user has perform an exit transaction . The withdrawal data will contain unique data (nullifier) which identifies the withdrawal. Hence, the smart contract will store that data to avoid performing withdrawals multiple times. Each withdrawal could be identified uniquely by: Merkle tree index number exit root // numExitRoot => (idx => true/false) mapping(uint64 => mapping(uint48 => bool)) public exitNullifierMap; In order to perform withdraw with a ZK Proof, all pretended public inputs are hashed with sha256 into one single public input in order to optimize number of public inputs and therefore save gas at the time to do the verification in the smart contract. Pretended public inputs are hashed following the next specification: **Buffer bytes notation** globalInputsData: [ 256 bits ] rootExit [ 160 bits ] ethAddr [ 32 bits ] tokenID [ 192 bits ] balance [ 48 bits ] idx hashGlobalInputs = SHA256(globalInputsData) % rField Example: rootExit = 0x1230000000000000000000000000000000000000000000000000000000000456 ethAddr = 0xAB000000000000000000000000000000000000CD tokenID = 0x700000007 balance = 0xEE00000000000000000000000000000000000000000000EE idx = 0xF0000000000F globalInputsData = 0x1230000000000000000000000000000000000000000000000000000000000456AB000000000000000000000000000000000000CD700000007EE00000000000000000000000000000000000000000000EEF0000000000F","title":"HermezWithdraw"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#data-availability","text":"ZK-Rollup approach determines that anyone can reconstruct the full tree state by just collecting data from the L1 chain. This is done by not having any dependency of third parties holding essential data to reconstruct the full state. This feature ensures liveness of the system, meaning that no third party needs to be active in order to provide data to rebuild the state tree. Transaction types: txs l1_txs: layer 1 transactions l1_user_txs: queued asynchronously by users via smart contract call l1_coordinator_txs: added by coordinator in forge smart contract call l2_txs: layer 2 transactions \\(len(txs) = len(l1\\_txs) + len(l2\\_txs)\\) \\(len(l1\\_txs) = len(l1\\_user\\_txs) + len(l1\\_coordinator\\_txs)\\) \\(len(txs) \\leq MAX\\_TXS\\) \\(len(l1\\_txs) \\leq MAX\\_L1\\_TXS < MAX\\_TXS\\) \\(len(l1\\_user\\_txs) \\leq MAX\\_L1\\_USER\\_TXS < MAX\\_L1\\_TXS\\)","title":"Data Availability"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#l1-user-transactions_1","text":"All transaction data triggered by a smart contract function can be directly retrieved since it will be stored on the blockchain, but it's harder when this data happens in internal transactions, not all nodes support that functionality. That's why all the L1 user transactions emit an L1UserTx event to facilitate the data retrieval. When a user calls a function that adds an L1UserTx , the following happens: Storage Add the L1UserTx data at the end of the last non-frozen non-full queue of L1UserTxs ( L1UserTxs[lastL1UserTxs] ). Each queue is identified by a toForgeL1TxsNumber that grows incrementally The queue in which this data is added is identified by a particular toForgeL1TxsNumber (which is lastL1UserTxs at the moment the L1UserTx is added) The L1UserTxs has a position in this queue: L1UserTxs[lastL1UserTxs][position] Event toForgeL1TxsNumber L1UserTx data (78 bytes) position","title":"L1 User Transactions"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#l1-coordinator-transactions","text":"Coordinator could perform some special transactions to trigger L1 transactions. These transactions are processed in the forgeBatch smart contract method, and all the necessary data is provided in the method inputs. This means that like L2 transactions, the data availability can be retrieved by inspecting the Ethereum transaction. Data needed to perform these transactions will be encoded as: **Buffer bytes notation** L1CoordinatorTx: [ 8 bits ] V (ecdsa signature) [ 256 bits ] S (ecdsa signature) [ 256 bits ] R (ecdsa signature) [ 256 bits ] Bjj compressed [ 32 bits ] tokenID L1CoordinatorTxs = L1CoordinatorTx[0] || L1CoordinatorTx[1] || ... || L1CoordinatorTx[N - 1] || L1CoordinatorTx[N] There two types of L1CoordinatorTx: CreateAccountEth: Ethereum address is recovered from the ecdsa signature Coordinator should create an account with an Ethereum address equal to the toEthAddr in the L2 transaction in order to process the L2 transaction Contract will have to build the AccountCreationAuthMsg , hash it and retrieve Ethereum account from signed message and the signature ( r , s and v ). CreateAccountBjj: Coordinator should create an account with a Baby Jubjub key equal to the toAx and toAy in the L2 transaction in order to process the L2 transaction ecdsa signature fields are set to 0","title":"L1 Coordinator Transactions"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#l1-l2-transactions","text":"All transactions processed in a batch must be posted on L1. This is assured by hashing all data-availability and forces the coordinator to match all his processed transactions with his posted L1 data-availability. L2 transactions data-availability struct L2TxData : finalToIdx is equal to toIdx except when toIdx == IDX 0 where it will be equal to auxToIdx **Buffer bytes notation** L2TxData: [ NLevels bits ] fromIdx [ NLevels bits ] finalToIdx [ 40 bits ] amountF [ 8 bits ] fee note that nopTxData is a L2TxData struct where all the fields are set to 0 L1 transactions data-availability struct L1TxData : note that effectiveAmount is the amount that will be transferred on L1 transaction once all the nullifiers are applied **Buffer bytes notation** L1TxData: [ NLevels bits ] fromIdx [ NLevels bits ] toIdx [ 40 bits ] effectiveAmountF = amounF * (1 - isNullified) [ 8 bits ] fee = 0 Example: considering NLevels = 32 bits , each L2Tx data-availability is 32 + 32 + 40 + 8 = 112 bits = 14 bytes L1L2TxsData is the all the L1-L2 transaction data concatenated: L1L2TxsData = L1TxData[0] || L1TxData[1] || ... || L1TxData[len(L1Txs) - 1] || L2TxData[0] || L2TxData[1] || ... || L2TxData[len(L2Txs) - 1] || nopTxData[len(Txs)] || ... || nopTxData[MAX_TXS - 1]","title":"L1 - L2 Transactions"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#fee-tx","text":"All indexes that will receive the fees accumulated. Further information can be found in this section . feeTxsData is all the indexes that will receive the fees concatenated: feeTxsData = idx[0] || ... || ... || L2Tx[MAX_FEE_TX - 1]","title":"Fee Tx"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#forging","text":"When the coordinator calls the forging function, the L1CoordinatorTxs, L2Txs and feeTxsData data is sent as input to the smart contract function. This data can be retrieved by querying the arguments of the function call. To allow this data retrieval from a regular Ethereum node, we must force that the call is not made from a smart contract: assert(msg.sender == tx.origin) For every forging call, an event will be sent with the following information: BatchNum The rollup forging function will be private, and will be called internally in the smart contract by a wrapper that adds a consensus mechanism to decide if the caller is allowed to forge or not at that Ethereum block. Contract will compute the hash of all pretended public inputs of the circuit in order to force these private signals to be processed by the coordinator. List parameters in hashGlobalData : oldLastIdx : old last merkle tree index created newLastIdx : new last merkle tree index created oldStateRoot : ols state root newStateRoot : new state root newExitRoot : new exit root L1TxsFullData : bits L2 full data L1L2TxsData : bits L1-L2 transaction data-availability feeTxsData : all index accounts to receive accumulated fees chainId : global chain identifier currentNumBatch : current batch number processed **Buffer bytes notation** hashGlobalData: [ MAX_NLEVELS bits ] oldLastIdx [ MAX_NLEVELS bits ] newLastIdx [ 256 bits ] oldStRoot [ 256 bits ] newStRoot [ 256 bits ] newExitRoot [ MAX_L1_TX*(2*MAX_NLEVELS + 528) bits ] L1TxsFullData [ MAX_TX*(2*NLevels + 48) bits ] L1L2TxsData [ NLevels * MAX_TOKENS_FEE ] feeTxsData [ 16 bits ] chainID [ 32 bits ] currentNumBatch hashGlobalInputs = SHA256(hashGlobalData) % rField","title":"Forging"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#fee-model","text":"","title":"Fee Model"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#user","text":"Fees are paid on L2 transactions in the same token that they are done. So, if the user sends \"Token A\", the fees will be paid in \"Token A\". Fee is represented as a percentage of the total amount sent: \\(Fee_{amount} = amount * Fee_{percentage}\\) \\(TotalTxCost = amount + Fee_{amount}\\) Since there are 8 reserved bits for this field, there will be 256 different fee percentages that the user could choose to perform its transaction. See the table showing the 256 values for each fee index","title":"User"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#compute-fees","text":"Procedure to compute fees must remain equal across protocol implementations. The following procedure has been adopted: given feeUser bits selects feeFactor shifted large integer 60 bits has been chosen in order to optimize precision at the time to compute fees. 60 bits is the minimum bits to achieve enough precision among all fee factor values \\(\\text{bitsShiftPrecision} = 60\\) \\(Fee_{amount} = amount * feeFactor_{shifted}\\) \\(Fee_{amount} = Fee_{amount} >> \\text{bitsShiftPrecision} \\quad \\text{if} \\quad i < 192\\) \\(Fee_{amount} = Fee_{amount} \\quad \\text{if} \\quad i \\geq 192\\) \\(assert(Fee_{amount} < 2^{128})\\)","title":"Compute Fees"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#coordinator","text":"L2 transactions are collected by the coordinator and it will receive all the fees collected by the L2 transactions. In order to optimize protocol speed, it has been defined a maximum number of tokens that the coordinator can collect fees from MAX_FEE_TX = 64 . It does not mean that the coordinator could forge as many transactions with more than 64 tokenID . The coordinator could do so, but it will only be available to collect fees from 64 different tokenID . The rest of tokenID that appear in the forged transactions will be processed but fees would not be collected. In order to ensure that the coordinator receives the correct amount of fees, the ZK-SNARK circuit will compute all the collected fees for all the L2 transactions processed. Then, the coordinator must submit in which leafs it wants to receive the fees collected.","title":"Coordinator"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#token-listing","text":"ERC20 tokens are supported by the rollup and it could be added up to \\(2^{32}\\) different tokens Ether is supported by the rollup and it has an assigned tokenID = 0 Contracts maintain a list of all tokens registered in the rollup and each token needs to be listed before using it tokenID is assigned (sequentially) each time a token is listed in the system and this identifier will be used for any rollup transaction, either L1 or L2, that modifies the state tree TokenInfo: TokenID Address Each time a new token is registered: Storage The TokenInfo is added to a mapping Event TokenInfo Constraints: A fee will be applied at the time to register tokens in order to prevent flooding attack this fee could be modified by the governance and it is paid in HEZ tokens Two tokens with the same Ethereum address cannot be added twice in the system","title":"Token Listing"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/protocol/#emergency-mechanism","text":"This logic is implemented in order to mitigate attacks that could potentially steal funds from Hermez Network. The aim of this method is to mitigate funds stolen while preserving decentralization. The core mechanism is to set a withdrawal limit in order to avoid infinite withdrawal in case of stolen funds. Therefore, it is assured that the attacker can only steal a certain amount of tokens. This logic is implemented in a smart contract: WithdrawalDelayer . This contract is for use completely independent of the Hermez Network but it meets the objective we need to mitigate attacks. The purpose of this smart contract is to delay the withdraw. Hence, tokens will be held by the smart contract for a period of D and only afterwards tokens could be really withdrawn. Hermez emergency mechanism Withdrawal delayer mechanism","title":"Emergency Mechanism"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/","text":"Circuits img[alt~=\"center\"] { display: block; margin: 0 auto; } Overview All of the rules a transaction must follow in order to be valid are designed and coded in the circuits. Those rules could be seen as constraints that a transaction must accomplish in order to be able to modify the state tree or the exit tree. Circuits are built from the bottom up. Hence, small circuits are first introduced and are referenced in advanced ones for the sake of clarity. Circuits would be split into three modules: library: basic Hermez circuits and structs commonly used across the rest of the circuits withdraw: specific circuit to allow a user to withdraw funds from Hermez contract rollup-main: main circuit that contains all the logic described in ZK-Rollup protocol withdraw: user could perform a withdrawal by submitting a ZK Proof or a Merkle tree proof. Both methods are equivalent in terms of functionality. Global variables: nTx : absolute maximum of L1 or L2 transactions allowed nLevels : Merkle tree depth maxL1Tx : absolute maximum of L1 transaction allowed maxFeeTx : absolute maximum of fee transactions allowed Circuits Organization Library: hash-state decode-float mux256 utils-bjj Source: decode-tx fee-accumulator rq-tx-verifier hash-inputs fee-tx compute-fee balance-updater rollup-tx-states rollup-tx rollup-main withdraw Dependencies Assumptions L1 Transactions Some assumptions must be taken into account in L1 transactions. They are performed by users which interact with the smart contract. Hence, the smart contract performs checks and forces some parameters that are assumed in the circuit implementation: tokenID must exist loadAmount < 2^128 amount < 2^192 if toIdx == 0 then amount == 0 if fromIdx == 0 then fromBjj-compressed != 0 if fromIdx > INITIAL_IDX then fromBjj-compressed == 0 A summary is shown in the next table with all the L1 transactions assumptions: UP : user parameter ME : must exist Transaction type toIdx tokenID amountF loadAmountF fromIdx fromBjj-compressed fromEthAddr createAccount 0 UP, ME 0 0 0 UP (!=0) msg.sender createAccountDeposit 0 UP, ME 0 UP < 2^128 0 UP (!=0) msg.sender createAccountDepositTransfer UP, ME UP, ME UP < 2^192 UP < 2^128 0 UP (!=0) msg.sender deposit 0 UP, ME 0 UP < 2^128 UP, ME 0 msg.sender depositTransfer UP, ME UP, ME UP < 2^192 UP < 2^128 UP, ME 0 msg.sender forceTransfer UP, ME UP, ME UP < 2^192 0 UP, ME 0 msg.sender forceExit 1 UP, ME UP < 2^192 0 UP, ME 0 msg.sender All L1 transactions are further explained here Legend It should be note that public and private signals will be highlighted only in top layer circuits: withdraw rollup-main Library hash-state Description Gets the inputs of the state and computes its hash as described here Schematic Inputs Input type Description tokenID uint32 token identifier nonce uint40 nonce sign boolean babyjubjub sign balance uint192 amount available ay field babyjubjub y coordinate ethAddr uint160 ethereum address Outputs Output type Description out field state hash decode-float Description Gets an input representing a float40 format and decode it to a large integer value as described here Steps: get the 40 less significant bits compute exponent compute mantissa compute final large integer Schematic Inputs Input type Description in uint40 float40 encode Outputs Output type Description out field float40 decode mux256 Description Multiplexer with 256 inputs Schematic Inputs Input type Description s[8] boolean array mux selectors in[256] field array mux inputs Outputs Output type Description out field selected input utils-bjj Description Implements two functionalities to be used for further circuits: BitsCompressed2AySign gets the bjjCompressed[256] in bits and retrieve ay and sign to be inserted into the account state AySign2Ax gets the ay and sign and computes de ax coordinate Schematic Input BitsCompressed2AySign Input type Description bjjCompressed[256] boolean array babyjubjub point compressed AySign2Ax Input type Description ay field babyjubjub y coordinate sign boolean babyjubjub sign Ouput BitsCompressed2AySign Output type Description ay field babyjubjub y coordinate sign boolean babyjubjub sign AySign2Ax Output type Description ax field babyjubjub x coordinate Source decode-tx Description Takes the transaction data, decodes it and builds data structures to be used in further circuits. Additionally, it performs checks on transactions fields. Listed below is all the built data and all the checks that this circuit performs. Decoders/Build decodes txCompressedData as specified here builds txCompressedDataV2 as specified here builds L1-L2 data availability L1L2TxData as specificied here builds message to sign by L2 transactions sigL2Hash as specified here build L1 full data L1TxFullData as specified here Checks L1 transactions must be processed before L2 transactions only switching from L1 to L2 is allowed checks newAccount is set to true only when it is an L1 transaction and fromIdx is 0 idx to be assigned to a new account creation is incremented and checked only if the transaction involves an account creation checks chainID transaction field matches globalChainID forced by the smart contract checks signatureConstant transaction field matches the hardcoded value CONST_SIG set in the circuit checks maxNumBatch signed in the transaction is greater or equal to currentNumBatch only if maxNumBatch != 0 Global variables: nLevels Schematic Inputs Input type Description previousOnChain bool determines if previous transaction is L1 txCompressedData uint241 encode transaction fields together maxNumBatch uint32 maximum allowed batch number when the transaction can be processed amountF uint40 amount to transfer from L2 to L2 encoded as float40 toEthAddr uint160 ethereum address receiver toBjjAy field babyjubjub y coordinate receiver rqTxCompressedDataV2 uint193 requested encode transaction fields together version 2 rqToEthAddr uint160 requested ethereum address receiver rqToBjjAy field requested babyjubjub y coordinate fromEthAddr uint160 ethereum address sender fromBjjCompressed[256] boolean array babyjubjub compressed sender loadAmountF uint40 amount to deposit from L1 to L2 encoded as float40 globalChainID uint16 global chain identifier currentNumBatch uint32 current batch number onChain bool determines if the transaction is L1 or L2 newAccount bool determines if transaction creates a new account auxFromIdx uint48 auxiliary index to create accounts auxToIdx uint48 auxiliary index when signed index receiver is set to null inIdx uint48 old last index assigned Outputs Output type Description L1L2TxData array boolean L1-L2 data availability txCompressedDataV2 uint193 encode transaction fields together version 2 L1TxFullData array boolean L1 full data outIdx uint48 old last index assigned fromIdx uint48 index sender toIdx uint48 index receiver amount uint192 amount to transfer from L2 to L2 tokenID uint32 token identifier nonce uint40 nonce userFee uint8 user fee selector toBjjSign boolean babyjubjub sign receiver sigL2Hash field hash L2 data to sign fee-accumulator Description Updates the fees accumulated by each transaction given its fee. Definitions: tokenID : token to update feePlanTokenID[numTokens] : array of all the tokenID that fees will be accumulated accFeeIn[numTokens] : initial array of all fees accumulated fee2Charge : effective fee charged in a transaction accFeeOut[numTokens] : final array of all fees accumulated Steps: find the position on the array feePlanTokenID[numTokens] where its element matches the current transaction tokenID if no match found, no fee would be accumulated and accFeeIn[0..numTokens] == accFeeOut[0..numTokens] if a match is found: accumulate the fee fee2Charge inside its position i on accFeeOut[i] avoid accumulate fees once the match is found Global variables: maxFeeTx Schematic Inputs Input type Description tokenID uint32 tokenID transaction fee2Charge uint192 fee charged feePlanTokenID[maxFeeTx] uint32 array all tokens eligible to accumulate fees accFeeIn[maxFeeTx] uint192 array initial fees accumulated Outputs Output type Description accFeeOut[maxFeeTx] uint192 array final fees accumulated rq-tx-verifier Description Required transaction offset rqTxOffset is the relative index of the transaction that would be linked. This implementation adds atomics swaps support since one transaction is linked to another by this relative index meaning that a transaction can only be processed if the linked transaction is processed too. The next circuit aims to check the past and future data transactions to match the required data signed. Data to be signed in order to link transactions can be found here rqTxOffset relativeIndex 0 no linked transaction 1 1 2 2 3 3 4 -4 5 -3 6 -2 7 -1 Note that setting rqTxOffset to 0 means that no transaction is linked Steps: get data of future/past transactions get relative index and current required data check required data matched the future/past transaction Schematic Input Input type Description futureTxCompressedDataV2[3] uint192 array future transactions txCompressedDataV2 pastTxCompressedDataV2[4] uint192 array past transactions txCompressedDataV2 futureToEthAddr[3] uint160 array future transactions toEthAddr pastToEthAddr[4] uint160 array past transactions toEthAddr futureToBjjAy[3] field array future transactions toBjjAy pastToBjjAy[4] field array past transactions toBjjAy rqTxCompressedDataV2 uint192 requested encode transaction fields together version 2 rqToEthAddr uint160 requested ethereum address receiver rqToBjjAy field requested babyjubjub y coordinate rqTxOffset uint3 relative linked transaction Output None hash-inputs Description Take all the intended public inputs and hash them all together to build a single public input for the circuit. The intended public inputs will turn into private inputs of the circuit. Note that this single input will be built by the smart contract. Therefore, proof must match all the data hashed in the input hash which is built inside the circuit from private signals. checkout here definition of global settings Specification for computing hashInputs can be found here Global variables: nLevels nTx maxL1Tx maxFeeTx Schematic Inputs Input type Description oldLastIdx uint48 old last merkle tree index created newLastIdx uint48 new last merkle tree index created oldStateRoot field old state root newStateRoot field new state root newExitRoot field new exit root L1TxsFullData[maxL1Tx * (2*nLevels + 32 + 40 + 40 + 256 + 160)] boolean array bits L1 full data L1L2TxsData[nTx * (2*nLevels + 40 + 8)] boolean array bits L1-L2 transaction data-availability feeTxsData[maxFeeTx] uint48 array all index accounts to receive accumulated fees globalChainID uint16 global chain identifier currentNumBatch uint32 current batch number processed Ouputs Output type Description hashInputsOut field sha256 hash of intended public inputs fee-tx Description This circuit handles each fee transaction. Fee transaction takes the accumulate fees for a given tokenID and updates the recipient where the fees are wanted to be paid. It checks account existence with the old state root, process the account update and compute the new state root. TokenID must match between fee accumulated and recipient account in order to not update wrong recipients. Besides, if coordinator does not fulfill all the possible recipient to receive fees, fee transaction could be a NOP transaction by setting the recipient to the null index ( IDX 0 ) Steps: check if idxFee is zero NOP transaction if idxFee is zero. Otherwise: check match planTokenID and tokenID for updating the state compute merkle tree processor function ( UPDATE or NOP ) compute old state value (old account balance) compute new state value (old account balance + accumulate fee) merkle tree processor to compute account update and get new state root Global variables: nLevels Schematic Inputs Input type Description oldStateRoot field old state root feePlanToken uint32 token identifier of fees accumulated feeIdx uint48 merkle tree index to receive fees accFee uint192 accumulated fees to transfer tokenID uint32 tokenID of leaf feeIdx nonce uint40 nonce of leaf feeIdx sign bool sign of leaf feeIdx balance uint192 balance of leaf feeIdx ay field ay of leaf feeIdx ethAddr uint160 ethAddr of leaf feeIdx siblings[nLevels + 1] field array siblings merkle proof Outputs Output type Description newStateRoot field new state root compute-fee Description Computes the final amount of fee to apply given the fee selector Steps: selects fee factor, feeOut , to apply given feeSel and applyFee compute feeOutNotShifted = amount * feeOut and convert it into bits in feeOutBits[253] compute applyShift to decide if shift has to be applied to feeOutNotShifted select bits on feeOutBits[253] depending on applyShift flag assert feeOut is \\(< 2^{128}\\) It should be noted that feeShiftTable[x] are values hardcoded in the circuit that will match the fee factor shifted 60 bits has been chosen in order to optimize precision at the time to compute fees. 60 bits is the minimum bits to achieve enough precision according fee table values Schematic Inputs Input type Description feeSel Uint8 fee selector amount Uint128 amount to apply the fee factor applyFee boolean determines if fee needs to be computed or if it is 0 Outputs Output type Description feeOut Uint128 amount * feeFactor balance-updater Description This circuit checks if there is enough balance in the sender account to do the transfer to the receiver account. It computes the new balances for the sender and the receiver. Besides, returns the fee that will be charged and if the amount to transfer is 0 ( isP2Nop signal). These signals will be used in further circuits. It should be noted that in L1 tx, no errors are allowed but the circuit needs to process them. Hence, in case it is not enough balance on the sender account, it will process the transaction as a 0 amount transfer. Hence, signal isAmountNullified will notify if a L1 transaction has been nullified if it is invalid. This isAmountNullified will be used to compute data-availability where the amount used would not be inserted in L1L2TxsData since L1Tx is not valid or triggers underflow. In case of an L2 tx, the protocol does not allow to do a transaction if there is not enough balance in the sender account. The following assumptions have been taken: smart contract filters loadAmount above 2^128 smart contract filters amount above 2^192 circuit reserves 192 bits for the balance of an account overflow applies only if more than 2^64 transactions are done assume overflow is not feasible Steps: compute fee to be applied( fee2Charge ) compute effective amount ( effectiveAmount1 and effectiveAmount2 ) check underflow ( txOk ) compute new balances from sender and receiver ( newStBalanceSender and newStBalanceReceiver ) Schematic Inputs Input type Description oldStBalanceSender field initial sender balance oldStBalanceReceiver field initial receiver balance amount uint192 amount to transfer from L2 to L2 loadAmount uint192 amount to deposit from L1 to L2 feeSelector uint8 user selector fee onChain bool determines if the transaction is L1 or L2 nop bool determines if the transfer amount and fees are considered 0 nullifyLoadAmount bool determines if loadAmount is considered to be 0 nullifyAmount bool determines if amount is considered to be 0 Outputs Output type Description newStBalanceSender uint192 final balance sender newStBalanceReceiver uint192 final balance receiver isP2Nop bool determines if processor 2 performs a NOP transaction fee2Charge uint192 effective transaction fee isAmountNullified uint32 determines if the amount is nullified rollup-tx-states Description This circuit is a subset of the rollup-tx circuit. It has been split for clarity. Transaction states are computed depending on transaction's type. All transaction types can be found here Note that L1 coordinator transactions are treated as L1 user createAccountDeposit inside the circuit. Circuit does not differentiate transactions taking into account its source, either launched by user or by coordinator. Sender and receiver accounts have their own Merkle tree processors inside the circuit in order to perform actions on their leaves: sender: processor 1 receiver: processor 2 The following table summarizes all the processor actions: func[0] func[1] Function 0 0 NOP 0 1 UPDATE 1 0 INSERT 1 1 DELETE Therefore, given the transaction type, it is needed to specify certain signals that would be used in rollup-tx circuit: isP1Insert : determines if processor 1 performs an INSERT function (sender) isP2Insert : determines if processor 2 performs an INSERT function (receiver) key1 : set key to be used in processor 1 key2 : set key to be used in processor 2 P1_fnc0 and P1_fnc1 : selectors for processor 1 P2_fnc0 and P2_fnc1 : selectors for processor 2 isExit : determines if the transaction is an exit type verifySignEnable : enable babyjubjub signature checker nop : transaction is processed as a NOP transaction checkToEthAddr : enable toEthAddr check checkToBjj : enable toBjjAy and toBjjSign check Following truth table determines how to set the above signals depending on transaction inputs: Note that italics make reference to outputs, regular makes reference to inputs Transaction type fromIdx auxFromIdx toIdx auxToIdx toEthAddr onChain newAccount loadAmount amount newExit isP1Insert isP2Insert processor 1 processor 2 isExit verifySignEnable nop checkToEthAddr checkToBjj createAccount 0 key1 0 0 0 1 1 0 0 0 1 0 INSERT UPDATE 0 0 0 0 0 createAccountDeposit 0 key1 0 0 0 1 1 X 0 0 1 0 INSERT UPDATE 0 0 0 0 0 createAccountDepositTransfer 0 key1 key2 0 0 1 1 X X 0 1 0 INSERT UPDATE 0 0 0 0 0 deposit key1 0 0 0 0 1 0 X 0 0 0 0 UPDATE UPDATE 0 0 0 0 0 depositTransfer key1 0 key2 0 0 1 0 X X 0 0 0 UPDATE UPDATE 0 0 0 0 0 forceTransfer key1 0 key2 0 0 1 0 0 X 0 0 0 UPDATE UPDATE 0 0 0 0 0 forceExit key1 - key2 0 1 0 0 1 0 0 X 0: UPDATE, 1: INSERT 0 X: UPDATE, 0: INSERT UPDATE EXIT INSERT - UPDATE 1 0 0 0 0 transfer key1 0 key2 0 0 0 0 0 X 0 0 0 UPDATE UPDATE 0 1 0 0 0 exit key1 - key2 0 1 0 0 0 0 0 X 0: UPDATE, 1: INSERT 0 X: UPDATE, 0: INSERT UPDATE EXIT INSERT - UPDATE 1 1 0 0 0 transferToEthAddr key1 0 0 key2 ANY_ETH_ADDR != 0xF..F 0 0 0 X 0 0 0 UPDATE UPDATE 0 1 0 1 0 transferToBjj key1 0 0 key2 ANY_ETH_ADDR == 0xF..F 0 0 0 X 0 0 0 UPDATE UPDATE 0 1 0 1 1 nop 0 0 0 0 0 0 0 0 0 0 0 0 NOP NOP 0 0 1 0 0 L1 invalid transactions should not be allowed but the circuit needs to process them even if they are not valid. In order to do so, the circuit performs a zero loadAmount \\ amount update if L1 transaction is not valid. Therefore, circuit nullifies loadAmount \\ amount if L1 invalid transaction is detected. Next table sets when to apply nullifyLoadAmount \\ nullifyAmount depending L1 transaction type: Note that nullifyLoadAmount \\ nullifyAmount fields are set to 1 only if checks are not successful and L1 transfers are only allowed if tokenID == tokenID1 == tokenID2 as a sanity check Transaction type newAccount isLoadAmount isAmount checkEthAddr checkTokenID1 checkTokenID2 nullifyLoadAmount nullifyAmount createAccount 1 0 0 0 0 0 0 0 createAccountDeposit 1 1 0 0 0 0 0 0 createAccountDepositTransfer 1 1 1 0 0 1 0 1 deposit 0 1 0 0 1 0 1 0 depositTransfer 0 1 1 1 1 1 1 1 forceTransfer 0 0 1 1 1 1 0 1 forceExit 0 0 1 1 1 1 if newExit = 0 0 1 Schematic Inputs Input type Description fromIdx uint48 index sender toIdx uint48 index receiver toEthAddr uint160 ethereum address receiver auxFromIdx uint48 auxiliary index to create accounts auxToIdx uint48 auxiliary index when signed index receiver is set to null amount uint192 amount to transfer from L2 to L2 newExit bool determines if the transaction create a new account in the exit tree loadAmount uint192 amount to deposit from L1 to L2 newAccount bool determines if transaction creates a new account onChain bool determines if the transaction is L1 or L2 fromEthAddr uint160 ethereum address sender ethAddr1 uint160 ethereum address of sender leaf tokenID uint32 tokenID signed in the transaction tokenID1 uint32 tokenID of the sender leaf tokenID2 uint32 tokenID of the receiver leaf Outputs Output type Description isP1Insert bool determines if processor 1 performs an INSERT function (sender) isP2Insert bool determines if processor 2 performs an INSERT function (receiver) key1 uint48 processor 1 key key2 uint48 processor 2 key P1_fnc0 bool processor 1 bit 0 functionality P1_fnc1 bool processor 1 bit 1 functionality P2_fnc0 bool processor 2 bit 0 functionality P2_fnc1 bool processor 2 bit 1 functionality isExit bool determines if the transaction is an exit verifySignEnabled bool determines if the eddsa signature needs to be verified nop bool determines if the transaction should be considered as a NOP transaction checkToEthAddr bool determines if receiver ethereum address needs to be checked checkToBjj bool determines if receiver babyjubjub needs to be checked nullifyLoadAmount bool determines if loadAmount is considered to be 0 nullifyAmount bool determines if amount is considered to be 0 rollup-tx Description This circuit includes all the rules given a transaction. Hence, rollup-tx includes the previous specified circuits: rollup-tx-states rq-tx-verifier balance-updater fee-accumulator For the sake of clarity, this circuit could be split internally into phases: A: compute transaction states B: check request transaction C: checks state fields D: compute hash old states E: signal processor selectors F: verify eddsa signature G: update balances H: accumulate fess I: compute hash new states J: smt processors K: select output roots Global variables: nLevels maxFeeTx Schematic Inputs Input type Description feePlanTokens[maxFeeTx] uint32 array all tokens eligible to accumulate fees accFeeIn[maxFeeTx] uint192 array initial fees accumulated futureTxCompressedDataV2[3] uint193 array future transactions txCompressedDataV2 pastTxCompressedDataV2[4] uint193 array past transactions toEthAddr futureToEthAddr[3] uint160 array future transactions toEthAddr pastToEthAddr[4] uint160 array past transactions toEthAddr futureToBjjAy[3] field array future transactions toBjjAy pastToBjjAy[4] field array past transactions toBjjAy fromIdx uint48 index sender auxFromIdx uint48 auxiliary index to create accounts toIdx uint48 index receiver auxToIdx uint48 auxiliary index when signed index receiver is set to null toBjjAy field babyjubjub y coordinate receiver toBjjSign bool babyjubjub sign receiver toEthAddr uint160 ethereum address receiver amount uint192 amount to transfer from L2 to L2 tokenID uint32 tokenID signed in the transaction nonce uint40 nonce signed in the transaction userFee uint16 user fee selector rqOffset uint3 relative linked transaction onChain bool determines if the transaction is L1 or L2 newAccount bool determines if transaction creates a new account rqTxCompressedDataV2 uint193 requested encode transaction fields together version 2 rqToEthAddr uint160 requested ethereum address receiver rqToBjjAy field requested babyjubjub y coordinate sigL2Hash field hash L2 data to sign s field eddsa signature field r8x field eddsa signature field r8y field eddsa signature field fromEthAddr uint160 ethereum address sender fromBjjCompressed[256] boolean array babyjubjub compressed sender loadAmountF uint40 amount to deposit from L1 to L2 encoded as float40 tokenID1 uint32 tokenID of the sender leaf nonce1 uint40 nonce of the sender leaf sign1 bool sign of the sender leaf balance1 uint192 balance of the sender leaf ay1 field ay of the sender leaf ethAddr1 uint160 ethAddr of the sender leaf siblings1[nLevels + 1] field array siblings merkle proof of the sender leaf isOld0_1 bool flag to require old key - value oldKey1 uint48 old key of the sender leaf oldValue1 field old value of the sender leaf tokenID2 uint32 tokenID of the receiver leaf nonce2 uint40 nonce of the receiver leaf sign2 bool sign of the receiver leaf balance2 uint192 balance of the receiver leaf ay2 field ay of the receiver leaf ethAddr2 uint160 ethAddr of the receiver leaf siblings2[nLevels + 1] field array siblings merkle proof of the receiver leaf isOld0_2 bool flag to require old key - value oldKey2 uint48 old key of the receiver leaf oldValue2 field old value of the receiver leaf oldStateRoot field initial state root oldExitRoot field initial exit root Ouputs Output type Description isAmountNullified bool determines if the amount is nullified accFeeOut[maxFeeTx] uint192 array final fees accumulated newStateRoot field final state root newExitRoot field final exit root rollup-main Description Join all transactions and process them. This includes, decode all possible transactions, process them and distribute all the fees through fee transactions. It is important to note that the templates included in this main circuit are intended to be computed in parallel. Meaning that the output of the very first transaction could be computed as it output is not necessary to compute the next transaction. Then, all transactions could be computed in parallel. In order to achieve that, it is needed to supply intermediate signals to allow modules parallelization. All signals prefixed with im are intermediary signals. Note that in circuit phases, there are specific phases to check integrity of intermediary signals. This adds constraints to the circuit, since it is needed to provided transactions output in advance, but it allows high parallelization at the time to compute the witness. Note that there is only one public input, hashGlobalInputs , which is a sha256 hash of all the intended public inputs of the circuit. This is done in order to save gas in the contract by just passing one public input. Global variables: nTx nLevels maxL1Tx maxFeeTx Main circuit could be split in the following phases: A: decode transactions B: check binary signals C: check integrity decode intermediary signals D: process transactions E: check integrity transactions intermediary signals F: process fee transactions G: check integrity fee transactions intermediary signals H: compute global hash input In section H, only bits associated to amountF in L1L2TxsData are multiplied by isAmountNullififed . Note that this only applies for invalid L1 transactions. Schematic Inputs Input type Description oldLastIdx uint48 old last index assigned oldStateRoot field initial state root globalChainID uint16 global chain identifier currentNumBatch uint32 current batch number processed feeIdxs[maxFeeTx] uint48 array merkle tree indexes to receive fees feePlanTokens[maxFeeTx] uint32 array tokens identifiers of fees accumulated imOnChain[nTx-1] boolean array intermediary signals: decode transaction output onChain flag imOutIdx[nTx-1] uint48 array intermediary signals: decode transaction final index assigned imStateRoot[nTx-1] field array intermediary signals: transaction final state root imExitRoot[nTx-1] field array intermediary signals: transaction final exit root imAccFeeOut[nTx-1][maxFeeTx] uint192 array array intermediary signals: transaction final accumulated fees imStateRootFee[maxFeeTx - 1] field array intermediary signals: transaction fee final state root imInitStateRootFee field intermediary signals: final state root of all rollup transactions imFinalAccFee[maxFeeTx] field array intermediary signals: final fees accumulated of all rollup transactions txCompressedData[nTx] uint241 array encode transaction fields together amountF[nTx] uint40 array amount to transfer from L2 to L2 encoded as float40 txCompressedDataV2[nTx] uint193 array encode transaction fields together version 2 fromIdx[nTx] uint48 array index sender auxFromIdx[nTx] uint48 array auxiliary index to create accounts toIdx[nTx] uint48 array index receiver auxToIdx[nTx] uint48 array auxiliary index when signed index receiver is set to null toBjjAy[nTx] field array babyjubjub y coordinate receiver toEthAddr[nTx] uint160 array ethereum address receiver maxNumBatch[nTx] uint32 array maximum allowed batch number when the transaction can be processed onChain[nTx] bool array determines if the transaction is L1 or L2 newAccount[nTx] bool array determines if transaction creates a new account rqTxCompressedDataV2[nTx] uint193 array requested encode transaction fields together version 2 rqToEthAddr[nTx] uint160 array requested ethereum address receiver rqToBjjAy[nTx] field array requested babyjubjub y coordinate s[nTx] field array eddsa signature field r8x[nTx] field array eddsa signature field r8y[nTx] field array eddsa signature field loadAmountF[nTx] uint40 array amount to deposit from L1 to L2 encoded as float40 fromEthAddr[nTx] uint160 array ethereum address sender fromBjjCompressed[nTx][256] boolean array array babyjubjub compressed sender tokenID1[nTx] uint32 array tokenID of the sender leaf nonce1[nTx] uint40 array nonce of the sender leaf sign1[nTx] bool array sign of the sender leaf balance1[nTx] uint192 array balance of the sender leaf ay1[nTx] field array ay of the sender leaf ethAddr1[nTx] uint160 array ethAddr of the sender leaf siblings1[nTx][nLevels + 1] field array array siblings merkle proof of the sender leaf isOld0_1[nTx] bool array flag to require old key - value oldKey1[nTx] uint48 array old key of the sender leaf oldValue1[nTx] field array old value of the sender leaf tokenID2[nTx] uint32 array tokenID of the receiver leaf nonce2[nTx] uint40 array nonce of the receiver leaf sign2[nTx] bool array sign of the receiver leaf balance2[nTx] uint192 array balance of the receiver leaf ay2[nTx] field array ay of the receiver leaf ethAddr2[nTx] uint160 array ethAddr of the receiver leaf siblings2[nTx][nLevels + 1] field array array siblings merkle proof of the receiver leaf isOld0_2[nTx] bool array flag to require old key - value oldKey2[nTx] uint48 array old key of the sender leaf oldValue2[nTx] field array old value of the sender leaf tokenID3[maxFeeTx] uint32 array tokenID of leafs feeIdxs nonce3[maxFeeTx] uint40 array nonce of leafs feeIdxs sign3[maxFeeTx] bool array sign of leafs feeIdxs balance3[maxFeeTx] uint192 array balance of leafs feeIdxs ay3[maxFeeTx] field array ay of leafs feeIdxs ethAddr3[maxFeeTx] uint160 array ethAddr of leafs feeIdxs siblings3[maxFeeTx][nLevels + 1] field array array siblings merkle proof of leafs Idxs Outputs Output type Description hashGlobalInputs field hash of all intended input signals withdraw Description This circuit is used to prove that a leaf exist on the exit tree. If its existence is proved, user will be able to withdraw funds from the Hermez contract. All intended public inputs are hashed together as described here . Steps: compute hash-state verify state exist in the exit tree root given the siblings compute hashGlobalInputs It should be noted that this circuit is heavily attached to the hermez smart contract Global variables nLevels Schematic Inputs Input type Description root exit field exit tree root ethAddr uint160 ethereum address tokenID uint32 token identifier balance uint192 balance idx uint48 merkle tree index sign boolean babyjubjub sign ay field babyjubjub y coordinate siblingsState[nLevels + 1] field array siblings merkle proof Outputs Output type Description hashGlobalInputs field hash of all intended input signals","title":"Circuits"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#circuits","text":"img[alt~=\"center\"] { display: block; margin: 0 auto; }","title":"Circuits"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#overview","text":"All of the rules a transaction must follow in order to be valid are designed and coded in the circuits. Those rules could be seen as constraints that a transaction must accomplish in order to be able to modify the state tree or the exit tree. Circuits are built from the bottom up. Hence, small circuits are first introduced and are referenced in advanced ones for the sake of clarity. Circuits would be split into three modules: library: basic Hermez circuits and structs commonly used across the rest of the circuits withdraw: specific circuit to allow a user to withdraw funds from Hermez contract rollup-main: main circuit that contains all the logic described in ZK-Rollup protocol withdraw: user could perform a withdrawal by submitting a ZK Proof or a Merkle tree proof. Both methods are equivalent in terms of functionality. Global variables: nTx : absolute maximum of L1 or L2 transactions allowed nLevels : Merkle tree depth maxL1Tx : absolute maximum of L1 transaction allowed maxFeeTx : absolute maximum of fee transactions allowed","title":"Overview"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#circuits-organization","text":"Library: hash-state decode-float mux256 utils-bjj Source: decode-tx fee-accumulator rq-tx-verifier hash-inputs fee-tx compute-fee balance-updater rollup-tx-states rollup-tx rollup-main withdraw","title":"Circuits Organization"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#dependencies","text":"","title":"Dependencies"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#assumptions","text":"","title":"Assumptions"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#l1-transactions","text":"Some assumptions must be taken into account in L1 transactions. They are performed by users which interact with the smart contract. Hence, the smart contract performs checks and forces some parameters that are assumed in the circuit implementation: tokenID must exist loadAmount < 2^128 amount < 2^192 if toIdx == 0 then amount == 0 if fromIdx == 0 then fromBjj-compressed != 0 if fromIdx > INITIAL_IDX then fromBjj-compressed == 0 A summary is shown in the next table with all the L1 transactions assumptions: UP : user parameter ME : must exist Transaction type toIdx tokenID amountF loadAmountF fromIdx fromBjj-compressed fromEthAddr createAccount 0 UP, ME 0 0 0 UP (!=0) msg.sender createAccountDeposit 0 UP, ME 0 UP < 2^128 0 UP (!=0) msg.sender createAccountDepositTransfer UP, ME UP, ME UP < 2^192 UP < 2^128 0 UP (!=0) msg.sender deposit 0 UP, ME 0 UP < 2^128 UP, ME 0 msg.sender depositTransfer UP, ME UP, ME UP < 2^192 UP < 2^128 UP, ME 0 msg.sender forceTransfer UP, ME UP, ME UP < 2^192 0 UP, ME 0 msg.sender forceExit 1 UP, ME UP < 2^192 0 UP, ME 0 msg.sender All L1 transactions are further explained here","title":"L1 Transactions"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#legend","text":"It should be note that public and private signals will be highlighted only in top layer circuits: withdraw rollup-main","title":"Legend"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#library","text":"","title":"Library"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#hash-state","text":"","title":"hash-state"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#description","text":"Gets the inputs of the state and computes its hash as described here","title":"Description"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#schematic","text":"","title":"Schematic"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#inputs","text":"Input type Description tokenID uint32 token identifier nonce uint40 nonce sign boolean babyjubjub sign balance uint192 amount available ay field babyjubjub y coordinate ethAddr uint160 ethereum address","title":"Inputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#outputs","text":"Output type Description out field state hash","title":"Outputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#decode-float","text":"","title":"decode-float"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#description_1","text":"Gets an input representing a float40 format and decode it to a large integer value as described here Steps: get the 40 less significant bits compute exponent compute mantissa compute final large integer","title":"Description"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#schematic_1","text":"","title":"Schematic"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#inputs_1","text":"Input type Description in uint40 float40 encode","title":"Inputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#outputs_1","text":"Output type Description out field float40 decode","title":"Outputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#mux256","text":"","title":"mux256"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#description_2","text":"Multiplexer with 256 inputs","title":"Description"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#schematic_2","text":"","title":"Schematic"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#inputs_2","text":"Input type Description s[8] boolean array mux selectors in[256] field array mux inputs","title":"Inputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#outputs_2","text":"Output type Description out field selected input","title":"Outputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#utils-bjj","text":"","title":"utils-bjj"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#description_3","text":"Implements two functionalities to be used for further circuits: BitsCompressed2AySign gets the bjjCompressed[256] in bits and retrieve ay and sign to be inserted into the account state AySign2Ax gets the ay and sign and computes de ax coordinate","title":"Description"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#schematic_3","text":"","title":"Schematic"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#input","text":"BitsCompressed2AySign Input type Description bjjCompressed[256] boolean array babyjubjub point compressed AySign2Ax Input type Description ay field babyjubjub y coordinate sign boolean babyjubjub sign","title":"Input"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#ouput","text":"BitsCompressed2AySign Output type Description ay field babyjubjub y coordinate sign boolean babyjubjub sign AySign2Ax Output type Description ax field babyjubjub x coordinate","title":"Ouput"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#source","text":"","title":"Source"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#decode-tx","text":"","title":"decode-tx"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#description_4","text":"Takes the transaction data, decodes it and builds data structures to be used in further circuits. Additionally, it performs checks on transactions fields. Listed below is all the built data and all the checks that this circuit performs. Decoders/Build decodes txCompressedData as specified here builds txCompressedDataV2 as specified here builds L1-L2 data availability L1L2TxData as specificied here builds message to sign by L2 transactions sigL2Hash as specified here build L1 full data L1TxFullData as specified here Checks L1 transactions must be processed before L2 transactions only switching from L1 to L2 is allowed checks newAccount is set to true only when it is an L1 transaction and fromIdx is 0 idx to be assigned to a new account creation is incremented and checked only if the transaction involves an account creation checks chainID transaction field matches globalChainID forced by the smart contract checks signatureConstant transaction field matches the hardcoded value CONST_SIG set in the circuit checks maxNumBatch signed in the transaction is greater or equal to currentNumBatch only if maxNumBatch != 0 Global variables: nLevels","title":"Description"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#schematic_4","text":"","title":"Schematic"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#inputs_3","text":"Input type Description previousOnChain bool determines if previous transaction is L1 txCompressedData uint241 encode transaction fields together maxNumBatch uint32 maximum allowed batch number when the transaction can be processed amountF uint40 amount to transfer from L2 to L2 encoded as float40 toEthAddr uint160 ethereum address receiver toBjjAy field babyjubjub y coordinate receiver rqTxCompressedDataV2 uint193 requested encode transaction fields together version 2 rqToEthAddr uint160 requested ethereum address receiver rqToBjjAy field requested babyjubjub y coordinate fromEthAddr uint160 ethereum address sender fromBjjCompressed[256] boolean array babyjubjub compressed sender loadAmountF uint40 amount to deposit from L1 to L2 encoded as float40 globalChainID uint16 global chain identifier currentNumBatch uint32 current batch number onChain bool determines if the transaction is L1 or L2 newAccount bool determines if transaction creates a new account auxFromIdx uint48 auxiliary index to create accounts auxToIdx uint48 auxiliary index when signed index receiver is set to null inIdx uint48 old last index assigned","title":"Inputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#outputs_3","text":"Output type Description L1L2TxData array boolean L1-L2 data availability txCompressedDataV2 uint193 encode transaction fields together version 2 L1TxFullData array boolean L1 full data outIdx uint48 old last index assigned fromIdx uint48 index sender toIdx uint48 index receiver amount uint192 amount to transfer from L2 to L2 tokenID uint32 token identifier nonce uint40 nonce userFee uint8 user fee selector toBjjSign boolean babyjubjub sign receiver sigL2Hash field hash L2 data to sign","title":"Outputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#fee-accumulator","text":"","title":"fee-accumulator"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#description_5","text":"Updates the fees accumulated by each transaction given its fee. Definitions: tokenID : token to update feePlanTokenID[numTokens] : array of all the tokenID that fees will be accumulated accFeeIn[numTokens] : initial array of all fees accumulated fee2Charge : effective fee charged in a transaction accFeeOut[numTokens] : final array of all fees accumulated Steps: find the position on the array feePlanTokenID[numTokens] where its element matches the current transaction tokenID if no match found, no fee would be accumulated and accFeeIn[0..numTokens] == accFeeOut[0..numTokens] if a match is found: accumulate the fee fee2Charge inside its position i on accFeeOut[i] avoid accumulate fees once the match is found Global variables: maxFeeTx","title":"Description"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#schematic_5","text":"","title":"Schematic"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#inputs_4","text":"Input type Description tokenID uint32 tokenID transaction fee2Charge uint192 fee charged feePlanTokenID[maxFeeTx] uint32 array all tokens eligible to accumulate fees accFeeIn[maxFeeTx] uint192 array initial fees accumulated","title":"Inputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#outputs_4","text":"Output type Description accFeeOut[maxFeeTx] uint192 array final fees accumulated","title":"Outputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#rq-tx-verifier","text":"","title":"rq-tx-verifier"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#description_6","text":"Required transaction offset rqTxOffset is the relative index of the transaction that would be linked. This implementation adds atomics swaps support since one transaction is linked to another by this relative index meaning that a transaction can only be processed if the linked transaction is processed too. The next circuit aims to check the past and future data transactions to match the required data signed. Data to be signed in order to link transactions can be found here rqTxOffset relativeIndex 0 no linked transaction 1 1 2 2 3 3 4 -4 5 -3 6 -2 7 -1 Note that setting rqTxOffset to 0 means that no transaction is linked Steps: get data of future/past transactions get relative index and current required data check required data matched the future/past transaction","title":"Description"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#schematic_6","text":"","title":"Schematic"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#input_1","text":"Input type Description futureTxCompressedDataV2[3] uint192 array future transactions txCompressedDataV2 pastTxCompressedDataV2[4] uint192 array past transactions txCompressedDataV2 futureToEthAddr[3] uint160 array future transactions toEthAddr pastToEthAddr[4] uint160 array past transactions toEthAddr futureToBjjAy[3] field array future transactions toBjjAy pastToBjjAy[4] field array past transactions toBjjAy rqTxCompressedDataV2 uint192 requested encode transaction fields together version 2 rqToEthAddr uint160 requested ethereum address receiver rqToBjjAy field requested babyjubjub y coordinate rqTxOffset uint3 relative linked transaction","title":"Input"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#output","text":"None","title":"Output"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#hash-inputs","text":"","title":"hash-inputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#description_7","text":"Take all the intended public inputs and hash them all together to build a single public input for the circuit. The intended public inputs will turn into private inputs of the circuit. Note that this single input will be built by the smart contract. Therefore, proof must match all the data hashed in the input hash which is built inside the circuit from private signals. checkout here definition of global settings Specification for computing hashInputs can be found here Global variables: nLevels nTx maxL1Tx maxFeeTx","title":"Description"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#schematic_7","text":"","title":"Schematic"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#inputs_5","text":"Input type Description oldLastIdx uint48 old last merkle tree index created newLastIdx uint48 new last merkle tree index created oldStateRoot field old state root newStateRoot field new state root newExitRoot field new exit root L1TxsFullData[maxL1Tx * (2*nLevels + 32 + 40 + 40 + 256 + 160)] boolean array bits L1 full data L1L2TxsData[nTx * (2*nLevels + 40 + 8)] boolean array bits L1-L2 transaction data-availability feeTxsData[maxFeeTx] uint48 array all index accounts to receive accumulated fees globalChainID uint16 global chain identifier currentNumBatch uint32 current batch number processed","title":"Inputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#ouputs","text":"Output type Description hashInputsOut field sha256 hash of intended public inputs","title":"Ouputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#fee-tx","text":"","title":"fee-tx"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#description_8","text":"This circuit handles each fee transaction. Fee transaction takes the accumulate fees for a given tokenID and updates the recipient where the fees are wanted to be paid. It checks account existence with the old state root, process the account update and compute the new state root. TokenID must match between fee accumulated and recipient account in order to not update wrong recipients. Besides, if coordinator does not fulfill all the possible recipient to receive fees, fee transaction could be a NOP transaction by setting the recipient to the null index ( IDX 0 ) Steps: check if idxFee is zero NOP transaction if idxFee is zero. Otherwise: check match planTokenID and tokenID for updating the state compute merkle tree processor function ( UPDATE or NOP ) compute old state value (old account balance) compute new state value (old account balance + accumulate fee) merkle tree processor to compute account update and get new state root Global variables: nLevels","title":"Description"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#schematic_8","text":"","title":"Schematic"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#inputs_6","text":"Input type Description oldStateRoot field old state root feePlanToken uint32 token identifier of fees accumulated feeIdx uint48 merkle tree index to receive fees accFee uint192 accumulated fees to transfer tokenID uint32 tokenID of leaf feeIdx nonce uint40 nonce of leaf feeIdx sign bool sign of leaf feeIdx balance uint192 balance of leaf feeIdx ay field ay of leaf feeIdx ethAddr uint160 ethAddr of leaf feeIdx siblings[nLevels + 1] field array siblings merkle proof","title":"Inputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#outputs_5","text":"Output type Description newStateRoot field new state root","title":"Outputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#compute-fee","text":"","title":"compute-fee"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#description_9","text":"Computes the final amount of fee to apply given the fee selector Steps: selects fee factor, feeOut , to apply given feeSel and applyFee compute feeOutNotShifted = amount * feeOut and convert it into bits in feeOutBits[253] compute applyShift to decide if shift has to be applied to feeOutNotShifted select bits on feeOutBits[253] depending on applyShift flag assert feeOut is \\(< 2^{128}\\) It should be noted that feeShiftTable[x] are values hardcoded in the circuit that will match the fee factor shifted 60 bits has been chosen in order to optimize precision at the time to compute fees. 60 bits is the minimum bits to achieve enough precision according fee table values","title":"Description"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#schematic_9","text":"","title":"Schematic"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#inputs_7","text":"Input type Description feeSel Uint8 fee selector amount Uint128 amount to apply the fee factor applyFee boolean determines if fee needs to be computed or if it is 0","title":"Inputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#outputs_6","text":"Output type Description feeOut Uint128 amount * feeFactor","title":"Outputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#balance-updater","text":"","title":"balance-updater"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#description_10","text":"This circuit checks if there is enough balance in the sender account to do the transfer to the receiver account. It computes the new balances for the sender and the receiver. Besides, returns the fee that will be charged and if the amount to transfer is 0 ( isP2Nop signal). These signals will be used in further circuits. It should be noted that in L1 tx, no errors are allowed but the circuit needs to process them. Hence, in case it is not enough balance on the sender account, it will process the transaction as a 0 amount transfer. Hence, signal isAmountNullified will notify if a L1 transaction has been nullified if it is invalid. This isAmountNullified will be used to compute data-availability where the amount used would not be inserted in L1L2TxsData since L1Tx is not valid or triggers underflow. In case of an L2 tx, the protocol does not allow to do a transaction if there is not enough balance in the sender account. The following assumptions have been taken: smart contract filters loadAmount above 2^128 smart contract filters amount above 2^192 circuit reserves 192 bits for the balance of an account overflow applies only if more than 2^64 transactions are done assume overflow is not feasible Steps: compute fee to be applied( fee2Charge ) compute effective amount ( effectiveAmount1 and effectiveAmount2 ) check underflow ( txOk ) compute new balances from sender and receiver ( newStBalanceSender and newStBalanceReceiver )","title":"Description"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#schematic_10","text":"","title":"Schematic"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#inputs_8","text":"Input type Description oldStBalanceSender field initial sender balance oldStBalanceReceiver field initial receiver balance amount uint192 amount to transfer from L2 to L2 loadAmount uint192 amount to deposit from L1 to L2 feeSelector uint8 user selector fee onChain bool determines if the transaction is L1 or L2 nop bool determines if the transfer amount and fees are considered 0 nullifyLoadAmount bool determines if loadAmount is considered to be 0 nullifyAmount bool determines if amount is considered to be 0","title":"Inputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#outputs_7","text":"Output type Description newStBalanceSender uint192 final balance sender newStBalanceReceiver uint192 final balance receiver isP2Nop bool determines if processor 2 performs a NOP transaction fee2Charge uint192 effective transaction fee isAmountNullified uint32 determines if the amount is nullified","title":"Outputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#rollup-tx-states","text":"","title":"rollup-tx-states"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#description_11","text":"This circuit is a subset of the rollup-tx circuit. It has been split for clarity. Transaction states are computed depending on transaction's type. All transaction types can be found here Note that L1 coordinator transactions are treated as L1 user createAccountDeposit inside the circuit. Circuit does not differentiate transactions taking into account its source, either launched by user or by coordinator. Sender and receiver accounts have their own Merkle tree processors inside the circuit in order to perform actions on their leaves: sender: processor 1 receiver: processor 2 The following table summarizes all the processor actions: func[0] func[1] Function 0 0 NOP 0 1 UPDATE 1 0 INSERT 1 1 DELETE Therefore, given the transaction type, it is needed to specify certain signals that would be used in rollup-tx circuit: isP1Insert : determines if processor 1 performs an INSERT function (sender) isP2Insert : determines if processor 2 performs an INSERT function (receiver) key1 : set key to be used in processor 1 key2 : set key to be used in processor 2 P1_fnc0 and P1_fnc1 : selectors for processor 1 P2_fnc0 and P2_fnc1 : selectors for processor 2 isExit : determines if the transaction is an exit type verifySignEnable : enable babyjubjub signature checker nop : transaction is processed as a NOP transaction checkToEthAddr : enable toEthAddr check checkToBjj : enable toBjjAy and toBjjSign check Following truth table determines how to set the above signals depending on transaction inputs: Note that italics make reference to outputs, regular makes reference to inputs Transaction type fromIdx auxFromIdx toIdx auxToIdx toEthAddr onChain newAccount loadAmount amount newExit isP1Insert isP2Insert processor 1 processor 2 isExit verifySignEnable nop checkToEthAddr checkToBjj createAccount 0 key1 0 0 0 1 1 0 0 0 1 0 INSERT UPDATE 0 0 0 0 0 createAccountDeposit 0 key1 0 0 0 1 1 X 0 0 1 0 INSERT UPDATE 0 0 0 0 0 createAccountDepositTransfer 0 key1 key2 0 0 1 1 X X 0 1 0 INSERT UPDATE 0 0 0 0 0 deposit key1 0 0 0 0 1 0 X 0 0 0 0 UPDATE UPDATE 0 0 0 0 0 depositTransfer key1 0 key2 0 0 1 0 X X 0 0 0 UPDATE UPDATE 0 0 0 0 0 forceTransfer key1 0 key2 0 0 1 0 0 X 0 0 0 UPDATE UPDATE 0 0 0 0 0 forceExit key1 - key2 0 1 0 0 1 0 0 X 0: UPDATE, 1: INSERT 0 X: UPDATE, 0: INSERT UPDATE EXIT INSERT - UPDATE 1 0 0 0 0 transfer key1 0 key2 0 0 0 0 0 X 0 0 0 UPDATE UPDATE 0 1 0 0 0 exit key1 - key2 0 1 0 0 0 0 0 X 0: UPDATE, 1: INSERT 0 X: UPDATE, 0: INSERT UPDATE EXIT INSERT - UPDATE 1 1 0 0 0 transferToEthAddr key1 0 0 key2 ANY_ETH_ADDR != 0xF..F 0 0 0 X 0 0 0 UPDATE UPDATE 0 1 0 1 0 transferToBjj key1 0 0 key2 ANY_ETH_ADDR == 0xF..F 0 0 0 X 0 0 0 UPDATE UPDATE 0 1 0 1 1 nop 0 0 0 0 0 0 0 0 0 0 0 0 NOP NOP 0 0 1 0 0 L1 invalid transactions should not be allowed but the circuit needs to process them even if they are not valid. In order to do so, the circuit performs a zero loadAmount \\ amount update if L1 transaction is not valid. Therefore, circuit nullifies loadAmount \\ amount if L1 invalid transaction is detected. Next table sets when to apply nullifyLoadAmount \\ nullifyAmount depending L1 transaction type: Note that nullifyLoadAmount \\ nullifyAmount fields are set to 1 only if checks are not successful and L1 transfers are only allowed if tokenID == tokenID1 == tokenID2 as a sanity check Transaction type newAccount isLoadAmount isAmount checkEthAddr checkTokenID1 checkTokenID2 nullifyLoadAmount nullifyAmount createAccount 1 0 0 0 0 0 0 0 createAccountDeposit 1 1 0 0 0 0 0 0 createAccountDepositTransfer 1 1 1 0 0 1 0 1 deposit 0 1 0 0 1 0 1 0 depositTransfer 0 1 1 1 1 1 1 1 forceTransfer 0 0 1 1 1 1 0 1 forceExit 0 0 1 1 1 1 if newExit = 0 0 1","title":"Description"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#schematic_11","text":"","title":"Schematic"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#inputs_9","text":"Input type Description fromIdx uint48 index sender toIdx uint48 index receiver toEthAddr uint160 ethereum address receiver auxFromIdx uint48 auxiliary index to create accounts auxToIdx uint48 auxiliary index when signed index receiver is set to null amount uint192 amount to transfer from L2 to L2 newExit bool determines if the transaction create a new account in the exit tree loadAmount uint192 amount to deposit from L1 to L2 newAccount bool determines if transaction creates a new account onChain bool determines if the transaction is L1 or L2 fromEthAddr uint160 ethereum address sender ethAddr1 uint160 ethereum address of sender leaf tokenID uint32 tokenID signed in the transaction tokenID1 uint32 tokenID of the sender leaf tokenID2 uint32 tokenID of the receiver leaf","title":"Inputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#outputs_8","text":"Output type Description isP1Insert bool determines if processor 1 performs an INSERT function (sender) isP2Insert bool determines if processor 2 performs an INSERT function (receiver) key1 uint48 processor 1 key key2 uint48 processor 2 key P1_fnc0 bool processor 1 bit 0 functionality P1_fnc1 bool processor 1 bit 1 functionality P2_fnc0 bool processor 2 bit 0 functionality P2_fnc1 bool processor 2 bit 1 functionality isExit bool determines if the transaction is an exit verifySignEnabled bool determines if the eddsa signature needs to be verified nop bool determines if the transaction should be considered as a NOP transaction checkToEthAddr bool determines if receiver ethereum address needs to be checked checkToBjj bool determines if receiver babyjubjub needs to be checked nullifyLoadAmount bool determines if loadAmount is considered to be 0 nullifyAmount bool determines if amount is considered to be 0","title":"Outputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#rollup-tx","text":"","title":"rollup-tx"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#description_12","text":"This circuit includes all the rules given a transaction. Hence, rollup-tx includes the previous specified circuits: rollup-tx-states rq-tx-verifier balance-updater fee-accumulator For the sake of clarity, this circuit could be split internally into phases: A: compute transaction states B: check request transaction C: checks state fields D: compute hash old states E: signal processor selectors F: verify eddsa signature G: update balances H: accumulate fess I: compute hash new states J: smt processors K: select output roots Global variables: nLevels maxFeeTx","title":"Description"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#schematic_12","text":"","title":"Schematic"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#inputs_10","text":"Input type Description feePlanTokens[maxFeeTx] uint32 array all tokens eligible to accumulate fees accFeeIn[maxFeeTx] uint192 array initial fees accumulated futureTxCompressedDataV2[3] uint193 array future transactions txCompressedDataV2 pastTxCompressedDataV2[4] uint193 array past transactions toEthAddr futureToEthAddr[3] uint160 array future transactions toEthAddr pastToEthAddr[4] uint160 array past transactions toEthAddr futureToBjjAy[3] field array future transactions toBjjAy pastToBjjAy[4] field array past transactions toBjjAy fromIdx uint48 index sender auxFromIdx uint48 auxiliary index to create accounts toIdx uint48 index receiver auxToIdx uint48 auxiliary index when signed index receiver is set to null toBjjAy field babyjubjub y coordinate receiver toBjjSign bool babyjubjub sign receiver toEthAddr uint160 ethereum address receiver amount uint192 amount to transfer from L2 to L2 tokenID uint32 tokenID signed in the transaction nonce uint40 nonce signed in the transaction userFee uint16 user fee selector rqOffset uint3 relative linked transaction onChain bool determines if the transaction is L1 or L2 newAccount bool determines if transaction creates a new account rqTxCompressedDataV2 uint193 requested encode transaction fields together version 2 rqToEthAddr uint160 requested ethereum address receiver rqToBjjAy field requested babyjubjub y coordinate sigL2Hash field hash L2 data to sign s field eddsa signature field r8x field eddsa signature field r8y field eddsa signature field fromEthAddr uint160 ethereum address sender fromBjjCompressed[256] boolean array babyjubjub compressed sender loadAmountF uint40 amount to deposit from L1 to L2 encoded as float40 tokenID1 uint32 tokenID of the sender leaf nonce1 uint40 nonce of the sender leaf sign1 bool sign of the sender leaf balance1 uint192 balance of the sender leaf ay1 field ay of the sender leaf ethAddr1 uint160 ethAddr of the sender leaf siblings1[nLevels + 1] field array siblings merkle proof of the sender leaf isOld0_1 bool flag to require old key - value oldKey1 uint48 old key of the sender leaf oldValue1 field old value of the sender leaf tokenID2 uint32 tokenID of the receiver leaf nonce2 uint40 nonce of the receiver leaf sign2 bool sign of the receiver leaf balance2 uint192 balance of the receiver leaf ay2 field ay of the receiver leaf ethAddr2 uint160 ethAddr of the receiver leaf siblings2[nLevels + 1] field array siblings merkle proof of the receiver leaf isOld0_2 bool flag to require old key - value oldKey2 uint48 old key of the receiver leaf oldValue2 field old value of the receiver leaf oldStateRoot field initial state root oldExitRoot field initial exit root","title":"Inputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#ouputs_1","text":"Output type Description isAmountNullified bool determines if the amount is nullified accFeeOut[maxFeeTx] uint192 array final fees accumulated newStateRoot field final state root newExitRoot field final exit root","title":"Ouputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#rollup-main","text":"","title":"rollup-main"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#description_13","text":"Join all transactions and process them. This includes, decode all possible transactions, process them and distribute all the fees through fee transactions. It is important to note that the templates included in this main circuit are intended to be computed in parallel. Meaning that the output of the very first transaction could be computed as it output is not necessary to compute the next transaction. Then, all transactions could be computed in parallel. In order to achieve that, it is needed to supply intermediate signals to allow modules parallelization. All signals prefixed with im are intermediary signals. Note that in circuit phases, there are specific phases to check integrity of intermediary signals. This adds constraints to the circuit, since it is needed to provided transactions output in advance, but it allows high parallelization at the time to compute the witness. Note that there is only one public input, hashGlobalInputs , which is a sha256 hash of all the intended public inputs of the circuit. This is done in order to save gas in the contract by just passing one public input. Global variables: nTx nLevels maxL1Tx maxFeeTx Main circuit could be split in the following phases: A: decode transactions B: check binary signals C: check integrity decode intermediary signals D: process transactions E: check integrity transactions intermediary signals F: process fee transactions G: check integrity fee transactions intermediary signals H: compute global hash input In section H, only bits associated to amountF in L1L2TxsData are multiplied by isAmountNullififed . Note that this only applies for invalid L1 transactions.","title":"Description"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#schematic_13","text":"","title":"Schematic"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#inputs_11","text":"Input type Description oldLastIdx uint48 old last index assigned oldStateRoot field initial state root globalChainID uint16 global chain identifier currentNumBatch uint32 current batch number processed feeIdxs[maxFeeTx] uint48 array merkle tree indexes to receive fees feePlanTokens[maxFeeTx] uint32 array tokens identifiers of fees accumulated imOnChain[nTx-1] boolean array intermediary signals: decode transaction output onChain flag imOutIdx[nTx-1] uint48 array intermediary signals: decode transaction final index assigned imStateRoot[nTx-1] field array intermediary signals: transaction final state root imExitRoot[nTx-1] field array intermediary signals: transaction final exit root imAccFeeOut[nTx-1][maxFeeTx] uint192 array array intermediary signals: transaction final accumulated fees imStateRootFee[maxFeeTx - 1] field array intermediary signals: transaction fee final state root imInitStateRootFee field intermediary signals: final state root of all rollup transactions imFinalAccFee[maxFeeTx] field array intermediary signals: final fees accumulated of all rollup transactions txCompressedData[nTx] uint241 array encode transaction fields together amountF[nTx] uint40 array amount to transfer from L2 to L2 encoded as float40 txCompressedDataV2[nTx] uint193 array encode transaction fields together version 2 fromIdx[nTx] uint48 array index sender auxFromIdx[nTx] uint48 array auxiliary index to create accounts toIdx[nTx] uint48 array index receiver auxToIdx[nTx] uint48 array auxiliary index when signed index receiver is set to null toBjjAy[nTx] field array babyjubjub y coordinate receiver toEthAddr[nTx] uint160 array ethereum address receiver maxNumBatch[nTx] uint32 array maximum allowed batch number when the transaction can be processed onChain[nTx] bool array determines if the transaction is L1 or L2 newAccount[nTx] bool array determines if transaction creates a new account rqTxCompressedDataV2[nTx] uint193 array requested encode transaction fields together version 2 rqToEthAddr[nTx] uint160 array requested ethereum address receiver rqToBjjAy[nTx] field array requested babyjubjub y coordinate s[nTx] field array eddsa signature field r8x[nTx] field array eddsa signature field r8y[nTx] field array eddsa signature field loadAmountF[nTx] uint40 array amount to deposit from L1 to L2 encoded as float40 fromEthAddr[nTx] uint160 array ethereum address sender fromBjjCompressed[nTx][256] boolean array array babyjubjub compressed sender tokenID1[nTx] uint32 array tokenID of the sender leaf nonce1[nTx] uint40 array nonce of the sender leaf sign1[nTx] bool array sign of the sender leaf balance1[nTx] uint192 array balance of the sender leaf ay1[nTx] field array ay of the sender leaf ethAddr1[nTx] uint160 array ethAddr of the sender leaf siblings1[nTx][nLevels + 1] field array array siblings merkle proof of the sender leaf isOld0_1[nTx] bool array flag to require old key - value oldKey1[nTx] uint48 array old key of the sender leaf oldValue1[nTx] field array old value of the sender leaf tokenID2[nTx] uint32 array tokenID of the receiver leaf nonce2[nTx] uint40 array nonce of the receiver leaf sign2[nTx] bool array sign of the receiver leaf balance2[nTx] uint192 array balance of the receiver leaf ay2[nTx] field array ay of the receiver leaf ethAddr2[nTx] uint160 array ethAddr of the receiver leaf siblings2[nTx][nLevels + 1] field array array siblings merkle proof of the receiver leaf isOld0_2[nTx] bool array flag to require old key - value oldKey2[nTx] uint48 array old key of the sender leaf oldValue2[nTx] field array old value of the sender leaf tokenID3[maxFeeTx] uint32 array tokenID of leafs feeIdxs nonce3[maxFeeTx] uint40 array nonce of leafs feeIdxs sign3[maxFeeTx] bool array sign of leafs feeIdxs balance3[maxFeeTx] uint192 array balance of leafs feeIdxs ay3[maxFeeTx] field array ay of leafs feeIdxs ethAddr3[maxFeeTx] uint160 array ethAddr of leafs feeIdxs siblings3[maxFeeTx][nLevels + 1] field array array siblings merkle proof of leafs Idxs","title":"Inputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#outputs_9","text":"Output type Description hashGlobalInputs field hash of all intended input signals","title":"Outputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#withdraw","text":"","title":"withdraw"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#description_14","text":"This circuit is used to prove that a leaf exist on the exit tree. If its existence is proved, user will be able to withdraw funds from the Hermez contract. All intended public inputs are hashed together as described here . Steps: compute hash-state verify state exist in the exit tree root given the siblings compute hashGlobalInputs It should be noted that this circuit is heavily attached to the hermez smart contract Global variables nLevels","title":"Description"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#schematic_14","text":"","title":"Schematic"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#inputs_12","text":"Input type Description root exit field exit tree root ethAddr uint160 ethereum address tokenID uint32 token identifier balance uint192 balance idx uint48 merkle tree index sign boolean babyjubjub sign ay field babyjubjub y coordinate siblingsState[nLevels + 1] field array siblings merkle proof","title":"Inputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/circuits/circuits/#outputs_10","text":"Output type Description hashGlobalInputs field hash of all intended input signals","title":"Outputs"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/","text":"Hermez smart contracts Glossary Batch: Set of transactions that determines a state transition of the accounts and sets an exit tree. L2-Batch: The set of transactions are only L2 L1-L2-Batch: The set of transactions are L1 or L2 Hermez General Goals Handle L1-user transactions Ensure that these transactions are forged Forge batches Ask consensus algorithm for coordinator approval Add L1 Coordinator Transactions Ensures that state transitions are valid through a validity proof which will assure that certain rules have been fulfilled. Set a new state Merkle root and exit Merkle root Utility actions Withdraw funds or add new tokens to the rollup Handle L1 User Transactions All L1UserTx are encoded and added to a queue, when the queue is full or frozen, a new queue is created. Once a queue is frozen means that L1 transactions can't be added anymore. Each queue is identified by an index that grows incrementally. The queue index of the next L1-L2-batch is always frozen which is identified by nextL1ToForgeQueue When a user calls a function that adds an L1UserTx, the following happens: Storage Add the L1UserTx data at the end of the last non-frozen non-full queue of L1UserTxs ( mapL1TxQueue[nextL1FillingQueue] ). The queue index in which this data is added is identified by nextL1FillingQueue The L1UserTxs is encoded as a byte array data and appended to the queue Once the nextL1FillingQueue is full, increment the nextL1FillingQueue Event Information nextL1FillingQueue position L1UserTx data (72 bytes) In the global spec, all L1 user transactions are specified The L1TxQueue has a lenght of MAX_L1_TX , L1UserTx can fulfill till MAX_L1_USER_TX , therefore always are some slots reserved for the L1-coordinator-Tx: MAX_L1_TX - len(L1_USER_TXS) Utility Actions Add Tokens Hermez has a list of all the tokens that the rollup supports. Tokens must be an ERC20, and everyone can add a new token with this method. A fee in HEZ must be payed to the governance address. Withdraw Transaction to get funds back from the smart contract to Ethereum address. This is done by proving the existence of a leaf in the exit tree. Once the withdrawal is done a nullifier is set, so this only can happen once. Remember withdraw is not a L1 transaction, it has no impact in the state or exit trees and it's not processed by the circuit. Forging The forgeBatch functionality depends on a consensus mechanism to decide who can be the coordinator of a given batch. Separate from the rollup smart contract, there is an external smart contract that implements the consensus mechanism and maintains its own state. During a forge call in the rollup smart contract, a call is made to the consensus smart contract to validate if the caller coordinator is allowed to forge and also to allow the consensus smart contract to update its own state and perform consensus actions if necessary. Then, the coordinator will add his L1-coordinator-transactions and will verify the circuit proof against the verifier smart contract as we can see in the previous diagram There are 2 kind of forgeBatch , a flag in the function will distinguish between them L2-batch Forge L2 and L1 coordinator transactions, L1 User transactions are not mined. L1-L2-batch Forge L1 user, L1 coordinator and L2 transactions. The coordinator must forge all the L1 transactions in the first frozen queue Optionally coordinator can add L1-coordinator-transactions Set a new state and exit root Delete the current frozen queue and freeze the next one In order to force the coordinator to forge the L1 transactions, but also allow him to parallelize his proof computation, the contract establishes a deadline for the L1-L2-batches. All L1-L2-batches reset the deadline, so, as shown in the diagram, the coordinator is free to choose to forge L2-batches or L1-L2-batches until the deadline, when only L1-L2-batches are accepted. L1 Coordinator Transactions In the global spec all of the L1 coordinator transactions are specified Data availability L1-User-Tx --> Events L1-Coordinator-Tx --> forgeBatch ethereum Tx Input L2-Tx --> forgeBatch ethereum Tx Input In order to provide data availability the forgeBatch transaction inputs must be recovered. To allow this data retrieval from a regular Ethereum node, Hermez must force that the call is not made from another smart contract: assert(msg.sender == tx.origin) Governance The governance will be able to set the following parameters: forgeL1L2BatchTimeout Number of Ethereum blocks after the last L1-L2-batch after which only an L1-L2-batch can be forged feeAddToken Fee in HEZ tokens that must be payed to the governance to add a new token into the rollup tokenExchange Update the tokenUSD value for the instant Withdraw purposes withdrawalDelay Delay in seconds of the delayed withdraw buckets Update buckets parameters for the instant Withdraw purposes Emergency Mechanism Goal This logic is implemented during the bootstrapping phase of the network as an additional security measure to mitigate attacks that could potentially provide illegitimate access to user funds from Hermez Network. The objective is to temporarily enable this last-resort measure while preserving decentralization. The core mechanism is to set a withdrawal limit in order to avoid infinite withdrawal in case of illegitimate funds access. Therefore, it is assured that the attacker can only withdraw a certain amount of tokens. Hermez Withdraw Limit There will be a histogram of maximum amount of withdrawals in a value range: - Limits the maximum amount to withdraw - Value range is set in USD - Buckets are filled in a blockRatio - If a withdraw reaches the histogram limit, an instant withdraw cannot be performed Every time a user tries to perform an instant withdraw: - Updates the counter of the histogram - If the counter is above the capacity of that range, instant withdraw is reverted Note that withdraw limit would be the maximum amount of tokens that an attacker can withdraw since the contract will return revert when the instant withdraw is called again and there are no tokens left to send. The histogram is understood as buckets. Mechanism The number of withdraws above the withdraw limit can not be withdrawn instantly, there will be a delay. Tokens will be sent to the WithdrawalDelayer smart contract. Users will be able to perform instant withdrawals as long as Hermez Contract does not reach the withdrawal limit , that is, it runs out of withdraws available in the bucket (in the bucket with that price range). Actions that will be taken if the withdrawal limit is reached are the following ones: - If a user does an instantWithdraw , Hermez Contract will return revert . - If a user does a delayWithdraw , it will be accepted and the tokens will be sent to WithdrawalDelayer . The user can withdraw their tokens but with a delay. There will be a delay time withdrawalDelay (parameter of the WithdrawalDelayer contract) during which the Hermez Foundation can decide if there has been an attack or not: - Not attack: - When enough blocks have passed for the bucket to refill, Hermez Contract will accept instantWithdraw again, while withdrawals are available in the bucket. - Attack: - The histogram values will all be set to 0 (change to safe mode ) so that all tokens are sent to WithdrawalDelayer until the histogram values are changed again. - If a decision is not made in the defined period: - When enough blocks have passed for the bucket to refill, Hermez Contract will accept instantWithdraw again. During the bootstrapping phase, Hermez devs team will be monitoring constantly the system in order to detect possible anomalies and to be able to decide as soon as possible if the network is under an attack. Parameters Bucket (part of histogram): ceilUSD : maximum amount to allow instant withdrawals (bucket range) blockStamp : last time a withdrawal was added ( or removed if the bucket was full) withdrawals : available withdrawals of the bucket blockWithdrawalRate : every x blocks add 1 withdrawal maxWithdrawals : max withdrawals the bucket can hold NUM_BUCKETS : number of buckets in histogram tokenExchange : mapping tokenAddress --> USD value (default 0, means that no limit applies)","title":"Smart contracts"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/#hermez-smart-contracts","text":"","title":"Hermez smart contracts"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/#glossary","text":"Batch: Set of transactions that determines a state transition of the accounts and sets an exit tree. L2-Batch: The set of transactions are only L2 L1-L2-Batch: The set of transactions are L1 or L2","title":"Glossary"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/#hermez-general-goals","text":"Handle L1-user transactions Ensure that these transactions are forged Forge batches Ask consensus algorithm for coordinator approval Add L1 Coordinator Transactions Ensures that state transitions are valid through a validity proof which will assure that certain rules have been fulfilled. Set a new state Merkle root and exit Merkle root Utility actions Withdraw funds or add new tokens to the rollup","title":"Hermez General Goals"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/#handle-l1-user-transactions","text":"All L1UserTx are encoded and added to a queue, when the queue is full or frozen, a new queue is created. Once a queue is frozen means that L1 transactions can't be added anymore. Each queue is identified by an index that grows incrementally. The queue index of the next L1-L2-batch is always frozen which is identified by nextL1ToForgeQueue When a user calls a function that adds an L1UserTx, the following happens: Storage Add the L1UserTx data at the end of the last non-frozen non-full queue of L1UserTxs ( mapL1TxQueue[nextL1FillingQueue] ). The queue index in which this data is added is identified by nextL1FillingQueue The L1UserTxs is encoded as a byte array data and appended to the queue Once the nextL1FillingQueue is full, increment the nextL1FillingQueue Event Information nextL1FillingQueue position L1UserTx data (72 bytes) In the global spec, all L1 user transactions are specified The L1TxQueue has a lenght of MAX_L1_TX , L1UserTx can fulfill till MAX_L1_USER_TX , therefore always are some slots reserved for the L1-coordinator-Tx: MAX_L1_TX - len(L1_USER_TXS)","title":"Handle L1 User Transactions"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/#utility-actions","text":"","title":"Utility Actions"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/#add-tokens","text":"Hermez has a list of all the tokens that the rollup supports. Tokens must be an ERC20, and everyone can add a new token with this method. A fee in HEZ must be payed to the governance address.","title":"Add Tokens"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/#withdraw","text":"Transaction to get funds back from the smart contract to Ethereum address. This is done by proving the existence of a leaf in the exit tree. Once the withdrawal is done a nullifier is set, so this only can happen once. Remember withdraw is not a L1 transaction, it has no impact in the state or exit trees and it's not processed by the circuit.","title":"Withdraw"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/#forging","text":"The forgeBatch functionality depends on a consensus mechanism to decide who can be the coordinator of a given batch. Separate from the rollup smart contract, there is an external smart contract that implements the consensus mechanism and maintains its own state. During a forge call in the rollup smart contract, a call is made to the consensus smart contract to validate if the caller coordinator is allowed to forge and also to allow the consensus smart contract to update its own state and perform consensus actions if necessary. Then, the coordinator will add his L1-coordinator-transactions and will verify the circuit proof against the verifier smart contract as we can see in the previous diagram There are 2 kind of forgeBatch , a flag in the function will distinguish between them L2-batch Forge L2 and L1 coordinator transactions, L1 User transactions are not mined. L1-L2-batch Forge L1 user, L1 coordinator and L2 transactions. The coordinator must forge all the L1 transactions in the first frozen queue Optionally coordinator can add L1-coordinator-transactions Set a new state and exit root Delete the current frozen queue and freeze the next one In order to force the coordinator to forge the L1 transactions, but also allow him to parallelize his proof computation, the contract establishes a deadline for the L1-L2-batches. All L1-L2-batches reset the deadline, so, as shown in the diagram, the coordinator is free to choose to forge L2-batches or L1-L2-batches until the deadline, when only L1-L2-batches are accepted.","title":"Forging"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/#l1-coordinator-transactions","text":"In the global spec all of the L1 coordinator transactions are specified","title":"L1 Coordinator Transactions"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/#data-availability","text":"L1-User-Tx --> Events L1-Coordinator-Tx --> forgeBatch ethereum Tx Input L2-Tx --> forgeBatch ethereum Tx Input In order to provide data availability the forgeBatch transaction inputs must be recovered. To allow this data retrieval from a regular Ethereum node, Hermez must force that the call is not made from another smart contract: assert(msg.sender == tx.origin)","title":"Data availability"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/#governance","text":"The governance will be able to set the following parameters: forgeL1L2BatchTimeout Number of Ethereum blocks after the last L1-L2-batch after which only an L1-L2-batch can be forged feeAddToken Fee in HEZ tokens that must be payed to the governance to add a new token into the rollup tokenExchange Update the tokenUSD value for the instant Withdraw purposes withdrawalDelay Delay in seconds of the delayed withdraw buckets Update buckets parameters for the instant Withdraw purposes","title":"Governance"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/#emergency-mechanism","text":"","title":"Emergency Mechanism"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/#goal","text":"This logic is implemented during the bootstrapping phase of the network as an additional security measure to mitigate attacks that could potentially provide illegitimate access to user funds from Hermez Network. The objective is to temporarily enable this last-resort measure while preserving decentralization. The core mechanism is to set a withdrawal limit in order to avoid infinite withdrawal in case of illegitimate funds access. Therefore, it is assured that the attacker can only withdraw a certain amount of tokens.","title":"Goal"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/#hermez-withdraw-limit","text":"There will be a histogram of maximum amount of withdrawals in a value range: - Limits the maximum amount to withdraw - Value range is set in USD - Buckets are filled in a blockRatio - If a withdraw reaches the histogram limit, an instant withdraw cannot be performed Every time a user tries to perform an instant withdraw: - Updates the counter of the histogram - If the counter is above the capacity of that range, instant withdraw is reverted Note that withdraw limit would be the maximum amount of tokens that an attacker can withdraw since the contract will return revert when the instant withdraw is called again and there are no tokens left to send. The histogram is understood as buckets.","title":"Hermez Withdraw Limit"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/#mechanism","text":"The number of withdraws above the withdraw limit can not be withdrawn instantly, there will be a delay. Tokens will be sent to the WithdrawalDelayer smart contract. Users will be able to perform instant withdrawals as long as Hermez Contract does not reach the withdrawal limit , that is, it runs out of withdraws available in the bucket (in the bucket with that price range). Actions that will be taken if the withdrawal limit is reached are the following ones: - If a user does an instantWithdraw , Hermez Contract will return revert . - If a user does a delayWithdraw , it will be accepted and the tokens will be sent to WithdrawalDelayer . The user can withdraw their tokens but with a delay. There will be a delay time withdrawalDelay (parameter of the WithdrawalDelayer contract) during which the Hermez Foundation can decide if there has been an attack or not: - Not attack: - When enough blocks have passed for the bucket to refill, Hermez Contract will accept instantWithdraw again, while withdrawals are available in the bucket. - Attack: - The histogram values will all be set to 0 (change to safe mode ) so that all tokens are sent to WithdrawalDelayer until the histogram values are changed again. - If a decision is not made in the defined period: - When enough blocks have passed for the bucket to refill, Hermez Contract will accept instantWithdraw again. During the bootstrapping phase, Hermez devs team will be monitoring constantly the system in order to detect possible anomalies and to be able to decide as soon as possible if the network is under an attack.","title":"Mechanism"},{"location":"Hermez_1.0/developers/protocol/hermez-protocol/contracts/contracts/#parameters","text":"Bucket (part of histogram): ceilUSD : maximum amount to allow instant withdrawals (bucket range) blockStamp : last time a withdrawal was added ( or removed if the bucket was full) withdrawals : available withdrawals of the bucket blockWithdrawalRate : every x blocks add 1 withdrawal maxWithdrawals : max withdrawals the bucket can hold NUM_BUCKETS : number of buckets in histogram tokenExchange : mapping tokenAddress --> USD value (default 0, means that no limit applies)","title":"Parameters"},{"location":"Hermez_1.0/developers/protocol/withdrawal-delayer/withdrawal-delayer/","text":"Withdrawal Delayer Protocol Goal As announced in the project whitepaper as well as the documentation, Hermez will be covering an initial phase of network bootstrapping where some additional security measures are deployed as a good practice for risk management. An automated limitation on withdrawals will be implemented as an additional checkpoint to identify anomalous behavior of the network. In such conditions, some time for the developers team to verify the system is required and to identify if the behavior has evolved and a change of security parameters is needed. The purpose of this smart contract is to delay the withdraw in case of anomalous behavior of the network. Users will be prompted to try again after some time or they can decide to use this delayed withdraw alternative with a guaranteed delay time. Hence, tokens will be held by the smart contract for a period of D and only afterward tokens could be really withdrawn. Actors hermezRollup : Smart contract responsible for making deposits and it's able to change the delay hermezKeeperAddress : can enable emergency mode and modify the delay to make a withdrawal hermezGovernanceDAOAddress : can claim the funds in an emergency mode whiteHackGroupAddress : can claim the funds in an emergency when MAX_EMERGENCY_MODE_TIME is exceeded These addresses can only be updated if the sender of the transaction that changes them is the current address. Mechanism When a certain state has been reached in Hermez Contract , the tokens will be sent to the WithdrawalDelayer contract. So, the tokens will be in the contract during period D . In that period it will be decided whether it was an attack or a normal process. That period D can only be changed by hermezKeeperAddress or by hermezRollup . Actions that will be taken if an attack is detected are the following ones: The WithdrawalDelayer contract will stay in NORMAL_MODE until it is decided that there has been an attack. Then, if there was an attack, it would go to EMERGENCY_MODE and the decision can not be reversed. Only hermezKeeperAddress will be able to put the system in EMERGENCY_MODE . There will be a delay time D to decide if there has been an attack or not: No attack: WithdrawalDelayer remains in NORMAL_MODE , and users will be able to withdraw their tokens normally but with a delay Attack: WithdrawalDelayer change to EMERGENCY_MODE , then only GovernanceDAO will be able to withdraw the funds Aragon court will have the option to reject proposals on how the GovernanceDAO will distribute the funds If after MAX_EMERGENCY_MODE_TIME the funds are still stopped, the whiteHackGroupAddress can withdraw the funds if they think it's necessary to avoid a permanent block Parameters D : delay to withdraw from WithdrawalDelayer measured in seconds MAX_WITHDRAWAL_DELAY : maximum delay time to decide if it was an attack or not, measured in weeks --> 2 weeks MAX_EMERGENCY_MODE_TIME : maximum time that funds can stay in the contract, measured in weeks --> 6 months (~ 26 weeks)","title":"Withdrawal delayer protocol"},{"location":"Hermez_1.0/developers/protocol/withdrawal-delayer/withdrawal-delayer/#withdrawal-delayer-protocol","text":"","title":"Withdrawal Delayer Protocol"},{"location":"Hermez_1.0/developers/protocol/withdrawal-delayer/withdrawal-delayer/#goal","text":"As announced in the project whitepaper as well as the documentation, Hermez will be covering an initial phase of network bootstrapping where some additional security measures are deployed as a good practice for risk management. An automated limitation on withdrawals will be implemented as an additional checkpoint to identify anomalous behavior of the network. In such conditions, some time for the developers team to verify the system is required and to identify if the behavior has evolved and a change of security parameters is needed. The purpose of this smart contract is to delay the withdraw in case of anomalous behavior of the network. Users will be prompted to try again after some time or they can decide to use this delayed withdraw alternative with a guaranteed delay time. Hence, tokens will be held by the smart contract for a period of D and only afterward tokens could be really withdrawn.","title":"Goal"},{"location":"Hermez_1.0/developers/protocol/withdrawal-delayer/withdrawal-delayer/#actors","text":"hermezRollup : Smart contract responsible for making deposits and it's able to change the delay hermezKeeperAddress : can enable emergency mode and modify the delay to make a withdrawal hermezGovernanceDAOAddress : can claim the funds in an emergency mode whiteHackGroupAddress : can claim the funds in an emergency when MAX_EMERGENCY_MODE_TIME is exceeded These addresses can only be updated if the sender of the transaction that changes them is the current address.","title":"Actors"},{"location":"Hermez_1.0/developers/protocol/withdrawal-delayer/withdrawal-delayer/#mechanism","text":"When a certain state has been reached in Hermez Contract , the tokens will be sent to the WithdrawalDelayer contract. So, the tokens will be in the contract during period D . In that period it will be decided whether it was an attack or a normal process. That period D can only be changed by hermezKeeperAddress or by hermezRollup . Actions that will be taken if an attack is detected are the following ones: The WithdrawalDelayer contract will stay in NORMAL_MODE until it is decided that there has been an attack. Then, if there was an attack, it would go to EMERGENCY_MODE and the decision can not be reversed. Only hermezKeeperAddress will be able to put the system in EMERGENCY_MODE . There will be a delay time D to decide if there has been an attack or not: No attack: WithdrawalDelayer remains in NORMAL_MODE , and users will be able to withdraw their tokens normally but with a delay Attack: WithdrawalDelayer change to EMERGENCY_MODE , then only GovernanceDAO will be able to withdraw the funds Aragon court will have the option to reject proposals on how the GovernanceDAO will distribute the funds If after MAX_EMERGENCY_MODE_TIME the funds are still stopped, the whiteHackGroupAddress can withdraw the funds if they think it's necessary to avoid a permanent block","title":"Mechanism"},{"location":"Hermez_1.0/developers/protocol/withdrawal-delayer/withdrawal-delayer/#parameters","text":"D : delay to withdraw from WithdrawalDelayer measured in seconds MAX_WITHDRAWAL_DELAY : maximum delay time to decide if it was an attack or not, measured in weeks --> 2 weeks MAX_EMERGENCY_MODE_TIME : maximum time that funds can stay in the contract, measured in weeks --> 6 months (~ 26 weeks)","title":"Parameters"},{"location":"Hermez_1.0/faq/coordinators/","text":"Coordinators Overview What is a Hermez Coordinator? A Coordinator is our term for rollup block producer. At any one time, there is one Coordinator responsible for creating blocks on the rollup chain selected among a number of registered nodes via an auction process. How many Coordinators are there? There is no limit to the number of registered Coordinators. Becoming a Coordinator is entirely permissionless via an auction process and it will be enabled shortly after launch. Although the first Coordinator will be the Hermez Boot Coordinator which will forge blocks when there are no alternative bids in the auction, it\u2019s important for us that the market for coordinators becomes open over time. How is the Coordinator Node selected? The Coordinator Node is selected using an auction process, where registered nodes bid for the right to forge batches during a time slot. The highest bidder in a given slot will become the Coordinator Will there be a competitive market for Coordinators? We are committed to creating a competitive market for Coordinators and we will open-source software to allow anyone to run a Coordinator node. Auction Process How do I become a Coordinator? To become a Coordinator you need to prepare the system infrastructure, take part in the auction, and win a bid for a time slot. How are bids placed in the auction? Coordinators will participate in the auction by sending an on-chain transaction to the auction smart contract. Bids are always paid in HEZ. Where do I get HEZ? HEZ can be easily obtained in Uniswap Is there a minimum amount of HEZ tokens you have to hold to be a Coordinator? You need to have at least as many tokens as your bid ammount. The Coordinator I am running has lost a bid. Where does the bid go? In case your bid didn't win the slot, the amount bid is transferred to the Auction smart contract under your account. You can use this amount for future bids, or withdraw it to the Coordinator account. How long are Coordinator time slots? Slots will be 40 Ethereum blocks long (10 minutes). During this time, a Coordinator can forge as many batches as possible. What happens if the Coordinator goes offline? If the Coordinator has not done anything in the first part a slot, then anyone can jump in and replace it by forging blocks (first come first served). How do Coordinators make money? Coordinators set and collect the transaction fees. They can expect a revenue per transaction and each coordinator will select to forge the more profitable transactions from the transaction pool. They profit from these fees minus the operational costs and the bid price for the slot. Running a Coordinator What are the infrastructure requirements to run a Coordinator? To run a Coordinator you need the following: - PostgreSQL database - Ethereum Node - Coordinator Server running the hermez-node repository . A reasonable server spec is AWS instance c5ad.2xlarge with 8 vCPU and 16GB RAM - Proof Server running the rapidsnark repository . A server spec able to run the ~2000 transaction circuit is AWS instance c5ad.24xlarge with 96 vCPU and 192GB RAM. Is there a step by step guide to configure a Coordinator node? Yes. You can find this guide here . How do you register as a Coordinator? You can use a JavaScript tool, cli-bidding to register your node as a Coordinator. How many transactions can be processed per batch? The number of transactions per batch depends on the circuit used. Hermez accepts two different circuit sizes: 400 transactions and 2048 transactions. I am having technical issues running a Coordinator node. Who can I contact for support? We recommend to go over this FAQ first, and if you still have issues, please send an email to hello@hello@hermez.network, or send a message to our Discord . You can also find more information in the Hermez documentation page","title":"Coordinators"},{"location":"Hermez_1.0/faq/coordinators/#coordinators","text":"","title":"Coordinators"},{"location":"Hermez_1.0/faq/coordinators/#overview","text":"","title":"Overview"},{"location":"Hermez_1.0/faq/coordinators/#what-is-a-hermez-coordinator","text":"A Coordinator is our term for rollup block producer. At any one time, there is one Coordinator responsible for creating blocks on the rollup chain selected among a number of registered nodes via an auction process.","title":"What is a Hermez Coordinator?"},{"location":"Hermez_1.0/faq/coordinators/#how-many-coordinators-are-there","text":"There is no limit to the number of registered Coordinators. Becoming a Coordinator is entirely permissionless via an auction process and it will be enabled shortly after launch. Although the first Coordinator will be the Hermez Boot Coordinator which will forge blocks when there are no alternative bids in the auction, it\u2019s important for us that the market for coordinators becomes open over time.","title":"How many Coordinators are there?"},{"location":"Hermez_1.0/faq/coordinators/#how-is-the-coordinator-node-selected","text":"The Coordinator Node is selected using an auction process, where registered nodes bid for the right to forge batches during a time slot. The highest bidder in a given slot will become the Coordinator","title":"How is the Coordinator Node selected?"},{"location":"Hermez_1.0/faq/coordinators/#will-there-be-a-competitive-market-for-coordinators","text":"We are committed to creating a competitive market for Coordinators and we will open-source software to allow anyone to run a Coordinator node.","title":"Will there be a competitive market for Coordinators?"},{"location":"Hermez_1.0/faq/coordinators/#auction-process","text":"","title":"Auction Process"},{"location":"Hermez_1.0/faq/coordinators/#how-do-i-become-a-coordinator","text":"To become a Coordinator you need to prepare the system infrastructure, take part in the auction, and win a bid for a time slot.","title":"How do I become a Coordinator?"},{"location":"Hermez_1.0/faq/coordinators/#how-are-bids-placed-in-the-auction","text":"Coordinators will participate in the auction by sending an on-chain transaction to the auction smart contract. Bids are always paid in HEZ.","title":"How are bids placed in the auction?"},{"location":"Hermez_1.0/faq/coordinators/#where-do-i-get-hez","text":"HEZ can be easily obtained in Uniswap","title":"Where do I get HEZ?"},{"location":"Hermez_1.0/faq/coordinators/#is-there-a-minimum-amount-of-hez-tokens-you-have-to-hold-to-be-a-coordinator","text":"You need to have at least as many tokens as your bid ammount.","title":"Is there a minimum amount of HEZ tokens you have to hold to be a Coordinator?"},{"location":"Hermez_1.0/faq/coordinators/#the-coordinator-i-am-running-has-lost-a-bid-where-does-the-bid-go","text":"In case your bid didn't win the slot, the amount bid is transferred to the Auction smart contract under your account. You can use this amount for future bids, or withdraw it to the Coordinator account.","title":"The Coordinator I am running has lost a bid. Where does the bid go?"},{"location":"Hermez_1.0/faq/coordinators/#how-long-are-coordinator-time-slots","text":"Slots will be 40 Ethereum blocks long (10 minutes). During this time, a Coordinator can forge as many batches as possible.","title":"How long are Coordinator time slots?"},{"location":"Hermez_1.0/faq/coordinators/#what-happens-if-the-coordinator-goes-offline","text":"If the Coordinator has not done anything in the first part a slot, then anyone can jump in and replace it by forging blocks (first come first served).","title":"What happens if the Coordinator goes offline?"},{"location":"Hermez_1.0/faq/coordinators/#how-do-coordinators-make-money","text":"Coordinators set and collect the transaction fees. They can expect a revenue per transaction and each coordinator will select to forge the more profitable transactions from the transaction pool. They profit from these fees minus the operational costs and the bid price for the slot.","title":"How do Coordinators make money?"},{"location":"Hermez_1.0/faq/coordinators/#running-a-coordinator","text":"","title":"Running a Coordinator"},{"location":"Hermez_1.0/faq/coordinators/#what-are-the-infrastructure-requirements-to-run-a-coordinator","text":"To run a Coordinator you need the following: - PostgreSQL database - Ethereum Node - Coordinator Server running the hermez-node repository . A reasonable server spec is AWS instance c5ad.2xlarge with 8 vCPU and 16GB RAM - Proof Server running the rapidsnark repository . A server spec able to run the ~2000 transaction circuit is AWS instance c5ad.24xlarge with 96 vCPU and 192GB RAM.","title":"What are the infrastructure requirements to run a Coordinator?"},{"location":"Hermez_1.0/faq/coordinators/#is-there-a-step-by-step-guide-to-configure-a-coordinator-node","text":"Yes. You can find this guide here .","title":"Is there a step by step guide to configure a Coordinator node?"},{"location":"Hermez_1.0/faq/coordinators/#how-do-you-register-as-a-coordinator","text":"You can use a JavaScript tool, cli-bidding to register your node as a Coordinator.","title":"How do you register as a Coordinator?"},{"location":"Hermez_1.0/faq/coordinators/#how-many-transactions-can-be-processed-per-batch","text":"The number of transactions per batch depends on the circuit used. Hermez accepts two different circuit sizes: 400 transactions and 2048 transactions.","title":"How many transactions can be processed per batch?"},{"location":"Hermez_1.0/faq/coordinators/#i-am-having-technical-issues-running-a-coordinator-node-who-can-i-contact-for-support","text":"We recommend to go over this FAQ first, and if you still have issues, please send an email to hello@hello@hermez.network, or send a message to our Discord . You can also find more information in the Hermez documentation page","title":"I am having technical issues running a Coordinator node. Who can I contact for support?"},{"location":"Hermez_1.0/faq/end-users/","text":"End User FAQ Overview & Getting Started What exactly is Hermez? Hermez is a Layer 2 solution to scale payments on top of Ethereum. It works by grouping transactions together to create SNARKs - succinct non-interactive arguments of knowledge. These SNARKs then get settled on the Ethereum base layer, Layer 1, as one transaction. The transactions are executed by Coordinators (our version of block producers). This means they are effectively running the network by computing the zero-knowledge proof-of-validity for the transactions made by users. The result is low-cost token transfers, with all the security of Ethereum. How do I set up my Hermez Wallet? From a desktop computer, please visit the Hermez Wallet landing page and follow the instructions for setup. Note : To withdraw funds, first select the token you want to withdraw from, and the next screen will show a Withdraw button. Transactions How long do transfers take on Hermez Network from start to finish? We expect that transaction time should be between 45 seconds and 30 minutes. There are several factors that can effect the transaction time, including; coordinator configuration, backlogged transactions and the transaction type. Deposits and Withdrawals take place on both L2 (Hermez) and L1 (Ethereum), which can cause an increase in transaction time depending on L1 volume. Who can I transact with on Hermez Network? For transfers on Hermez, both the sender and receiver must be on L2. However, the sender may transfer funds to a receiver who has not yet created an account on Hermez L2 as long as the receiver has opened the Hermez Wallet app with their Metamask account. When I send my funds to Hermez on Layer 2, how secure is it? It is as secure as it would be on the Layer 1, Ethereum blockchain. Hermez has completed two security audits before launching the mainnet to ensure network security. For more information on Hermez security please visit, https://docs.hermez.io/#/about/security I'm getting an error message when I try to finalise my withdrawal, what's going on? The most common reason for this error message is that there are not enough funds in your Ethereum L1 account to complete the withdrawal. Withdrawals take place first on the Hermez L2, where the fee is paid in the same token as the transaction. Next, it needs to move back to L1 which requires \"gas\" to cover the L1 transaction fee (this amount is determined by current prices on Ethereum Network. Hermez has no control over this fee). If your L1 Ethereum account does not have enough funds to cover the gas charge, then the withdrawal cannot be completed and will produce the error message. To remedy this, please make sure you have enough funds in your L1 Ethereum account to cover the gas to complete the withdrawal. My withdrawal is stuck in the last step The last step of the withdrawal transfers the funds from the smart contract to the user's account. If the gas price suddenly increases, the recommended gas price from Metamask will be too low and the transaction will be stuck in Ethereum transaction pool. You can go to Metamask and speed up the transaction by setting a higher gas price. Why is my Deposit taking so long to process? Deposits move funds from Ethereum L1 to L2 (Hermez) and must be forged by the Coordinator. Depending on where the Coordinator is in the forging process, deposits may be as fast as 45 seconds or could take up to 15 minutes maximum. Can I use my Ledger/Trezor hardware with my Hermez Wallet? Currently, hardware wallets are not supported on Hermez but should be supported in the near future. Can Coordinators take my money? In short, no. Coordinators are the Hermez batch producer, they are responsible for running the network. In exchange for their work, they collect all transaction fees in the batch. Can coordinators censor transactions? Coordinators can decide which transactions they select to include in the batch to forge. In the case that a Coordinator censures a transaction, users have the option to force Coordinators to include their transaction. Fees and Tokens What is the HEZ token? HEZ is an ERC-20 utility token used to place bids in the Coordinator auction. Who makes money from the transaction fees? Transaction fees are collected by the Coordinator who placed the highest bid in the Coordinator auction. How much will transactions cost on Hermez? Fees are used to pay for the infrastructure required to maintain the Hermez Coordinator plus the L1 costs involved in forging a new batch of transactions. The cost of the transaction will be split among the hundreds (or even thousands) of transactions in the batch, resulting in a lower cost compared to L1. How are transaction fees paid by users? Transaction fees are paid in the same token of the transaction. How much will a new Hermez account cost? Creating a new Hermez account involves an L1 transaction or an L2 transaction. L1 transactions need to pay for gas, and L2 transactions need to pay the Coordinator fees. Which tokens can I use on Hermez Network? For the current list of tokens registered in Hermez Network please visit: https://explorer.hermez.io/tokens Why is the gas fee so high? I thought Hermez was supposed to lower the cost of transactions. The \"gas\" fee is charged to move funds from L2 back to Ethereum mainnet (L1). It is determined by current prices on the Ethereum Network and Hermez has no control over this fee. Do I need HEZ tokens to use the Hermez Network? There's no need for HEZ tokens on the user side to send transactions as fees are paid in the same token of the transaction. For a list of the current tokens registered in Hermez please visit: https://explorer.hermez.io/tokens Troubleshooting Where can I submit a bug report or contact Hermez for additional help? First, look over these FAQs to see if your question has been properly addressed already. In addition, you can always report bugs to hello@hermez.network or contact us in Discord . Another source of information is the Hermez documentation page","title":"End-Users"},{"location":"Hermez_1.0/faq/end-users/#end-user-faq","text":"","title":"End User FAQ"},{"location":"Hermez_1.0/faq/end-users/#overview-getting-started","text":"","title":"Overview &amp; Getting Started"},{"location":"Hermez_1.0/faq/end-users/#what-exactly-is-hermez","text":"Hermez is a Layer 2 solution to scale payments on top of Ethereum. It works by grouping transactions together to create SNARKs - succinct non-interactive arguments of knowledge. These SNARKs then get settled on the Ethereum base layer, Layer 1, as one transaction. The transactions are executed by Coordinators (our version of block producers). This means they are effectively running the network by computing the zero-knowledge proof-of-validity for the transactions made by users. The result is low-cost token transfers, with all the security of Ethereum.","title":"What exactly is Hermez?"},{"location":"Hermez_1.0/faq/end-users/#how-do-i-set-up-my-hermez-wallet","text":"From a desktop computer, please visit the Hermez Wallet landing page and follow the instructions for setup. Note : To withdraw funds, first select the token you want to withdraw from, and the next screen will show a Withdraw button.","title":"How do I set up my Hermez Wallet?"},{"location":"Hermez_1.0/faq/end-users/#transactions","text":"","title":"Transactions"},{"location":"Hermez_1.0/faq/end-users/#how-long-do-transfers-take-on-hermez-network-from-start-to-finish","text":"We expect that transaction time should be between 45 seconds and 30 minutes. There are several factors that can effect the transaction time, including; coordinator configuration, backlogged transactions and the transaction type. Deposits and Withdrawals take place on both L2 (Hermez) and L1 (Ethereum), which can cause an increase in transaction time depending on L1 volume.","title":"How long do transfers take on Hermez Network from start to finish?"},{"location":"Hermez_1.0/faq/end-users/#who-can-i-transact-with-on-hermez-network","text":"For transfers on Hermez, both the sender and receiver must be on L2. However, the sender may transfer funds to a receiver who has not yet created an account on Hermez L2 as long as the receiver has opened the Hermez Wallet app with their Metamask account.","title":"Who can I transact with on Hermez Network?"},{"location":"Hermez_1.0/faq/end-users/#when-i-send-my-funds-to-hermez-on-layer-2-how-secure-is-it","text":"It is as secure as it would be on the Layer 1, Ethereum blockchain. Hermez has completed two security audits before launching the mainnet to ensure network security. For more information on Hermez security please visit, https://docs.hermez.io/#/about/security","title":"When I send my funds to Hermez on Layer 2, how secure is it?"},{"location":"Hermez_1.0/faq/end-users/#im-getting-an-error-message-when-i-try-to-finalise-my-withdrawal-whats-going-on","text":"The most common reason for this error message is that there are not enough funds in your Ethereum L1 account to complete the withdrawal. Withdrawals take place first on the Hermez L2, where the fee is paid in the same token as the transaction. Next, it needs to move back to L1 which requires \"gas\" to cover the L1 transaction fee (this amount is determined by current prices on Ethereum Network. Hermez has no control over this fee). If your L1 Ethereum account does not have enough funds to cover the gas charge, then the withdrawal cannot be completed and will produce the error message. To remedy this, please make sure you have enough funds in your L1 Ethereum account to cover the gas to complete the withdrawal.","title":"I'm getting an error message when I try to finalise my withdrawal, what's going on?"},{"location":"Hermez_1.0/faq/end-users/#my-withdrawal-is-stuck-in-the-last-step","text":"The last step of the withdrawal transfers the funds from the smart contract to the user's account. If the gas price suddenly increases, the recommended gas price from Metamask will be too low and the transaction will be stuck in Ethereum transaction pool. You can go to Metamask and speed up the transaction by setting a higher gas price.","title":"My withdrawal is stuck in the last step"},{"location":"Hermez_1.0/faq/end-users/#why-is-my-deposit-taking-so-long-to-process","text":"Deposits move funds from Ethereum L1 to L2 (Hermez) and must be forged by the Coordinator. Depending on where the Coordinator is in the forging process, deposits may be as fast as 45 seconds or could take up to 15 minutes maximum.","title":"Why is my Deposit taking so long to process?"},{"location":"Hermez_1.0/faq/end-users/#can-i-use-my-ledgertrezor-hardware-with-my-hermez-wallet","text":"Currently, hardware wallets are not supported on Hermez but should be supported in the near future.","title":"Can I use my Ledger/Trezor hardware with my Hermez Wallet?"},{"location":"Hermez_1.0/faq/end-users/#can-coordinators-take-my-money","text":"In short, no. Coordinators are the Hermez batch producer, they are responsible for running the network. In exchange for their work, they collect all transaction fees in the batch.","title":"Can Coordinators take my money?"},{"location":"Hermez_1.0/faq/end-users/#can-coordinators-censor-transactions","text":"Coordinators can decide which transactions they select to include in the batch to forge. In the case that a Coordinator censures a transaction, users have the option to force Coordinators to include their transaction.","title":"Can coordinators censor transactions?"},{"location":"Hermez_1.0/faq/end-users/#fees-and-tokens","text":"","title":"Fees and Tokens"},{"location":"Hermez_1.0/faq/end-users/#what-is-the-hez-token","text":"HEZ is an ERC-20 utility token used to place bids in the Coordinator auction.","title":"What is the HEZ token?"},{"location":"Hermez_1.0/faq/end-users/#who-makes-money-from-the-transaction-fees","text":"Transaction fees are collected by the Coordinator who placed the highest bid in the Coordinator auction.","title":"Who makes money from the transaction fees?"},{"location":"Hermez_1.0/faq/end-users/#how-much-will-transactions-cost-on-hermez","text":"Fees are used to pay for the infrastructure required to maintain the Hermez Coordinator plus the L1 costs involved in forging a new batch of transactions. The cost of the transaction will be split among the hundreds (or even thousands) of transactions in the batch, resulting in a lower cost compared to L1.","title":"How much will transactions cost on Hermez?"},{"location":"Hermez_1.0/faq/end-users/#how-are-transaction-fees-paid-by-users","text":"Transaction fees are paid in the same token of the transaction.","title":"How are transaction fees paid by users?"},{"location":"Hermez_1.0/faq/end-users/#how-much-will-a-new-hermez-account-cost","text":"Creating a new Hermez account involves an L1 transaction or an L2 transaction. L1 transactions need to pay for gas, and L2 transactions need to pay the Coordinator fees.","title":"How much will a new Hermez account cost?"},{"location":"Hermez_1.0/faq/end-users/#which-tokens-can-i-use-on-hermez-network","text":"For the current list of tokens registered in Hermez Network please visit: https://explorer.hermez.io/tokens","title":"Which tokens can I use on Hermez Network?"},{"location":"Hermez_1.0/faq/end-users/#why-is-the-gas-fee-so-high-i-thought-hermez-was-supposed-to-lower-the-cost-of-transactions","text":"The \"gas\" fee is charged to move funds from L2 back to Ethereum mainnet (L1). It is determined by current prices on the Ethereum Network and Hermez has no control over this fee.","title":"Why is the gas fee so high? I thought Hermez was supposed to lower the cost of transactions."},{"location":"Hermez_1.0/faq/end-users/#do-i-need-hez-tokens-to-use-the-hermez-network","text":"There's no need for HEZ tokens on the user side to send transactions as fees are paid in the same token of the transaction. For a list of the current tokens registered in Hermez please visit: https://explorer.hermez.io/tokens","title":"Do I need HEZ tokens to use the Hermez Network?"},{"location":"Hermez_1.0/faq/end-users/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"Hermez_1.0/faq/end-users/#where-can-i-submit-a-bug-report-or-contact-hermez-for-additional-help","text":"First, look over these FAQs to see if your question has been properly addressed already. In addition, you can always report bugs to hello@hermez.network or contact us in Discord . Another source of information is the Hermez documentation page","title":"Where can I submit a bug report or contact Hermez for additional help?"},{"location":"Hermez_1.0/faq/integrators/","text":"Integrators This FAQ is addressed to developers integrating Hermez Network into their service, such as exchanges. Overview & Getting Started Where do I start? The first place to start is the Developer Guide that provides an introduction to Hermez and the protocol. Additionally, there are some code examples in the SDK section and in the Exchanges section that may be useful to get a deeper understanding of Hermez. Is there an SDK available? HermezJS is an open-source SDK to interact with Hermez Rollup network. It can be downloaded as an npm package , or via github . Additionally, there are some examples of how to interact with Hermez written in Golang. You can find these examples here What are the different account types in Hermez? An account in Hermez is represented by a leaf in the Merkle tree. Each account can only store one token type. There are two account types: - Normal accounts include a hezEthereum and a Baby Jubjub address. These accounts can be used to do deposits from L1, transfers within L2 and withdrawals to L1. - Internal accounts include only a Baby Jubjub address. These accounts can be only be used to do transfers within L2. Is it possible to send a transfer to a non-existing Hermez account? Yes, it is. The receiver of the transfer needs to have previously authorized the Coordinator to create the account at the moment of the transfer. This authorization is done by opening the account with the Hermez wallet. Do I need to run a Coordinator node? You don't unless you want to. However, as an integrator offering some service on top of Hermez Network, you may want to spin a Hermez node in synchronizer mode to directly access the Hermez data directly without an intermediary. How do I check the status of a transaction? Whenever you send an L2 transaction to Hermez, it will be added to a transaction-pool queue. This transaction will remain there until it has been processed or expires. The possible states of a transaction in the transaction pool include forged , forging , pending and invalid .To check the status of a transaction, you can query the API using the returned transaction id by sending a GET /transactions-pool/{transaction-id}. What happens if a transaction is not processed? Coordinators select the transactions to process according to some internal rules configured by the Coordinator. If the transaction is not processed, it will expire and be removed from the transaction pool. What is the timeout for a transaction in the transaction pool? Currently, this timeout is set to 24 hours. What are the reasons a transaction may not be processed? A valid transaction should always be processed within 15 minutes. There are several reasons why a transaction may be invalid and therefore not processed by any Coordinator; insufficient balance in the sender account, nonexistent sender account, destination account hasn't given permission to create an account, fees lower than suggested Coordinator fees,... Checking the transaction status will provide some feedback on the reason why the transaction wasn't forged. Can I cancel a transaction in the pool? Transactions cannot be cancelled once submitted. How do I set the fee when sending a transaction? Coordinators select the recommended fee depending on the different transaction types. These fees can be queried in the /state endpoint and are in USD. There are three types of fees: - existingAccount used for transfers to existing Hermez accounts - createAccount used for deposits or transfers to nonexistent normal accounts ( transferToEthAddress transaction) - creteAccountInternal used for transfers to nonexistent internal accounts ( transfertoBJJ transaction) These USD fees need to be converted to the equivalent fee in the token used for the transaction. How do I set the nonce when sending a transaction? Each Hermez transaction includes a nonce value that prevents replay attacks. The Coordinator will forge transactions with the expected nonce (that is, the nonce of the transaction to be processed needs to be one more than the nonce of the last transaction processed from the same sender account). These nonces are computed by the SDK automatically unless specifically initialized. Recommended practice is to let the SDK compute these nonces. Troubleshooting Where can I submit a bug report or contact Hermez for additional help? As always, please report bugs to hello@hermez.network. Additionally, you can always contact us in Discord . You can also find more information in the Hermez documentation page","title":"Integrators"},{"location":"Hermez_1.0/faq/integrators/#integrators","text":"This FAQ is addressed to developers integrating Hermez Network into their service, such as exchanges.","title":"Integrators"},{"location":"Hermez_1.0/faq/integrators/#overview-getting-started","text":"","title":"Overview &amp; Getting Started"},{"location":"Hermez_1.0/faq/integrators/#where-do-i-start","text":"The first place to start is the Developer Guide that provides an introduction to Hermez and the protocol. Additionally, there are some code examples in the SDK section and in the Exchanges section that may be useful to get a deeper understanding of Hermez.","title":"Where do I start?"},{"location":"Hermez_1.0/faq/integrators/#is-there-an-sdk-available","text":"HermezJS is an open-source SDK to interact with Hermez Rollup network. It can be downloaded as an npm package , or via github . Additionally, there are some examples of how to interact with Hermez written in Golang. You can find these examples here","title":"Is there an SDK available?"},{"location":"Hermez_1.0/faq/integrators/#what-are-the-different-account-types-in-hermez","text":"An account in Hermez is represented by a leaf in the Merkle tree. Each account can only store one token type. There are two account types: - Normal accounts include a hezEthereum and a Baby Jubjub address. These accounts can be used to do deposits from L1, transfers within L2 and withdrawals to L1. - Internal accounts include only a Baby Jubjub address. These accounts can be only be used to do transfers within L2.","title":"What are the different account types in Hermez?"},{"location":"Hermez_1.0/faq/integrators/#is-it-possible-to-send-a-transfer-to-a-non-existing-hermez-account","text":"Yes, it is. The receiver of the transfer needs to have previously authorized the Coordinator to create the account at the moment of the transfer. This authorization is done by opening the account with the Hermez wallet.","title":"Is it possible to send a transfer to a non-existing Hermez account?"},{"location":"Hermez_1.0/faq/integrators/#do-i-need-to-run-a-coordinator-node","text":"You don't unless you want to. However, as an integrator offering some service on top of Hermez Network, you may want to spin a Hermez node in synchronizer mode to directly access the Hermez data directly without an intermediary.","title":"Do I need to run a Coordinator node?"},{"location":"Hermez_1.0/faq/integrators/#how-do-i-check-the-status-of-a-transaction","text":"Whenever you send an L2 transaction to Hermez, it will be added to a transaction-pool queue. This transaction will remain there until it has been processed or expires. The possible states of a transaction in the transaction pool include forged , forging , pending and invalid .To check the status of a transaction, you can query the API using the returned transaction id by sending a GET /transactions-pool/{transaction-id}.","title":"How do I check the status of a transaction?"},{"location":"Hermez_1.0/faq/integrators/#what-happens-if-a-transaction-is-not-processed","text":"Coordinators select the transactions to process according to some internal rules configured by the Coordinator. If the transaction is not processed, it will expire and be removed from the transaction pool.","title":"What happens if a transaction is not processed?"},{"location":"Hermez_1.0/faq/integrators/#what-is-the-timeout-for-a-transaction-in-the-transaction-pool","text":"Currently, this timeout is set to 24 hours.","title":"What is the timeout for a transaction in the transaction pool?"},{"location":"Hermez_1.0/faq/integrators/#what-are-the-reasons-a-transaction-may-not-be-processed","text":"A valid transaction should always be processed within 15 minutes. There are several reasons why a transaction may be invalid and therefore not processed by any Coordinator; insufficient balance in the sender account, nonexistent sender account, destination account hasn't given permission to create an account, fees lower than suggested Coordinator fees,... Checking the transaction status will provide some feedback on the reason why the transaction wasn't forged.","title":"What are the reasons a transaction may not be processed?"},{"location":"Hermez_1.0/faq/integrators/#can-i-cancel-a-transaction-in-the-pool","text":"Transactions cannot be cancelled once submitted.","title":"Can I cancel a transaction in the pool?"},{"location":"Hermez_1.0/faq/integrators/#how-do-i-set-the-fee-when-sending-a-transaction","text":"Coordinators select the recommended fee depending on the different transaction types. These fees can be queried in the /state endpoint and are in USD. There are three types of fees: - existingAccount used for transfers to existing Hermez accounts - createAccount used for deposits or transfers to nonexistent normal accounts ( transferToEthAddress transaction) - creteAccountInternal used for transfers to nonexistent internal accounts ( transfertoBJJ transaction) These USD fees need to be converted to the equivalent fee in the token used for the transaction.","title":"How do I set the fee when sending a transaction?"},{"location":"Hermez_1.0/faq/integrators/#how-do-i-set-the-nonce-when-sending-a-transaction","text":"Each Hermez transaction includes a nonce value that prevents replay attacks. The Coordinator will forge transactions with the expected nonce (that is, the nonce of the transaction to be processed needs to be one more than the nonce of the last transaction processed from the same sender account). These nonces are computed by the SDK automatically unless specifically initialized. Recommended practice is to let the SDK compute these nonces.","title":"How do I set the nonce when sending a transaction?"},{"location":"Hermez_1.0/faq/integrators/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"Hermez_1.0/faq/integrators/#where-can-i-submit-a-bug-report-or-contact-hermez-for-additional-help","text":"As always, please report bugs to hello@hermez.network. Additionally, you can always contact us in Discord . You can also find more information in the Hermez documentation page","title":"Where can I submit a bug report or contact Hermez for additional help?"},{"location":"Hermez_1.0/faq/other/","text":"Other Where can I find the Smart Contracts? Smart Contracts can be downloaded from here","title":"Other"},{"location":"Hermez_1.0/faq/other/#other","text":"","title":"Other"},{"location":"Hermez_1.0/faq/other/#where-can-i-find-the-smart-contracts","text":"Smart Contracts can be downloaded from here","title":"Where can I find the Smart Contracts?"},{"location":"Hermez_1.0/faq/pod/","text":"Proof-of-donation Hermez is currently under development. Some of the details in the answers can be modified before network launch. How exactly does proof-of-donation work? We have an auction where everyone bids the amount of Hermez network tokens (HEZ) they're willing to donate in order to obtain the right to create the next block. The winning bid is the highest amount of HEZ. And this address is assigned the right to create the next block. We refer to this mechanism as proof-of-donation because 40% of this bid goes back to be reinvested in the protocols and services that run on top of Ethereum. For more on the details how it works, see this ethresearch post (though you should replace all instances of burn with donation when reading). Where are the funds from the proof-of-donation sent? They will be sent initially to the Gitcoin quadratic funding pool, but with future governance, other funding pools might be enabled as they become available.","title":"Proof of Donation"},{"location":"Hermez_1.0/faq/pod/#proof-of-donation","text":"Hermez is currently under development. Some of the details in the answers can be modified before network launch.","title":"Proof-of-donation"},{"location":"Hermez_1.0/faq/pod/#how-exactly-does-proof-of-donation-work","text":"We have an auction where everyone bids the amount of Hermez network tokens (HEZ) they're willing to donate in order to obtain the right to create the next block. The winning bid is the highest amount of HEZ. And this address is assigned the right to create the next block. We refer to this mechanism as proof-of-donation because 40% of this bid goes back to be reinvested in the protocols and services that run on top of Ethereum. For more on the details how it works, see this ethresearch post (though you should replace all instances of burn with donation when reading).","title":"How exactly does proof-of-donation work?"},{"location":"Hermez_1.0/faq/pod/#where-are-the-funds-from-the-proof-of-donation-sent","text":"They will be sent initially to the Gitcoin quadratic funding pool, but with future governance, other funding pools might be enabled as they become available.","title":"Where are the funds from the proof-of-donation sent?"},{"location":"Hermez_1.0/users/exchanges/","text":"Exchanges This example shows a possible flow of how an exchange would use Hermez. This example requires npm version 1.0.0-beta.15 or later of @hermeznetwork/hermezjs SDK. To get a complete tutorial on other functionalities, check out the SDK documentation Pre-requisites Exchange already has some Hermez accounts for each trading token ( HEZEx-ETH , HEZEx-DAI ,...). User has a Hermez account ( HEZUser-ETH ) Both exchange and user pre-existing accounts are regular Hermez accounts, consisting of an L2 account linked to an Ethereum account where funds can be withdrawn. The following is an example of code used to initialize hermezjs with Hermez testnet deployment and create both user and exchange accounts. You need to supply your own WEB3_URL (Ethereum Node URL) and two Rinkeby Ethereum Private Keys. Note that the latest smart contract addresses can always be found here const hermez = require(\"@hermeznetwork/hermezjs\"); const EXAMPLES_HERMEZ_API_URL = \"https://api.testnet.hermez.io/v1\"; const EXAMPLES_HERMEZ_ROLLUP_ADDRESS = \"0x679b11E0229959C1D3D27C9d20529E4C5DF7997c\"; const EXAMPLES_HERMEZ_WDELAYER_ADDRESS = \"0xeFD96CFBaF1B0Dd24d3882B0D6b8D95F85634724\"; // Provide your own values const EXAMPLES_WEB3_URL = \"http://----\"; const EXAMPLES_PRIVATE_KEY1 = \"0x----\"; const EXAMPLES_PRIVATE_KEY2 = \"0x----\"; async function sleep (timeout) { await new Promise(resolve => setTimeout(resolve, timeout)); } function configureEnvironment () { // Initializes Tx Pool hermez.TxPool.initializeTransactionPool() // load ethereum network provider hermez.Providers.setProvider(EXAMPLES_WEB3_URL) // set environment hermez.Environment.setEnvironment({ baseApiUrl: EXAMPLES_HERMEZ_API_URL, contractAddresses: { [hermez.Constants.ContractNames.Hermez]: EXAMPLES_HERMEZ_ROLLUP_ADDRESS, [hermez.Constants.ContractNames.WithdrawalDelayer]: EXAMPLES_HERMEZ_WDELAYER_ADDRESS } }) } async function main(){ // INITIALIZATION // initialize hermezjs and prepare two Hermez accounts with some ETH (user and exchange accounts) configureEnvironment() const exchangePrivKey = EXAMPLES_PRIVATE_KEY1; const userPrivKey = EXAMPLES_PRIVATE_KEY2; // load token to deposit information const tokenEthIndex = 0; const token = await hermez.CoordinatorAPI.getTokens(); const tokenETH = token.tokens[tokenEthIndex]; // load first account const wallet = await hermez.HermezWallet.createWalletFromEtherAccount(EXAMPLES_WEB3_URL, { type: \"WALLET\", privateKey: exchangePrivKey }); const hermezExchangeWallet = wallet.hermezWallet; const hermezExchangeEthereumAddress = wallet.hermezEthereumAddress; // load second account const wallet2 = await hermez.HermezWallet.createWalletFromEtherAccount(EXAMPLES_WEB3_URL, { type: \"WALLET\", privateKey: userPrivKey }); const hermezUserWallet = wallet2.hermezWallet; const hermezUserEthereumAddress = wallet2.hermezEthereumAddress; console.log(\"W2\", wallet2) // set amount to deposit const amountDeposit = hermez.Utils.getTokenAmountBigInt(\"0.1\", 18); const compressedDepositAmount = hermez.HermezCompressedAmount.compressAmount(amountDeposit); // perform deposit hermezExchangeAccount await hermez.Tx.deposit( compressedDepositAmount, hermezExchangeEthereumAddress, tokenETH, hermezExchangeWallet.publicKeyCompressedHex, { type: \"WALLET\", privateKey: exchangePrivKey } ); // perform deposit hermezUserAccount await hermez.Tx.deposit( compressedDepositAmount, hermezUserEthereumAddress, tokenETH, hermezUserWallet.publicKeyCompressedHex, { type: \"WALLET\", privateKey: userPrivKey } ); // WAIT until accounts are created const pollingAccountCreate = true; while (pollingAccountCreate){ const accountExchangeInfo = await hermez.CoordinatorAPI.getAccounts(hermezExchangeEthereumAddress, [tokenETH.id]); if (accountExchangeInfo.accounts.length === 0){ console.log(\"Waiting for deposits to be forged...\"); await sleep(10000); } else { console.log(\"Accounts created\", accountExchangeInfo) break; } } const infoAccountExchange = (await hermez.CoordinatorAPI.getAccounts(hermezExchangeWallet.hermezEthereumAddress, [tokenETH.id])) .accounts[0]; console.log(infoAccountExchange); } main(); Deposit to Exchange A User wants to transfer 10 ETH from his Hermez account to the exchange for the first time. To do so, the user requests to transfer some funds via some sort of front end provided by the exchange. After the request is done, the exchange provides the address of an internal Hermez account where the user can deposit his tokens. This account doesn't have an Ethereum counterpart account, and thus the creation is very inexpensive. Once the user has received the L2 account address, he can perform the transfer normally. In the meantime, the exchange is monitoring the status of this account, and once the user transfer is completed, the exchange can transfer the funds to its main account. This process is depicted in the diagram below. The creation of this user account by the exchange needs to only done once per user and token. Flow User requests to do a transfer to the exchange from his Hermez account using some front-end. Exchange creates an L2 (internal) account on behalf of the user ( L2ExUser-ETH ) and provides the address via front-end. This account is controlled by the exchange. // create rollup internal account from bjj private key const resExchangeWallet = await hermez.HermezWallet.createWalletFromBjjPvtKey(); const hermezExchangeUserWallet = resExchangeWallet.hermezWallet; // share public bjj key with the user console.log(`Transfer funds to this hermez address:\\n ${hermezExchangeUserWallet.publicKeyBase64}\\n\\n`); User does a L2 transfer from his account to the destination account using the web wallet const infoAccountUser = (await hermez.CoordinatorAPI.getAccounts(hermezUserWallet.hermezEthereumAddress, [tokenETH.id])) .accounts[0]; const state = await hermez.CoordinatorAPI.getState(); const usdTokenExchangeRate = tokenETH.USD; const fee = usdTokenExchangeRate ? state.recommendedFee.createAccountInternal / usdTokenExchangeRate : 0; // user creates transaction to deposit 10 ether into exchange account // deposit 10 ether const userDepositToExchange = hermez.Utils.getTokenAmountBigInt(\"10.0\", 18); const compressedUserDepositToExchange = hermez.HermezCompressedAmount.compressAmount(userDepositToExchange); // the following transaction would: // - create an account for the exchange in hermez network // - transfer to exchange account 0.1 eth const transferToExchange = { from: infoAccountUser.accountIndex, to: hermezExchangeUserWallet.publicKeyBase64, amount: compressedUserDepositToExchange, fee : fee }; console.log(\"transferToExchange: \", transferToExchange, fee); // send tx to hermez network await hermez.Tx.generateAndSendL2Tx(transferToExchange, hermezUserWallet, tokenETH); Exchange monitors balance of the account L2ExUser-ETH , and once transfer is complete, exchange performs transfer from L2ExUser-ETH to L2Ex-ETH for 10 ETH. const pollingExchangeAddr = true; while (pollingExchangeAddr){ const accountExchangeInfo = await hermez.CoordinatorAPI.getAccounts(hermezExchangeUserWallet.publicKeyBase64, [tokenETH.id]); if (accountExchangeInfo.accounts.length === 0){ console.log(\"Waiting for user deposit to be forged...\"); await sleep(10000); } else { console.log(\"<=== Received deposit from user ===>\"); console.log(`accountExchangeInfo:\\n ${accountExchangeInfo.accounts[0]}`); break; } } const infoAccountExchangeUser = (await hermez.CoordinatorAPI.getAccounts(hermezExchangeUserWallet.publicKeyBase64, [tokenETH.id])) .accounts[0]; // Transfer funds to main exchange account // generate L2 transaction const l2TxTransfer = { from: infoAccountExchangeUser.accountIndex, to: infoAccountExchange.accountIndex, amount: compressedUserDepositToExchange, fee: fee }; const transferResponse = await hermez.Tx.generateAndSendL2Tx(l2TxTransfer, hermezExchangeUserWallet, tokenETH).catch(console.log); console.log(\"transferResponse: \", transferResponse); Full Example const hermez = require(\"@hermeznetwork/hermezjs\"); const EXAMPLES_HERMEZ_API_URL = \"https://api.testnet.hermez.io/v1\"; const EXAMPLES_HERMEZ_ROLLUP_ADDRESS = \"0x14a3b6f3328766c7421034e14472f5c14c5ba090\"; const EXAMPLES_HERMEZ_WDELAYER_ADDRESS = \"0x6ea0abf3ef52d24427043cad3ec26aa4f2c8e8fd\"; // Provide your own values const EXAMPLES_WEB3_URL = \"http://----\"; const EXAMPLES_PRIVATE_KEY1 = \"0x----\"; const EXAMPLES_PRIVATE_KEY2 = \"0x----\"; async function sleep (timeout) { await new Promise(resolve => setTimeout(resolve, timeout)); } function configureEnvironment () { // Initializes Tx Pool hermez.TxPool.initializeTransactionPool() // load ethereum network provider hermez.Providers.setProvider(EXAMPLES_WEB3_URL) // set environment hermez.Environment.setEnvironment({ baseApiUrl: EXAMPLES_HERMEZ_API_URL, contractAddresses: { [hermez.Constants.ContractNames.Hermez]: EXAMPLES_HERMEZ_ROLLUP_ADDRESS, [hermez.Constants.ContractNames.WithdrawalDelayer]: EXAMPLES_HERMEZ_WDELAYER_ADDRESS } }) } async function main(){ // INITIALIZATION // initialize hermezjs and prepare two Hermez accounts with some ETH (user and exchange accounts) configureEnvironment() const exchangePrivKey = EXAMPLES_PRIVATE_KEY1; const userPrivKey = EXAMPLES_PRIVATE_KEY2; // load token to deposit information const tokenEthIndex = 0; const token = await hermez.CoordinatorAPI.getTokens(); const tokenETH = token.tokens[tokenEthIndex]; // load first account const wallet = await hermez.HermezWallet.createWalletFromEtherAccount(EXAMPLES_WEB3_URL, { type: \"WALLET\", privateKey: exchangePrivKey }); const hermezExchangeWallet = wallet.hermezWallet; const hermezExchangeEthereumAddress = wallet.hermezEthereumAddress; // load second account const wallet2 = await hermez.HermezWallet.createWalletFromEtherAccount(EXAMPLES_WEB3_URL, { type: \"WALLET\", privateKey: userPrivKey }); const hermezUserWallet = wallet2.hermezWallet; const hermezUserEthereumAddress = wallet2.hermezEthereumAddress; // set amount to deposit const amountDeposit = hermez.Utils.getTokenAmountBigInt(\"0.1\", 18); const compressedDepositAmount = hermez.HermezCompressedAmount.compressAmount(amountDeposit); // perform deposit hermezExchangeAccount await hermez.Tx.deposit( compressedDepositAmount, hermezExchangeEthereumAddress, tokenETH, hermezExchangeWallet.publicKeyCompressedHex, { type: \"WALLET\", privateKey: exchangePrivKey } ); // perform deposit hermezUserAccount await hermez.Tx.deposit( compressedDepositAmount, hermezUserEthereumAddress, tokenETH, hermezUserWallet.publicKeyCompressedHex, { type: \"WALLET\", privateKey: userPrivKey } ); console.log(\"Deposits\") // WAIT until accounts are created const pollingAccountCreate = true; while (pollingAccountCreate){ const accountExchangeInfo = await hermez.CoordinatorAPI.getAccounts(hermezExchangeEthereumAddress, [tokenETH.id]); if (accountExchangeInfo.accounts.length === 0){ console.log(\"Waiting for deposits to be forged...\"); await sleep(10000); } else { console.log(\"Accounts created\", accountExchangeInfo) break; } } const infoAccountExchange = (await hermez.CoordinatorAPI.getAccounts(hermezExchangeWallet.hermezEthereumAddress, [tokenETH.id])) .accounts[0]; // EXCHANGE ACTION // create rollup internal account from bjj private key const resExchangeWallet = await hermez.HermezWallet.createWalletFromBjjPvtKey(); const hermezExchangeUserWallet = resExchangeWallet.hermezWallet; // share public bjj key with the user console.log(`Transfer funds to this hermez address:\\n ${hermezExchangeUserWallet.publicKeyBase64}\\n\\n`); // USER ACTION // - the following code could be done through the web wallet provided by hermez network // - it is assumed that the user has already Ether in Hermez Network const infoAccountUser = (await hermez.CoordinatorAPI.getAccounts(hermezUserWallet.hermezEthereumAddress, [tokenETH.id])) .accounts[0]; const state = await hermez.CoordinatorAPI.getState(); const usdTokenExchangeRate = tokenETH.USD; const fee = usdTokenExchangeRate ? state.recommendedFee.createAccountInternal / usdTokenExchangeRate : 0; // user creates transaction to deposit some ether into exchange account const userDepositToExchange = hermez.Utils.getTokenAmountBigInt(\"0.0001\", 18); const compressedUserDepositToExchange = hermez.HermezCompressedAmount.compressAmount(userDepositToExchange); // the following transaction would: // - create an account for the exchange in hermez network const transferToExchange = { from: infoAccountUser.accountIndex, to: hermezExchangeUserWallet.publicKeyBase64, amount: compressedUserDepositToExchange, fee : fee }; console.log(\"transferToExchange: \", transferToExchange, fee); // send tx to hermez network await hermez.Tx.generateAndSendL2Tx(transferToExchange, hermezUserWallet, tokenETH); // EXCHANGE ACTION // polling exchange account to check deposit from user is received const pollingExchangeAddr = true; while (pollingExchangeAddr){ const accountExchangeInfo = await hermez.CoordinatorAPI.getAccounts(hermezExchangeUserWallet.publicKeyBase64, [tokenETH.id]); if (accountExchangeInfo.accounts.length === 0){ console.log(\"Waiting for user deposit to be forged...\"); await sleep(10000); } else { console.log(\"<=== Received deposit from user ===>\"); console.log(\"accountExchangeInfo:\\n\", accountExchangeInfo.accounts[0]); break; } } const infoAccountExchangeUser = (await hermez.CoordinatorAPI.getAccounts(hermezExchangeUserWallet.publicKeyBase64, [tokenETH.id])) .accounts[0]; // Transfer funds to main exchange account // generate L2 transaction const l2TxTransfer = { from: infoAccountExchangeUser.accountIndex, to: infoAccountExchange.accountIndex, amount: compressedUserDepositToExchange, fee: fee }; const transferResponse = await hermez.Tx.generateAndSendL2Tx(l2TxTransfer, hermezExchangeUserWallet, tokenETH).catch(console.log); console.log(\"transferResponse: \", transferResponse); } main();","title":"Exchanges"},{"location":"Hermez_1.0/users/exchanges/#exchanges","text":"This example shows a possible flow of how an exchange would use Hermez. This example requires npm version 1.0.0-beta.15 or later of @hermeznetwork/hermezjs SDK. To get a complete tutorial on other functionalities, check out the SDK documentation","title":"Exchanges"},{"location":"Hermez_1.0/users/exchanges/#pre-requisites","text":"Exchange already has some Hermez accounts for each trading token ( HEZEx-ETH , HEZEx-DAI ,...). User has a Hermez account ( HEZUser-ETH ) Both exchange and user pre-existing accounts are regular Hermez accounts, consisting of an L2 account linked to an Ethereum account where funds can be withdrawn. The following is an example of code used to initialize hermezjs with Hermez testnet deployment and create both user and exchange accounts. You need to supply your own WEB3_URL (Ethereum Node URL) and two Rinkeby Ethereum Private Keys. Note that the latest smart contract addresses can always be found here const hermez = require(\"@hermeznetwork/hermezjs\"); const EXAMPLES_HERMEZ_API_URL = \"https://api.testnet.hermez.io/v1\"; const EXAMPLES_HERMEZ_ROLLUP_ADDRESS = \"0x679b11E0229959C1D3D27C9d20529E4C5DF7997c\"; const EXAMPLES_HERMEZ_WDELAYER_ADDRESS = \"0xeFD96CFBaF1B0Dd24d3882B0D6b8D95F85634724\"; // Provide your own values const EXAMPLES_WEB3_URL = \"http://----\"; const EXAMPLES_PRIVATE_KEY1 = \"0x----\"; const EXAMPLES_PRIVATE_KEY2 = \"0x----\"; async function sleep (timeout) { await new Promise(resolve => setTimeout(resolve, timeout)); } function configureEnvironment () { // Initializes Tx Pool hermez.TxPool.initializeTransactionPool() // load ethereum network provider hermez.Providers.setProvider(EXAMPLES_WEB3_URL) // set environment hermez.Environment.setEnvironment({ baseApiUrl: EXAMPLES_HERMEZ_API_URL, contractAddresses: { [hermez.Constants.ContractNames.Hermez]: EXAMPLES_HERMEZ_ROLLUP_ADDRESS, [hermez.Constants.ContractNames.WithdrawalDelayer]: EXAMPLES_HERMEZ_WDELAYER_ADDRESS } }) } async function main(){ // INITIALIZATION // initialize hermezjs and prepare two Hermez accounts with some ETH (user and exchange accounts) configureEnvironment() const exchangePrivKey = EXAMPLES_PRIVATE_KEY1; const userPrivKey = EXAMPLES_PRIVATE_KEY2; // load token to deposit information const tokenEthIndex = 0; const token = await hermez.CoordinatorAPI.getTokens(); const tokenETH = token.tokens[tokenEthIndex]; // load first account const wallet = await hermez.HermezWallet.createWalletFromEtherAccount(EXAMPLES_WEB3_URL, { type: \"WALLET\", privateKey: exchangePrivKey }); const hermezExchangeWallet = wallet.hermezWallet; const hermezExchangeEthereumAddress = wallet.hermezEthereumAddress; // load second account const wallet2 = await hermez.HermezWallet.createWalletFromEtherAccount(EXAMPLES_WEB3_URL, { type: \"WALLET\", privateKey: userPrivKey }); const hermezUserWallet = wallet2.hermezWallet; const hermezUserEthereumAddress = wallet2.hermezEthereumAddress; console.log(\"W2\", wallet2) // set amount to deposit const amountDeposit = hermez.Utils.getTokenAmountBigInt(\"0.1\", 18); const compressedDepositAmount = hermez.HermezCompressedAmount.compressAmount(amountDeposit); // perform deposit hermezExchangeAccount await hermez.Tx.deposit( compressedDepositAmount, hermezExchangeEthereumAddress, tokenETH, hermezExchangeWallet.publicKeyCompressedHex, { type: \"WALLET\", privateKey: exchangePrivKey } ); // perform deposit hermezUserAccount await hermez.Tx.deposit( compressedDepositAmount, hermezUserEthereumAddress, tokenETH, hermezUserWallet.publicKeyCompressedHex, { type: \"WALLET\", privateKey: userPrivKey } ); // WAIT until accounts are created const pollingAccountCreate = true; while (pollingAccountCreate){ const accountExchangeInfo = await hermez.CoordinatorAPI.getAccounts(hermezExchangeEthereumAddress, [tokenETH.id]); if (accountExchangeInfo.accounts.length === 0){ console.log(\"Waiting for deposits to be forged...\"); await sleep(10000); } else { console.log(\"Accounts created\", accountExchangeInfo) break; } } const infoAccountExchange = (await hermez.CoordinatorAPI.getAccounts(hermezExchangeWallet.hermezEthereumAddress, [tokenETH.id])) .accounts[0]; console.log(infoAccountExchange); } main();","title":"Pre-requisites"},{"location":"Hermez_1.0/users/exchanges/#deposit-to-exchange","text":"A User wants to transfer 10 ETH from his Hermez account to the exchange for the first time. To do so, the user requests to transfer some funds via some sort of front end provided by the exchange. After the request is done, the exchange provides the address of an internal Hermez account where the user can deposit his tokens. This account doesn't have an Ethereum counterpart account, and thus the creation is very inexpensive. Once the user has received the L2 account address, he can perform the transfer normally. In the meantime, the exchange is monitoring the status of this account, and once the user transfer is completed, the exchange can transfer the funds to its main account. This process is depicted in the diagram below. The creation of this user account by the exchange needs to only done once per user and token.","title":"Deposit to Exchange"},{"location":"Hermez_1.0/users/exchanges/#flow","text":"User requests to do a transfer to the exchange from his Hermez account using some front-end. Exchange creates an L2 (internal) account on behalf of the user ( L2ExUser-ETH ) and provides the address via front-end. This account is controlled by the exchange. // create rollup internal account from bjj private key const resExchangeWallet = await hermez.HermezWallet.createWalletFromBjjPvtKey(); const hermezExchangeUserWallet = resExchangeWallet.hermezWallet; // share public bjj key with the user console.log(`Transfer funds to this hermez address:\\n ${hermezExchangeUserWallet.publicKeyBase64}\\n\\n`); User does a L2 transfer from his account to the destination account using the web wallet const infoAccountUser = (await hermez.CoordinatorAPI.getAccounts(hermezUserWallet.hermezEthereumAddress, [tokenETH.id])) .accounts[0]; const state = await hermez.CoordinatorAPI.getState(); const usdTokenExchangeRate = tokenETH.USD; const fee = usdTokenExchangeRate ? state.recommendedFee.createAccountInternal / usdTokenExchangeRate : 0; // user creates transaction to deposit 10 ether into exchange account // deposit 10 ether const userDepositToExchange = hermez.Utils.getTokenAmountBigInt(\"10.0\", 18); const compressedUserDepositToExchange = hermez.HermezCompressedAmount.compressAmount(userDepositToExchange); // the following transaction would: // - create an account for the exchange in hermez network // - transfer to exchange account 0.1 eth const transferToExchange = { from: infoAccountUser.accountIndex, to: hermezExchangeUserWallet.publicKeyBase64, amount: compressedUserDepositToExchange, fee : fee }; console.log(\"transferToExchange: \", transferToExchange, fee); // send tx to hermez network await hermez.Tx.generateAndSendL2Tx(transferToExchange, hermezUserWallet, tokenETH); Exchange monitors balance of the account L2ExUser-ETH , and once transfer is complete, exchange performs transfer from L2ExUser-ETH to L2Ex-ETH for 10 ETH. const pollingExchangeAddr = true; while (pollingExchangeAddr){ const accountExchangeInfo = await hermez.CoordinatorAPI.getAccounts(hermezExchangeUserWallet.publicKeyBase64, [tokenETH.id]); if (accountExchangeInfo.accounts.length === 0){ console.log(\"Waiting for user deposit to be forged...\"); await sleep(10000); } else { console.log(\"<=== Received deposit from user ===>\"); console.log(`accountExchangeInfo:\\n ${accountExchangeInfo.accounts[0]}`); break; } } const infoAccountExchangeUser = (await hermez.CoordinatorAPI.getAccounts(hermezExchangeUserWallet.publicKeyBase64, [tokenETH.id])) .accounts[0]; // Transfer funds to main exchange account // generate L2 transaction const l2TxTransfer = { from: infoAccountExchangeUser.accountIndex, to: infoAccountExchange.accountIndex, amount: compressedUserDepositToExchange, fee: fee }; const transferResponse = await hermez.Tx.generateAndSendL2Tx(l2TxTransfer, hermezExchangeUserWallet, tokenETH).catch(console.log); console.log(\"transferResponse: \", transferResponse);","title":"Flow"},{"location":"Hermez_1.0/users/exchanges/#full-example","text":"const hermez = require(\"@hermeznetwork/hermezjs\"); const EXAMPLES_HERMEZ_API_URL = \"https://api.testnet.hermez.io/v1\"; const EXAMPLES_HERMEZ_ROLLUP_ADDRESS = \"0x14a3b6f3328766c7421034e14472f5c14c5ba090\"; const EXAMPLES_HERMEZ_WDELAYER_ADDRESS = \"0x6ea0abf3ef52d24427043cad3ec26aa4f2c8e8fd\"; // Provide your own values const EXAMPLES_WEB3_URL = \"http://----\"; const EXAMPLES_PRIVATE_KEY1 = \"0x----\"; const EXAMPLES_PRIVATE_KEY2 = \"0x----\"; async function sleep (timeout) { await new Promise(resolve => setTimeout(resolve, timeout)); } function configureEnvironment () { // Initializes Tx Pool hermez.TxPool.initializeTransactionPool() // load ethereum network provider hermez.Providers.setProvider(EXAMPLES_WEB3_URL) // set environment hermez.Environment.setEnvironment({ baseApiUrl: EXAMPLES_HERMEZ_API_URL, contractAddresses: { [hermez.Constants.ContractNames.Hermez]: EXAMPLES_HERMEZ_ROLLUP_ADDRESS, [hermez.Constants.ContractNames.WithdrawalDelayer]: EXAMPLES_HERMEZ_WDELAYER_ADDRESS } }) } async function main(){ // INITIALIZATION // initialize hermezjs and prepare two Hermez accounts with some ETH (user and exchange accounts) configureEnvironment() const exchangePrivKey = EXAMPLES_PRIVATE_KEY1; const userPrivKey = EXAMPLES_PRIVATE_KEY2; // load token to deposit information const tokenEthIndex = 0; const token = await hermez.CoordinatorAPI.getTokens(); const tokenETH = token.tokens[tokenEthIndex]; // load first account const wallet = await hermez.HermezWallet.createWalletFromEtherAccount(EXAMPLES_WEB3_URL, { type: \"WALLET\", privateKey: exchangePrivKey }); const hermezExchangeWallet = wallet.hermezWallet; const hermezExchangeEthereumAddress = wallet.hermezEthereumAddress; // load second account const wallet2 = await hermez.HermezWallet.createWalletFromEtherAccount(EXAMPLES_WEB3_URL, { type: \"WALLET\", privateKey: userPrivKey }); const hermezUserWallet = wallet2.hermezWallet; const hermezUserEthereumAddress = wallet2.hermezEthereumAddress; // set amount to deposit const amountDeposit = hermez.Utils.getTokenAmountBigInt(\"0.1\", 18); const compressedDepositAmount = hermez.HermezCompressedAmount.compressAmount(amountDeposit); // perform deposit hermezExchangeAccount await hermez.Tx.deposit( compressedDepositAmount, hermezExchangeEthereumAddress, tokenETH, hermezExchangeWallet.publicKeyCompressedHex, { type: \"WALLET\", privateKey: exchangePrivKey } ); // perform deposit hermezUserAccount await hermez.Tx.deposit( compressedDepositAmount, hermezUserEthereumAddress, tokenETH, hermezUserWallet.publicKeyCompressedHex, { type: \"WALLET\", privateKey: userPrivKey } ); console.log(\"Deposits\") // WAIT until accounts are created const pollingAccountCreate = true; while (pollingAccountCreate){ const accountExchangeInfo = await hermez.CoordinatorAPI.getAccounts(hermezExchangeEthereumAddress, [tokenETH.id]); if (accountExchangeInfo.accounts.length === 0){ console.log(\"Waiting for deposits to be forged...\"); await sleep(10000); } else { console.log(\"Accounts created\", accountExchangeInfo) break; } } const infoAccountExchange = (await hermez.CoordinatorAPI.getAccounts(hermezExchangeWallet.hermezEthereumAddress, [tokenETH.id])) .accounts[0]; // EXCHANGE ACTION // create rollup internal account from bjj private key const resExchangeWallet = await hermez.HermezWallet.createWalletFromBjjPvtKey(); const hermezExchangeUserWallet = resExchangeWallet.hermezWallet; // share public bjj key with the user console.log(`Transfer funds to this hermez address:\\n ${hermezExchangeUserWallet.publicKeyBase64}\\n\\n`); // USER ACTION // - the following code could be done through the web wallet provided by hermez network // - it is assumed that the user has already Ether in Hermez Network const infoAccountUser = (await hermez.CoordinatorAPI.getAccounts(hermezUserWallet.hermezEthereumAddress, [tokenETH.id])) .accounts[0]; const state = await hermez.CoordinatorAPI.getState(); const usdTokenExchangeRate = tokenETH.USD; const fee = usdTokenExchangeRate ? state.recommendedFee.createAccountInternal / usdTokenExchangeRate : 0; // user creates transaction to deposit some ether into exchange account const userDepositToExchange = hermez.Utils.getTokenAmountBigInt(\"0.0001\", 18); const compressedUserDepositToExchange = hermez.HermezCompressedAmount.compressAmount(userDepositToExchange); // the following transaction would: // - create an account for the exchange in hermez network const transferToExchange = { from: infoAccountUser.accountIndex, to: hermezExchangeUserWallet.publicKeyBase64, amount: compressedUserDepositToExchange, fee : fee }; console.log(\"transferToExchange: \", transferToExchange, fee); // send tx to hermez network await hermez.Tx.generateAndSendL2Tx(transferToExchange, hermezUserWallet, tokenETH); // EXCHANGE ACTION // polling exchange account to check deposit from user is received const pollingExchangeAddr = true; while (pollingExchangeAddr){ const accountExchangeInfo = await hermez.CoordinatorAPI.getAccounts(hermezExchangeUserWallet.publicKeyBase64, [tokenETH.id]); if (accountExchangeInfo.accounts.length === 0){ console.log(\"Waiting for user deposit to be forged...\"); await sleep(10000); } else { console.log(\"<=== Received deposit from user ===>\"); console.log(\"accountExchangeInfo:\\n\", accountExchangeInfo.accounts[0]); break; } } const infoAccountExchangeUser = (await hermez.CoordinatorAPI.getAccounts(hermezExchangeUserWallet.publicKeyBase64, [tokenETH.id])) .accounts[0]; // Transfer funds to main exchange account // generate L2 transaction const l2TxTransfer = { from: infoAccountExchangeUser.accountIndex, to: infoAccountExchange.accountIndex, amount: compressedUserDepositToExchange, fee: fee }; const transferResponse = await hermez.Tx.generateAndSendL2Tx(l2TxTransfer, hermezExchangeUserWallet, tokenETH).catch(console.log); console.log(\"transferResponse: \", transferResponse); } main();","title":"Full Example"},{"location":"Hermez_1.0/users/hermez-wallet/","text":"Hermez Wallet Guide Welcome to the Hermez Wallet Hermez Wallet provides a simple user interface to get started with the Hermez Network. It supports depositing, transferring, and withdrawing ETH and ERC-20 tokens on Hermez Network. Getting Started When opening the wallet, there's a button to log in with Metamask. This will automatically derive a Hermez account from the Ethereum account. This will then lead to an empty wallet: The next step is to make a deposit Transactions There are 3 kinds of transactions: Deposits. Sends ETH or an ERC-20 token (must be registered in Hermez) from your Ethereum account to your Hermez account. Transfers. Sends ETH or an ERC-20 token from a Hermez account to another Hermez account. Withdrawals. Sends ETH or an ERC-20 token from a Hermez account to its corresponding Ethereum account. They all follow a similar flow. First, we select a token. If it's a Deposit , the token must be in the Ethereum account. Otherwise, it must be in the Hermez account. Then there's a form to select the amount: In the case of a Transfer , there will also be a receiver input. This input also supports scanning a QR code or pasting the Receiver's address directly. If everything is valid, the next step is the confirmation with a look at all of the transaction parameters. With a Deposit , as it is a Layer 1 transaction, it will require signing with your Ethereum Wallet (e.g. Metamask). This leads to the confirmation screen if everything went well: Accounts Making Deposits creates accounts that now appear on the home screen. Opening an account shows all the transactions related to that account. Opening a transaction shows information related to that transaction. There's also a button to open the Batch Explorer with all the information. Withdrawals Withdrawals are a two-part process. The first part requires you to select the Token account you want to withdraw from (for example HEZ) and on the next screen click on the Withdraw button, enter the amount to withdraw, and click on Continue . After completing the first part explained above, a card with the withdrawal details appears on the Home screen or on the respective account page. When ready, it will show a button to finalize the withdrawal. *Withdrawals require paying an Ether gas fee on L1, insufficient gas in your L1 account will cause the withdrawal to stall. *Withdrawals are final and cannot be stopped, reversed, or altered in any way after initiated. Alternatively, you can transfer your funds to a different account in Hermez and perform the withdrawal from that account. This may be helpful in situations where you don't have enough Ether in the original L1 account but do in a different account. My Account There's a My Account page. Current options are: Copying your Hermez Address or displaying it as a QR code. Changing the default FIAT currency between EUR and USD. Making a Force Withdrawal . This is a L1 equivalent of the first step of the withdrawal as explained above. This uses more Gas but forces the Coordinator to pick the transaction up. It's only a security measure and shouldn't be needed. View the Hermez account in the Batch Explorer. Logging out.","title":"Polygon Hermez Wallet"},{"location":"Hermez_1.0/users/hermez-wallet/#hermez-wallet-guide","text":"","title":"Hermez Wallet Guide"},{"location":"Hermez_1.0/users/hermez-wallet/#welcome-to-the-hermez-wallet","text":"Hermez Wallet provides a simple user interface to get started with the Hermez Network. It supports depositing, transferring, and withdrawing ETH and ERC-20 tokens on Hermez Network.","title":"Welcome to the Hermez Wallet"},{"location":"Hermez_1.0/users/hermez-wallet/#getting-started","text":"When opening the wallet, there's a button to log in with Metamask. This will automatically derive a Hermez account from the Ethereum account. This will then lead to an empty wallet: The next step is to make a deposit","title":"Getting Started"},{"location":"Hermez_1.0/users/hermez-wallet/#transactions","text":"There are 3 kinds of transactions: Deposits. Sends ETH or an ERC-20 token (must be registered in Hermez) from your Ethereum account to your Hermez account. Transfers. Sends ETH or an ERC-20 token from a Hermez account to another Hermez account. Withdrawals. Sends ETH or an ERC-20 token from a Hermez account to its corresponding Ethereum account. They all follow a similar flow. First, we select a token. If it's a Deposit , the token must be in the Ethereum account. Otherwise, it must be in the Hermez account. Then there's a form to select the amount: In the case of a Transfer , there will also be a receiver input. This input also supports scanning a QR code or pasting the Receiver's address directly. If everything is valid, the next step is the confirmation with a look at all of the transaction parameters. With a Deposit , as it is a Layer 1 transaction, it will require signing with your Ethereum Wallet (e.g. Metamask). This leads to the confirmation screen if everything went well:","title":"Transactions"},{"location":"Hermez_1.0/users/hermez-wallet/#accounts","text":"Making Deposits creates accounts that now appear on the home screen. Opening an account shows all the transactions related to that account. Opening a transaction shows information related to that transaction. There's also a button to open the Batch Explorer with all the information.","title":"Accounts"},{"location":"Hermez_1.0/users/hermez-wallet/#withdrawals","text":"Withdrawals are a two-part process. The first part requires you to select the Token account you want to withdraw from (for example HEZ) and on the next screen click on the Withdraw button, enter the amount to withdraw, and click on Continue . After completing the first part explained above, a card with the withdrawal details appears on the Home screen or on the respective account page. When ready, it will show a button to finalize the withdrawal. *Withdrawals require paying an Ether gas fee on L1, insufficient gas in your L1 account will cause the withdrawal to stall. *Withdrawals are final and cannot be stopped, reversed, or altered in any way after initiated. Alternatively, you can transfer your funds to a different account in Hermez and perform the withdrawal from that account. This may be helpful in situations where you don't have enough Ether in the original L1 account but do in a different account.","title":"Withdrawals"},{"location":"Hermez_1.0/users/hermez-wallet/#my-account","text":"There's a My Account page. Current options are: Copying your Hermez Address or displaying it as a QR code. Changing the default FIAT currency between EUR and USD. Making a Force Withdrawal . This is a L1 equivalent of the first step of the withdrawal as explained above. This uses more Gas but forces the Coordinator to pick the transaction up. It's only a security measure and shouldn't be needed. View the Hermez account in the Batch Explorer. Logging out.","title":"My Account"},{"location":"Hermez_1.0/users/mainnet/","text":"Hermez Mainnet Hermez is now live on Ethereum. Tools Web wallet to interact with Hermez ZK-Rollup user accounts Hermez L2 batch explorer Hermez SDK Hermez API Useful Links To interact with the Hermez, you'll need a Metamask wallet. Contract Addresses Hermez uses 4 main smart contracts: - HermezAuctionProtocol: 0x15468b45ed46c8383f5c0b1b6cf2ecf403c2aec2 - HermezAddress: 0xa68d85df56e733a06443306a095646317b5fa633 - HermezWithdrawalDelayerAddress: 0x392361427ef5e17b69cfdd1294f31ab555c86124 - HEZTokenAddress: 0xeef9f339514298c6a857efcfc1a762af84438dee To get the latest smart contracts configuration, you can consult the API","title":"Polygon Hermez Mainnet"},{"location":"Hermez_1.0/users/mainnet/#hermez-mainnet","text":"Hermez is now live on Ethereum.","title":"Hermez Mainnet"},{"location":"Hermez_1.0/users/mainnet/#tools","text":"Web wallet to interact with Hermez ZK-Rollup user accounts Hermez L2 batch explorer Hermez SDK Hermez API","title":"Tools"},{"location":"Hermez_1.0/users/mainnet/#useful-links","text":"To interact with the Hermez, you'll need a Metamask wallet.","title":"Useful Links"},{"location":"Hermez_1.0/users/mainnet/#contract-addresses","text":"Hermez uses 4 main smart contracts: - HermezAuctionProtocol: 0x15468b45ed46c8383f5c0b1b6cf2ecf403c2aec2 - HermezAddress: 0xa68d85df56e733a06443306a095646317b5fa633 - HermezWithdrawalDelayerAddress: 0x392361427ef5e17b69cfdd1294f31ab555c86124 - HEZTokenAddress: 0xeef9f339514298c6a857efcfc1a762af84438dee To get the latest smart contracts configuration, you can consult the API","title":"Contract Addresses"},{"location":"Hermez_1.0/users/testnet/","text":"Testnet Hermez testnet is now live on the Ethereum Rinkeby network. Checkout our blogpost announcing the launch of Hermez Testnet for additional information. Tools Web wallet to interact with Hermez ZK-Rollup user accounts Hermez L2 batch explorer Hermez SDK Hermez API Useful Links To interact with the Testnet, you'll need a Metamask wallet and some Rinkeby tokens. Get Rinkeby ETH using this faucet . If you want to swap some of your Rinkeby ETH for Rinkeby HEZ, you can use Rinkeby Uniswap pair . Contract Addresses Hermez uses 4 main smart contracts: - HermezAuctionProtocol: 0x0a8a6D65Ad9046c2a57a5Ca8Bab2ae9c3345316d - HermezAddress: 0x679b11E0229959C1D3D27C9d20529E4C5DF7997c - HermezWithdrawalDelayerAddress: 0xeFD96CFBaF1B0Dd24d3882B0D6b8D95F85634724 - HEZTokenAddress: 0x2521Bc90B4f5Fb9a8D61278197e5FF5cDbc4FBF2 To get the latest smart contracts configuration, you can consult the API","title":"Polygon Hermez Testnet"},{"location":"Hermez_1.0/users/testnet/#testnet","text":"Hermez testnet is now live on the Ethereum Rinkeby network. Checkout our blogpost announcing the launch of Hermez Testnet for additional information.","title":"Testnet"},{"location":"Hermez_1.0/users/testnet/#tools","text":"Web wallet to interact with Hermez ZK-Rollup user accounts Hermez L2 batch explorer Hermez SDK Hermez API","title":"Tools"},{"location":"Hermez_1.0/users/testnet/#useful-links","text":"To interact with the Testnet, you'll need a Metamask wallet and some Rinkeby tokens. Get Rinkeby ETH using this faucet . If you want to swap some of your Rinkeby ETH for Rinkeby HEZ, you can use Rinkeby Uniswap pair .","title":"Useful Links"},{"location":"Hermez_1.0/users/testnet/#contract-addresses","text":"Hermez uses 4 main smart contracts: - HermezAuctionProtocol: 0x0a8a6D65Ad9046c2a57a5Ca8Bab2ae9c3345316d - HermezAddress: 0x679b11E0229959C1D3D27C9d20529E4C5DF7997c - HermezWithdrawalDelayerAddress: 0xeFD96CFBaF1B0Dd24d3882B0D6b8D95F85634724 - HEZTokenAddress: 0x2521Bc90B4f5Fb9a8D61278197e5FF5cDbc4FBF2 To get the latest smart contracts configuration, you can consult the API","title":"Contract Addresses"},{"location":"zkEVM/references/","text":"Resources List A curated list of cryptographic protocols used in this project. Groth16 protocol The STARK paper PLONK: Permutations over Lagrange-bases for Oecumenical Noninteractive arguments of Knowledge Plookup: A simplified polynomial protocol for lookup tables","title":"References"},{"location":"zkEVM/references/#resources-list","text":"A curated list of cryptographic protocols used in this project. Groth16 protocol The STARK paper PLONK: Permutations over Lagrange-bases for Oecumenical Noninteractive arguments of Knowledge Plookup: A simplified polynomial protocol for lookup tables","title":"Resources List"},{"location":"zkEVM/Architecture/zkProver/","text":"zkProver The task of creating the execution trace is performed by a component called the executor . The executor takes as inputs the transactions of a batch, a ChainID, the root of a Merkle tree representing the previous state of the zkEVM in that chain and the root of the new state after executing the transactions. Additionally, the executor gets values of the current state of the zkEVM to build the proof. The executor is in fact an interpreter of an assembly language called zkASM. The zkASM language is used to build a program called zkEVM-ROM that when executed by the Executor provides a suitable execution trace. In the zkEVM-ROM program, each EVM opcode is implemented with a set of zkASM instructions. Each instruction utilizes a row of the execution trace matrix, also known as a \"step\" of the zkEVM. The executor is part of the zkProver , which is the core component of the Polygon zkEVM. Figure 1: Big picture of the Prover in the Polygon zkEVM.","title":"zkProver"},{"location":"zkEVM/Architecture/zkProver/#zkprover","text":"The task of creating the execution trace is performed by a component called the executor . The executor takes as inputs the transactions of a batch, a ChainID, the root of a Merkle tree representing the previous state of the zkEVM in that chain and the root of the new state after executing the transactions. Additionally, the executor gets values of the current state of the zkEVM to build the proof. The executor is in fact an interpreter of an assembly language called zkASM. The zkASM language is used to build a program called zkEVM-ROM that when executed by the Executor provides a suitable execution trace. In the zkEVM-ROM program, each EVM opcode is implemented with a set of zkASM instructions. Each instruction utilizes a row of the execution trace matrix, also known as a \"step\" of the zkEVM. The executor is part of the zkProver , which is the core component of the Polygon zkEVM. Figure 1: Big picture of the Prover in the Polygon zkEVM.","title":"zkProver"},{"location":"zkEVM/Basic-Concepts/fibonacci/","text":"Fibonacci State Machine Let's consider that we want to validate that a certain number is a number of a Fibonacci sequence given certain initial conditions. To do so, we can build a state machine with two registries, \\(A\\) and \\(B\\) as shown in the following picture: Notice that the initial conditions for the state machine are \\(A_1=0\\) and \\(B_1=1\\) and that we have the following relations between the states of these registries: \\[\\begin{aligned} A_{i+1} &= B_i, \\\\ B_{i+1} &= A_i + B_i. \\end{aligned}\\] Let's represent the states of these registries as polynomials in \\(\\mathbb{Z}_p[x]\\) evaluated on the subgroup \\(H = \\{\\omega, \\omega^2, \\omega^3, \\omega^4, \\omega^5, \\omega^6, \\omega^7, \\omega^8 = 1\\}\\) of \\(8\\) -roots of unity in \\(\\mathbb{Z}_p^*\\) . Then, we have the following relations: \\[\\begin{aligned} A(\\omega^i) &= A_i \\quad \\Longrightarrow \\quad A = [0, 1, 1, 2, 3, 5, 8, 13] \\\\ B(\\omega^i) &= B_i \\quad \\Longrightarrow \\quad B = [1, 1, 2, 3, 5, 8, 13, 21] \\end{aligned}\\] The relations between the states of registries can be translated into identities in the polynomial setting as follows: \\[\\begin{aligned} A(x\\omega) &= \\bigg\\lvert_H B(x), \\\\ B(x\\omega) &= \\bigg\\lvert_H A(x) + B(x). \\end{aligned}\\] However, the previous identities do not correctly and uniquely describe our sequence because: The registries are not cyclic: When we evaluate the identities at \\(\\omega^8\\) : \\[\\begin{aligned} A(\\omega^9) &= A(\\omega) = 0 \\neq 21 = B(\\omega^8), \\\\ B(\\omega^9) &= B(\\omega) = 1 \\neq 34 = A(\\omega^8) + B(\\omega^8). \\end{aligned}\\] We can use other initial conditions, for example \\((2,4)\\) , that also fulfill the identities: \\((2,4)\\to(4,6)\\to(6,10)\\to(10,16)\\to(16,26)\\to(26,42)\\to(42,68)\\to(68,110).\\) We have to modify a little our solution in order correctly and uniquely describe the Fibonacci sequence with cyclic polynomial identities. To do that, let's add an auxiliary registry \\(C\\) : The corresponding polynomial \\(C\\) is: \\[\\begin{aligned} C(\\omega^i) &= C_i \\quad \\Longrightarrow \\quad C = [1, 0, 0, 0, 0, 0, 0, 0]. \\end{aligned}\\] With this auxiliary registry, we can now fix the polynomial identities as follows: \\[\\begin{aligned} A(x\\omega) &= \\bigg\\lvert_H B(x)(1 - C(x\\omega)), \\\\ B(x\\omega) &= \\bigg\\lvert_H (A(x) + B(x))(1 - C(x\\omega)) + C(x\\omega). \\end{aligned}\\] Note that now at \\(x = \\omega^8\\) the identities are satisfied: \\[\\begin{aligned} A(\\omega^9) &= A(\\omega) = 0 = B(\\omega^8)(1 - C(\\omega)), \\\\ B(\\omega^9) &= B(\\omega) = 1 = (A(\\omega^8) + B(\\omega^8))(1 - C(\\omega)) + C(\\omega). \\end{aligned}\\] Observe that we can also use other initial conditions \\((A_1, B_1)\\) slightly modifying our polynomial identities: \\[\\begin{aligned} A(x\\omega) &= \\bigg\\lvert_H B(x)(1 - C(x\\omega))+ A_1C(x\\omega), \\\\ B(x\\omega) &= \\bigg\\lvert_H (A(x) + B(x))(1 - C(x\\omega)) + B_1 C(x\\omega). \\end{aligned}\\] In our previous example \\((A_1, B_1) = (0, 1)\\) . Proving our State Machine (High Level) The previous polynomial relations can be efficiently proven through polynomial commitments such as Kate and FRI-based . Commitment schemes are binding and hiding: Binding : The prover can not change the polynomial she committed to. Hiding : The verifier can not deduce which is the committed polynomial by only looking at the commitment.","title":"First Example: Fibonacci"},{"location":"zkEVM/Basic-Concepts/fibonacci/#fibonacci-state-machine","text":"Let's consider that we want to validate that a certain number is a number of a Fibonacci sequence given certain initial conditions. To do so, we can build a state machine with two registries, \\(A\\) and \\(B\\) as shown in the following picture: Notice that the initial conditions for the state machine are \\(A_1=0\\) and \\(B_1=1\\) and that we have the following relations between the states of these registries: \\[\\begin{aligned} A_{i+1} &= B_i, \\\\ B_{i+1} &= A_i + B_i. \\end{aligned}\\] Let's represent the states of these registries as polynomials in \\(\\mathbb{Z}_p[x]\\) evaluated on the subgroup \\(H = \\{\\omega, \\omega^2, \\omega^3, \\omega^4, \\omega^5, \\omega^6, \\omega^7, \\omega^8 = 1\\}\\) of \\(8\\) -roots of unity in \\(\\mathbb{Z}_p^*\\) . Then, we have the following relations: \\[\\begin{aligned} A(\\omega^i) &= A_i \\quad \\Longrightarrow \\quad A = [0, 1, 1, 2, 3, 5, 8, 13] \\\\ B(\\omega^i) &= B_i \\quad \\Longrightarrow \\quad B = [1, 1, 2, 3, 5, 8, 13, 21] \\end{aligned}\\] The relations between the states of registries can be translated into identities in the polynomial setting as follows: \\[\\begin{aligned} A(x\\omega) &= \\bigg\\lvert_H B(x), \\\\ B(x\\omega) &= \\bigg\\lvert_H A(x) + B(x). \\end{aligned}\\] However, the previous identities do not correctly and uniquely describe our sequence because: The registries are not cyclic: When we evaluate the identities at \\(\\omega^8\\) : \\[\\begin{aligned} A(\\omega^9) &= A(\\omega) = 0 \\neq 21 = B(\\omega^8), \\\\ B(\\omega^9) &= B(\\omega) = 1 \\neq 34 = A(\\omega^8) + B(\\omega^8). \\end{aligned}\\] We can use other initial conditions, for example \\((2,4)\\) , that also fulfill the identities: \\((2,4)\\to(4,6)\\to(6,10)\\to(10,16)\\to(16,26)\\to(26,42)\\to(42,68)\\to(68,110).\\) We have to modify a little our solution in order correctly and uniquely describe the Fibonacci sequence with cyclic polynomial identities. To do that, let's add an auxiliary registry \\(C\\) : The corresponding polynomial \\(C\\) is: \\[\\begin{aligned} C(\\omega^i) &= C_i \\quad \\Longrightarrow \\quad C = [1, 0, 0, 0, 0, 0, 0, 0]. \\end{aligned}\\] With this auxiliary registry, we can now fix the polynomial identities as follows: \\[\\begin{aligned} A(x\\omega) &= \\bigg\\lvert_H B(x)(1 - C(x\\omega)), \\\\ B(x\\omega) &= \\bigg\\lvert_H (A(x) + B(x))(1 - C(x\\omega)) + C(x\\omega). \\end{aligned}\\] Note that now at \\(x = \\omega^8\\) the identities are satisfied: \\[\\begin{aligned} A(\\omega^9) &= A(\\omega) = 0 = B(\\omega^8)(1 - C(\\omega)), \\\\ B(\\omega^9) &= B(\\omega) = 1 = (A(\\omega^8) + B(\\omega^8))(1 - C(\\omega)) + C(\\omega). \\end{aligned}\\] Observe that we can also use other initial conditions \\((A_1, B_1)\\) slightly modifying our polynomial identities: \\[\\begin{aligned} A(x\\omega) &= \\bigg\\lvert_H B(x)(1 - C(x\\omega))+ A_1C(x\\omega), \\\\ B(x\\omega) &= \\bigg\\lvert_H (A(x) + B(x))(1 - C(x\\omega)) + B_1 C(x\\omega). \\end{aligned}\\] In our previous example \\((A_1, B_1) = (0, 1)\\) .","title":"Fibonacci State Machine"},{"location":"zkEVM/Basic-Concepts/fibonacci/#proving-our-state-machine-high-level","text":"The previous polynomial relations can be efficiently proven through polynomial commitments such as Kate and FRI-based . Commitment schemes are binding and hiding: Binding : The prover can not change the polynomial she committed to. Hiding : The verifier can not deduce which is the committed polynomial by only looking at the commitment.","title":"Proving our State Machine (High Level)"},{"location":"zkEVM/Basic-Concepts/introduction/","text":"We must stress that this documentation is still a Work In Progress (WIP). In particular, some aspects are more covered than others, some components still miss an explanation, some sections are going to be greatly extended and, some other sections might be reorganized. Concept Polygon zkEVM is an execution layer 2 that can process a batch of EVM transactions and generate a zero knowledge proof that efficiently proves the correctness of the execution. The decision of proving EVM transactions instead of creating a virtual machine with simpler transactions is for minimizing the friction of current Ethereum users and dApps when using the solution. It is an approach that requires the recreation of all the EVM opcodes, which allows the transparent deployment of any existing Ethereum smart contract. For this purpose, a new set of technologies and tools have been engineered and developed and, they are briefly presented below. EVM Arithmetization The first step to prove the execution correctness of an EVM transaction is to build a suitable execution trace. By a suitable execution trace, we mean a set of values that fulfill the constraints imposed by the EVM processing. The trace is expressed as a matrix, where each column has a name. Each column is interpolated into a polynomial and the correctness of the execution is finally reduced to verifying a set of identities between polynomials (columns). The process of designing the proper set of columns and identities is called arithmetization. The Polygon zkEVM provides an efficient arithmetization of the EVM. Executor, zkASM and zkProver The task of creating the execution trace is performed by a component called the executor . The executor takes as inputs the transactions of a batch, a ChainID, the root of a Merkle tree representing the previous state of the zkEVM in that chain and the root of the new state after executing the transactions. Additionally, the executor gets values of the current state of the zkEVM to build the proof. The executor is in fact an interpreter of an assembly language called zkASM. The zkASM language is used to build a program called zkEVM-ROM that when executed by the Executor provides a suitable execution trace. In the zkEVM-ROM program, each EVM opcode is implemented with a set of zkASM instructions. Each instruction utilizes a row of the execution trace matrix, also known as a \"step\" of the zkEVM. The executor is part of the zkProver , which is the core component of the Polygon zkEVM. The following figure shows, at a high level, the interaction of the zkProver with the other components of the solution, which are the Node and the Database (DB): The Node sends the content of the Ethereum state and the EVM Merkle trees to the DB, to be stored there. The Node sends the input batch of transactions to the zkProver. The zkProver accesses the DB, fetching the information it needs to produce verifiable proofs of the transaction batch sent by the Node. The zkProver generates the proofs of transactions, and sends these proofs back to the Node. Polynomial Identity Language (PIL) The Polynomial Identity Language (PIL) is a novel domain-specific language for defining the constraints of the execution trace of state machines. It is used to define the name of the polynomials of the execution trace and, to describe the identities or relationships that these polynomials must fulfill to consider an execution as correct. Modular Design The amount of columns and identities can grow beyond thousands for the execution trace of complex state machines like the EVM. Managing such a huge matrix makes its design complex and hard to handle. To simplify this, the Polygon zkEVM uses a divide and conquer technique in which the execution trace is split in smaller matrices. Then, using a proving technique called plookup, it is possible to relate rows in one matrix with rows in another matrix. In particular, we use inclusion and permutation. Inclusion checks that the rows in a matrix are included in another matrix. Permutation checks that the rows of a matrix are the same rows of another matrix but in a different order. The PIL language allows to name the columns of each matrix in which the execution trace is divided (using the keyword \\(\\mathtt{namespace}\\) ) and, it also allows the definition of inclusions (using the keyword \\(\\mathtt{in}\\) ) and permutations (using the keyword \\(\\mathtt{is}\\) ). In the Polygon zkEVM, the execution trace is divided into a main matrix also called the main state machine and secondary matrices also called secondary state machines . Further Reading In the subsections following, simple examples of arithmetization are shown and, the assembly and PIL languages are introduced. In posterior sections, the assembly, the PIL, and the secondary state machines are described in more detail.","title":"Introduction"},{"location":"zkEVM/Basic-Concepts/introduction/#concept","text":"Polygon zkEVM is an execution layer 2 that can process a batch of EVM transactions and generate a zero knowledge proof that efficiently proves the correctness of the execution. The decision of proving EVM transactions instead of creating a virtual machine with simpler transactions is for minimizing the friction of current Ethereum users and dApps when using the solution. It is an approach that requires the recreation of all the EVM opcodes, which allows the transparent deployment of any existing Ethereum smart contract. For this purpose, a new set of technologies and tools have been engineered and developed and, they are briefly presented below.","title":"Concept"},{"location":"zkEVM/Basic-Concepts/introduction/#evm-arithmetization","text":"The first step to prove the execution correctness of an EVM transaction is to build a suitable execution trace. By a suitable execution trace, we mean a set of values that fulfill the constraints imposed by the EVM processing. The trace is expressed as a matrix, where each column has a name. Each column is interpolated into a polynomial and the correctness of the execution is finally reduced to verifying a set of identities between polynomials (columns). The process of designing the proper set of columns and identities is called arithmetization. The Polygon zkEVM provides an efficient arithmetization of the EVM.","title":"EVM Arithmetization"},{"location":"zkEVM/Basic-Concepts/introduction/#executor-zkasm-and-zkprover","text":"The task of creating the execution trace is performed by a component called the executor . The executor takes as inputs the transactions of a batch, a ChainID, the root of a Merkle tree representing the previous state of the zkEVM in that chain and the root of the new state after executing the transactions. Additionally, the executor gets values of the current state of the zkEVM to build the proof. The executor is in fact an interpreter of an assembly language called zkASM. The zkASM language is used to build a program called zkEVM-ROM that when executed by the Executor provides a suitable execution trace. In the zkEVM-ROM program, each EVM opcode is implemented with a set of zkASM instructions. Each instruction utilizes a row of the execution trace matrix, also known as a \"step\" of the zkEVM. The executor is part of the zkProver , which is the core component of the Polygon zkEVM. The following figure shows, at a high level, the interaction of the zkProver with the other components of the solution, which are the Node and the Database (DB): The Node sends the content of the Ethereum state and the EVM Merkle trees to the DB, to be stored there. The Node sends the input batch of transactions to the zkProver. The zkProver accesses the DB, fetching the information it needs to produce verifiable proofs of the transaction batch sent by the Node. The zkProver generates the proofs of transactions, and sends these proofs back to the Node.","title":"Executor, zkASM and zkProver"},{"location":"zkEVM/Basic-Concepts/introduction/#polynomial-identity-language-pil","text":"The Polynomial Identity Language (PIL) is a novel domain-specific language for defining the constraints of the execution trace of state machines. It is used to define the name of the polynomials of the execution trace and, to describe the identities or relationships that these polynomials must fulfill to consider an execution as correct.","title":"Polynomial Identity Language (PIL)"},{"location":"zkEVM/Basic-Concepts/introduction/#modular-design","text":"The amount of columns and identities can grow beyond thousands for the execution trace of complex state machines like the EVM. Managing such a huge matrix makes its design complex and hard to handle. To simplify this, the Polygon zkEVM uses a divide and conquer technique in which the execution trace is split in smaller matrices. Then, using a proving technique called plookup, it is possible to relate rows in one matrix with rows in another matrix. In particular, we use inclusion and permutation. Inclusion checks that the rows in a matrix are included in another matrix. Permutation checks that the rows of a matrix are the same rows of another matrix but in a different order. The PIL language allows to name the columns of each matrix in which the execution trace is divided (using the keyword \\(\\mathtt{namespace}\\) ) and, it also allows the definition of inclusions (using the keyword \\(\\mathtt{in}\\) ) and permutations (using the keyword \\(\\mathtt{is}\\) ). In the Polygon zkEVM, the execution trace is divided into a main matrix also called the main state machine and secondary matrices also called secondary state machines .","title":"Modular Design"},{"location":"zkEVM/Basic-Concepts/introduction/#further-reading","text":"In the subsections following, simple examples of arithmetization are shown and, the assembly and PIL languages are introduced. In posterior sections, the assembly, the PIL, and the secondary state machines are described in more detail.","title":"Further Reading"},{"location":"zkEVM/Basic-Concepts/modular-design/","text":"Divide and Conquer We want now to extend the previous idea to a more complex machine that can handle, for example, multiplications. We could keep adding columns to our state machine to express such operations but that would make the design complex and hard to handle. Instead, we are going to use a divide and conquer technique: Our zk-EVM architecture comprises different connected state machines. Each state machine is devoted to proving the execution of a specific task. Then, relevant columns (polynomials) of these different state machines are related using inclusion proofs (with plookup). To illustrate this important process: Let's design a state machine to manage arithmetic operations with elements of 32 bits. Then, let's connect this state machine to our main state machine with an inclusion proof. Arithmetic State Machine The arithmetic state machine will check sums, subtractions, multiplications and divisions with elements of 32 bits. For this, we use the following constraint with five registries: $$ \\mathcal{A}_i \\cdot \\mathcal{B}_i + \\mathcal{C}_i = 2^{32} \\mathcal{D}_i + \\mathcal{E}_i. $$ Notice that the multiplication between \\(\\mathcal{A}_i\\) and \\(\\mathcal{B}_i\\) , which are elements of 32 bits, can be expressed with \\(\\mathcal{E}_i\\) and \\(\\mathcal{D}_i\\) where these are also elements of 32 bits. The \\(\\mathcal{D_i}\\) term carries the exceeding part of the multiplication. As before, we will express the previous relation as a cyclic polynomial identity at some subgroup \\(H\\) of roots of unity of \\(\\mathbb{Z}_{p}\\) : \\[ \\mathcal{A}(x) \\cdot \\mathcal{B}(x) + \\mathcal{C}(x) = 2^{32} \\mathcal{D}(x) + \\mathcal{E}(x). \\] Notice also that we have to enforce that all the images of \\(\\mathcal{A}(x)\\) , \\(\\mathcal{B}(x)\\) , \\(\\mathcal{C}(x)\\) , \\(\\mathcal{D}(x)\\) and \\(\\mathcal{E}(x)\\) at \\(H\\) are elements of 32 bits. We will design a machine to check this kind of operations as follows: \\[ \\tiny \\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|} \\hline \\textbf{set}\\mathcal{A} & \\textbf{set}\\mathcal{B} & \\textbf{set}\\mathcal{C} & \\textbf{set}\\mathcal{D} & \\textbf{set}\\mathcal{E} & \\textbf{latch} & \\textbf{freeIn} & \\mathcal{A} & \\mathcal{A'} & \\mathcal{B} & \\mathcal{B'} & \\mathcal{C} & \\mathcal{C'} & \\mathcal{D} & \\mathcal{D'} & \\mathcal{E} & \\mathcal{E'}\\\\ \\hline 1 & 0 & 0 & 0 & 0 & 0 & 0x0003 & 0 & 0x003 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\ \\hline 0 & 1 & 0 & 0 & 0 & 0 & 0x0002 & 0x0003 & 0x0003 & 0 & 0x0002 & 0 & 0 & 0 & 0 & 0 & 0\\\\ \\hline 0 & 0 & 1 & 0 & 0 & 0 & 0x0004 & 0x0003 & 0x0003 & 0x0002 & 0x0002 & 0 & 0x0004 & 0 & 0 & 0 & 0\\\\ \\hline 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0x0003 & 0x0003 & 0x0002 & 0x0002 & 0x0004 & 0x0004 & 0 & 0 & 0 & 0\\\\ \\hline 0 & 0 & 0 & 0 & 1 & 0 & 0x000a & 0x0003 & 0x0003 & 0x0002 & 0x0002 & 0x0004 & 0x0004 & 0 & 0 & 0 & 0x000a\\\\ \\hline 1 & 0 & 0 & 0 & 0 & \\mathbf{1} & 0x1111 & \\mathbf{0x0003} & 0x1111 & \\mathbf{0x0002} & 0x0002 & \\mathbf{0x0004} & 0x0004 & \\mathbf{0} & 0 & \\mathbf{0x000a} & 0x000a\\\\ \\hline 0 & 1 & 0 & 0 & 0 & 0 & 0x2222 & {0x1111} & 0x1111 & {0x0002} & 0x2222 & {0x0004} & 0x0004 & {0} & 0 & {0x000a} & 0x000a\\\\ \\hline 0 & 0 & 1 & 0 & 0 & 0 & 0x3333 & {0x1111} & 0x1111 & {0x2222} & 0x2222 & {0x0004} & 0x3333 & {0} & 0 & {0x000a} & 0x000a\\\\ \\hline 0 & 0 & 0 & 1 & 0 & 0 & 0x0246 & {0x1111} & 0x1111 & {0x2222} & 0x2222 & {0x3333} & 0x3333 & {0} & 0x0246 & {0x000a} & 0x000a\\\\ \\hline 0 & 0 & 0 & 0 & 1 & 0 & 0xb975 & {0x1111} & 0x1111 & {0x2222} & 0x2222 & {0x3333} & 0x3333 & {0x0246} & 0x0246 & {0x000a} & 0xb975\\\\ \\hline 1 & 0 & 0 & 0 & 0 & \\mathbf{1} & 0x7777 & \\mathbf{0x1111} & 0x7777 & \\mathbf{0x2222} & 0x2222 & \\mathbf{0x3333} & 0x3333 & \\mathbf{0x0246} & 0x0246 & \\mathbf{0xb975} & 0xb975\\\\ \\hline ... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ...\\\\ \\hline \\end{array} \\] Accents are used to denote the next value of the registry. We use latch to flag when the operation is ready and there is the need to check the constraint with the actual values of \\(\\mathcal{A}, \\mathcal{B}, \\mathcal{C}, \\mathcal{D}, \\mathcal{E}\\) . Notice that \\(\\textbf{set}\\mathcal{A}\\) , \\(\\textbf{set}\\mathcal{B}\\) , \\(\\textbf{set}\\mathcal{C}\\) , \\(\\textbf{set}\\mathcal{D}\\) , \\(\\textbf{set}\\mathcal{E}\\) and latch are constant (preprocessed), in other words, they do not depend on the input. The column freeIn is committed and contains the values for which we want to do the arithmetic operations. The values of \\(\\mathcal{A}\\) , \\(\\mathcal{B}\\) , \\(\\mathcal{C}\\) , \\(\\mathcal{D}\\) and \\(\\mathcal{E}\\) depend on the freeIn and are obviously also committed. Therefore, the polynomial identities that define the arithmetic state machine are the following: \\[\\begin{aligned} \\mathcal{A'} &= \\mathbf{sel}\\mathcal{A}\\cdot(\\mathbf{freeIn}-\\mathcal{A}) + \\mathcal{A} \\\\ \\mathcal{B'} &= \\mathbf{sel}\\mathcal{B}\\cdot(\\mathbf{freeIn}-\\mathcal{B}) + \\mathcal{B} \\\\ \\mathcal{C'} &= \\mathbf{sel}\\mathcal{C}\\cdot(\\mathbf{freeIn}-\\mathcal{C}) + \\mathcal{C} \\\\ \\mathcal{D'} &= \\mathbf{sel}\\mathcal{D}\\cdot(\\mathbf{freeIn}-\\mathcal{D}) + \\mathcal{D} \\\\ \\mathcal{E'} &= \\mathbf{sel}\\mathcal{E}\\cdot(\\mathbf{freeIn}-\\mathcal{E}) + \\mathcal{E} \\\\ 0 &= [ \\mathcal{A} \\cdot \\mathcal{B} + \\mathcal{C} - (2^{32} \\mathcal{D} + \\mathcal{E}) ] \\cdot \\mathbf{latch} \\\\ \\mathbf{freeIn} &\\subset byte4\\end{aligned}\\] Note that we only have to check that \\(\\mathbf{freeIn} \\subset byte4\\) because \\(\\mathcal{A}, \\mathcal{B}, \\mathcal{C}, \\mathcal{D}, \\mathcal{E}\\) will only take the \\(\\mathbf{freeIn}\\) values. The following figure illustrates the design of our arithmetic machine: Extending our Main State Machine Taking our main state machine as reference, we extend it to 5 registries and add a flag called arith to connect it to the arithmetic state machine. This allows us to check arithmetic operations between our resgistries whenever arith flag is setted to \\(1\\) . The overall design is the following one: The following figure exemplifies how we can connect both machines. The main point is that, when the arith flag is set to \\(1\\) , we need to ensure that the registries are present in the our arithmetic table when latch is \\(1\\) , i.e, the arithmetic constraint is fullfiled. Hence, we need to ensure the following inclusion: \\[[arith \\cdot A , arith \\cdot B , arith \\cdot C , arith \\cdot D, arith \\cdot op] \\subset [latch \\cdot \\mathcal{A} , latch \\cdot \\mathcal{B} , latch \\cdot \\mathcal{C} , latch \\cdot \\mathcal{D} , latch \\cdot \\mathcal{E}]\\] Notice that we use op because it contains the value of the E registry in the current tick. As we can see in the next figure, we use Plookup as a bus to connect our main state machine to the other specific state machines: This allows us to design in a modular way a virtual state machine that can be verified with zero knowledge technology.","title":"Modular Design"},{"location":"zkEVM/Basic-Concepts/modular-design/#divide-and-conquer","text":"We want now to extend the previous idea to a more complex machine that can handle, for example, multiplications. We could keep adding columns to our state machine to express such operations but that would make the design complex and hard to handle. Instead, we are going to use a divide and conquer technique: Our zk-EVM architecture comprises different connected state machines. Each state machine is devoted to proving the execution of a specific task. Then, relevant columns (polynomials) of these different state machines are related using inclusion proofs (with plookup). To illustrate this important process: Let's design a state machine to manage arithmetic operations with elements of 32 bits. Then, let's connect this state machine to our main state machine with an inclusion proof.","title":"Divide and Conquer"},{"location":"zkEVM/Basic-Concepts/modular-design/#arithmetic-state-machine","text":"The arithmetic state machine will check sums, subtractions, multiplications and divisions with elements of 32 bits. For this, we use the following constraint with five registries: $$ \\mathcal{A}_i \\cdot \\mathcal{B}_i + \\mathcal{C}_i = 2^{32} \\mathcal{D}_i + \\mathcal{E}_i. $$ Notice that the multiplication between \\(\\mathcal{A}_i\\) and \\(\\mathcal{B}_i\\) , which are elements of 32 bits, can be expressed with \\(\\mathcal{E}_i\\) and \\(\\mathcal{D}_i\\) where these are also elements of 32 bits. The \\(\\mathcal{D_i}\\) term carries the exceeding part of the multiplication. As before, we will express the previous relation as a cyclic polynomial identity at some subgroup \\(H\\) of roots of unity of \\(\\mathbb{Z}_{p}\\) : \\[ \\mathcal{A}(x) \\cdot \\mathcal{B}(x) + \\mathcal{C}(x) = 2^{32} \\mathcal{D}(x) + \\mathcal{E}(x). \\] Notice also that we have to enforce that all the images of \\(\\mathcal{A}(x)\\) , \\(\\mathcal{B}(x)\\) , \\(\\mathcal{C}(x)\\) , \\(\\mathcal{D}(x)\\) and \\(\\mathcal{E}(x)\\) at \\(H\\) are elements of 32 bits. We will design a machine to check this kind of operations as follows: \\[ \\tiny \\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|} \\hline \\textbf{set}\\mathcal{A} & \\textbf{set}\\mathcal{B} & \\textbf{set}\\mathcal{C} & \\textbf{set}\\mathcal{D} & \\textbf{set}\\mathcal{E} & \\textbf{latch} & \\textbf{freeIn} & \\mathcal{A} & \\mathcal{A'} & \\mathcal{B} & \\mathcal{B'} & \\mathcal{C} & \\mathcal{C'} & \\mathcal{D} & \\mathcal{D'} & \\mathcal{E} & \\mathcal{E'}\\\\ \\hline 1 & 0 & 0 & 0 & 0 & 0 & 0x0003 & 0 & 0x003 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\ \\hline 0 & 1 & 0 & 0 & 0 & 0 & 0x0002 & 0x0003 & 0x0003 & 0 & 0x0002 & 0 & 0 & 0 & 0 & 0 & 0\\\\ \\hline 0 & 0 & 1 & 0 & 0 & 0 & 0x0004 & 0x0003 & 0x0003 & 0x0002 & 0x0002 & 0 & 0x0004 & 0 & 0 & 0 & 0\\\\ \\hline 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0x0003 & 0x0003 & 0x0002 & 0x0002 & 0x0004 & 0x0004 & 0 & 0 & 0 & 0\\\\ \\hline 0 & 0 & 0 & 0 & 1 & 0 & 0x000a & 0x0003 & 0x0003 & 0x0002 & 0x0002 & 0x0004 & 0x0004 & 0 & 0 & 0 & 0x000a\\\\ \\hline 1 & 0 & 0 & 0 & 0 & \\mathbf{1} & 0x1111 & \\mathbf{0x0003} & 0x1111 & \\mathbf{0x0002} & 0x0002 & \\mathbf{0x0004} & 0x0004 & \\mathbf{0} & 0 & \\mathbf{0x000a} & 0x000a\\\\ \\hline 0 & 1 & 0 & 0 & 0 & 0 & 0x2222 & {0x1111} & 0x1111 & {0x0002} & 0x2222 & {0x0004} & 0x0004 & {0} & 0 & {0x000a} & 0x000a\\\\ \\hline 0 & 0 & 1 & 0 & 0 & 0 & 0x3333 & {0x1111} & 0x1111 & {0x2222} & 0x2222 & {0x0004} & 0x3333 & {0} & 0 & {0x000a} & 0x000a\\\\ \\hline 0 & 0 & 0 & 1 & 0 & 0 & 0x0246 & {0x1111} & 0x1111 & {0x2222} & 0x2222 & {0x3333} & 0x3333 & {0} & 0x0246 & {0x000a} & 0x000a\\\\ \\hline 0 & 0 & 0 & 0 & 1 & 0 & 0xb975 & {0x1111} & 0x1111 & {0x2222} & 0x2222 & {0x3333} & 0x3333 & {0x0246} & 0x0246 & {0x000a} & 0xb975\\\\ \\hline 1 & 0 & 0 & 0 & 0 & \\mathbf{1} & 0x7777 & \\mathbf{0x1111} & 0x7777 & \\mathbf{0x2222} & 0x2222 & \\mathbf{0x3333} & 0x3333 & \\mathbf{0x0246} & 0x0246 & \\mathbf{0xb975} & 0xb975\\\\ \\hline ... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ...\\\\ \\hline \\end{array} \\] Accents are used to denote the next value of the registry. We use latch to flag when the operation is ready and there is the need to check the constraint with the actual values of \\(\\mathcal{A}, \\mathcal{B}, \\mathcal{C}, \\mathcal{D}, \\mathcal{E}\\) . Notice that \\(\\textbf{set}\\mathcal{A}\\) , \\(\\textbf{set}\\mathcal{B}\\) , \\(\\textbf{set}\\mathcal{C}\\) , \\(\\textbf{set}\\mathcal{D}\\) , \\(\\textbf{set}\\mathcal{E}\\) and latch are constant (preprocessed), in other words, they do not depend on the input. The column freeIn is committed and contains the values for which we want to do the arithmetic operations. The values of \\(\\mathcal{A}\\) , \\(\\mathcal{B}\\) , \\(\\mathcal{C}\\) , \\(\\mathcal{D}\\) and \\(\\mathcal{E}\\) depend on the freeIn and are obviously also committed. Therefore, the polynomial identities that define the arithmetic state machine are the following: \\[\\begin{aligned} \\mathcal{A'} &= \\mathbf{sel}\\mathcal{A}\\cdot(\\mathbf{freeIn}-\\mathcal{A}) + \\mathcal{A} \\\\ \\mathcal{B'} &= \\mathbf{sel}\\mathcal{B}\\cdot(\\mathbf{freeIn}-\\mathcal{B}) + \\mathcal{B} \\\\ \\mathcal{C'} &= \\mathbf{sel}\\mathcal{C}\\cdot(\\mathbf{freeIn}-\\mathcal{C}) + \\mathcal{C} \\\\ \\mathcal{D'} &= \\mathbf{sel}\\mathcal{D}\\cdot(\\mathbf{freeIn}-\\mathcal{D}) + \\mathcal{D} \\\\ \\mathcal{E'} &= \\mathbf{sel}\\mathcal{E}\\cdot(\\mathbf{freeIn}-\\mathcal{E}) + \\mathcal{E} \\\\ 0 &= [ \\mathcal{A} \\cdot \\mathcal{B} + \\mathcal{C} - (2^{32} \\mathcal{D} + \\mathcal{E}) ] \\cdot \\mathbf{latch} \\\\ \\mathbf{freeIn} &\\subset byte4\\end{aligned}\\] Note that we only have to check that \\(\\mathbf{freeIn} \\subset byte4\\) because \\(\\mathcal{A}, \\mathcal{B}, \\mathcal{C}, \\mathcal{D}, \\mathcal{E}\\) will only take the \\(\\mathbf{freeIn}\\) values. The following figure illustrates the design of our arithmetic machine:","title":"Arithmetic State Machine"},{"location":"zkEVM/Basic-Concepts/modular-design/#extending-our-main-state-machine","text":"Taking our main state machine as reference, we extend it to 5 registries and add a flag called arith to connect it to the arithmetic state machine. This allows us to check arithmetic operations between our resgistries whenever arith flag is setted to \\(1\\) . The overall design is the following one: The following figure exemplifies how we can connect both machines. The main point is that, when the arith flag is set to \\(1\\) , we need to ensure that the registries are present in the our arithmetic table when latch is \\(1\\) , i.e, the arithmetic constraint is fullfiled. Hence, we need to ensure the following inclusion: \\[[arith \\cdot A , arith \\cdot B , arith \\cdot C , arith \\cdot D, arith \\cdot op] \\subset [latch \\cdot \\mathcal{A} , latch \\cdot \\mathcal{B} , latch \\cdot \\mathcal{C} , latch \\cdot \\mathcal{D} , latch \\cdot \\mathcal{E}]\\] Notice that we use op because it contains the value of the E registry in the current tick. As we can see in the next figure, we use Plookup as a bus to connect our main state machine to the other specific state machines: This allows us to design in a modular way a virtual state machine that can be verified with zero knowledge technology.","title":"Extending our Main State Machine"},{"location":"zkEVM/Basic-Concepts/simple-state-machine/","text":"A Simple State Machine Next we show the arithmetization process of a more complex but yet simple state machine. Our simple state machine transitionates from one state to the following one using the rules of a certain instruction. This machine can be represented as follows: The following program describes a state machine with two registries \\(\\mathtt{A}\\) and \\(\\mathtt{B}\\) that accepts an input: \\[\\begin{array}{|l|} \\hline \\mathbf{Instruction} \\\\ \\hline \\mathtt{\\$\\{getInput()\\} => A}\\\\ \\hline \\mathtt{3 => B} \\\\ \\hline \\mathtt{:ADD} \\\\ \\hline \\mathtt{0 => A,B} \\\\ \\hline \\end{array}\\] The previous program written in an assembly language that is read by a program called \"the executor\". The executor generates an execution trace according to each instruction of the assembly program. In the previous program, the assembly instructions mean the following: \\(\\mathtt{\\$\\{getInput()\\} => A}\\) . It is an instruction that asks for a free input value and saves it into register \\(A\\) . \\(\\mathtt{3 => B}\\) . Moves the value 3 into register \\(\\mathtt{B}\\) . \\(\\mathtt{:ADD}\\) . Sums the values of the registers \\(\\mathtt{A}\\) and \\(\\mathtt{B}\\) and saves the output into register \\(\\mathtt{A}\\) . \\(\\mathtt{0 => A, B}\\) . Moves the value 0 into registers \\(\\mathtt{A}\\) and \\(\\mathtt{B}\\) . For example, the execution trace that the executor must generate with free input \\(7\\) is the following: \\[\\begin{array}{|l|c|c|c|c|c|} \\hline \\mathbf{Instruction} & \\mathtt{free} & \\mathtt{A} & \\mathtt{A'} & \\mathtt{B} & \\mathtt{B'} \\\\ \\hline \\mathtt{\\$\\{getInput()\\} => A} & 7 & 0 & 7 & 0 & 0 \\\\ \\hline \\mathtt{3 => B} & 0 & 7 & 7 & 0 & 3 \\\\ \\hline \\mathtt{:ADD} & 0 & 7 & 10 & 3 & 3 \\\\ \\hline \\mathtt{0 => A,B} & 0 & 10 & 0 & 3 & 0 \\\\ \\hline \\end{array}\\] We denote as \\(\\mathtt{X'}\\) as the next state of the register \\(\\mathtt{X}\\) , where \\(\\mathtt{X} \\in \\{\\mathtt{A}, \\mathtt{B}\\}\\) . Now we need to create a proper set of arithmetic constraints to prove the correctness of the execution trace. To achieve this, we add auxiliary states and selectors to express the relations between the next values of registries \\(A\\) and \\(B\\) as a linear combination of the previous ones and these auxiliary states and selectors. This is shown in the following figure: Where we denote: a) \\(\\mathtt{inX}^i \\in \\{0,1\\}\\) : Selector to include or not \\(X_i\\) in the linear combination. b) \\(\\mathtt{setX}^i \\in \\{0,1\\}\\) : Selector to move or not the result of the linear combination into \\(X_{i+1}\\) . c) \\(\\mathtt{freeIn}^i\\) contains the inputs that we can freely choose to execute the program. d) \\(\\mathtt{const}^i\\) contains the fixed values of the instructions. Introducing the new auxiliary variables, we have the following extended table: \\[ \\scriptsize \\begin{array}{|l|} \\hline \\mathbf{Instruction} \\\\ \\hline \\mathtt{\\$\\{getInput()\\} => A} \\\\ \\hline \\mathtt{3 => B} \\\\ \\hline \\mathtt{:ADD} \\\\ \\hline \\mathtt{0 => A, B} \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|c|c|} \\hline \\texttt{free} & \\texttt{const} & \\texttt{setB} & \\texttt{setA} & \\texttt{inFree} & \\texttt{selB} & \\texttt{selA} \\\\ \\hline 7 & 0 & 0 & 1 & 1 & 0 & 0 \\\\ \\hline 0 & 3 & 1 & 0 & 0 & 0 & 0 \\\\ \\hline 0 & 0 & 0 & 1 & 0 & 1 & 1 \\\\ \\hline 0 & 0 & 1 & 1 & 0 & 0 & 0 \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|} \\hline \\mathtt{A} & \\mathtt{A'} & \\mathtt{B} & \\mathtt{B'} \\\\ \\hline 0 & 7 & 0 & 0\\\\ \\hline 7 & 7 & 0 & 3\\\\ \\hline 7 & 10 & 3 & 3\\\\ \\hline 10 & 0 & 3 & 0\\\\ \\hline \\end{array} \\] Henceforth, the relations between the states of the registries can be expressed algebraically as follows: \\[\\begin{aligned} &\\mathtt{A}^{i+1} = \\mathtt{A}^i + \\mathtt{setA}^i \\cdot (\\mathtt{selA}^i \\cdot \\mathtt{A}^i + \\mathtt{selB}^i \\cdot \\mathtt{B^i} + \\mathtt{inFree}^i \\cdot \\mathtt{free}^i + \\mathtt{const}^i - \\mathtt{A}^i), \\\\ &\\mathtt{B}^{i+1} = \\mathtt{B}^i + \\mathtt{setB}^i \\cdot (\\mathtt{selA}^i \\cdot \\mathtt{A}^i + \\mathtt{selB}^i \\cdot \\mathtt{B}^i + \\mathtt{inFree}^i \\cdot \\mathtt{free}^i + \\mathtt{const}^i - \\mathtt{B}^i).\\\\ \\end{aligned}\\] Let's represent the states of these registries for four steps as polynomials \\(\\mathtt{A}, \\mathtt{B} \\in \\mathbb{Z}_p[x]\\) evaluated on the subgroup \\(H = \\{\\omega, \\omega^2, \\omega^3, \\omega^4 = 1\\}\\) , in order to produce a cyclic relation: \\[\\begin{aligned} &\\mathtt{A}(x\\omega) = \\mathtt{A}(x) + \\mathtt{setA}(x) \\cdot (\\mathtt{selA}(x) \\cdot \\mathtt{A}(x) + \\mathtt{selB}(x) \\cdot \\mathtt{B}(x) + \\mathtt{inFree}(x) \\cdot \\mathtt{free}(x) + \\mathtt{const}(x) - \\mathtt{A}(x)), \\\\ &\\mathtt{B}(x\\omega) = \\mathtt{B}(x) + \\mathtt{setB}(x) \\cdot (\\mathtt{selA}(x) \\cdot \\mathtt{A}(x) + \\mathtt{selB}(x) \\cdot \\mathtt{B}(x) + \\mathtt{inFree}(x) \\cdot \\mathtt{free}(x) + \\mathtt{const}(x) - \\mathtt{B}(x)). \\end{aligned}\\] Observe that the program is completely described by the constant (and public) polynomials \\(\\mathtt{selA(x)}\\) , \\(\\mathtt{selB(x)}\\) , \\(\\mathtt{setA(x)}\\) , \\(\\mathtt{setB(x)}\\) , \\(\\mathtt{inFree(x)}\\) and \\(\\mathtt{const(x)}\\) . The polynomial \\(\\mathtt{free}(x)\\) can be public or committed and by changing this polynomial, we can proof different executions for different initial conditions for the same \"program\". In our previous program, we can provide a result of the execution by giving \\(A(\\omega^4)\\) . Notice that the last instruction resets the states' values and \"glues\" the last instruction with the first one, achieving a cycle. Programs with Conditional Jumps We are going to add the instruction \\(\\mathtt{JMPZ}\\) to our assembly. \\(\\mathtt{JMPZ}\\) jumps to a specified position in the program if the preceding state of the register \\(\\mathtt{A}\\) is zero. In the next program, \\(\\mathtt{JMPZ}\\) will jump to position \\(5\\) if the previous result of \\(\\mathtt{A + B}\\) (which is actually stored in the register \\(\\mathtt{A}\\) ) is \\(0\\) : \\[ \\begin{array}{|c|l|} \\hline \\textbf{Position} & \\mathbf{Instruction} \\\\ \\hline 0 & \\mathtt{\\$\\{getInput()\\} => A} \\\\ \\hline 1 & \\mathtt{-3 => B} \\\\ \\hline 2 & \\mathtt{:ADD} \\\\ \\hline 3 & \\mathtt{:JMPZ(5)} \\\\ \\hline 4 & \\mathtt{:ADD} \\\\ \\hline 5 & \\mathtt{0 => A, B} \\\\ \\hline \\end{array} \\] Note: We will discuss later on how to introduce negative values into our program. In programs with conditional jumps, our previous model will not work, because the flow of the program may vary depending on the values of the input. As it can be seen next, with conditional jumps, the length of the execution trace is not constant (it depends on the free input): \\[\\scriptsize \\begin{array}{|l|c|c|c|c|c|} \\hline \\mathbf{Instruction} & \\mathtt{free} & \\mathtt{A} & \\mathtt{A'} & \\mathtt{B} & \\mathtt{B'} \\\\ \\hline \\mathtt{\\$\\{getInput()\\} => A} & 7 & 0 & 7 & 0 & 0 \\\\ \\hline \\mathtt{-3 => B} & 0 & 7 & 7 & 0 & -3 \\\\ \\hline \\mathtt{:ADD} & 0 & 7 & 4 & -3 & -3 \\\\ \\hline \\mathtt{:JMPZ(5)} & 0 & 4 & 4 & -3 & -3 \\\\ \\hline \\mathtt{:ADD} & 0 & 4 & 1 & -3 & -3 \\\\ \\hline \\mathtt{0 => A, B} & 0 & 1 & 0 & -3 & 0 \\\\ \\hline \\end{array}\\] \\[\\scriptsize \\begin{array}{|l|c|c|c|c|c|} \\hline \\mathbf{Instruction} & \\mathtt{free} & \\mathtt{A} & \\mathtt{A'} & \\mathtt{B} & \\mathtt{B'} \\\\ \\hline \\mathtt{\\$\\{getInput()\\} => A} & 3 & 0 & 3 & 0 & 0 \\\\ \\hline \\mathtt{-3 => B} & 0 & 3 & 3 & 0 & -3 \\\\ \\hline \\mathtt{:ADD} & 0 & 3 & 0 & -3 & -3 \\\\ \\hline \\mathtt{:JMPZ(5)} & 0 & 0 & 0 & -3 & -3 \\\\ \\hline \\mathtt{0 => A, B} & 0 & 0 & 0 & -3 & 0 \\\\ \\hline \\end{array}\\] The first execution is done in 6 steps, meanwhile the second one has been done in 5 steps. Managing Conditional Jumps Now, let us introduce a new model to manage a program that contains conditional jumps. To do this, we need to add the Program Counter (PC) . The \\(\\mathtt{PC}\\) is a special registry that contains the position of the instruction in the program being executed. We use \\(\\texttt{op}_i\\) as a shorthand for the linear combination of our state machine to simplify the forthcoming constraints: $$ \\mathtt{op}^i := \\mathtt{setA}^i \\cdot \\mathtt{A}^i + \\mathtt{setB}^i \\cdot \\mathtt{B}^i + \\mathtt{inFree}^i \\cdot \\mathtt{free}^i + \\mathtt{const}^i. $$ The \\(\\mathtt{JMPZ}\\) instruction will jump to the instruction \\(\\texttt{addr}^i\\) (specified by the \\(\\mathtt{JMPZ}\\) instruction) if \\(\\texttt{op}^i\\) is zero. Let us first develop some procedure to check if our operation is or not zero in \\(\\mathbb{Z}_p\\) : To check that a number in the field \\(\\mathbb{Z}_p\\) is zero, we use the fact that a number \\(a\\) has a multiplicative inverse \\(a^{-1}\\) if and only if \\(a \\neq 0\\) . Using this fact, we use the following definition and constraint to do the \\(\\mathtt{isZero}\\) check: \\[\\begin{aligned} &\\mathtt{isZero}^i := 1 - \\mathtt{op}^i \\cdot (\\mathtt{op}^i)^{-1}, \\\\ &\\mathtt{isZero}^i \\cdot \\mathtt{op}^i = 0. \\end{aligned}\\] We can proof that the previous equations describe the desired check by case examination where \\(a \\neq 0\\) and \\(\\alpha, \\beta \\in \\mathbb{Z}_p\\) : \\(\\mathtt{op}^i = 0,~(\\mathtt{op}^i)^{-1} = \\alpha,~\\mathtt{isZero}^i = 1\\) passes the definition and constraint, \\(\\mathtt{op}^i = a,~(\\mathtt{op}^i)^{-1} = a^{-1},~\\mathtt{isZero}^i = 0\\) passes the definition and constraint. \\(\\mathtt{op}^i = 0,~(\\mathtt{op}^i)^{-1} = \\alpha,~\\mathtt{isZero}^i \\neq 1\\) does not pass the definition of \\(\\mathtt{isZero}\\) . \\(\\mathtt{op}^i = a,~(\\mathtt{op}^i)^{-1} = \\beta,~\\mathtt{isZero}^i \\neq 0\\) does not pass the definition and constraint, either you consider \\(\\beta = 0\\) , \\(\\beta = a^{-1}\\) or \\(\\beta \\neq a^{-1}\\) . We can mix the two equations into just one constraint: $$ \\mathtt{isZero}^i \\cdot \\mathtt{op}^i = 0,~~\\mathtt{isZero}^i = 1 - \\mathtt{op}^i \\cdot (\\mathtt{op}^i)^{-1}~~\\rightarrow~~(1 - \\mathtt{op}^i \\cdot (\\mathtt{op}^i)^{-1}) \\cdot \\mathtt{op}^i = 0. $$ Let us introduce the following machinery to our setup in order to introduce jumps: We add a selector \\(\\texttt{jmpz}^i \\in \\{0,1\\}\\) to our state machine to code the \\(\\mathtt{JMPZ}\\) instruction and express the behaviour of the PC . Then, the set of constraints is the following: \\[\\begin{aligned} &\\mathtt{op}^i := \\mathtt{setA}^i \\cdot \\mathtt{A}^i + \\mathtt{setB}^i \\cdot \\mathtt{B}^i + \\mathtt{inFree}^i \\cdot \\mathtt{free}^i + \\mathtt{const}^i, \\\\ &\\mathtt{PC}^{i+1} = \\mathtt{PC}^i + 1 + \\mathtt{jmpz}^i \\cdot (1 - \\mathtt{op}^i \\cdot (\\mathtt{op}^i)^{-1}) \\cdot (\\mathtt{addr}^i - \\mathtt{PC}^i - 1),\\\\ &(1 - \\mathtt{op}^i \\cdot (\\mathtt{op}^i)^{-1}) \\cdot \\mathtt{op}^i = 0. \\end{aligned}\\] Observe that: If \\(\\mathtt{op}^i \\neq 0\\) , then \\((1 - \\mathtt{op}^i \\cdot (\\mathtt{op}^i)^{-1}) = 0\\) and hence \\(\\mathtt{PC}^{i+1} = \\mathtt{PC}^i + 1\\) ; If \\(\\mathtt{op}^i = 0\\) , then \\((1 - \\mathtt{op}^i \\cdot (\\mathtt{op}^i)^{-1}) = 1\\) and hence \\(\\mathtt{PC}^{i+1} = \\mathtt{PC}^i + 1 + \\mathtt{addr}^i - \\mathtt{PC}^i - 1 = \\mathtt{addr}^i\\) . This is exactly the wanted behaviour. Next, we show the execution traces for the free inputs 7 and 3 respectively: \\[ \\tiny \\begin{array}{|l|} \\hline \\mathbf{Instruction} \\\\ \\hline \\mathtt{\\$\\{getInput()\\} => A} \\\\ \\hline \\mathtt{-3 => B} \\\\ \\hline \\mathtt{:ADD} \\\\ \\hline \\mathtt{:JMPZ(5)} \\\\ \\hline \\mathtt{:ADD} \\\\ \\hline \\mathtt{0 => A, B, PC} \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|} \\hline \\texttt{free} & \\textbf{const} & \\texttt{addr} & \\texttt{jmpz} & \\texttt{setB} & \\texttt{setA} & \\texttt{inFree} & \\texttt{selB} & \\texttt{selA} & \\texttt{op} & \\texttt{invOp} \\\\ \\hline 7 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 7 & 7^{-1} \\\\ \\hline 0 & -3 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & -3 & (-3)^{-1} \\\\ \\hline 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 1 & \\mathbf{\\color{blue!75!black} 4} & \\mathbf{\\color{blue!75!black} 4^{-1}} \\\\ \\hline 0 & 0 & 5 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ \\hline 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 1 & 1 & 1 \\\\ \\hline 0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|} \\hline \\mathtt{PC} & \\mathtt{PC'} & \\mathtt{A} & \\mathtt{A'} & \\mathtt{B} & \\mathtt{B'} \\\\ \\hline 0 & 1 & 0 & 7 & 0 & 0\\\\ \\hline 1 & 2 & 7 & 7 & 0 & -3\\\\ \\hline 2 & 3 & 7 & 4 & -3 & -3\\\\ \\hline 3 & 4 & 4 & 4 & -3 & -3\\\\ \\hline 4 & 5 & 4 & 1 & -3 & -3\\\\ \\hline 5 & 0 & 1 & 0 & -3 & 0\\\\ \\hline \\end{array} \\] \\[ \\tiny \\begin{array}{|l|} \\hline \\mathbf{Instruction} \\\\ \\hline \\mathtt{\\$\\{getInput()\\} => A} \\\\ \\hline \\mathtt{-3 => B} \\\\ \\hline \\mathtt{:ADD} \\\\ \\hline \\mathtt{:JMPZ(5)} \\\\ \\hline \\mathtt{0 => A, B} \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|c|} \\hline \\texttt{free} & \\texttt{const} & \\texttt{addr} & \\texttt{jmpz} & \\texttt{setB} & \\texttt{setA} & \\texttt{inFree} & \\texttt{selB} & \\texttt{selA} & \\texttt{op} & \\texttt{invOp} \\\\ \\hline 3 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 3 & 3^{-1} \\\\ \\hline 0 & -3 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & -3 & (-3)^{-1} \\\\ \\hline 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 1 & \\mathbf{\\color{blue!75!black} 0} & \\mathbf{\\color{blue!75!black} \\alpha} \\\\ \\hline 0 & 0 & 5 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ \\hline 0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|} \\hline \\mathtt{PC} & \\mathtt{PC'} & \\mathtt{A} & \\mathtt{A'} & \\mathtt{B} & \\mathtt{B'} \\\\ \\hline 0 & 1 & 0 & 3 & 0 & 0\\\\ \\hline 1 & 2 & 3 & 3 & 0 & -3\\\\ \\hline 2 & 3 & 3 & 0 & -3 & -3\\\\ \\hline 3 & 5 & 3 & 0 & -3 & -3\\\\ \\hline 5 & 0 & 0 & 0 & -3 & 0\\\\ \\hline \\end{array} \\] Note that we use \\(\\mathtt{invOp}\\) for the column containing the inverses of \\(\\mathtt{op}\\) . Note also that the \\(\\mathtt{PC}\\) turns to be an important registry when jumps are included in the set of possible instructions because jumps can modify the sequence of instructions that is executed also known as \"the trace\". Now, our polynomials are definitely not preprocessed, this is because the values of the table will not only depend on the program, but also on the free input values. Hence, we need to ensure that we are verifying the correct program. Proving the Execution of the \"Correct Program\" Up to now, we can prove that each instruction is correctly executed, but, how do we prove that we are executing the correct set of instructions, that is to say, that we are executing the \"correct program\"? The solution seems obvious: Check that every executed instruction is some instruction in the program, but how do we do this in a succinct manner? To do so, we have to provide a codification for each instruction and then we will check that the codification of the execution's instructions is included in the codification of the program's instructions. Let's begin showing how to encode the constant values of our instructions. As a particular example, consider that we want to use signed integers of 4 bits (in the real machine, we will use an analogous 32 bits codification). The four bit codification is shown next: \\[\\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|c|c|} \\hline -8 & -7 & -6 & ... & -2 & -1 & 0 & 1 & 2 & ... & 6 & 7 & 8 \\\\ \\hline 1000 & 1001 & 1010 & ... & 1110 & 1111 & 0000 & 0001 & 0010 & ... & 0110 & 0111 & 1000 \\\\ \\hline \\end{array}\\] Notice that with this arithmetic \\(8=-8\\) , which is a weird case that we discard, using only values from -7 to 7. Then, we encode these values in elements of the field \\(\\mathbb{Z}_p\\) : \\[\\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|} \\hline -7 & -6 & ... & -2 & -1 & 0 & 1 & 2 & ...& 6 & 7 \\\\ \\hline p-7 & p-6 & ... & p-2 & p-1 & 0 & 1 & 2 & ...& 6 & 7 \\\\ \\hline \\end{array}\\] So, we have to enforce that \\(\\mathsf{const}(x) \\in \\{p-7, p-6, ..., p-2, p-1, 0,1,2, ..., 6, 7\\}\\) . We enforce the previous condition with the following equivalent inclusion: \\[\\mathsf{const}(x) + 7 \\in \\{0,1,2,...,14\\}\\] Hence, we will use \\(\\mathsf{const}(x) + 7\\) in base \\(2\\) instead of \\(\\mathsf{const}(x)\\) to encode our instruction, just to avoid the sum. Let's now explain how to encode every distinct instruction to be executed by the program: \\[ \\scriptsize \\begin{array}{|c|l|} \\hline \\mathbf{Instruction} \\\\ \\hline \\mathtt{\\$\\{getInput()\\} => A} \\\\ \\hline \\mathtt{-3 => B} \\\\ \\hline \\mathtt{:ADD} \\\\ \\hline \\mathtt{:JMPZ(5)} \\\\ \\hline \\mathtt{:ADD} \\\\ \\hline \\mathtt{0 => A, B, PC} \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|} \\hline \\mathbf{\\color{blue!75!black} \\texttt{const+7}} & \\texttt{addr} & \\texttt{jmpz} & \\texttt{setB} & \\texttt{setA} & \\texttt{inFree} & \\texttt{selB} & \\texttt{selA} & \\texttt{instruction} \\\\ \\hline \\mathbf{\\color{blue!75!black} 7} & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 0111.0000.001100 \\\\ \\hline \\mathbf{\\color{blue!75!black} 4} & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0100.0000.010000 \\\\ \\hline \\mathbf{\\color{blue!75!black} 7} & 0 & 0 & 0 & 1 & 0 & 1 & 1 & 0111.0000.001011\\\\ \\hline \\mathbf{\\color{blue!75!black} 7} & 5 & 1 & 0 & 0 & 0 & 0 & 0 & 0111.0101.100000 \\\\ \\hline \\mathbf{\\color{blue!75!black} 7} & 0 & 0 & 0 & 1 & 0 & 1 & 1 & 0111.0000.001011 \\\\ \\hline \\mathbf{\\color{blue!75!black} 7} & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0111.0000.111000 \\\\ \\hline \\end{array} \\] Observe that we have codified the instruction using the following rule: $$ \\texttt{instruction}^i := 2^{10}\\cdot(\\texttt{const}^i + 7) + 2^6\\cdot \\texttt{addr}^i + 2^5\\cdot \\texttt{jmpz}^i + 2^4 \\cdot \\texttt{setB}^i + 2^3 \\cdot \\texttt{setA}^i + 2^2 \\cdot \\texttt{inFree}^i + 2 \\cdot \\texttt{selB}^i + \\texttt{selA}^i. $$ That is, we are codifying it as the concatenated base \\(2\\) integer of all the values (in the order of appearance on the table). Note that additionally, we will need to check that the selectors are binary and that \\(\\texttt{addr}\\) is composed of \\(4\\) bits, i.e., \\(\\texttt{addr}^i \\in \\{0, 1, \\dots, 15\\}\\) Also observe that, when \\(\\texttt{const}^i+7 = 7\\) , this means that \\(\\texttt{const}^i = 0\\) , so the constant is not used in those cases. Now, to prove the program, every instruction will be uniquely identified by its code and position in the program (we also use 4 bits in this example for the position). We define the \\(\\mathtt{ROM}\\) of the program as the sum between every instruction and the position in which it is defined: $$ \\texttt{ROM}^i := 2^{14} \\cdot \\texttt{position}^i + \\texttt{instruction}^i. $$ Observe that the \\(\\mathtt{ROM}\\) uniquely identifies the program we want to verify and it is independent of the different possible executions. The resulting \\(\\mathtt{ROM}\\) of our program is the following: \\[ \\begin{array}{|c|c|} \\hline \\texttt{position} & \\mathbf{Instruction} \\\\ \\hline 0 & \\mathtt{\\$\\{getInput()\\} => A} \\\\ \\hline 1 & \\mathtt{-3 => B} \\\\ \\hline 2 & \\mathtt{:ADD} \\\\ \\hline 3 & \\mathtt{:JMPZ(5)} \\\\ \\hline 4 & \\mathtt{:ADD} \\\\ \\hline 5 & \\mathtt{0 => A, B, PC} \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|} \\hline \\texttt{ROM} \\\\ \\hline 0111.0000.001100 \\\\ \\hline 0100.0000.010000 \\\\ \\hline 0111.0000.001011\\\\ \\hline 0111.0101.100000 \\\\ \\hline 0111.0000.001011 \\\\ \\hline 0111.0000.111000 \\\\ \\hline \\end{array} \\] We will encode the program trace using the PC: \\[ \\scriptsize \\begin{array}{|c|c|c|c|c|c|} \\hline \\mathtt{PC} \\\\ \\hline 0 \\\\ \\hline 1 \\\\ \\hline 2 \\\\ \\hline 3 \\\\ \\hline 4 \\\\ \\hline 5 \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|} \\hline \\mathtt{position} & \\mathbf{Instruction} \\\\ \\hline 0 & \\mathtt{\\$\\{getInput()\\} => A} \\\\ \\hline 1 & \\mathtt{-3 => B} \\\\ \\hline 2 & \\mathtt{:ADD} \\\\ \\hline 3 & \\mathtt{:JMPZ(5)} \\\\ \\hline 4 & \\mathtt{:ADD} \\\\ \\hline 5 & \\mathtt{0 => A, B, PC} \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|c|c|c|} \\hline \\texttt{const+7} & \\texttt{addr} & \\texttt{jmpz} & \\texttt{setB} & \\texttt{setA} & \\texttt{inFree} & \\texttt{selB} & \\texttt{selA} \\\\ \\hline 7 & 0 & 0 & 0 & 1 & 1 & 0 & 0 \\\\ \\hline 4 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\ \\hline 7 & 0 & 0 & 0 & 1 & 0 & 1 & 1 \\\\ \\hline 7 & 5 & 1 & 0 & 0 & 0 & 0 & 0 \\\\ \\hline 7 & 0 & 0 & 0 & 1 & 0 & 1 & 1 \\\\ \\hline 7 & 0 & 1 & 1 & 1 & 0 & 0 & 0 \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|} \\hline \\mathtt{insTrace} \\\\ \\hline 0000.0111.0000.001100 \\\\ \\hline 0001.0100.0000.010000 \\\\ \\hline 0010.0111.0000.001011\\\\ \\hline 0011.0111.0101.100000 \\\\ \\hline 0100.0111.0000.001011 \\\\ \\hline 0101.0111.0000.111000 \\\\ \\hline \\end{array} \\] \\[ \\scriptsize \\begin{array}{|c|c|c|c|c|c|} \\hline \\mathtt{PC} \\\\ \\hline 0 \\\\ \\hline 1 \\\\ \\hline 2 \\\\ \\hline 3 \\\\ \\hline 5 \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|} \\hline \\mathtt{position} & \\mathbf{Instruction} \\\\ \\hline 0 & \\mathtt{\\$\\{getInput()\\} => A} \\\\ \\hline 1 & \\mathtt{-3 => B} \\\\ \\hline 2 & \\mathtt{:ADD} \\\\ \\hline 3 & \\mathtt{:JMPZ(5)} \\\\ \\hline 4 & \\mathtt{0 => A, B, PC} \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|c|c|c|} \\hline \\texttt{const+7} & \\texttt{addr} & \\texttt{jmpz} & \\texttt{setB} & \\texttt{setA} & \\texttt{inFree} & \\texttt{selB} & \\texttt{selA} \\\\ \\hline 7 & 0 & 0 & 0 & 1 & 1 & 0 & 0 \\\\ \\hline 4 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\ \\hline 7 & 0 & 0 & 0 & 1 & 0 & 1 & 1 \\\\ \\hline 7 & 5 & 1 & 0 & 0 & 0 & 0 & 0 \\\\ \\hline 7 & 0 & 1 & 1 & 1 & 0 & 0 & 0 \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|} \\hline \\mathtt{insTrace} \\\\ \\hline 0000.0111.0000.001100 \\\\ \\hline 0001.0100.0000.010000 \\\\ \\hline 0010.0111.0000.001011\\\\ \\hline 0011.0111.0101.100000 \\\\ \\hline 0101.0111.0000.111000 \\\\ \\hline \\end{array} \\] Recall that our main question was: How do we actually check correctness in an efficient manner? We can achieve it with the Plookup protocol. So, to check that the correct program is being executed, we simply have to use Plookup to determine if: \\[\\mathsf{insTrace(x)} \\subset \\mathsf{ROM(x)}\\] In words, the trace being executed is an execution of the actual program if the instruction trace is contained in the ROM of the program. Identities to Prove an Execution Trace As a summary, we have seen that the following set of identities are used to define our program: \\[\\begin{aligned} &\\mathsf{A}(x\\omega) = \\mathsf{A}(x) + \\mathsf{setA}(x) \\cdot (\\mathsf{op}(x) - \\mathsf{A}(x)), \\\\ &\\mathsf{B}(x\\omega) = \\mathsf{B}(x) + \\mathsf{setB}(x) \\cdot (\\mathsf{op}(x) - \\mathsf{B}(x)), \\\\ &\\mathsf{PC}(x\\omega) = \\mathsf{PC}(x) + 1 + \\mathsf{jmpz}(x) \\cdot (1 - \\mathsf{op}(x) \\cdot \\mathsf{invOp}(x)) \\cdot (\\mathsf{addr}(x) - \\mathsf{PC}(x) - 1), \\\\ &(1 - \\mathsf{op}(x) \\cdot \\mathsf{invOp}(x)) \\cdot \\mathsf{op}(x) = 0. \\end{aligned}\\] With the following definition: $$ \\mathsf{op}(x) := \\mathsf{selA}(x) \\cdot \\mathsf{A}(x) + \\mathsf{selB}(x) \\cdot \\mathsf{B}(x) + \\mathsf{inFree}(x) \\cdot \\mathsf{free}(x) + \\mathsf{const}(x). $$ Moreover, we should add the following Plookup checks: \\[\\begin{aligned} &\\textsf{const}(x) + 7 \\subset \\{0,1, \\dots, 14\\},\\\\ &\\mathsf{addr}(x) \\subset \\{0,1, \\dots, 15\\},\\\\ &\\mathsf{position}(x) \\subset \\{0,1, \\dots, 15\\},\\\\ &\\mathsf{PC}(x) \\subset \\{0,1, \\dots, 15\\},\\\\ &\\textsf{insTrace}(x) \\subset \\textsf{ROM}(x). \\end{aligned}\\] With the following definitions: \\[\\begin{aligned} &\\textsf{instruction}(x) := 2^{10}\\cdot(\\textsf{const}(x) + 7) + 2^6\\cdot \\textsf{addr}(x) + 2^5\\cdot \\textsf{jmpz}(x) + 2^4 \\cdot \\textsf{setB}(x) + \\\\ &\\qquad \\qquad \\qquad \\quad~~2^3 \\cdot \\textsf{setA}(x) + 2^2 \\cdot \\textsf{inFree}(x) + 2 \\cdot \\textsf{selB}(x) + \\textsf{selA}(x),\\\\ &\\textsf{ROM}(x) := 2^{14} \\cdot \\textsf{position}(x) + \\textsf{instruction}(x), \\\\ &\\textsf{insTrace}(x) := 2^{14} \\cdot \\textsf{PC}(x) + \\textsf{instruction}(x). \\end{aligned}\\] Finally, it should be checked that the whole set of selectors are, in fact, binary: \\[\\begin{aligned} &\\mathsf{selA}(x) \\cdot (\\mathsf{selA}(x) - 1) = 0, \\quad \\mathsf{setA}(x) \\cdot (\\mathsf{setA}(x) - 1) = 0, \\quad\\\\ &\\mathsf{selB}(x) \\cdot (\\mathsf{selB}(x)- 1) = 0, \\quad \\mathsf{setB}(x) \\cdot (\\mathsf{setB}(x) - 1) = 0, \\quad\\\\ &\\mathsf{inFree}(x) \\cdot (\\mathsf{inFree}(x) - 1) = 0, \\quad \\mathsf{jmpz}(x) \\cdot (\\mathsf{jmpz}(x) - 1) = 0. \\end{aligned}\\] Regarding the polynomials, in this state machine: We have to commit \\(\\textsf{inFree}(x), \\textsf{selA}(x), \\textsf{selB}(x), \\textsf{setA}(x), \\textsf{setB}(x)\\) \\(\\textsf{A}(x), \\textsf{B}(x), \\textsf{const}(x),\\) \\(\\textsf{jmpz}(x),\\) \\(\\textsf{invOp}(x)\\) , \\(\\textsf{addr}(x)\\) , \\(\\textsf{free}(x)\\) , \\(\\textsf{position}(x)\\) and \\(\\textsf{PC}(x)\\) . While the only constant (preprocessed) polynomial is \\(\\textsf{ROM}(x)\\) .","title":"Simple State Machine"},{"location":"zkEVM/Basic-Concepts/simple-state-machine/#a-simple-state-machine","text":"Next we show the arithmetization process of a more complex but yet simple state machine. Our simple state machine transitionates from one state to the following one using the rules of a certain instruction. This machine can be represented as follows: The following program describes a state machine with two registries \\(\\mathtt{A}\\) and \\(\\mathtt{B}\\) that accepts an input: \\[\\begin{array}{|l|} \\hline \\mathbf{Instruction} \\\\ \\hline \\mathtt{\\$\\{getInput()\\} => A}\\\\ \\hline \\mathtt{3 => B} \\\\ \\hline \\mathtt{:ADD} \\\\ \\hline \\mathtt{0 => A,B} \\\\ \\hline \\end{array}\\] The previous program written in an assembly language that is read by a program called \"the executor\". The executor generates an execution trace according to each instruction of the assembly program. In the previous program, the assembly instructions mean the following: \\(\\mathtt{\\$\\{getInput()\\} => A}\\) . It is an instruction that asks for a free input value and saves it into register \\(A\\) . \\(\\mathtt{3 => B}\\) . Moves the value 3 into register \\(\\mathtt{B}\\) . \\(\\mathtt{:ADD}\\) . Sums the values of the registers \\(\\mathtt{A}\\) and \\(\\mathtt{B}\\) and saves the output into register \\(\\mathtt{A}\\) . \\(\\mathtt{0 => A, B}\\) . Moves the value 0 into registers \\(\\mathtt{A}\\) and \\(\\mathtt{B}\\) . For example, the execution trace that the executor must generate with free input \\(7\\) is the following: \\[\\begin{array}{|l|c|c|c|c|c|} \\hline \\mathbf{Instruction} & \\mathtt{free} & \\mathtt{A} & \\mathtt{A'} & \\mathtt{B} & \\mathtt{B'} \\\\ \\hline \\mathtt{\\$\\{getInput()\\} => A} & 7 & 0 & 7 & 0 & 0 \\\\ \\hline \\mathtt{3 => B} & 0 & 7 & 7 & 0 & 3 \\\\ \\hline \\mathtt{:ADD} & 0 & 7 & 10 & 3 & 3 \\\\ \\hline \\mathtt{0 => A,B} & 0 & 10 & 0 & 3 & 0 \\\\ \\hline \\end{array}\\] We denote as \\(\\mathtt{X'}\\) as the next state of the register \\(\\mathtt{X}\\) , where \\(\\mathtt{X} \\in \\{\\mathtt{A}, \\mathtt{B}\\}\\) . Now we need to create a proper set of arithmetic constraints to prove the correctness of the execution trace. To achieve this, we add auxiliary states and selectors to express the relations between the next values of registries \\(A\\) and \\(B\\) as a linear combination of the previous ones and these auxiliary states and selectors. This is shown in the following figure: Where we denote: a) \\(\\mathtt{inX}^i \\in \\{0,1\\}\\) : Selector to include or not \\(X_i\\) in the linear combination. b) \\(\\mathtt{setX}^i \\in \\{0,1\\}\\) : Selector to move or not the result of the linear combination into \\(X_{i+1}\\) . c) \\(\\mathtt{freeIn}^i\\) contains the inputs that we can freely choose to execute the program. d) \\(\\mathtt{const}^i\\) contains the fixed values of the instructions. Introducing the new auxiliary variables, we have the following extended table: \\[ \\scriptsize \\begin{array}{|l|} \\hline \\mathbf{Instruction} \\\\ \\hline \\mathtt{\\$\\{getInput()\\} => A} \\\\ \\hline \\mathtt{3 => B} \\\\ \\hline \\mathtt{:ADD} \\\\ \\hline \\mathtt{0 => A, B} \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|c|c|} \\hline \\texttt{free} & \\texttt{const} & \\texttt{setB} & \\texttt{setA} & \\texttt{inFree} & \\texttt{selB} & \\texttt{selA} \\\\ \\hline 7 & 0 & 0 & 1 & 1 & 0 & 0 \\\\ \\hline 0 & 3 & 1 & 0 & 0 & 0 & 0 \\\\ \\hline 0 & 0 & 0 & 1 & 0 & 1 & 1 \\\\ \\hline 0 & 0 & 1 & 1 & 0 & 0 & 0 \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|} \\hline \\mathtt{A} & \\mathtt{A'} & \\mathtt{B} & \\mathtt{B'} \\\\ \\hline 0 & 7 & 0 & 0\\\\ \\hline 7 & 7 & 0 & 3\\\\ \\hline 7 & 10 & 3 & 3\\\\ \\hline 10 & 0 & 3 & 0\\\\ \\hline \\end{array} \\] Henceforth, the relations between the states of the registries can be expressed algebraically as follows: \\[\\begin{aligned} &\\mathtt{A}^{i+1} = \\mathtt{A}^i + \\mathtt{setA}^i \\cdot (\\mathtt{selA}^i \\cdot \\mathtt{A}^i + \\mathtt{selB}^i \\cdot \\mathtt{B^i} + \\mathtt{inFree}^i \\cdot \\mathtt{free}^i + \\mathtt{const}^i - \\mathtt{A}^i), \\\\ &\\mathtt{B}^{i+1} = \\mathtt{B}^i + \\mathtt{setB}^i \\cdot (\\mathtt{selA}^i \\cdot \\mathtt{A}^i + \\mathtt{selB}^i \\cdot \\mathtt{B}^i + \\mathtt{inFree}^i \\cdot \\mathtt{free}^i + \\mathtt{const}^i - \\mathtt{B}^i).\\\\ \\end{aligned}\\] Let's represent the states of these registries for four steps as polynomials \\(\\mathtt{A}, \\mathtt{B} \\in \\mathbb{Z}_p[x]\\) evaluated on the subgroup \\(H = \\{\\omega, \\omega^2, \\omega^3, \\omega^4 = 1\\}\\) , in order to produce a cyclic relation: \\[\\begin{aligned} &\\mathtt{A}(x\\omega) = \\mathtt{A}(x) + \\mathtt{setA}(x) \\cdot (\\mathtt{selA}(x) \\cdot \\mathtt{A}(x) + \\mathtt{selB}(x) \\cdot \\mathtt{B}(x) + \\mathtt{inFree}(x) \\cdot \\mathtt{free}(x) + \\mathtt{const}(x) - \\mathtt{A}(x)), \\\\ &\\mathtt{B}(x\\omega) = \\mathtt{B}(x) + \\mathtt{setB}(x) \\cdot (\\mathtt{selA}(x) \\cdot \\mathtt{A}(x) + \\mathtt{selB}(x) \\cdot \\mathtt{B}(x) + \\mathtt{inFree}(x) \\cdot \\mathtt{free}(x) + \\mathtt{const}(x) - \\mathtt{B}(x)). \\end{aligned}\\] Observe that the program is completely described by the constant (and public) polynomials \\(\\mathtt{selA(x)}\\) , \\(\\mathtt{selB(x)}\\) , \\(\\mathtt{setA(x)}\\) , \\(\\mathtt{setB(x)}\\) , \\(\\mathtt{inFree(x)}\\) and \\(\\mathtt{const(x)}\\) . The polynomial \\(\\mathtt{free}(x)\\) can be public or committed and by changing this polynomial, we can proof different executions for different initial conditions for the same \"program\". In our previous program, we can provide a result of the execution by giving \\(A(\\omega^4)\\) . Notice that the last instruction resets the states' values and \"glues\" the last instruction with the first one, achieving a cycle.","title":"A Simple State Machine"},{"location":"zkEVM/Basic-Concepts/simple-state-machine/#programs-with-conditional-jumps","text":"We are going to add the instruction \\(\\mathtt{JMPZ}\\) to our assembly. \\(\\mathtt{JMPZ}\\) jumps to a specified position in the program if the preceding state of the register \\(\\mathtt{A}\\) is zero. In the next program, \\(\\mathtt{JMPZ}\\) will jump to position \\(5\\) if the previous result of \\(\\mathtt{A + B}\\) (which is actually stored in the register \\(\\mathtt{A}\\) ) is \\(0\\) : \\[ \\begin{array}{|c|l|} \\hline \\textbf{Position} & \\mathbf{Instruction} \\\\ \\hline 0 & \\mathtt{\\$\\{getInput()\\} => A} \\\\ \\hline 1 & \\mathtt{-3 => B} \\\\ \\hline 2 & \\mathtt{:ADD} \\\\ \\hline 3 & \\mathtt{:JMPZ(5)} \\\\ \\hline 4 & \\mathtt{:ADD} \\\\ \\hline 5 & \\mathtt{0 => A, B} \\\\ \\hline \\end{array} \\] Note: We will discuss later on how to introduce negative values into our program. In programs with conditional jumps, our previous model will not work, because the flow of the program may vary depending on the values of the input. As it can be seen next, with conditional jumps, the length of the execution trace is not constant (it depends on the free input): \\[\\scriptsize \\begin{array}{|l|c|c|c|c|c|} \\hline \\mathbf{Instruction} & \\mathtt{free} & \\mathtt{A} & \\mathtt{A'} & \\mathtt{B} & \\mathtt{B'} \\\\ \\hline \\mathtt{\\$\\{getInput()\\} => A} & 7 & 0 & 7 & 0 & 0 \\\\ \\hline \\mathtt{-3 => B} & 0 & 7 & 7 & 0 & -3 \\\\ \\hline \\mathtt{:ADD} & 0 & 7 & 4 & -3 & -3 \\\\ \\hline \\mathtt{:JMPZ(5)} & 0 & 4 & 4 & -3 & -3 \\\\ \\hline \\mathtt{:ADD} & 0 & 4 & 1 & -3 & -3 \\\\ \\hline \\mathtt{0 => A, B} & 0 & 1 & 0 & -3 & 0 \\\\ \\hline \\end{array}\\] \\[\\scriptsize \\begin{array}{|l|c|c|c|c|c|} \\hline \\mathbf{Instruction} & \\mathtt{free} & \\mathtt{A} & \\mathtt{A'} & \\mathtt{B} & \\mathtt{B'} \\\\ \\hline \\mathtt{\\$\\{getInput()\\} => A} & 3 & 0 & 3 & 0 & 0 \\\\ \\hline \\mathtt{-3 => B} & 0 & 3 & 3 & 0 & -3 \\\\ \\hline \\mathtt{:ADD} & 0 & 3 & 0 & -3 & -3 \\\\ \\hline \\mathtt{:JMPZ(5)} & 0 & 0 & 0 & -3 & -3 \\\\ \\hline \\mathtt{0 => A, B} & 0 & 0 & 0 & -3 & 0 \\\\ \\hline \\end{array}\\] The first execution is done in 6 steps, meanwhile the second one has been done in 5 steps.","title":"Programs with Conditional Jumps"},{"location":"zkEVM/Basic-Concepts/simple-state-machine/#managing-conditional-jumps","text":"Now, let us introduce a new model to manage a program that contains conditional jumps. To do this, we need to add the Program Counter (PC) . The \\(\\mathtt{PC}\\) is a special registry that contains the position of the instruction in the program being executed. We use \\(\\texttt{op}_i\\) as a shorthand for the linear combination of our state machine to simplify the forthcoming constraints: $$ \\mathtt{op}^i := \\mathtt{setA}^i \\cdot \\mathtt{A}^i + \\mathtt{setB}^i \\cdot \\mathtt{B}^i + \\mathtt{inFree}^i \\cdot \\mathtt{free}^i + \\mathtt{const}^i. $$ The \\(\\mathtt{JMPZ}\\) instruction will jump to the instruction \\(\\texttt{addr}^i\\) (specified by the \\(\\mathtt{JMPZ}\\) instruction) if \\(\\texttt{op}^i\\) is zero. Let us first develop some procedure to check if our operation is or not zero in \\(\\mathbb{Z}_p\\) : To check that a number in the field \\(\\mathbb{Z}_p\\) is zero, we use the fact that a number \\(a\\) has a multiplicative inverse \\(a^{-1}\\) if and only if \\(a \\neq 0\\) . Using this fact, we use the following definition and constraint to do the \\(\\mathtt{isZero}\\) check: \\[\\begin{aligned} &\\mathtt{isZero}^i := 1 - \\mathtt{op}^i \\cdot (\\mathtt{op}^i)^{-1}, \\\\ &\\mathtt{isZero}^i \\cdot \\mathtt{op}^i = 0. \\end{aligned}\\] We can proof that the previous equations describe the desired check by case examination where \\(a \\neq 0\\) and \\(\\alpha, \\beta \\in \\mathbb{Z}_p\\) : \\(\\mathtt{op}^i = 0,~(\\mathtt{op}^i)^{-1} = \\alpha,~\\mathtt{isZero}^i = 1\\) passes the definition and constraint, \\(\\mathtt{op}^i = a,~(\\mathtt{op}^i)^{-1} = a^{-1},~\\mathtt{isZero}^i = 0\\) passes the definition and constraint. \\(\\mathtt{op}^i = 0,~(\\mathtt{op}^i)^{-1} = \\alpha,~\\mathtt{isZero}^i \\neq 1\\) does not pass the definition of \\(\\mathtt{isZero}\\) . \\(\\mathtt{op}^i = a,~(\\mathtt{op}^i)^{-1} = \\beta,~\\mathtt{isZero}^i \\neq 0\\) does not pass the definition and constraint, either you consider \\(\\beta = 0\\) , \\(\\beta = a^{-1}\\) or \\(\\beta \\neq a^{-1}\\) . We can mix the two equations into just one constraint: $$ \\mathtt{isZero}^i \\cdot \\mathtt{op}^i = 0,~~\\mathtt{isZero}^i = 1 - \\mathtt{op}^i \\cdot (\\mathtt{op}^i)^{-1}~~\\rightarrow~~(1 - \\mathtt{op}^i \\cdot (\\mathtt{op}^i)^{-1}) \\cdot \\mathtt{op}^i = 0. $$ Let us introduce the following machinery to our setup in order to introduce jumps: We add a selector \\(\\texttt{jmpz}^i \\in \\{0,1\\}\\) to our state machine to code the \\(\\mathtt{JMPZ}\\) instruction and express the behaviour of the PC . Then, the set of constraints is the following: \\[\\begin{aligned} &\\mathtt{op}^i := \\mathtt{setA}^i \\cdot \\mathtt{A}^i + \\mathtt{setB}^i \\cdot \\mathtt{B}^i + \\mathtt{inFree}^i \\cdot \\mathtt{free}^i + \\mathtt{const}^i, \\\\ &\\mathtt{PC}^{i+1} = \\mathtt{PC}^i + 1 + \\mathtt{jmpz}^i \\cdot (1 - \\mathtt{op}^i \\cdot (\\mathtt{op}^i)^{-1}) \\cdot (\\mathtt{addr}^i - \\mathtt{PC}^i - 1),\\\\ &(1 - \\mathtt{op}^i \\cdot (\\mathtt{op}^i)^{-1}) \\cdot \\mathtt{op}^i = 0. \\end{aligned}\\] Observe that: If \\(\\mathtt{op}^i \\neq 0\\) , then \\((1 - \\mathtt{op}^i \\cdot (\\mathtt{op}^i)^{-1}) = 0\\) and hence \\(\\mathtt{PC}^{i+1} = \\mathtt{PC}^i + 1\\) ; If \\(\\mathtt{op}^i = 0\\) , then \\((1 - \\mathtt{op}^i \\cdot (\\mathtt{op}^i)^{-1}) = 1\\) and hence \\(\\mathtt{PC}^{i+1} = \\mathtt{PC}^i + 1 + \\mathtt{addr}^i - \\mathtt{PC}^i - 1 = \\mathtt{addr}^i\\) . This is exactly the wanted behaviour. Next, we show the execution traces for the free inputs 7 and 3 respectively: \\[ \\tiny \\begin{array}{|l|} \\hline \\mathbf{Instruction} \\\\ \\hline \\mathtt{\\$\\{getInput()\\} => A} \\\\ \\hline \\mathtt{-3 => B} \\\\ \\hline \\mathtt{:ADD} \\\\ \\hline \\mathtt{:JMPZ(5)} \\\\ \\hline \\mathtt{:ADD} \\\\ \\hline \\mathtt{0 => A, B, PC} \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|} \\hline \\texttt{free} & \\textbf{const} & \\texttt{addr} & \\texttt{jmpz} & \\texttt{setB} & \\texttt{setA} & \\texttt{inFree} & \\texttt{selB} & \\texttt{selA} & \\texttt{op} & \\texttt{invOp} \\\\ \\hline 7 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 7 & 7^{-1} \\\\ \\hline 0 & -3 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & -3 & (-3)^{-1} \\\\ \\hline 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 1 & \\mathbf{\\color{blue!75!black} 4} & \\mathbf{\\color{blue!75!black} 4^{-1}} \\\\ \\hline 0 & 0 & 5 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ \\hline 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 1 & 1 & 1 \\\\ \\hline 0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|} \\hline \\mathtt{PC} & \\mathtt{PC'} & \\mathtt{A} & \\mathtt{A'} & \\mathtt{B} & \\mathtt{B'} \\\\ \\hline 0 & 1 & 0 & 7 & 0 & 0\\\\ \\hline 1 & 2 & 7 & 7 & 0 & -3\\\\ \\hline 2 & 3 & 7 & 4 & -3 & -3\\\\ \\hline 3 & 4 & 4 & 4 & -3 & -3\\\\ \\hline 4 & 5 & 4 & 1 & -3 & -3\\\\ \\hline 5 & 0 & 1 & 0 & -3 & 0\\\\ \\hline \\end{array} \\] \\[ \\tiny \\begin{array}{|l|} \\hline \\mathbf{Instruction} \\\\ \\hline \\mathtt{\\$\\{getInput()\\} => A} \\\\ \\hline \\mathtt{-3 => B} \\\\ \\hline \\mathtt{:ADD} \\\\ \\hline \\mathtt{:JMPZ(5)} \\\\ \\hline \\mathtt{0 => A, B} \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|c|} \\hline \\texttt{free} & \\texttt{const} & \\texttt{addr} & \\texttt{jmpz} & \\texttt{setB} & \\texttt{setA} & \\texttt{inFree} & \\texttt{selB} & \\texttt{selA} & \\texttt{op} & \\texttt{invOp} \\\\ \\hline 3 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 3 & 3^{-1} \\\\ \\hline 0 & -3 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & -3 & (-3)^{-1} \\\\ \\hline 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 1 & \\mathbf{\\color{blue!75!black} 0} & \\mathbf{\\color{blue!75!black} \\alpha} \\\\ \\hline 0 & 0 & 5 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ \\hline 0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|} \\hline \\mathtt{PC} & \\mathtt{PC'} & \\mathtt{A} & \\mathtt{A'} & \\mathtt{B} & \\mathtt{B'} \\\\ \\hline 0 & 1 & 0 & 3 & 0 & 0\\\\ \\hline 1 & 2 & 3 & 3 & 0 & -3\\\\ \\hline 2 & 3 & 3 & 0 & -3 & -3\\\\ \\hline 3 & 5 & 3 & 0 & -3 & -3\\\\ \\hline 5 & 0 & 0 & 0 & -3 & 0\\\\ \\hline \\end{array} \\] Note that we use \\(\\mathtt{invOp}\\) for the column containing the inverses of \\(\\mathtt{op}\\) . Note also that the \\(\\mathtt{PC}\\) turns to be an important registry when jumps are included in the set of possible instructions because jumps can modify the sequence of instructions that is executed also known as \"the trace\". Now, our polynomials are definitely not preprocessed, this is because the values of the table will not only depend on the program, but also on the free input values. Hence, we need to ensure that we are verifying the correct program.","title":"Managing Conditional Jumps"},{"location":"zkEVM/Basic-Concepts/simple-state-machine/#proving-the-execution-of-the-correct-program","text":"Up to now, we can prove that each instruction is correctly executed, but, how do we prove that we are executing the correct set of instructions, that is to say, that we are executing the \"correct program\"? The solution seems obvious: Check that every executed instruction is some instruction in the program, but how do we do this in a succinct manner? To do so, we have to provide a codification for each instruction and then we will check that the codification of the execution's instructions is included in the codification of the program's instructions. Let's begin showing how to encode the constant values of our instructions. As a particular example, consider that we want to use signed integers of 4 bits (in the real machine, we will use an analogous 32 bits codification). The four bit codification is shown next: \\[\\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|c|c|} \\hline -8 & -7 & -6 & ... & -2 & -1 & 0 & 1 & 2 & ... & 6 & 7 & 8 \\\\ \\hline 1000 & 1001 & 1010 & ... & 1110 & 1111 & 0000 & 0001 & 0010 & ... & 0110 & 0111 & 1000 \\\\ \\hline \\end{array}\\] Notice that with this arithmetic \\(8=-8\\) , which is a weird case that we discard, using only values from -7 to 7. Then, we encode these values in elements of the field \\(\\mathbb{Z}_p\\) : \\[\\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|} \\hline -7 & -6 & ... & -2 & -1 & 0 & 1 & 2 & ...& 6 & 7 \\\\ \\hline p-7 & p-6 & ... & p-2 & p-1 & 0 & 1 & 2 & ...& 6 & 7 \\\\ \\hline \\end{array}\\] So, we have to enforce that \\(\\mathsf{const}(x) \\in \\{p-7, p-6, ..., p-2, p-1, 0,1,2, ..., 6, 7\\}\\) . We enforce the previous condition with the following equivalent inclusion: \\[\\mathsf{const}(x) + 7 \\in \\{0,1,2,...,14\\}\\] Hence, we will use \\(\\mathsf{const}(x) + 7\\) in base \\(2\\) instead of \\(\\mathsf{const}(x)\\) to encode our instruction, just to avoid the sum. Let's now explain how to encode every distinct instruction to be executed by the program: \\[ \\scriptsize \\begin{array}{|c|l|} \\hline \\mathbf{Instruction} \\\\ \\hline \\mathtt{\\$\\{getInput()\\} => A} \\\\ \\hline \\mathtt{-3 => B} \\\\ \\hline \\mathtt{:ADD} \\\\ \\hline \\mathtt{:JMPZ(5)} \\\\ \\hline \\mathtt{:ADD} \\\\ \\hline \\mathtt{0 => A, B, PC} \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|} \\hline \\mathbf{\\color{blue!75!black} \\texttt{const+7}} & \\texttt{addr} & \\texttt{jmpz} & \\texttt{setB} & \\texttt{setA} & \\texttt{inFree} & \\texttt{selB} & \\texttt{selA} & \\texttt{instruction} \\\\ \\hline \\mathbf{\\color{blue!75!black} 7} & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 0111.0000.001100 \\\\ \\hline \\mathbf{\\color{blue!75!black} 4} & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0100.0000.010000 \\\\ \\hline \\mathbf{\\color{blue!75!black} 7} & 0 & 0 & 0 & 1 & 0 & 1 & 1 & 0111.0000.001011\\\\ \\hline \\mathbf{\\color{blue!75!black} 7} & 5 & 1 & 0 & 0 & 0 & 0 & 0 & 0111.0101.100000 \\\\ \\hline \\mathbf{\\color{blue!75!black} 7} & 0 & 0 & 0 & 1 & 0 & 1 & 1 & 0111.0000.001011 \\\\ \\hline \\mathbf{\\color{blue!75!black} 7} & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0111.0000.111000 \\\\ \\hline \\end{array} \\] Observe that we have codified the instruction using the following rule: $$ \\texttt{instruction}^i := 2^{10}\\cdot(\\texttt{const}^i + 7) + 2^6\\cdot \\texttt{addr}^i + 2^5\\cdot \\texttt{jmpz}^i + 2^4 \\cdot \\texttt{setB}^i + 2^3 \\cdot \\texttt{setA}^i + 2^2 \\cdot \\texttt{inFree}^i + 2 \\cdot \\texttt{selB}^i + \\texttt{selA}^i. $$ That is, we are codifying it as the concatenated base \\(2\\) integer of all the values (in the order of appearance on the table). Note that additionally, we will need to check that the selectors are binary and that \\(\\texttt{addr}\\) is composed of \\(4\\) bits, i.e., \\(\\texttt{addr}^i \\in \\{0, 1, \\dots, 15\\}\\) Also observe that, when \\(\\texttt{const}^i+7 = 7\\) , this means that \\(\\texttt{const}^i = 0\\) , so the constant is not used in those cases. Now, to prove the program, every instruction will be uniquely identified by its code and position in the program (we also use 4 bits in this example for the position). We define the \\(\\mathtt{ROM}\\) of the program as the sum between every instruction and the position in which it is defined: $$ \\texttt{ROM}^i := 2^{14} \\cdot \\texttt{position}^i + \\texttt{instruction}^i. $$ Observe that the \\(\\mathtt{ROM}\\) uniquely identifies the program we want to verify and it is independent of the different possible executions. The resulting \\(\\mathtt{ROM}\\) of our program is the following: \\[ \\begin{array}{|c|c|} \\hline \\texttt{position} & \\mathbf{Instruction} \\\\ \\hline 0 & \\mathtt{\\$\\{getInput()\\} => A} \\\\ \\hline 1 & \\mathtt{-3 => B} \\\\ \\hline 2 & \\mathtt{:ADD} \\\\ \\hline 3 & \\mathtt{:JMPZ(5)} \\\\ \\hline 4 & \\mathtt{:ADD} \\\\ \\hline 5 & \\mathtt{0 => A, B, PC} \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|} \\hline \\texttt{ROM} \\\\ \\hline 0111.0000.001100 \\\\ \\hline 0100.0000.010000 \\\\ \\hline 0111.0000.001011\\\\ \\hline 0111.0101.100000 \\\\ \\hline 0111.0000.001011 \\\\ \\hline 0111.0000.111000 \\\\ \\hline \\end{array} \\] We will encode the program trace using the PC: \\[ \\scriptsize \\begin{array}{|c|c|c|c|c|c|} \\hline \\mathtt{PC} \\\\ \\hline 0 \\\\ \\hline 1 \\\\ \\hline 2 \\\\ \\hline 3 \\\\ \\hline 4 \\\\ \\hline 5 \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|} \\hline \\mathtt{position} & \\mathbf{Instruction} \\\\ \\hline 0 & \\mathtt{\\$\\{getInput()\\} => A} \\\\ \\hline 1 & \\mathtt{-3 => B} \\\\ \\hline 2 & \\mathtt{:ADD} \\\\ \\hline 3 & \\mathtt{:JMPZ(5)} \\\\ \\hline 4 & \\mathtt{:ADD} \\\\ \\hline 5 & \\mathtt{0 => A, B, PC} \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|c|c|c|} \\hline \\texttt{const+7} & \\texttt{addr} & \\texttt{jmpz} & \\texttt{setB} & \\texttt{setA} & \\texttt{inFree} & \\texttt{selB} & \\texttt{selA} \\\\ \\hline 7 & 0 & 0 & 0 & 1 & 1 & 0 & 0 \\\\ \\hline 4 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\ \\hline 7 & 0 & 0 & 0 & 1 & 0 & 1 & 1 \\\\ \\hline 7 & 5 & 1 & 0 & 0 & 0 & 0 & 0 \\\\ \\hline 7 & 0 & 0 & 0 & 1 & 0 & 1 & 1 \\\\ \\hline 7 & 0 & 1 & 1 & 1 & 0 & 0 & 0 \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|} \\hline \\mathtt{insTrace} \\\\ \\hline 0000.0111.0000.001100 \\\\ \\hline 0001.0100.0000.010000 \\\\ \\hline 0010.0111.0000.001011\\\\ \\hline 0011.0111.0101.100000 \\\\ \\hline 0100.0111.0000.001011 \\\\ \\hline 0101.0111.0000.111000 \\\\ \\hline \\end{array} \\] \\[ \\scriptsize \\begin{array}{|c|c|c|c|c|c|} \\hline \\mathtt{PC} \\\\ \\hline 0 \\\\ \\hline 1 \\\\ \\hline 2 \\\\ \\hline 3 \\\\ \\hline 5 \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|} \\hline \\mathtt{position} & \\mathbf{Instruction} \\\\ \\hline 0 & \\mathtt{\\$\\{getInput()\\} => A} \\\\ \\hline 1 & \\mathtt{-3 => B} \\\\ \\hline 2 & \\mathtt{:ADD} \\\\ \\hline 3 & \\mathtt{:JMPZ(5)} \\\\ \\hline 4 & \\mathtt{0 => A, B, PC} \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|c|c|c|} \\hline \\texttt{const+7} & \\texttt{addr} & \\texttt{jmpz} & \\texttt{setB} & \\texttt{setA} & \\texttt{inFree} & \\texttt{selB} & \\texttt{selA} \\\\ \\hline 7 & 0 & 0 & 0 & 1 & 1 & 0 & 0 \\\\ \\hline 4 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\ \\hline 7 & 0 & 0 & 0 & 1 & 0 & 1 & 1 \\\\ \\hline 7 & 5 & 1 & 0 & 0 & 0 & 0 & 0 \\\\ \\hline 7 & 0 & 1 & 1 & 1 & 0 & 0 & 0 \\\\ \\hline \\end{array} \\hspace{0.1cm} \\begin{array}{|c|c|c|c|c|c|} \\hline \\mathtt{insTrace} \\\\ \\hline 0000.0111.0000.001100 \\\\ \\hline 0001.0100.0000.010000 \\\\ \\hline 0010.0111.0000.001011\\\\ \\hline 0011.0111.0101.100000 \\\\ \\hline 0101.0111.0000.111000 \\\\ \\hline \\end{array} \\] Recall that our main question was: How do we actually check correctness in an efficient manner? We can achieve it with the Plookup protocol. So, to check that the correct program is being executed, we simply have to use Plookup to determine if: \\[\\mathsf{insTrace(x)} \\subset \\mathsf{ROM(x)}\\] In words, the trace being executed is an execution of the actual program if the instruction trace is contained in the ROM of the program.","title":"Proving the Execution of the \"Correct Program\""},{"location":"zkEVM/Basic-Concepts/simple-state-machine/#identities-to-prove-an-execution-trace","text":"As a summary, we have seen that the following set of identities are used to define our program: \\[\\begin{aligned} &\\mathsf{A}(x\\omega) = \\mathsf{A}(x) + \\mathsf{setA}(x) \\cdot (\\mathsf{op}(x) - \\mathsf{A}(x)), \\\\ &\\mathsf{B}(x\\omega) = \\mathsf{B}(x) + \\mathsf{setB}(x) \\cdot (\\mathsf{op}(x) - \\mathsf{B}(x)), \\\\ &\\mathsf{PC}(x\\omega) = \\mathsf{PC}(x) + 1 + \\mathsf{jmpz}(x) \\cdot (1 - \\mathsf{op}(x) \\cdot \\mathsf{invOp}(x)) \\cdot (\\mathsf{addr}(x) - \\mathsf{PC}(x) - 1), \\\\ &(1 - \\mathsf{op}(x) \\cdot \\mathsf{invOp}(x)) \\cdot \\mathsf{op}(x) = 0. \\end{aligned}\\] With the following definition: $$ \\mathsf{op}(x) := \\mathsf{selA}(x) \\cdot \\mathsf{A}(x) + \\mathsf{selB}(x) \\cdot \\mathsf{B}(x) + \\mathsf{inFree}(x) \\cdot \\mathsf{free}(x) + \\mathsf{const}(x). $$ Moreover, we should add the following Plookup checks: \\[\\begin{aligned} &\\textsf{const}(x) + 7 \\subset \\{0,1, \\dots, 14\\},\\\\ &\\mathsf{addr}(x) \\subset \\{0,1, \\dots, 15\\},\\\\ &\\mathsf{position}(x) \\subset \\{0,1, \\dots, 15\\},\\\\ &\\mathsf{PC}(x) \\subset \\{0,1, \\dots, 15\\},\\\\ &\\textsf{insTrace}(x) \\subset \\textsf{ROM}(x). \\end{aligned}\\] With the following definitions: \\[\\begin{aligned} &\\textsf{instruction}(x) := 2^{10}\\cdot(\\textsf{const}(x) + 7) + 2^6\\cdot \\textsf{addr}(x) + 2^5\\cdot \\textsf{jmpz}(x) + 2^4 \\cdot \\textsf{setB}(x) + \\\\ &\\qquad \\qquad \\qquad \\quad~~2^3 \\cdot \\textsf{setA}(x) + 2^2 \\cdot \\textsf{inFree}(x) + 2 \\cdot \\textsf{selB}(x) + \\textsf{selA}(x),\\\\ &\\textsf{ROM}(x) := 2^{14} \\cdot \\textsf{position}(x) + \\textsf{instruction}(x), \\\\ &\\textsf{insTrace}(x) := 2^{14} \\cdot \\textsf{PC}(x) + \\textsf{instruction}(x). \\end{aligned}\\] Finally, it should be checked that the whole set of selectors are, in fact, binary: \\[\\begin{aligned} &\\mathsf{selA}(x) \\cdot (\\mathsf{selA}(x) - 1) = 0, \\quad \\mathsf{setA}(x) \\cdot (\\mathsf{setA}(x) - 1) = 0, \\quad\\\\ &\\mathsf{selB}(x) \\cdot (\\mathsf{selB}(x)- 1) = 0, \\quad \\mathsf{setB}(x) \\cdot (\\mathsf{setB}(x) - 1) = 0, \\quad\\\\ &\\mathsf{inFree}(x) \\cdot (\\mathsf{inFree}(x) - 1) = 0, \\quad \\mathsf{jmpz}(x) \\cdot (\\mathsf{jmpz}(x) - 1) = 0. \\end{aligned}\\] Regarding the polynomials, in this state machine: We have to commit \\(\\textsf{inFree}(x), \\textsf{selA}(x), \\textsf{selB}(x), \\textsf{setA}(x), \\textsf{setB}(x)\\) \\(\\textsf{A}(x), \\textsf{B}(x), \\textsf{const}(x),\\) \\(\\textsf{jmpz}(x),\\) \\(\\textsf{invOp}(x)\\) , \\(\\textsf{addr}(x)\\) , \\(\\textsf{free}(x)\\) , \\(\\textsf{position}(x)\\) and \\(\\textsf{PC}(x)\\) . While the only constant (preprocessed) polynomial is \\(\\textsf{ROM}(x)\\) .","title":"Identities to Prove an Execution Trace"},{"location":"zkEVM/PIL/advanced-features/","text":"This last section wraps the document by introducing some advanced features that PIL supports, such as permutation checks over multiple (possibly distinct) domains. Public Inputs Public inputs are values of a polynomial that are known prior to the execution of a state machine. In the following example, the public input \\(\\texttt{publicInput}\\) is set to be the first element of the polynomial \\(\\texttt{a}\\) and a colon \" \\(:\\) \" is used to indicate this to the compiler (see line 12 in the code excerpt below). Code Excerpt 19: Public Inputs PIL Example Note here, the use of the Lagrange polynomial \\(L_1\\) to create a constraint, \\[ L_1 \\cdot (\\texttt{a} - :\\texttt{publicInput}) = 0. \\] Whenever relevant, the constraint enforces the value of \\(\\texttt{a}\\) to be equal to \\(\\texttt{publicInput}\\) . Permutation Check In this example we use the \\(\\texttt{is}\\) keyword to denote that the vectors \\([\\texttt{sm1.a},\\texttt{sm1.b},\\texttt{sm1.c}]\\) and \\([\\texttt{sm2.a}, \\texttt{sm2.b}, \\texttt{sm2.c}]\\) are a permutation of each other, seen as evaluations over the designated domain. Code Excerpt 20: Permutation Check PIL Example This constraint becomes useful to connect distinct state machines, since it is forcing that polynomials belonging to different state machines are the same (up to permutation). Two Special Functionalities Here are some vectors for which the \\(\\texttt{in}\\) and \\(\\texttt{is}\\) functionalities are designed for: \\[\\begin{array}{ccc} (3,2) & \\text{in} & (1,2,3,4)\\\\ (1,5,5,5,8,1,1,2) & \\text{in} & (1,2,4,5,8)\\\\ (3,2,3,1) & \\text{is} & (1,2,3,3)\\\\ (5,5,6,9,0) & \\text{is} & (6,5,9,0,5). \\end{array}\\] The Connect Keyword The \\(\\texttt{connect}\\) keyword is introduced to denote that the copy constraint argument is applied to \\([\\texttt{a},\\texttt{b},\\texttt{c}]\\) using the permutation induced by \\([\\texttt{SA}, \\texttt{SB}, \\texttt{SC}]\\) . Code Excerpt 21: Connect Keywords PIL Example Naturally, the previous feature can be used to describe the correctness of an entire PlonK circuit in PIL: Code Excerpt 22: Plonk Circuit in PIL Permutation Check with Multiple Domain Another important feature is the possibility to prove that polynomials of distinct state machines are the same (up to permutation) in a subset of its elements. This helps to improve efficiency when state machines are defined over subgroups of distinct size, since without this permutation argument one would need to equal the size of both polynomials. PIL introduces this possibility by the introducing selectors that choose the subset of elements to be included in the permutation argument. Code Excerpt 23: Permutation Argument in PIL Any combination of \\(\\texttt{sel}\\) , \\(\\texttt{not sel}\\) and \\(\\texttt{in}\\) , \\(\\texttt{is}\\) are available as permutation arguments. This leads to a total of \\(4\\) possibilities. Figure 18 depicts an example of the permutation multi-domain protocol, with one selector per table, that is, we prove that: \\[ \\text{sel } \\cdot [a,b,c] = \\sigma\\left(\\text{sel' } \\cdot [d,e,f]\\right). \\] Figure 18: Permutation Multi-Domain Protocol","title":"Advanced Features"},{"location":"zkEVM/PIL/advanced-features/#public-inputs","text":"Public inputs are values of a polynomial that are known prior to the execution of a state machine. In the following example, the public input \\(\\texttt{publicInput}\\) is set to be the first element of the polynomial \\(\\texttt{a}\\) and a colon \" \\(:\\) \" is used to indicate this to the compiler (see line 12 in the code excerpt below). Code Excerpt 19: Public Inputs PIL Example Note here, the use of the Lagrange polynomial \\(L_1\\) to create a constraint, \\[ L_1 \\cdot (\\texttt{a} - :\\texttt{publicInput}) = 0. \\] Whenever relevant, the constraint enforces the value of \\(\\texttt{a}\\) to be equal to \\(\\texttt{publicInput}\\) .","title":"Public Inputs"},{"location":"zkEVM/PIL/advanced-features/#permutation-check","text":"In this example we use the \\(\\texttt{is}\\) keyword to denote that the vectors \\([\\texttt{sm1.a},\\texttt{sm1.b},\\texttt{sm1.c}]\\) and \\([\\texttt{sm2.a}, \\texttt{sm2.b}, \\texttt{sm2.c}]\\) are a permutation of each other, seen as evaluations over the designated domain. Code Excerpt 20: Permutation Check PIL Example This constraint becomes useful to connect distinct state machines, since it is forcing that polynomials belonging to different state machines are the same (up to permutation).","title":"Permutation Check"},{"location":"zkEVM/PIL/advanced-features/#two-special-functionalities","text":"Here are some vectors for which the \\(\\texttt{in}\\) and \\(\\texttt{is}\\) functionalities are designed for: \\[\\begin{array}{ccc} (3,2) & \\text{in} & (1,2,3,4)\\\\ (1,5,5,5,8,1,1,2) & \\text{in} & (1,2,4,5,8)\\\\ (3,2,3,1) & \\text{is} & (1,2,3,3)\\\\ (5,5,6,9,0) & \\text{is} & (6,5,9,0,5). \\end{array}\\]","title":"Two Special Functionalities"},{"location":"zkEVM/PIL/advanced-features/#the-connect-keyword","text":"The \\(\\texttt{connect}\\) keyword is introduced to denote that the copy constraint argument is applied to \\([\\texttt{a},\\texttt{b},\\texttt{c}]\\) using the permutation induced by \\([\\texttt{SA}, \\texttt{SB}, \\texttt{SC}]\\) . Code Excerpt 21: Connect Keywords PIL Example Naturally, the previous feature can be used to describe the correctness of an entire PlonK circuit in PIL: Code Excerpt 22: Plonk Circuit in PIL","title":"The Connect Keyword"},{"location":"zkEVM/PIL/advanced-features/#permutation-check-with-multiple-domain","text":"Another important feature is the possibility to prove that polynomials of distinct state machines are the same (up to permutation) in a subset of its elements. This helps to improve efficiency when state machines are defined over subgroups of distinct size, since without this permutation argument one would need to equal the size of both polynomials. PIL introduces this possibility by the introducing selectors that choose the subset of elements to be included in the permutation argument. Code Excerpt 23: Permutation Argument in PIL Any combination of \\(\\texttt{sel}\\) , \\(\\texttt{not sel}\\) and \\(\\texttt{in}\\) , \\(\\texttt{is}\\) are available as permutation arguments. This leads to a total of \\(4\\) possibilities. Figure 18 depicts an example of the permutation multi-domain protocol, with one selector per table, that is, we prove that: \\[ \\text{sel } \\cdot [a,b,c] = \\sigma\\left(\\text{sel' } \\cdot [d,e,f]\\right). \\] Figure 18: Permutation Multi-Domain Protocol","title":"Permutation Check with Multiple Domain"},{"location":"zkEVM/PIL/components/","text":"The aim with this section is to explain most of the PIL components in-depth. Namespaces Code Excerpt 6: PIL Namespace File State machines in PIL are organized in namespaces . Namespaces are written with the keyword \\(\\texttt{namespace}\\) followed by the name of the state machine, and they can optionally include other parameters. In the previous snippet, a state machine called \\(\\texttt{Name}\\) is created. The namespace keyword opens a workspace for the developer to englobe all the polynomials and identities of a single state machine. Every component of a state machine is included within its namespace. There is a one-to-one correspondence between state machine and namespaces. The same name cannot be used twice between state machines that are directly or indirectly related, since this would cause an overlap in the lookup arguments and the compiler would not be able to decide. So, for instance the following two examples are not allowed, Code Excerpt 7: PIL No Common Names Polynomials Code Excerpt 8: PIL Constant and Committed Polynomials Polynomials are the key component of PIL. Values of polynomials have to be compared with computational trace's columns. In fact, in PIL, the two are considered to be the same thing. More precisely, polynomials are just the interpolation of the columns over all the rows of the computational trace. Every polynomial is prefixed with the keyword \\(\\texttt{pol}\\) and needs to be explicitly set to be either a constant (also known as preprocessed ) or committed. Polynomials fall into these two categories depending on the origin of their creation or how they are going to be used. Consequently, in PIL there exist two keywords to denote the two types of polynomials: \\(\\texttt{constant}\\) and \\(\\texttt{commit}\\) . Constant Polynomials Code Excerpt 9: A Constant in PIL Constant polynomials , also known in the literature as preprocessed polynomials , are polynomials known prior to the execution of the state machine. They correspond to polynomials that do not change during the execution, and are known to both the prover \\(\\mathcal{P}\\) and the verifier \\(\\mathcal{V}\\) prior to execution. They can be thought of as the preprocessed polynomials of an arithmetic circuit. A typical use of these polynomials is in the inclusion of selectors, latches and sequencers. A constant polynomial is created or initialize as a polynomial with the keyword \\(\\texttt{constant}\\) . And it is typically written in uppercase. This is good practice as it helps to differentiate them from the committed ones. Committed Polynomials Code Excerpt 9: A Constant in PIL Committed polynomials are not known prior to the execution of the state machine. They are analogous to variables because their values change during execution, and are only known to the prover \\(\\mathcal{P}\\) . In order to create a committed polynomial, simply prefix the polynomial in question with the keyword \\(\\texttt{committed}\\) (in the same way a variable-type is declared in standard programming languages). These polynomials are typically divided between input polynomials and state variables . Although they are instantiated in the usual way, their purpose is completely different in the PIL context. Free Input Polynomials Free input polynomials are used to introduce data to the state machines. Each individual state machine applies its specific logic over the data introduced by these polynomials when executing computations. The data is considered the output of some state transition (or the output of the state machine, if it is the last transition). Also, free input polynomials are introduced by the prover, yet they are unknown to the verifier. They are therefore labelled, and prefixed, as \\(\\texttt{committed}\\) . State Variables State variables are a set of values considered to be the state of the state machine. These polynomials play a pivotal role in the state machines, which is to help the prover focus on the correct evolution of the state variables during the generation of a proof. The output of the computation in each state transition is included in the state variables. The state of the state variables in the last transition is the \\(\\textit{output}\\) of the computation. State variables depend on the input and the constant polynomials. They are also therefore labelled as committed. Polynomial Element Types Code Excerpt 10: Types of Polynomial Element A polynomial definition can also contain a keyword indicating the type of elements a polynomial is composed of. Types include, for instance, \\(\\texttt{bool}\\) , \\(\\texttt{u16}\\) , \\(\\texttt{field}\\) . The type is strictly informative. This means that to enforce the elements of some polynomial to be restricted over some smaller domain, one should include a constraint reflecting the bounds. Constraints The set of constraints is one of the most important part of a PIL code. The constraints are defined to be the set of relations between polynomials that dictate the correct evolution of the state machine at every step. A state machine does what it does because the set of constraints enforces such a behavior. Code Excerpt 11: Polynomial Constraints Constraints can generally be of the following types (to be changed), Code Excerpt 12: The Main Polynomial Constraints","title":"Components"},{"location":"zkEVM/PIL/components/#namespaces","text":"Code Excerpt 6: PIL Namespace File State machines in PIL are organized in namespaces . Namespaces are written with the keyword \\(\\texttt{namespace}\\) followed by the name of the state machine, and they can optionally include other parameters. In the previous snippet, a state machine called \\(\\texttt{Name}\\) is created. The namespace keyword opens a workspace for the developer to englobe all the polynomials and identities of a single state machine. Every component of a state machine is included within its namespace. There is a one-to-one correspondence between state machine and namespaces. The same name cannot be used twice between state machines that are directly or indirectly related, since this would cause an overlap in the lookup arguments and the compiler would not be able to decide. So, for instance the following two examples are not allowed, Code Excerpt 7: PIL No Common Names","title":"Namespaces"},{"location":"zkEVM/PIL/components/#polynomials","text":"Code Excerpt 8: PIL Constant and Committed Polynomials Polynomials are the key component of PIL. Values of polynomials have to be compared with computational trace's columns. In fact, in PIL, the two are considered to be the same thing. More precisely, polynomials are just the interpolation of the columns over all the rows of the computational trace. Every polynomial is prefixed with the keyword \\(\\texttt{pol}\\) and needs to be explicitly set to be either a constant (also known as preprocessed ) or committed. Polynomials fall into these two categories depending on the origin of their creation or how they are going to be used. Consequently, in PIL there exist two keywords to denote the two types of polynomials: \\(\\texttt{constant}\\) and \\(\\texttt{commit}\\) .","title":"Polynomials"},{"location":"zkEVM/PIL/components/#constant-polynomials","text":"Code Excerpt 9: A Constant in PIL Constant polynomials , also known in the literature as preprocessed polynomials , are polynomials known prior to the execution of the state machine. They correspond to polynomials that do not change during the execution, and are known to both the prover \\(\\mathcal{P}\\) and the verifier \\(\\mathcal{V}\\) prior to execution. They can be thought of as the preprocessed polynomials of an arithmetic circuit. A typical use of these polynomials is in the inclusion of selectors, latches and sequencers. A constant polynomial is created or initialize as a polynomial with the keyword \\(\\texttt{constant}\\) . And it is typically written in uppercase. This is good practice as it helps to differentiate them from the committed ones.","title":"Constant Polynomials"},{"location":"zkEVM/PIL/components/#committed-polynomials","text":"Code Excerpt 9: A Constant in PIL Committed polynomials are not known prior to the execution of the state machine. They are analogous to variables because their values change during execution, and are only known to the prover \\(\\mathcal{P}\\) . In order to create a committed polynomial, simply prefix the polynomial in question with the keyword \\(\\texttt{committed}\\) (in the same way a variable-type is declared in standard programming languages). These polynomials are typically divided between input polynomials and state variables . Although they are instantiated in the usual way, their purpose is completely different in the PIL context. Free Input Polynomials Free input polynomials are used to introduce data to the state machines. Each individual state machine applies its specific logic over the data introduced by these polynomials when executing computations. The data is considered the output of some state transition (or the output of the state machine, if it is the last transition). Also, free input polynomials are introduced by the prover, yet they are unknown to the verifier. They are therefore labelled, and prefixed, as \\(\\texttt{committed}\\) . State Variables State variables are a set of values considered to be the state of the state machine. These polynomials play a pivotal role in the state machines, which is to help the prover focus on the correct evolution of the state variables during the generation of a proof. The output of the computation in each state transition is included in the state variables. The state of the state variables in the last transition is the \\(\\textit{output}\\) of the computation. State variables depend on the input and the constant polynomials. They are also therefore labelled as committed.","title":"Committed Polynomials"},{"location":"zkEVM/PIL/components/#polynomial-element-types","text":"Code Excerpt 10: Types of Polynomial Element A polynomial definition can also contain a keyword indicating the type of elements a polynomial is composed of. Types include, for instance, \\(\\texttt{bool}\\) , \\(\\texttt{u16}\\) , \\(\\texttt{field}\\) . The type is strictly informative. This means that to enforce the elements of some polynomial to be restricted over some smaller domain, one should include a constraint reflecting the bounds.","title":"Polynomial Element Types"},{"location":"zkEVM/PIL/components/#constraints","text":"The set of constraints is one of the most important part of a PIL code. The constraints are defined to be the set of relations between polynomials that dictate the correct evolution of the state machine at every step. A state machine does what it does because the set of constraints enforces such a behavior. Code Excerpt 11: Polynomial Constraints Constraints can generally be of the following types (to be changed), Code Excerpt 12: The Main Polynomial Constraints","title":"Constraints"},{"location":"zkEVM/PIL/cyclical-nature/","text":"There is one implicit complexity in the design of state machines: \\[ \\textbf{State machines should have a cyclical nature.} \\] This means the description (in terms of constraints) of a state machine is not correct if the appropriate constraints are not satisfied in every row transition. In particular, this should remain true in the transition from the last row to the first row. This is an important aspect that has to be taken care of when designing the set of constraints of a state machine. Figure 10: Cyclic Nature of State Machines If there is some constraint that is not satisfied in the last transition, one normally overcomes this problem by adding artificial values in latter evaluations of some polynomials. For example, consider the following state machine with its respective computational trace. Code Excerpt 13: State Machine Example Clearly, the constraint \\(b' = b+a\\) is not satisfied in the last transition: \\((a,b) = (1,2)\\) to \\((a,b) = (1,1)\\) . This can be solved by appending two extra rows. Figure 11 shows how this can be performed in the previous example. Figure 11: Inducing a Cyclic Nature Another option would be the introduction of a selector: Code Excerpt 14: State Machine Example As it can be seen in the above code excerpt, now the cost of adding extra rows has been substituted by the addition of the selector \\(\\texttt{SEL}\\) . A third option (when possible) is taking advantage of some existing selectors to accommodate latter values.","title":"Cyclical Nature"},{"location":"zkEVM/PIL/hello-world-examples/","text":"In this section, an exploration of some state machine examples is presented. State Machine that Multiplies Two Numbers Consider a state machine that takes two input numbers \\(x\\) and \\(y\\) , and multiplies them. Hence call the state machine, the Multiplier state machine, described by the function; \\[ f(x,y) = x \\cdot y. \\] Table 5 below, shows the computational trace on various inputs. As it can be observed, the input to this computation is fed into the two free input polynomials, \\(\\texttt{freeIn}_1\\) and \\(\\texttt{freeIn}_2\\) , and the output of this computation is set to the output polynomial \\(\\texttt{out}\\) , which contains the product of the free input polynomials. Table 5: Computational Trace for the Multiplier State Machine The nature of the previous polynomials suggests the following classification, \\(\\textbf{Free Input Polynomials}\\) . These are polynomials which are in charge of introducing the various inputs to the computation.They are referred to as \"free\" because at every clocking of the computation their values do not strictly depend on any previous iteration. These are analogous to independent variables of the entire computation. \\(\\textbf{State Variables}\\) . These are the polynomials that compose the state of the state machine. Here state refers to the set of values that represent the output of the state machine at each step and, if we are in the last step, the output of the entire computation. Figure 6 below provides a diagram of this division. Figure 6: Multiplier State Machine with the distinct polynomials In order to achieve correct behaviour of this state machine, one obvious constraint that must be satisfied is, \\[ \\texttt{out} = \\texttt{freeIn}_1 \\cdot \\texttt{freeIn}_2. \\] In PIL, all the components (polynomials and identities) of this state machine are introduced as shown in the code snippet below: Code Excerpt 1: Components of PIL The problem with this design is that the number of committed polynomials grows linearly with the number of multiplications; so that, if we would have to compute a huge number of (possibly distinct) operations, the number of free input polynomials would be unnecessarily big. Reduction of the number of free input polynomials can be achieved by introducing constant polynomials. These are preprocessed inputs to the state machine. That is, polynomials known prior to the execution of the computation and used as selectors, latches or sequencers, among other roles. Figure 7 below, is an updated version of Figure 6 above. The difference being an addition of constants. Figure 6: Multiplier State Machine with the Constant Polynomials Table 8 shows the computational trace for the optimized Multiplier state machine. Table 6: State Machine with the Constant Polynomials Now, the two inputs to this computation are sequentially fed into the only free input polynomial \\(\\texttt{freeIn}\\) . In the first step, the first input \\(x=4\\) is moved from \\(\\texttt{freeIn}\\) to \\(\\texttt{out}\\) . In the second step, \\(x\\) is multiplied by the second input \\(y=2\\) , and the result is set to be in \\(\\texttt{out}\\) . In order to achieve the correctness of this new version, the previous constraint is changed so that the constant polynomial \\(\\texttt{SET}\\) helps in achieving the desired behavior: \\[ \\texttt{out}' = \\texttt{SET} \\cdot \\texttt{freeIn} + (1 - \\texttt{SET}) \\cdot (\\texttt{out} \\cdot \\texttt{freeIn}). \\] Notice how the \\(\\texttt{SET}\\) polynomial helps out with the branching. On the one hand, whenever \\(\\texttt{SET}\\) is set to \\(1\\) , then \\(\\texttt{freeIn}\\) is moved to the next value of \\(\\texttt{out}\\) . While on the other hand, when \\(\\texttt{SET}\\) is set to \\(0\\) , then the stored value in \\(\\texttt{out}\\) is multiplied by the actual value of \\(\\texttt{freeIn}\\) , which corresponds to the second input to the computation. Note that as a convention, a tick \\('\\) (which is read \"prime\") is used to denote the \"next\" iteration. In the case of polynomials defined over the roots of unity, this notation translates to, \\[ f'(X) := f(\\omega X). \\] In PIL, the optimized Multiplier is implemented as follows, Code Excerpt 2: Optimised Multiplier State Machine A State Machine that Generates 4-Byte Numbers Consider now building a state machine that takes two \\(2\\) -byte numbers and generates a \\(4\\) -byte number from them. Since the logic of this state machine is similar to the previous one, the number of polynomials (and its meaning) is also the same. In the first step, the first input \\(x\\) is moved from \\(\\texttt{freeIn}\\) to \\(\\texttt{out}\\) . In a second step, \\(x\\) is concatenated to the second input \\(y\\) and set to be in \\(\\texttt{out}\\) . Table 9 shows the computational trace for a Byte4 state machine. Table 9: Computational Trace for the Byte4 State Machine For the purpose of displaying PIL's new features, the Byte4 state machine is built in a modular manner as illustrated next. First, deploy the configuration file, called config.pil, which is typically used to include some configuration-related components, shared among various state machines. In the example below, this configuration file will include the definition of a constant \\(N\\) representing the upper bound for the number of rows to be used across various state machines. Code Excerpt 3: PIL Configuration File for the Byte4 State Machine Second, use the Global state machine. This state machine is used to store various polynomials representing \"small\" lookup tables, to be used by other state machines. For instance, defining the Lagrange polynomial \\(L_1\\) or the polynomial representing the set of \\(1\\) -byte numbers. As we have set this state machine to have size \\(N\\) , there are some polynomials that need to be accommodated in size. Code Excerpt 4: PIL Global File for the Byte4 State Machine Third, and finally, the Byte4 state machine is completed. Similar to the previous example, the constraint that needs to be satisfied is the following: \\[ \\texttt{out}' = \\texttt{SET} \\cdot \\texttt{freeIn} + (1 - \\texttt{SET}) \\cdot (2^{16} \\cdot \\texttt{out} + \\texttt{freeIn}). \\] Note how the product \\(2^{16} \\cdot \\texttt{out}\\) forces the state machine to allocate the value from \\(\\texttt{out}\\) at the upper part of the result, while the addition of \\(\\texttt{freeIn}\\) allocates them at the lower part of the result. This state machine is implemented in PIL as follows: Code Excerpt 5: The Byte4 State Machine PIL File","title":"Hello Word Examples"},{"location":"zkEVM/PIL/hello-world-examples/#state-machine-that-multiplies-two-numbers","text":"Consider a state machine that takes two input numbers \\(x\\) and \\(y\\) , and multiplies them. Hence call the state machine, the Multiplier state machine, described by the function; \\[ f(x,y) = x \\cdot y. \\] Table 5 below, shows the computational trace on various inputs. As it can be observed, the input to this computation is fed into the two free input polynomials, \\(\\texttt{freeIn}_1\\) and \\(\\texttt{freeIn}_2\\) , and the output of this computation is set to the output polynomial \\(\\texttt{out}\\) , which contains the product of the free input polynomials. Table 5: Computational Trace for the Multiplier State Machine The nature of the previous polynomials suggests the following classification, \\(\\textbf{Free Input Polynomials}\\) . These are polynomials which are in charge of introducing the various inputs to the computation.They are referred to as \"free\" because at every clocking of the computation their values do not strictly depend on any previous iteration. These are analogous to independent variables of the entire computation. \\(\\textbf{State Variables}\\) . These are the polynomials that compose the state of the state machine. Here state refers to the set of values that represent the output of the state machine at each step and, if we are in the last step, the output of the entire computation. Figure 6 below provides a diagram of this division. Figure 6: Multiplier State Machine with the distinct polynomials In order to achieve correct behaviour of this state machine, one obvious constraint that must be satisfied is, \\[ \\texttt{out} = \\texttt{freeIn}_1 \\cdot \\texttt{freeIn}_2. \\] In PIL, all the components (polynomials and identities) of this state machine are introduced as shown in the code snippet below: Code Excerpt 1: Components of PIL The problem with this design is that the number of committed polynomials grows linearly with the number of multiplications; so that, if we would have to compute a huge number of (possibly distinct) operations, the number of free input polynomials would be unnecessarily big. Reduction of the number of free input polynomials can be achieved by introducing constant polynomials. These are preprocessed inputs to the state machine. That is, polynomials known prior to the execution of the computation and used as selectors, latches or sequencers, among other roles. Figure 7 below, is an updated version of Figure 6 above. The difference being an addition of constants. Figure 6: Multiplier State Machine with the Constant Polynomials Table 8 shows the computational trace for the optimized Multiplier state machine. Table 6: State Machine with the Constant Polynomials Now, the two inputs to this computation are sequentially fed into the only free input polynomial \\(\\texttt{freeIn}\\) . In the first step, the first input \\(x=4\\) is moved from \\(\\texttt{freeIn}\\) to \\(\\texttt{out}\\) . In the second step, \\(x\\) is multiplied by the second input \\(y=2\\) , and the result is set to be in \\(\\texttt{out}\\) . In order to achieve the correctness of this new version, the previous constraint is changed so that the constant polynomial \\(\\texttt{SET}\\) helps in achieving the desired behavior: \\[ \\texttt{out}' = \\texttt{SET} \\cdot \\texttt{freeIn} + (1 - \\texttt{SET}) \\cdot (\\texttt{out} \\cdot \\texttt{freeIn}). \\] Notice how the \\(\\texttt{SET}\\) polynomial helps out with the branching. On the one hand, whenever \\(\\texttt{SET}\\) is set to \\(1\\) , then \\(\\texttt{freeIn}\\) is moved to the next value of \\(\\texttt{out}\\) . While on the other hand, when \\(\\texttt{SET}\\) is set to \\(0\\) , then the stored value in \\(\\texttt{out}\\) is multiplied by the actual value of \\(\\texttt{freeIn}\\) , which corresponds to the second input to the computation. Note that as a convention, a tick \\('\\) (which is read \"prime\") is used to denote the \"next\" iteration. In the case of polynomials defined over the roots of unity, this notation translates to, \\[ f'(X) := f(\\omega X). \\] In PIL, the optimized Multiplier is implemented as follows, Code Excerpt 2: Optimised Multiplier State Machine","title":"State Machine that Multiplies Two Numbers"},{"location":"zkEVM/PIL/hello-world-examples/#a-state-machine-that-generates-4-byte-numbers","text":"Consider now building a state machine that takes two \\(2\\) -byte numbers and generates a \\(4\\) -byte number from them. Since the logic of this state machine is similar to the previous one, the number of polynomials (and its meaning) is also the same. In the first step, the first input \\(x\\) is moved from \\(\\texttt{freeIn}\\) to \\(\\texttt{out}\\) . In a second step, \\(x\\) is concatenated to the second input \\(y\\) and set to be in \\(\\texttt{out}\\) . Table 9 shows the computational trace for a Byte4 state machine. Table 9: Computational Trace for the Byte4 State Machine For the purpose of displaying PIL's new features, the Byte4 state machine is built in a modular manner as illustrated next. First, deploy the configuration file, called config.pil, which is typically used to include some configuration-related components, shared among various state machines. In the example below, this configuration file will include the definition of a constant \\(N\\) representing the upper bound for the number of rows to be used across various state machines. Code Excerpt 3: PIL Configuration File for the Byte4 State Machine Second, use the Global state machine. This state machine is used to store various polynomials representing \"small\" lookup tables, to be used by other state machines. For instance, defining the Lagrange polynomial \\(L_1\\) or the polynomial representing the set of \\(1\\) -byte numbers. As we have set this state machine to have size \\(N\\) , there are some polynomials that need to be accommodated in size. Code Excerpt 4: PIL Global File for the Byte4 State Machine Third, and finally, the Byte4 state machine is completed. Similar to the previous example, the constraint that needs to be satisfied is the following: \\[ \\texttt{out}' = \\texttt{SET} \\cdot \\texttt{freeIn} + (1 - \\texttt{SET}) \\cdot (2^{16} \\cdot \\texttt{out} + \\texttt{freeIn}). \\] Note how the product \\(2^{16} \\cdot \\texttt{out}\\) forces the state machine to allocate the value from \\(\\texttt{out}\\) at the upper part of the result, while the addition of \\(\\texttt{freeIn}\\) allocates them at the lower part of the result. This state machine is implemented in PIL as follows: Code Excerpt 5: The Byte4 State Machine PIL File","title":"A State Machine that Generates 4-Byte Numbers"},{"location":"zkEVM/PIL/introduction/","text":"Polynomial Identity Language (PIL) is a novel domain-specific language useful for defining state machines. The aim for creating PIL is to provide developers a holistic framework for both constructing state machines through an easy-to-use interface, and abstracting the complexity of the proving mechanisms. One of the main peculiarities of PIL is its modularity , which allows programmers to define parametrizable state machines, called namespaces , which can be instantiated from larger state machines. Building state machines in a modular manner makes it easier to test, review, audit and formally verify even large and complex state machines. In this regard, by using PIL, developers can create their own custom namespaces or instantiate namespaces from some public library. Some of the keys features of PIL are; Providing \\(\\texttt{namespaces}\\) for naming the essential parts that constitutes state machines. Denoting whether the polynomials are \\(\\texttt{committed}\\) or \\(\\texttt{constant}\\) . Expressing polynomial relations, including \\(\\texttt{identities}\\) and \\(\\texttt{lookup arguments}\\) . Specifying the type of a polynomial, such as \\(\\texttt{bool}\\) or \\(\\texttt{u32}\\) . State Machines: The Computational Model Behind PIL Many other domain-specific languages (DSL) or toolstacks, such as Circom or Halo2 , focus on the abstraction of a particular computational model, such as an arithmetic circuit. Arithmetic circuits arise naturally in the context of succinct interactive protocols and are therefore an appropriate representation in the context of PIL. Arithmetic circuits are covered by developer tools generally in two ways, either in the vanilla PlonK Style or the PlonKish Style. See Figure 1 for a high-level description of these two styles and how they differ. Figure 1: Vanilla PlonK vs PlonKish Circuit Representation Style However, recent proof systems such as STARKs have shown that arithmetic circuits might not be the best computational models in all use-cases. Given a complete programming language, computing a valid proof for a circuit satisfiability problem, may result in long proving times due to the overhead of re-used logic. Opting for deployment of state machines, with their low-level programming, shorter proving times are attainable especially with the advent of proof/verification-aiding languages such as PIL. Figure 2 below, provides a high-level description of a state machine architecture. A typical state machine takes some input and produces the corresponding output, according to the Arithmetic-Logic Unit (ALU). This ALU is the very core of the state machine as it determines the internal state of the state machine, as well as the values of its output. Figure 2: Architectural view of a State Machine Figure 3 and 4 show the comparison between the design of circuits and state machines in various natural scenarios. The former makes a comparison in the case of a program with a looping nature, and the latter shows a program with a branching nature. Figure 3: Circuit and state machine comparison in a loop-based computation Figure 4: Circuit and State Machine comparison in a branch-based computation","title":"Introduction"},{"location":"zkEVM/PIL/introduction/#state-machines-the-computational-model-behind-pil","text":"Many other domain-specific languages (DSL) or toolstacks, such as Circom or Halo2 , focus on the abstraction of a particular computational model, such as an arithmetic circuit. Arithmetic circuits arise naturally in the context of succinct interactive protocols and are therefore an appropriate representation in the context of PIL. Arithmetic circuits are covered by developer tools generally in two ways, either in the vanilla PlonK Style or the PlonKish Style. See Figure 1 for a high-level description of these two styles and how they differ. Figure 1: Vanilla PlonK vs PlonKish Circuit Representation Style However, recent proof systems such as STARKs have shown that arithmetic circuits might not be the best computational models in all use-cases. Given a complete programming language, computing a valid proof for a circuit satisfiability problem, may result in long proving times due to the overhead of re-used logic. Opting for deployment of state machines, with their low-level programming, shorter proving times are attainable especially with the advent of proof/verification-aiding languages such as PIL. Figure 2 below, provides a high-level description of a state machine architecture. A typical state machine takes some input and produces the corresponding output, according to the Arithmetic-Logic Unit (ALU). This ALU is the very core of the state machine as it determines the internal state of the state machine, as well as the values of its output. Figure 2: Architectural view of a State Machine Figure 3 and 4 show the comparison between the design of circuits and state machines in various natural scenarios. The former makes a comparison in the case of a program with a looping nature, and the latter shows a program with a branching nature. Figure 3: Circuit and state machine comparison in a loop-based computation Figure 4: Circuit and State Machine comparison in a branch-based computation","title":"State Machines: The Computational Model Behind PIL"},{"location":"zkEVM/PIL/modularity/","text":"Although several polynomials could be added to the above state machine so as to express more operations, it would only make the design hard to test, audit or formally verify. In order to avoid this complication, PIL lets one use a divide and conquer technique: (a) Instead of developing one (big) state machine, a typical architecture consists of different state machines. (b) Each state machine is devoted to proving the execution of a specific task, each with its own set of constraints. (c) Then, relevant polynomials on different state machines are related and compared using lookup tables or permutation arguments. (d) This guarantees consistency as if it would have been a single state machine. PIL is therefore best suited for a modular design of state machines. Figure 12 depicts a connection between the polynomials \\([a,b,c]\\) and \\([d,e,f]\\) . Figure 12: Polynomial Connections Across State Machines To illustrate this process, First, design a state machine to manage arithmetic operations over \\(2\\) -byte elements. Then, connect this state machine with another state machine (that needs to perform arithmetic operations) via a lookup argument. The Arithmetic State Machine The Arithmetic State Machine is in charge of checking that some arithmetic operations like additions and multiplications are correctly performed over \\(2\\) -byte elements. For this, the polynomials; \\(\\texttt{a}\\) , \\(\\texttt{b}\\) , \\(\\texttt{c}\\) , \\(\\texttt{d}\\) , and \\(\\texttt{e}\\) ; must satisfy the identity: \\[ \\texttt{a}(X) \\cdot \\texttt{b}(X) + \\texttt{c}(X) = 2^{16} \\cdot \\texttt{d}(X) + \\texttt{e}(X). \\] Notice the following, (a) The multiplication between \\(\\texttt{a}\\) and \\(\\texttt{b}\\) , which are \\(2\\) -byte elements, can be expressed with \\(\\texttt{e}\\) and \\(\\texttt{d}\\) , where these are also \\(2\\) -byte elements. (b) Enforce that all the evaluations of \\(\\texttt{a}\\) , \\(\\texttt{b}\\) , \\(\\texttt{c}\\) , \\(\\texttt{d}\\) and \\(\\texttt{e}\\) are \\(2\\) -byte elements. Figure 13: Architecture of the Arithmetic State Machine Figure 13 shows how the Arithmetic State Machine is designed. And, Tableb14 displays an example of how the computational trace looks like. Table 14: Computational Trace of the Arithmetic State Machine The Arithmetic state machine works as follows. \\(\\texttt{LATCH}\\) is used to flag when the operation is ready. Note that \\(\\texttt{SET}[A]\\) , \\(\\texttt{SET}[B]\\) , \\(\\texttt{SET}[C]\\) , \\(\\texttt{SET}[D]\\) , \\(\\texttt{SET}[E]\\) and \\(\\texttt{LATCH}\\) are constant polynomials. \\(\\texttt{freeIn}\\) is committed, and contains the values on which arithmetic operations are performed. Polynomials \\(\\texttt{a}\\) , \\(\\texttt{b}\\) , \\(\\texttt{c}\\) , \\(\\texttt{d}\\) and \\(\\texttt{e}\\) compose the state variables. The polynomial identities that define the Arithmetic State Machine are as follows: \\[ \\begin{aligned} &\\texttt{freeIn} \\subset [0,2^{16} - 1], \\\\ \\texttt{a}' &= \\texttt{SET}[A]\\cdot(\\texttt{freeIn} - \\texttt{a}) + \\texttt{a}, \\\\ \\texttt{b}' &= \\texttt{SET}[B]\\cdot(\\texttt{freeIn} - \\texttt{b}) + \\texttt{b}, \\\\ \\texttt{c}' &= \\texttt{SET}[C]\\cdot(\\texttt{freeIn} - \\texttt{c}) + \\texttt{c}, \\\\ \\texttt{d}' &= \\texttt{SET}[D]\\cdot(\\texttt{freeIn} - \\texttt{d}) + \\texttt{d}, \\\\ \\texttt{e}' &= \\texttt{SET}[E]\\cdot(\\texttt{freeIn} - \\texttt{e}) + \\texttt{e}, \\\\ 0 &= [ \\texttt{a} \\cdot \\texttt{b} + \\texttt{c} - (2^{16} \\cdot \\texttt{d} + \\texttt{e}) ] \\cdot \\texttt{LATCH}. \\end{aligned} \\] These are included in PIL as shown in the code excerpt below. Code Excerpt 15: PIL Example The Main State Machine The Main State Machine is in charge of some (major) tasks, but will specifically use the Arithmetic SM when Arithmetic operations needs to be performed over certain values. Figure 15: The Main State Machine Architecture Hence, the first task in PIL is to introduce the various polynomials. It looks as follows, Code Excerpt 15: Arithmetic State Machine PIL Example if some polynomial is intended to be boolean, then a constraint that reflects so must be added. Code Excerpt 16: PIL Example with Added Constraint Now, add various constraints regarding the evolution of the \"main\" state variables \\(a\\) , \\(b\\) , \\(c\\) , \\(d\\) and \\(e\\) , so that any kind of linear combination between the main state variables, the free input and any constant is subject to be moved in the next iteration of some (or all) the state variables. Figure 16 shows a diagram of the desired behavior. Figure 16: Boolean Polynommials in the Main State Machine In PIL, it translates to the following: Code Excerpt 17: Verification of Basic Registry Operations Finally, the constraints reflecting the relationship between the Main and the Arithmetic SMs can be checked. Code Excerpt 18: PIL Example Connect Main and Arithmetic SMs The connections can be depicted in terms of tables, as Figure 17 below, Figure 17: Connecting Arithmetic and Main State Machines On the one side, the \\(\\texttt{arith}\\) selector is used in the Main SM to point to this state machine when an arithmetic lookup have to be performed. On the other side, the \\(\\texttt{LATCH}\\) selector, which also works as a selector for which rows should be added in the lookup argument is used. And, as illustrated in Figure 17 above, this proves that, \\[\\begin{array}{c} \\texttt{Main.arith} \\cdot [\\texttt{Main.a} , \\texttt{Main.b} , \\texttt{Main.c} , \\texttt{Main.d}, \\texttt{Main.e}] \\\\ \\subset \\\\ \\texttt{Arith.LATCH} \\cdot [\\texttt{Arith.a}, \\texttt{Arith.b}, \\texttt{Arith.c}, \\texttt{Arith.d}, \\texttt{Arith.e}]. \\end{array}\\]","title":"Modularity"},{"location":"zkEVM/PIL/modularity/#the-arithmetic-state-machine","text":"The Arithmetic State Machine is in charge of checking that some arithmetic operations like additions and multiplications are correctly performed over \\(2\\) -byte elements. For this, the polynomials; \\(\\texttt{a}\\) , \\(\\texttt{b}\\) , \\(\\texttt{c}\\) , \\(\\texttt{d}\\) , and \\(\\texttt{e}\\) ; must satisfy the identity: \\[ \\texttt{a}(X) \\cdot \\texttt{b}(X) + \\texttt{c}(X) = 2^{16} \\cdot \\texttt{d}(X) + \\texttt{e}(X). \\] Notice the following, (a) The multiplication between \\(\\texttt{a}\\) and \\(\\texttt{b}\\) , which are \\(2\\) -byte elements, can be expressed with \\(\\texttt{e}\\) and \\(\\texttt{d}\\) , where these are also \\(2\\) -byte elements. (b) Enforce that all the evaluations of \\(\\texttt{a}\\) , \\(\\texttt{b}\\) , \\(\\texttt{c}\\) , \\(\\texttt{d}\\) and \\(\\texttt{e}\\) are \\(2\\) -byte elements. Figure 13: Architecture of the Arithmetic State Machine Figure 13 shows how the Arithmetic State Machine is designed. And, Tableb14 displays an example of how the computational trace looks like. Table 14: Computational Trace of the Arithmetic State Machine The Arithmetic state machine works as follows. \\(\\texttt{LATCH}\\) is used to flag when the operation is ready. Note that \\(\\texttt{SET}[A]\\) , \\(\\texttt{SET}[B]\\) , \\(\\texttt{SET}[C]\\) , \\(\\texttt{SET}[D]\\) , \\(\\texttt{SET}[E]\\) and \\(\\texttt{LATCH}\\) are constant polynomials. \\(\\texttt{freeIn}\\) is committed, and contains the values on which arithmetic operations are performed. Polynomials \\(\\texttt{a}\\) , \\(\\texttt{b}\\) , \\(\\texttt{c}\\) , \\(\\texttt{d}\\) and \\(\\texttt{e}\\) compose the state variables. The polynomial identities that define the Arithmetic State Machine are as follows: \\[ \\begin{aligned} &\\texttt{freeIn} \\subset [0,2^{16} - 1], \\\\ \\texttt{a}' &= \\texttt{SET}[A]\\cdot(\\texttt{freeIn} - \\texttt{a}) + \\texttt{a}, \\\\ \\texttt{b}' &= \\texttt{SET}[B]\\cdot(\\texttt{freeIn} - \\texttt{b}) + \\texttt{b}, \\\\ \\texttt{c}' &= \\texttt{SET}[C]\\cdot(\\texttt{freeIn} - \\texttt{c}) + \\texttt{c}, \\\\ \\texttt{d}' &= \\texttt{SET}[D]\\cdot(\\texttt{freeIn} - \\texttt{d}) + \\texttt{d}, \\\\ \\texttt{e}' &= \\texttt{SET}[E]\\cdot(\\texttt{freeIn} - \\texttt{e}) + \\texttt{e}, \\\\ 0 &= [ \\texttt{a} \\cdot \\texttt{b} + \\texttt{c} - (2^{16} \\cdot \\texttt{d} + \\texttt{e}) ] \\cdot \\texttt{LATCH}. \\end{aligned} \\] These are included in PIL as shown in the code excerpt below. Code Excerpt 15: PIL Example","title":"The Arithmetic State Machine"},{"location":"zkEVM/PIL/modularity/#the-main-state-machine","text":"The Main State Machine is in charge of some (major) tasks, but will specifically use the Arithmetic SM when Arithmetic operations needs to be performed over certain values. Figure 15: The Main State Machine Architecture Hence, the first task in PIL is to introduce the various polynomials. It looks as follows, Code Excerpt 15: Arithmetic State Machine PIL Example if some polynomial is intended to be boolean, then a constraint that reflects so must be added. Code Excerpt 16: PIL Example with Added Constraint Now, add various constraints regarding the evolution of the \"main\" state variables \\(a\\) , \\(b\\) , \\(c\\) , \\(d\\) and \\(e\\) , so that any kind of linear combination between the main state variables, the free input and any constant is subject to be moved in the next iteration of some (or all) the state variables. Figure 16 shows a diagram of the desired behavior. Figure 16: Boolean Polynommials in the Main State Machine In PIL, it translates to the following: Code Excerpt 17: Verification of Basic Registry Operations Finally, the constraints reflecting the relationship between the Main and the Arithmetic SMs can be checked. Code Excerpt 18: PIL Example Connect Main and Arithmetic SMs The connections can be depicted in terms of tables, as Figure 17 below, Figure 17: Connecting Arithmetic and Main State Machines On the one side, the \\(\\texttt{arith}\\) selector is used in the Main SM to point to this state machine when an arithmetic lookup have to be performed. On the other side, the \\(\\texttt{LATCH}\\) selector, which also works as a selector for which rows should be added in the lookup argument is used. And, as illustrated in Figure 17 above, this proves that, \\[\\begin{array}{c} \\texttt{Main.arith} \\cdot [\\texttt{Main.a} , \\texttt{Main.b} , \\texttt{Main.c} , \\texttt{Main.d}, \\texttt{Main.e}] \\\\ \\subset \\\\ \\texttt{Arith.LATCH} \\cdot [\\texttt{Arith.a}, \\texttt{Arith.b}, \\texttt{Arith.c}, \\texttt{Arith.d}, \\texttt{Arith.e}]. \\end{array}\\]","title":"The Main State Machine"},{"location":"zkEVM/PIL/related-repos/","text":"A compiler that compiles the PIL description to a JSON file that can be read by the zkExecutor and the zkProver can be found at this repository .","title":"Related Repositories"},{"location":"zkEVM/Prover/zk-prover-debugging/","text":"zkProver debugging zkProver debugging Repositories involved Setup environment Executor insights VSCode debugging Debugging tips Table rom assembly instructions Examples assembly MSTORE MREAD LOAD FROM STORAGE WRITE TO STORAGE Repositories involved zkevm-proverjs : prover reference implementation writen in javascript zkevm-prover : prover implementation writen in C zkasm : compiles .zkasm to a json ready for the zkevm-proverjs pilcom : Polynomial Identity Language zkvmpil : PIL source code for the zkVM (state-machines) zkevm-rom : zkasm source code of the zkEVM zkevm-doc : docs zkevm Setup environment ideal repository structure: github --> zkevm-rom --> zkvmpil --> zkevm-proverjs Next steps are required to run the zkprover:executor : git clone https://github.com/hermeznetwork/zkevm-rom.git cd zkevm-rom npm i && npm run build cd .. git clone https://github.com/hermeznetwork/zkvmpil.git cd zkvmpil npm i && npm run build git clone https://github.com/0xPolygonHermez/zkevm-proverjs.git cd zkevm-proverjs npm i Detailed explanation: repository zkevm-rom main/* : contains assembly code build : compiled assembly. code ready to the executor repository zkvmpil src : state-machines build : compiled state-machines. code ready to the executor repository zkevm-proverjs src/main_executor.js : cli to run executor easily executor needs files fenerated from zkevm-rom/build & zkvm pil/build it also needs an input.json Examples: zkevm-rom file zkvmpil file input file Run executor (in zkevm-proverjs repository) to just test the executor, the output is not needed node src/main_executor.js ./testvectors/input.json -r ../zkevm-rom/build/rom.json -p ../zkvmpil/build/zkevm.pil.json -o ./testvectors/poly.bin Executor insights Basically, the executor runs the program that is specified by the ROM. The program can be seen in the rom.json file, which includes some debugging information. Let's see an example of assembly code builded into the rom.json : ASSEMBLY: 1 => B JSON FILE: { \"CONST\": 1, \"neg\": 0, \"setB\": 1, \"line\": 51, \"fileName\": \"../zkevm-rom/main/main.zkasm\" } All operations are defined in the JSON file, plus line & fileName where the assembly code is. This JSON file is ready to be interpreted by the executor VSCode debugging In the zkevm-proverjs repository you can find an example of launch.json to debug the executor code: https://github.com/0xPolygonHermez/zkevm-proverjs/blob/main/.vscode/launch.json#L8 Debugging tips Main executor code to debug: https://github.com/0xPolygonHermez/zkevm-proverjs/blob/main/src/executor.js#L12 variable l is the rom.json that is going to be executed: https://github.com/0xPolygonHermez/zkevm-proverjs/blob/main/src/executor.js#L61 debug helpers print registers By monioring ctx(context) , registers and op you will see all the states changes made by the executor ctx.input contins all the variables loaded from input.json storage makes refrence to the merkle-tree transactions places at input.json are pre-processed and store it on ctx.pTxs . Besides, globalHash is computed given all the inputs.json according to specification (TO_BE_UPDATED) Table rom assembly instructions NAME DESCRIPTION EXECUTION MLOAD memory load op = mem(addr) MSTORE memory storage mem(addr) = op SLOAD storage load op = storage.get(SR, H[A0 , A1 , A2 , B0 , C0 , C1 , C2 , C3, 0...0])) where storage.get(root, key) -> value SSTORE storage store op = storage.set(SR, (H[A0 , A1 , A2 , B0 , C0 , C1 , C2 , C3, 0...0], D0 + D1 * 2^64 + D2 * 2^128 + D3 * 2^192 ) where storage.set(oldRoot, key, newValue) -> newRoot HASHW hash write bytes hash[addr].push(op[0..D-1]) HASHE hash end hash[addr].end() HASHR hash read op = hash[addr].result ARITH arithmetic operation AB + C = D OR op SHL shift left op = A << D SHR shift right op = A >> D ECRECOVER signature recover op = ECRECOVER( A: HASH, B: R, C:S, D: V) ASSERT assertion A = op Examples assembly MSTORE assembly ```javascript= A :MSTORE(sequencerAddr) - rom.json ```json= { \"inA\": 1, \"neg\": 0, \"offset\": 4, \"mWR\": 1, \"line\": 9, \"offsetLabel\": \"sequencerAddr\", \"useCTX\": 0, \"fileName\": \".../zkevm-rom/main/main.zkasm\" } description: load A register in op , write in memory position 4 ( offset ) the op value MREAD assembly: ```javascript= $ => A : MLOAD(pendingTxs) - rom.json ```json= { \"freeInTag\": { \"op\": \"\" }, \"inFREE\": 1, \"neg\": 0, \"setA\": 1, \"offset\": 1, \"mRD\": 1, \"line\": 25, \"offsetLabel\": \"pendingTxs\", \"useCTX\": 0, \"fileName\": \".../zkevm-rom/main/main.zkasm\" } description: load a memory value from position 1 ( offset ) into op (action marked by inFREE ), set op in A register LOAD FROM STORAGE assembly ```javascript= $ => A :MLOAD(sequencerAddr) 0 => B,C $ => A :SLOAD - rom.json ```json= { \"freeInTag\": { \"op\": \"\" }, \"inFREE\": 1, \"neg\": 0, \"setA\": 1, \"offset\": 4, \"mRD\": 1, \"line\": 47, \"offsetLabel\": \"sequencerAddr\", \"useCTX\": 0, \"fileName\": \".../zkevm-rom/main/main.zkasm\" }, { \"CONST\": 0, \"neg\": 0, \"setB\": 1, \"setC\": 1, \"line\": 48, \"fileName\": \".../zkevm-rom/main/main.zkasm\" }, { \"freeInTag\": { \"op\": \"\" }, \"inFREE\": 1, \"neg\": 0, \"setA\": 1, \"sRD\": 1, \"line\": 49, \"fileName\": \".../zkevm-rom/main/main.zkasm\" } description load from memory position 5 ( sequencerAccValue ) into op , store op on D register load from memory position 4 ( sequencerAddr ) into op , store op on A register load CONST in op , store it in registers B and C Perform SLOAD (reading from merkle-tree) with the follwing key: storage.get(SR, H[A0 , A1 , A2 , B0 , C0 , C1 , C2 , C3, 0...0])) SR is the current state-root saved in register SR A0, A1, A2 has the sequencer address B0 is set to 0 pointing out that the balance is going to be read C0,C1,C2,C3 are set to 0 since they are not used when reading balance from merkle-tree merkle-tree value is store in op (marked by inFREE tag), set op to register A WRITE TO STORAGE assembly ```javascript= $ => A :MLOAD(sequencerAddr) 0 => B,C $ => SR :SSTORE - rom.json ```json= { \"freeInTag\": { \"op\": \"\" }, \"inFREE\": 1, \"neg\": 0, \"setA\": 1, \"offset\": 4, \"mRD\": 1, \"line\": 56, \"offsetLabel\": \"sequencerAddr\", \"useCTX\": 0, \"fileName\": \".../zkevm-rom/main/main.zkasm\" }, { \"CONST\": 0, \"neg\": 0, \"setB\": 1, \"setC\": 1, \"line\": 57, \"fileName\": \".../zkevm-rom/main/main.zkasm\" }, { \"freeInTag\": { \"op\": \"\" }, \"inFREE\": 1, \"neg\": 0, \"setSR\": 1, \"sWR\": 1, \"line\": 58, \"fileName\": \".../zkevm-rom/main/main.zkasm\" } description read from memory position 4 ( sequencerAddr ) and store it on op , set op to register A set CONST to op , store op in registers B and C Perform SWRITE (write to merkle-tree) according: storage.set(SR, (H[A0 , A1 , A2 , B0 , C0 , C1 , C2 , C3, 0...0], D0 + D1 * 2^64 + D2 * 2^128 + D3 * 2^192 ) SR is the current state-root saved in register SR A0, A1, A2 has the sequencer address B0 is set to 0 pointing out that the balance is going to be read C0,C1,C2,C3 are set to 0 since they are not used when reading balance from merkle-tree D0, D1, D2, D3 is the value writen in the merkle-tree pointed out by H[A0 , A1 , A2 , B0 , C0 , C1 , C2 , C3, 0...0] --> in this example register D has the balance of the seqAddr write merkle-tree state root in SR register","title":"Zk prover debugging"},{"location":"zkEVM/Prover/zk-prover-debugging/#zkprover-debugging","text":"zkProver debugging Repositories involved Setup environment Executor insights VSCode debugging Debugging tips Table rom assembly instructions Examples assembly MSTORE MREAD LOAD FROM STORAGE WRITE TO STORAGE","title":"zkProver debugging"},{"location":"zkEVM/Prover/zk-prover-debugging/#repositories-involved","text":"zkevm-proverjs : prover reference implementation writen in javascript zkevm-prover : prover implementation writen in C zkasm : compiles .zkasm to a json ready for the zkevm-proverjs pilcom : Polynomial Identity Language zkvmpil : PIL source code for the zkVM (state-machines) zkevm-rom : zkasm source code of the zkEVM zkevm-doc : docs zkevm","title":"Repositories involved"},{"location":"zkEVM/Prover/zk-prover-debugging/#setup-environment","text":"ideal repository structure: github --> zkevm-rom --> zkvmpil --> zkevm-proverjs Next steps are required to run the zkprover:executor : git clone https://github.com/hermeznetwork/zkevm-rom.git cd zkevm-rom npm i && npm run build cd .. git clone https://github.com/hermeznetwork/zkvmpil.git cd zkvmpil npm i && npm run build git clone https://github.com/0xPolygonHermez/zkevm-proverjs.git cd zkevm-proverjs npm i Detailed explanation: repository zkevm-rom main/* : contains assembly code build : compiled assembly. code ready to the executor repository zkvmpil src : state-machines build : compiled state-machines. code ready to the executor repository zkevm-proverjs src/main_executor.js : cli to run executor easily executor needs files fenerated from zkevm-rom/build & zkvm pil/build it also needs an input.json Examples: zkevm-rom file zkvmpil file input file Run executor (in zkevm-proverjs repository) to just test the executor, the output is not needed node src/main_executor.js ./testvectors/input.json -r ../zkevm-rom/build/rom.json -p ../zkvmpil/build/zkevm.pil.json -o ./testvectors/poly.bin","title":"Setup environment"},{"location":"zkEVM/Prover/zk-prover-debugging/#executor-insights","text":"Basically, the executor runs the program that is specified by the ROM. The program can be seen in the rom.json file, which includes some debugging information. Let's see an example of assembly code builded into the rom.json : ASSEMBLY: 1 => B JSON FILE: { \"CONST\": 1, \"neg\": 0, \"setB\": 1, \"line\": 51, \"fileName\": \"../zkevm-rom/main/main.zkasm\" } All operations are defined in the JSON file, plus line & fileName where the assembly code is. This JSON file is ready to be interpreted by the executor","title":"Executor insights"},{"location":"zkEVM/Prover/zk-prover-debugging/#vscode-debugging","text":"In the zkevm-proverjs repository you can find an example of launch.json to debug the executor code: https://github.com/0xPolygonHermez/zkevm-proverjs/blob/main/.vscode/launch.json#L8","title":"VSCode debugging"},{"location":"zkEVM/Prover/zk-prover-debugging/#debugging-tips","text":"Main executor code to debug: https://github.com/0xPolygonHermez/zkevm-proverjs/blob/main/src/executor.js#L12 variable l is the rom.json that is going to be executed: https://github.com/0xPolygonHermez/zkevm-proverjs/blob/main/src/executor.js#L61 debug helpers print registers By monioring ctx(context) , registers and op you will see all the states changes made by the executor ctx.input contins all the variables loaded from input.json storage makes refrence to the merkle-tree transactions places at input.json are pre-processed and store it on ctx.pTxs . Besides, globalHash is computed given all the inputs.json according to specification (TO_BE_UPDATED)","title":"Debugging tips"},{"location":"zkEVM/Prover/zk-prover-debugging/#table-rom-assembly-instructions","text":"NAME DESCRIPTION EXECUTION MLOAD memory load op = mem(addr) MSTORE memory storage mem(addr) = op SLOAD storage load op = storage.get(SR, H[A0 , A1 , A2 , B0 , C0 , C1 , C2 , C3, 0...0])) where storage.get(root, key) -> value SSTORE storage store op = storage.set(SR, (H[A0 , A1 , A2 , B0 , C0 , C1 , C2 , C3, 0...0], D0 + D1 * 2^64 + D2 * 2^128 + D3 * 2^192 ) where storage.set(oldRoot, key, newValue) -> newRoot HASHW hash write bytes hash[addr].push(op[0..D-1]) HASHE hash end hash[addr].end() HASHR hash read op = hash[addr].result ARITH arithmetic operation AB + C = D OR op SHL shift left op = A << D SHR shift right op = A >> D ECRECOVER signature recover op = ECRECOVER( A: HASH, B: R, C:S, D: V) ASSERT assertion A = op","title":"Table rom assembly instructions"},{"location":"zkEVM/Prover/zk-prover-debugging/#examples-assembly","text":"","title":"Examples assembly"},{"location":"zkEVM/Prover/zk-prover-debugging/#mstore","text":"assembly ```javascript= A :MSTORE(sequencerAddr) - rom.json ```json= { \"inA\": 1, \"neg\": 0, \"offset\": 4, \"mWR\": 1, \"line\": 9, \"offsetLabel\": \"sequencerAddr\", \"useCTX\": 0, \"fileName\": \".../zkevm-rom/main/main.zkasm\" } description: load A register in op , write in memory position 4 ( offset ) the op value","title":"MSTORE"},{"location":"zkEVM/Prover/zk-prover-debugging/#mread","text":"assembly: ```javascript= $ => A : MLOAD(pendingTxs) - rom.json ```json= { \"freeInTag\": { \"op\": \"\" }, \"inFREE\": 1, \"neg\": 0, \"setA\": 1, \"offset\": 1, \"mRD\": 1, \"line\": 25, \"offsetLabel\": \"pendingTxs\", \"useCTX\": 0, \"fileName\": \".../zkevm-rom/main/main.zkasm\" } description: load a memory value from position 1 ( offset ) into op (action marked by inFREE ), set op in A register","title":"MREAD"},{"location":"zkEVM/Prover/zk-prover-debugging/#load-from-storage","text":"assembly ```javascript= $ => A :MLOAD(sequencerAddr) 0 => B,C $ => A :SLOAD - rom.json ```json= { \"freeInTag\": { \"op\": \"\" }, \"inFREE\": 1, \"neg\": 0, \"setA\": 1, \"offset\": 4, \"mRD\": 1, \"line\": 47, \"offsetLabel\": \"sequencerAddr\", \"useCTX\": 0, \"fileName\": \".../zkevm-rom/main/main.zkasm\" }, { \"CONST\": 0, \"neg\": 0, \"setB\": 1, \"setC\": 1, \"line\": 48, \"fileName\": \".../zkevm-rom/main/main.zkasm\" }, { \"freeInTag\": { \"op\": \"\" }, \"inFREE\": 1, \"neg\": 0, \"setA\": 1, \"sRD\": 1, \"line\": 49, \"fileName\": \".../zkevm-rom/main/main.zkasm\" } description load from memory position 5 ( sequencerAccValue ) into op , store op on D register load from memory position 4 ( sequencerAddr ) into op , store op on A register load CONST in op , store it in registers B and C Perform SLOAD (reading from merkle-tree) with the follwing key: storage.get(SR, H[A0 , A1 , A2 , B0 , C0 , C1 , C2 , C3, 0...0])) SR is the current state-root saved in register SR A0, A1, A2 has the sequencer address B0 is set to 0 pointing out that the balance is going to be read C0,C1,C2,C3 are set to 0 since they are not used when reading balance from merkle-tree merkle-tree value is store in op (marked by inFREE tag), set op to register A","title":"LOAD FROM STORAGE"},{"location":"zkEVM/Prover/zk-prover-debugging/#write-to-storage","text":"assembly ```javascript= $ => A :MLOAD(sequencerAddr) 0 => B,C $ => SR :SSTORE - rom.json ```json= { \"freeInTag\": { \"op\": \"\" }, \"inFREE\": 1, \"neg\": 0, \"setA\": 1, \"offset\": 4, \"mRD\": 1, \"line\": 56, \"offsetLabel\": \"sequencerAddr\", \"useCTX\": 0, \"fileName\": \".../zkevm-rom/main/main.zkasm\" }, { \"CONST\": 0, \"neg\": 0, \"setB\": 1, \"setC\": 1, \"line\": 57, \"fileName\": \".../zkevm-rom/main/main.zkasm\" }, { \"freeInTag\": { \"op\": \"\" }, \"inFREE\": 1, \"neg\": 0, \"setSR\": 1, \"sWR\": 1, \"line\": 58, \"fileName\": \".../zkevm-rom/main/main.zkasm\" } description read from memory position 4 ( sequencerAddr ) and store it on op , set op to register A set CONST to op , store op in registers B and C Perform SWRITE (write to merkle-tree) according: storage.set(SR, (H[A0 , A1 , A2 , B0 , C0 , C1 , C2 , C3, 0...0], D0 + D1 * 2^64 + D2 * 2^128 + D3 * 2^192 ) SR is the current state-root saved in register SR A0, A1, A2 has the sequencer address B0 is set to 0 pointing out that the balance is going to be read C0,C1,C2,C3 are set to 0 since they are not used when reading balance from merkle-tree D0, D1, D2, D3 is the value writen in the merkle-tree pointed out by H[A0 , A1 , A2 , B0 , C0 , C1 , C2 , C3, 0...0] --> in this example register D has the balance of the seqAddr write merkle-tree state root in SR register","title":"WRITE TO STORAGE"},{"location":"zkEVM/Prover/zk-prover-mock/","text":"The mock server is at git@github.com:0xPolygonHermez/zkevm-comms-protocol.git Server definition proto/zk-prover-proto contains the service specification syntax = \"proto3\"; package zkprover; service ZKProver { rpc GetStatus(NoParams) returns (State) {} rpc GenProof(stream Batch) returns (stream Proof) {} rpc Cancel(NoParams) returns (State) {} rpc GetProof(NoParams) returns (Proof) {} } message NoParams {} message State { enum Status { IDLE = 0; ERROR = 1; PENDING = 2; FINISHED = 3; } Status status = 1; Proof proof = 2; } message ProofX { repeated string proof = 1; } message PublicInputs { bytes currentStateRoot = 1; bytes currentLocalExitRoot = 2; bytes newStateRoot = 3; bytes newLocalExitRoot = 4; string sequencerAddress = 5; bytes l2TxsDataLastGlobalExitRoot = 6; uint64 chainId = 7; } message Proof { repeated string proofA = 1; repeated ProofX proofB = 2; repeated string proofC = 3; PublicInputs publicInputs = 4; } message Batch { string message = 1; bytes currentStateRoot = 2; bytes newStateRoot = 3; bytes l2Txs = 4; bytes lastGlobalExitRoot = 5; string sequencerAddress = 6; uint64 chainId = 7; } Following documentation pretends to explain further its behaviour Service functionalities rpc GetStatus(NoParams) returns (State) {} rpc GenProof(stream Batch) returns (stream Proof) {} rpc Cancel(NoParams) returns (State) {} rpc GetProof(NoParams) returns (Proof) {} GetStatus Function to know the status of the prover. The client does not need to enter data to make this call. The status is returned in the following form: message State { enum Status { IDLE = 0; ERROR = 1; PENDING = 2; FINISHED = 3; } Status status = 1; Proof proof = 2; } The status will be one of those defined in the enum . Proof is only defined if the status is FINISHED . GenProof Function to generate the proofs. The client must provide the following information to the server when calling the function: message Batch { string message = 1; bytes currentStateRoot = 2; bytes newStateRoot = 3; bytes l2Txs = 4; bytes lastGlobalExitRoot = 5; string sequencerAddress = 6; uint64 chainId = 7; } Where the message can be: - \"calculate\" : to generate the proof - \"cancel\" : to cancel the last proof And the server will respond: message Proof { repeated string proofA = 1; repeated ProofX proofB = 2; repeated string proofC = 3; PublicInputs publicInputs = 4; } Where: message PublicInputs { bytes currentStateRoot = 1; bytes currentLocalExitRoot = 2; bytes newStateRoot = 3; bytes newLocalExitRoot = 4; string sequencerAddress = 5; bytes l2TxsDataLastGlobalExitRoot = 6; uint64 chainId = 7; } message ProofX { repeated string proof = 1; } This channel will be open until the client decides to close it. In this way, the client can continue requesting proofs by sending the message Batch . Cancel If the previous channel is closed and the server has computed a proof, the client can cancel it with this call. The client does not need to enter data to make this call. The prover returns the status to confirm that the proof calculation is canceled. GetProof Function to get the last calculated proof. The client does not need to enter data to make this call. If the status is FINISHED , the last proof is returned.","title":"The mock server is at git@github.com:0xPolygonHermez/zkevm-comms-protocol.git"},{"location":"zkEVM/Prover/zk-prover-mock/#the-mock-server-is-at-gitgithubcom0xpolygonhermezzkevm-comms-protocolgit","text":"","title":"The mock server is at git@github.com:0xPolygonHermez/zkevm-comms-protocol.git"},{"location":"zkEVM/Prover/zk-prover-mock/#server-definition","text":"proto/zk-prover-proto contains the service specification syntax = \"proto3\"; package zkprover; service ZKProver { rpc GetStatus(NoParams) returns (State) {} rpc GenProof(stream Batch) returns (stream Proof) {} rpc Cancel(NoParams) returns (State) {} rpc GetProof(NoParams) returns (Proof) {} } message NoParams {} message State { enum Status { IDLE = 0; ERROR = 1; PENDING = 2; FINISHED = 3; } Status status = 1; Proof proof = 2; } message ProofX { repeated string proof = 1; } message PublicInputs { bytes currentStateRoot = 1; bytes currentLocalExitRoot = 2; bytes newStateRoot = 3; bytes newLocalExitRoot = 4; string sequencerAddress = 5; bytes l2TxsDataLastGlobalExitRoot = 6; uint64 chainId = 7; } message Proof { repeated string proofA = 1; repeated ProofX proofB = 2; repeated string proofC = 3; PublicInputs publicInputs = 4; } message Batch { string message = 1; bytes currentStateRoot = 2; bytes newStateRoot = 3; bytes l2Txs = 4; bytes lastGlobalExitRoot = 5; string sequencerAddress = 6; uint64 chainId = 7; } Following documentation pretends to explain further its behaviour","title":"Server definition"},{"location":"zkEVM/Prover/zk-prover-mock/#service-functionalities","text":"rpc GetStatus(NoParams) returns (State) {} rpc GenProof(stream Batch) returns (stream Proof) {} rpc Cancel(NoParams) returns (State) {} rpc GetProof(NoParams) returns (Proof) {}","title":"Service functionalities"},{"location":"zkEVM/Prover/zk-prover-mock/#getstatus","text":"Function to know the status of the prover. The client does not need to enter data to make this call. The status is returned in the following form: message State { enum Status { IDLE = 0; ERROR = 1; PENDING = 2; FINISHED = 3; } Status status = 1; Proof proof = 2; } The status will be one of those defined in the enum . Proof is only defined if the status is FINISHED .","title":"GetStatus"},{"location":"zkEVM/Prover/zk-prover-mock/#genproof","text":"Function to generate the proofs. The client must provide the following information to the server when calling the function: message Batch { string message = 1; bytes currentStateRoot = 2; bytes newStateRoot = 3; bytes l2Txs = 4; bytes lastGlobalExitRoot = 5; string sequencerAddress = 6; uint64 chainId = 7; } Where the message can be: - \"calculate\" : to generate the proof - \"cancel\" : to cancel the last proof And the server will respond: message Proof { repeated string proofA = 1; repeated ProofX proofB = 2; repeated string proofC = 3; PublicInputs publicInputs = 4; } Where: message PublicInputs { bytes currentStateRoot = 1; bytes currentLocalExitRoot = 2; bytes newStateRoot = 3; bytes newLocalExitRoot = 4; string sequencerAddress = 5; bytes l2TxsDataLastGlobalExitRoot = 6; uint64 chainId = 7; } message ProofX { repeated string proof = 1; } This channel will be open until the client decides to close it. In this way, the client can continue requesting proofs by sending the message Batch .","title":"GenProof"},{"location":"zkEVM/Prover/zk-prover-mock/#cancel","text":"If the previous channel is closed and the server has computed a proof, the client can cancel it with this call. The client does not need to enter data to make this call. The prover returns the status to confirm that the proof calculation is canceled.","title":"Cancel"},{"location":"zkEVM/Prover/zk-prover-mock/#getproof","text":"Function to get the last calculated proof. The client does not need to enter data to make this call. If the status is FINISHED , the last proof is returned.","title":"GetProof"},{"location":"zkEVM/State-Machines/Arithmetic/Arithmetic-State-Machine-typ/","text":"[ToC] The Arithmetic State Machine As a secondary state machine, the Arithmetic State Machine has the executor part (the Arithmetic SM Executor) and an internal Arithmetic PIL (program) which is a set of verification rules, written in the PIL language. The Arithmetic SM Executor is written in two versions; Javascript and C/C++. The Polygon Hermez Repo is here https://github.com/0xPolygonHermez Arithmetic SM Executor : sm_arith folder Arithmetic SM PIL : arith.pil Introduction The Arithmetic State Machine (SM) is one of the six secondary state machines receiving instructions from the Main SM Executor. As a secondary state machine, the Arithmetic SM has the executor part (the Arithmetic SM Executor) and an internal Arithmetic PIL program written in the PIL language. The main purpose of the Arithmetic SM is carry out elliptic curve arithmetic operations, such as Point Addition and Point Doubling. Standard Elliptic Curve Arithmetic Consider an elliptic curve \\(E\\) defined by \\(y^2 = x^3 + ax + b\\) over the finite field \\(\\mathbb{F} = \\mathbb{Z}_p\\) , where \\(p\\) is the prime, \\[\\begin{aligned} p = 2^{256} - 2^{32} - 2^9 - 2^8 - 2^7 -2^6 - 2^4 - 1. \\end{aligned}\\] Set the coefficients \\(a = 0\\) and \\(b = 7\\) , so that \\(E\\) reduces to \\begin{aligned} y^2 = x^3 + 7. \\end{aligned} Field Arithmetic Consider points \\(( x_1, y_1)\\) , \\(( x_2, y_2)\\) , and \\(( x_3, y_3)\\) on \\(E\\) . Here, \\(y_2\\) and \\(y_3\\) are the result of performing field arithmetic over \\(x_1,y_1\\) and \\(x_2\\) . That is, $$ x_1 \\cdot y_1 + x_2 = y_2 \\cdot 2^{256} + y_3. $$ Note that, If \\(y_1\\) is set to \\(1\\) , the above equation represents field addition. Similarly, if \\(x_2\\) is set to \\(0\\) , then the equation represents field multiplication. Elliptic Curve Point Addition Given two points, \\(P = (x_1,y_1)\\) and \\(Q = (x_2,y_2)\\) , on the curve \\(E\\) with \\(x_1 \\neq x_2\\) , the point \\(P+Q = (x_3,y_3)\\) is computed as follows, \\[\\begin{aligned} x_3 &= s^2 - x_1 - x_2,\\\\ y_3 &= s (x_1 - x_3) - y_1 \\end{aligned}\\] where \\begin{aligned} s = \\dfrac{y_2 - y_1}{x_2 - x_1}. \\end{aligned} Elliptic Curve Point Doubling Given a point \\(P = (x_1,y_1)\\) on the curve \\(E\\) such that \\(P \\neq \\mathcal{O}\\) , the point \\(P+P = 2P = (x_3,y_3)\\) is computed as follows, \\[\\begin{aligned} x_3 &= s^2 - 2x_1,\\\\ y_3 &= s (x_1 - x_3) - y_1, \\end{aligned}\\] where \\begin{aligned} s = \\dfrac{3x_1^2}{2y_1}. \\end{aligned} Remark : Since the above Elliptic Curve operations are implemented in the PIL language, it is more convenient to express them in terms of the constraints they must satisfy. These constraints are: \\[\\begin{aligned} \\text{EQ}_0 \\colon \\quad &x_1 \\cdot y_1 + x_2 - y_2 \\cdot 2^{256} - y_3 = 0, \\\\ \\text{EQ}_1 \\colon \\quad &s \\cdot x_2 - s \\cdot x_1 -y_2 + y_1 + q_0 \\cdot p = 0, \\\\ \\text{EQ}_2 \\colon \\quad & 2 \\cdot s \\cdot y_1 - 3 \\cdot x_1 \\cdot x_1 + q_0 \\cdot p = 0, \\\\ \\text{EQ}_3 \\colon \\quad & s \\cdot s - x_1 - x_2 - x_3 + q_1 \\cdot p = 0, \\\\ \\text{EQ}_4 \\colon \\quad & s \\cdot x_1 - s \\cdot x_3 - y_1 - y_3 + q_2 \\cdot p = 0, \\end{aligned}\\] where \\(q_0,q_1,q_2 \\in \\mathbb{Z}\\) , implying that these equations hold true over the integers. This approach is taken in order avoid having to compute divisions by \\(p\\) . Note also that only three possible computation scenarios arise: \\(\\text{EQ}_0\\) is activated while the rest are deactivated, \\(\\text{EQ}_1\\) , \\(\\text{EQ}_3\\) and \\(\\text{EQ}_4\\) are activated but \\(\\text{EQ}_0\\) and \\(\\text{EQ}_2\\) are deactivated, \\(\\text{EQ}_2\\) , \\(\\text{EQ}_3\\) and \\(\\text{EQ}_4\\) are activated and \\(\\text{EQ}_0\\) and \\(\\text{EQ}_1\\) are deactivated. Since at most, one of \\(\\text{EQ}_1\\) and \\(\\text{EQ}_2\\) are activated in any scenario, we can afford \"sharing'' the same \\(q_0\\) for both. Motivated by the implemented operations, the Arithmetic SM is composed of 6 registers \\begin{aligned} x_1,\\ y_1,\\ x_2,\\ y_2,\\ x_3,\\ y_3. \\end{aligned} Each of these registers is composed of \\(16\\) sub-registers of \\(16\\) -bit ( \\(2\\) byte) capacity, adding up to a total of \\(256\\) bits per register. There is also a need to provide \\(s\\) and \\(q_0,q_1,q_2\\) , which are also \\(256\\) -bit field elements. How The Operations Are Performed Compute the previous operations at \\(2\\) -byte level. This means that if, for instance, one is performing the multiplication of \\(x_1\\) and \\(y_1\\) , at the first clock \\(x_1[0] \\cdot y_1[0]\\) is computed. Then, \\((x_1[0] \\cdot y_1[1]) + (x_1[1] \\cdot y_1[0])\\) is computed in the second clock, followed by \\((x_1[0] \\cdot y_1[2]) + (x_1[1] \\cdot y_1[1]) + (x_1[2] \\cdot y_1[0])\\) in the third, and so on. As depicted in Figure 1 , this process is completely analogous to the schoolbook multiplication. However, it is performed at \\(2\\) -byte level, instead of at decimal level. School Multiplication Example Use the following notation; $$ \\begin{aligned} \\mathbf{eq\\ } &= x_1[0] \\cdot y_1[0] \\ \\mathbf{eq'} &= x_1[0] \\cdot y_1[1] + x_1[1] \\cdot y_1[0] \\end{aligned} $$ But then, the carry generated by \\(\\mathbf{eq}\\) has to be taken into account by \\(\\mathbf{eq'}\\) . Going back to our equations; \\(\\text{EQ}_0, \\text{EQ}_1, \\text{EQ}_2, \\text{EQ}_4\\) ; let's see how the operation is performed in \\(\\text{EQ}_0\\) . First, we compute \\(\\mathbf{eq}_0 = (x_1[0] \\cdot y_1[0]) + x_2[0] - y_3[0]\\) . Second, we compute \\(\\mathbf{eq}_1 = (x_1[0] \\cdot y_1[1]) + (x_1[1] \\cdot y_1[0]) + x_2[1] - y_3[1]\\) . Third, \\(\\mathbf{eq}_2 = (x_1[0] \\cdot y_1[2]) + (x_1[1] \\cdot y_1[1]) + (x_1[2] \\cdot y_1[0]) + x_2[2] - y_3[2]\\) . This is continued until one reaches the computation, \\(\\mathbf{eq}_{15} = (x_1[0] \\cdot y_1[15]) + (x_1[1] \\cdot y_1[14]) + \\dots + x_2[15] - y_3[15]\\) . This is the time when \\(y_2\\) come into place. Since we have filled the first \\(256\\) bits of the result of the operation (and the result can be made of more than \\(256\\) bits) we need a new register to place the result from this point. We change the addition of \\(x_2[i] - y_3[i]\\) by \\(-y_2[i]\\) . Therefore, we obtain that \\(\\mathbf{eq}_{16} = (x_1[1] \\cdot y_1[15]) + (x_1[2] \\cdot y_1[14]) + \\dots - y_2[0]\\) , \\(\\mathbf{eq}_{17} = (x_1[2] \\cdot y_1[15]) + (x_1[3] \\cdot y_1[14]) + \\dots - y_2[1]\\) and so on. Continuing until the last two \\(\\mathbf{eq}_{30} = (x_1[15] \\cdot y_1[15]) - y_2[14]\\) , \\(\\mathbf{eq}_{31} = -y_2[15]\\) . The full list can be found in Appendix A. Now, notice that the \\(\\mathbf{eq}_i\\) 's do not care about the carry they generate. That means, if \\(\\mathbf{eq}_i = 10\\) , then what we really want the result to be is \\(0\\) and save \\(1\\) as a carry for the next operation. To express this fact as a constraint, we say that the following has to be satisfied: $$ \\mathbf{eq} + \\text{carry} = \\text{carry}' \\cdot 2^{16}, $$ where \\(\\text{carry}\\) represents the carry taken into account in the actual clock, and \\(\\text{carry}'\\) represents the carry generated by the actual operation. Remark : A technicality is that \\(\\text{carry}\\) is subdivided into two other \\(\\text{carry}_L\\) and \\(\\text{carry}_H\\) such that: $$ \\text{carry} = \\text{carry}_L + \\text{carry}_H \\cdot 2^{18}. $$","title":"Arithmetic"},{"location":"zkEVM/State-Machines/Arithmetic/Arithmetic-State-Machine-typ/#the-arithmetic-state-machine","text":"As a secondary state machine, the Arithmetic State Machine has the executor part (the Arithmetic SM Executor) and an internal Arithmetic PIL (program) which is a set of verification rules, written in the PIL language. The Arithmetic SM Executor is written in two versions; Javascript and C/C++. The Polygon Hermez Repo is here https://github.com/0xPolygonHermez Arithmetic SM Executor : sm_arith folder Arithmetic SM PIL : arith.pil","title":"The Arithmetic State Machine"},{"location":"zkEVM/State-Machines/Arithmetic/Arithmetic-State-Machine-typ/#introduction","text":"The Arithmetic State Machine (SM) is one of the six secondary state machines receiving instructions from the Main SM Executor. As a secondary state machine, the Arithmetic SM has the executor part (the Arithmetic SM Executor) and an internal Arithmetic PIL program written in the PIL language. The main purpose of the Arithmetic SM is carry out elliptic curve arithmetic operations, such as Point Addition and Point Doubling.","title":"Introduction"},{"location":"zkEVM/State-Machines/Arithmetic/Arithmetic-State-Machine-typ/#standard-elliptic-curve-arithmetic","text":"Consider an elliptic curve \\(E\\) defined by \\(y^2 = x^3 + ax + b\\) over the finite field \\(\\mathbb{F} = \\mathbb{Z}_p\\) , where \\(p\\) is the prime, \\[\\begin{aligned} p = 2^{256} - 2^{32} - 2^9 - 2^8 - 2^7 -2^6 - 2^4 - 1. \\end{aligned}\\] Set the coefficients \\(a = 0\\) and \\(b = 7\\) , so that \\(E\\) reduces to \\begin{aligned} y^2 = x^3 + 7. \\end{aligned}","title":"Standard Elliptic Curve Arithmetic"},{"location":"zkEVM/State-Machines/Arithmetic/Arithmetic-State-Machine-typ/#field-arithmetic","text":"Consider points \\(( x_1, y_1)\\) , \\(( x_2, y_2)\\) , and \\(( x_3, y_3)\\) on \\(E\\) . Here, \\(y_2\\) and \\(y_3\\) are the result of performing field arithmetic over \\(x_1,y_1\\) and \\(x_2\\) . That is, $$ x_1 \\cdot y_1 + x_2 = y_2 \\cdot 2^{256} + y_3. $$ Note that, If \\(y_1\\) is set to \\(1\\) , the above equation represents field addition. Similarly, if \\(x_2\\) is set to \\(0\\) , then the equation represents field multiplication.","title":"Field Arithmetic"},{"location":"zkEVM/State-Machines/Arithmetic/Arithmetic-State-Machine-typ/#elliptic-curve-point-addition","text":"Given two points, \\(P = (x_1,y_1)\\) and \\(Q = (x_2,y_2)\\) , on the curve \\(E\\) with \\(x_1 \\neq x_2\\) , the point \\(P+Q = (x_3,y_3)\\) is computed as follows, \\[\\begin{aligned} x_3 &= s^2 - x_1 - x_2,\\\\ y_3 &= s (x_1 - x_3) - y_1 \\end{aligned}\\] where \\begin{aligned} s = \\dfrac{y_2 - y_1}{x_2 - x_1}. \\end{aligned}","title":"Elliptic Curve Point Addition"},{"location":"zkEVM/State-Machines/Arithmetic/Arithmetic-State-Machine-typ/#elliptic-curve-point-doubling","text":"Given a point \\(P = (x_1,y_1)\\) on the curve \\(E\\) such that \\(P \\neq \\mathcal{O}\\) , the point \\(P+P = 2P = (x_3,y_3)\\) is computed as follows, \\[\\begin{aligned} x_3 &= s^2 - 2x_1,\\\\ y_3 &= s (x_1 - x_3) - y_1, \\end{aligned}\\] where \\begin{aligned} s = \\dfrac{3x_1^2}{2y_1}. \\end{aligned} Remark : Since the above Elliptic Curve operations are implemented in the PIL language, it is more convenient to express them in terms of the constraints they must satisfy. These constraints are: \\[\\begin{aligned} \\text{EQ}_0 \\colon \\quad &x_1 \\cdot y_1 + x_2 - y_2 \\cdot 2^{256} - y_3 = 0, \\\\ \\text{EQ}_1 \\colon \\quad &s \\cdot x_2 - s \\cdot x_1 -y_2 + y_1 + q_0 \\cdot p = 0, \\\\ \\text{EQ}_2 \\colon \\quad & 2 \\cdot s \\cdot y_1 - 3 \\cdot x_1 \\cdot x_1 + q_0 \\cdot p = 0, \\\\ \\text{EQ}_3 \\colon \\quad & s \\cdot s - x_1 - x_2 - x_3 + q_1 \\cdot p = 0, \\\\ \\text{EQ}_4 \\colon \\quad & s \\cdot x_1 - s \\cdot x_3 - y_1 - y_3 + q_2 \\cdot p = 0, \\end{aligned}\\] where \\(q_0,q_1,q_2 \\in \\mathbb{Z}\\) , implying that these equations hold true over the integers. This approach is taken in order avoid having to compute divisions by \\(p\\) . Note also that only three possible computation scenarios arise: \\(\\text{EQ}_0\\) is activated while the rest are deactivated, \\(\\text{EQ}_1\\) , \\(\\text{EQ}_3\\) and \\(\\text{EQ}_4\\) are activated but \\(\\text{EQ}_0\\) and \\(\\text{EQ}_2\\) are deactivated, \\(\\text{EQ}_2\\) , \\(\\text{EQ}_3\\) and \\(\\text{EQ}_4\\) are activated and \\(\\text{EQ}_0\\) and \\(\\text{EQ}_1\\) are deactivated. Since at most, one of \\(\\text{EQ}_1\\) and \\(\\text{EQ}_2\\) are activated in any scenario, we can afford \"sharing'' the same \\(q_0\\) for both. Motivated by the implemented operations, the Arithmetic SM is composed of 6 registers \\begin{aligned} x_1,\\ y_1,\\ x_2,\\ y_2,\\ x_3,\\ y_3. \\end{aligned} Each of these registers is composed of \\(16\\) sub-registers of \\(16\\) -bit ( \\(2\\) byte) capacity, adding up to a total of \\(256\\) bits per register. There is also a need to provide \\(s\\) and \\(q_0,q_1,q_2\\) , which are also \\(256\\) -bit field elements.","title":"Elliptic Curve Point Doubling"},{"location":"zkEVM/State-Machines/Arithmetic/Arithmetic-State-Machine-typ/#how-the-operations-are-performed","text":"Compute the previous operations at \\(2\\) -byte level. This means that if, for instance, one is performing the multiplication of \\(x_1\\) and \\(y_1\\) , at the first clock \\(x_1[0] \\cdot y_1[0]\\) is computed. Then, \\((x_1[0] \\cdot y_1[1]) + (x_1[1] \\cdot y_1[0])\\) is computed in the second clock, followed by \\((x_1[0] \\cdot y_1[2]) + (x_1[1] \\cdot y_1[1]) + (x_1[2] \\cdot y_1[0])\\) in the third, and so on. As depicted in Figure 1 , this process is completely analogous to the schoolbook multiplication. However, it is performed at \\(2\\) -byte level, instead of at decimal level. School Multiplication Example Use the following notation; $$ \\begin{aligned} \\mathbf{eq\\ } &= x_1[0] \\cdot y_1[0] \\ \\mathbf{eq'} &= x_1[0] \\cdot y_1[1] + x_1[1] \\cdot y_1[0] \\end{aligned} $$ But then, the carry generated by \\(\\mathbf{eq}\\) has to be taken into account by \\(\\mathbf{eq'}\\) . Going back to our equations; \\(\\text{EQ}_0, \\text{EQ}_1, \\text{EQ}_2, \\text{EQ}_4\\) ; let's see how the operation is performed in \\(\\text{EQ}_0\\) . First, we compute \\(\\mathbf{eq}_0 = (x_1[0] \\cdot y_1[0]) + x_2[0] - y_3[0]\\) . Second, we compute \\(\\mathbf{eq}_1 = (x_1[0] \\cdot y_1[1]) + (x_1[1] \\cdot y_1[0]) + x_2[1] - y_3[1]\\) . Third, \\(\\mathbf{eq}_2 = (x_1[0] \\cdot y_1[2]) + (x_1[1] \\cdot y_1[1]) + (x_1[2] \\cdot y_1[0]) + x_2[2] - y_3[2]\\) . This is continued until one reaches the computation, \\(\\mathbf{eq}_{15} = (x_1[0] \\cdot y_1[15]) + (x_1[1] \\cdot y_1[14]) + \\dots + x_2[15] - y_3[15]\\) . This is the time when \\(y_2\\) come into place. Since we have filled the first \\(256\\) bits of the result of the operation (and the result can be made of more than \\(256\\) bits) we need a new register to place the result from this point. We change the addition of \\(x_2[i] - y_3[i]\\) by \\(-y_2[i]\\) . Therefore, we obtain that \\(\\mathbf{eq}_{16} = (x_1[1] \\cdot y_1[15]) + (x_1[2] \\cdot y_1[14]) + \\dots - y_2[0]\\) , \\(\\mathbf{eq}_{17} = (x_1[2] \\cdot y_1[15]) + (x_1[3] \\cdot y_1[14]) + \\dots - y_2[1]\\) and so on. Continuing until the last two \\(\\mathbf{eq}_{30} = (x_1[15] \\cdot y_1[15]) - y_2[14]\\) , \\(\\mathbf{eq}_{31} = -y_2[15]\\) . The full list can be found in Appendix A. Now, notice that the \\(\\mathbf{eq}_i\\) 's do not care about the carry they generate. That means, if \\(\\mathbf{eq}_i = 10\\) , then what we really want the result to be is \\(0\\) and save \\(1\\) as a carry for the next operation. To express this fact as a constraint, we say that the following has to be satisfied: $$ \\mathbf{eq} + \\text{carry} = \\text{carry}' \\cdot 2^{16}, $$ where \\(\\text{carry}\\) represents the carry taken into account in the actual clock, and \\(\\text{carry}'\\) represents the carry generated by the actual operation. Remark : A technicality is that \\(\\text{carry}\\) is subdivided into two other \\(\\text{carry}_L\\) and \\(\\text{carry}_H\\) such that: $$ \\text{carry} = \\text{carry}_L + \\text{carry}_H \\cdot 2^{18}. $$","title":"How The Operations Are Performed"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/","text":"[ToC] Binary State Machine The Binary State Machine (SM) is one of the six secondary state machines receiving instructions, called Binary Actions, from the Main State Machine Executor. It is responsible for the execution of all binary operations in the zkProver. As a secondary state machine, the Binary State Machine has the executor part (the Binary SM Executor) and an internal Binary PIL (program) which is a set of verification rules, written in the PIL language. The Binary SM Executor is written in two versions; Javascript and C/C++. The Polygon zkEVM Repo is here https://github.com/0xPolygonHermez Binary SM Executor : sm_binary.js Binary SM PIL : binary.pil Test Vectors : binary_test.js Binary Operations on 256-bit Strings The zkEVM (zero-knowledge Ethereum Virtual Machine) performs the following binary operations on 256-bit strings, \\(\\text{ADD }\\) ( \\(+\\) ), the addition operation adds two 256-bit numbers. \\(\\text{SUB }\\) ( \\(-\\) ), the subtraction operation computes the difference between two 256-bit numbers. \\(\\text{LT }\\) ( \\(<\\) ), the less-than operation checks if a 256-bit number is smaller than another 256-bit number, without considering the signs the numbers. \\(\\text{SLT }\\) ( \\(<\\) ), the signed less-than operation checks if a 256-bit number is smaller than another 256-bit number, but takes into consideration the respective signs of the numbers. \\(\\text{EQ }\\) ( \\(=\\) ), the 'equal' operation checks if two 256-bit numbers are equal. \\(\\text{AND }\\) ( \\(\\land\\) ), the operation that computes the bit-wise \"AND\" of two numbers. \\(\\text{OR }\\) ( \\(\\lor\\) ), the operation computes the bit-wise \"OR\" of two numbers. \\(\\text{XOR }\\) ( \\(\\oplus\\) ), the operation computes the bit-wise \"XOR\" of two numbers. \\(\\text{NOT }\\) ( \\(\\neg\\) ), the operation computes the bit-wise \"NOT\" of a binary number. In order to understand how the \\(\\text{ADD}\\) , \\(\\text{SUB}\\) , \\(\\text{LT}\\) and \\(\\text{SLT}\\) operations work, one needs to first understand how the zkEVM codes 256-bit strings to signed and unsigned integers. Figure 1 shows these codifications for 3-bit strings but the idea can be easily extended to 256-bit strings. Figure 1: Codifications of 3-bit strings for signed and unsigned integers as used by the EVM Adding two strings is performed bit-by-bit using the corresponding carry. For example, add the 3-bit strings \\(\\mathtt{0b001}\\) and \\(\\mathtt{0b101}\\) , where \\(\\mathtt{0b}\\) means binary, Start with an initial \\(carry=0\\) and add the least significant bits, \\(1+1+carry=1+1+0=0\\) , so the next carry becomes \\(carry'=1\\) . Next, add the the second least-significant bits using the previous carry, \\(0+0+carry = 0+0+1 = 1\\) , this time the next carry is \\(carry'=0\\) . Finally, add the most significant bits, \\(0+1+carry=0+1+0=1\\) , with the final carry being \\(carry'=0\\) . As a result: \\(\\mathtt{0b001}+\\mathtt{0b101} = \\mathtt{0b110}\\) with \\(carry=0\\) . The sum \\(\\mathtt{0b001}+\\mathtt{0b101} = \\mathtt{0b110}\\) , for unsigned integers is \\(1+5=6\\) , while for signed integers encoded with complement to two, this sum is \\(1+(-3) =(-2)\\) . In other words, the same binary sum can be done for both signed integers and for unsigned integers. The operations \\(\\text{LT}\\) and \\(\\text{SLT}\\) are different however. When comparing unsigned integers (using \\(\\text{LT}\\) ), the natural order for comparisons is applied. For example, \\(010 < 110\\) , i.e., \\(2 < 6\\) . When comparing signed integers (using \\(\\text{SLT}\\) ), one must take into account the most significant bit that acts as the sign. If the most-significant bits of the two strings being compared is the same, the the natural order applies. For example, \\(101 < 110\\) . i.e., \\(-3 < -2\\) However, if the most significant bits of strings being compared are different, then the order must be flipped (bigger numbers start with 0). For example, \\(110 < 001\\) . i.e., \\(-2 < 1\\) . Finally, notice that with unsigned integers, there is a caveat since 4 and -4 have the same codification. On the other hand, the \\(\\text{AND}\\) , \\(\\text{OR}\\) , \\(\\text{XOR}\\) and \\(\\text{NOT}\\) operations are bit-wise operations, that is to say, the operation is done bit-by-bit. As a result, there is no carry to be considered when operating a pair of bits. This makes the checks easier to implement for bit-wise operations. Table 1 depicts the truth tables of \\(\\text{AND}\\) , \\(\\text{OR}\\) and \\(\\text{XOR}\\) operators, respectively. Table 1: Truth Tables of bit-wise operations Notice that we do not consider the \\(\\text{NOT}\\) operation. This is because the \\(\\text{NOT}\\) operation can be easily implemented with the \\(\\text{XOR}\\) operation, by taking an \\(\\text{XOR}\\) of the 256-bit string and \\(\\texttt{0xff...ff}\\) . The Design Of The Binary SM The Executor of the Binary SM records the trace of each computation in the state machine, and this computational trace is used to prove correctness of computations. The execution trace is typically in the form of 256-bit strings. And the polynomial constraints, that every correct execution trace must satisfy, are described in a PIL file (or 'code'). For the Binary SM, these computations refers to the aforementioned binary operations, and uses special codes for each of the operations. Codes for the Binary Operations Each operation that the Binary SM checks has a code as shown in Table 2, below. In instances where none of the defined binary operations is carried out, the Binary SM's operation is considered to be a \\(\\text{NOP}\\) (No Operation), in which case any code not in the defined list of codes can be used. Table 2: All Operations Checked by the Binary SM \\(\\textbf{Operation Name}\\) \\(\\textbf{Mnemonic}\\) \\(\\textbf{Symbol}\\) \\(\\textbf{BinOpCode}\\) \\(\\text{Addition}\\) \\(\\mathrm{ADD}\\) \\(+\\) \\(0\\) \\(\\text{Subtraction}\\) \\(\\mathrm{SUB}\\) \\(-\\) \\(1\\) \\(\\text{Less Than}\\) \\(\\mathrm{LT}\\) \\(<\\) \\(2\\) \\(\\text{Signed Less Than}\\) \\(\\mathrm{SLT}\\) \\(<\\) \\(3\\) \\(\\text{Equal To}\\) \\(\\mathrm{EQ}\\) \\(=\\) \\(4\\) \\(\\text{Bitwise AND}\\) \\(\\mathrm{AND}\\) \\(\\wedge\\) \\(5\\) \\(\\text{Bitwise OR}\\) \\(\\mathrm{OR}\\) \\(\\vee\\) \\(6\\) \\(\\text{Bitwise XOR}\\) \\(\\mathrm{XOR}\\) \\(\\oplus\\) \\(7\\) \\(\\text{No Operation}\\) \\(\\mathrm{NOP}\\) \\(\\mathrm{NOP}\\) \\(\\star\\) Internal Byte Plookups The Binary SM is internally designed to use plookups of bytes for all the binary operations. That is, it uses plookups that contain all the possible input bytes and output byte combinations, \\[ \\text{byte}_{in_0} \\star \\text{byte}_{in_1} = \\text{byte}_{out}, \\] where \\(\\star\\) is one of the possible operations. When executing a binary operation between the 256-bit input strings, an execution trace is generated in cycles of \\(32\\) steps per operation. At each step, the corresponding byte-wise operation and any required extra information, such as 'carries' or auxiliary values, form part of the computation trace. Additionally, each \\(256\\) -bit string (the two inputs and the output) are expressed using \\(8\\) registers of \\(32\\) -bits. Connection with the Main SM The constraint that connects the execution trace of the Main SM with the execution trace of the Binary SM is a Plookup, which is performed at each row of the Binary SM execution trace when the cycle is completed (this is when a register called \\(\\texttt{RESET}\\) is 1). The Plookup checks the operation code, the registries for the input and output 256-bit strings, and the final carry. Operating At Byte-Level This section provides examples of how the byte-wise operations work. A \\(256\\) -bit integer \\(\\mathbf{a}\\) is herein denoted in vector form as \\((a_{31}, \\dots, a_1, a_0)\\) to indicate that, $$ \\mathbf{a} = a_{31}\\cdot (2^8)^{31} + a_{30}\\cdot (2^8)^{30} + \\cdots + a_1\\cdot2^8 + a_0 = \\sum_{i = {31}}^{0} a_i \\cdot (2^8)^i, $$ where each \\(a_i\\) is a byte that can take values between \\(0\\) and \\(2^8 - 1\\) . Example 1. If \\(\\mathbf{a} = 29967\\) , its byte decomposition can be written as \\(\\mathbf{a} = (\\mathtt{0x75}, \\mathtt{0x0F})\\) , because \\(\\mathbf{a} = 29967 = 117 \\cdot 2^8 + 15\\) , and in hexadecimal, \\(117 \\mapsto \\mathtt{0x75}\\) and \\(15 \\mapsto \\mathtt{0x0F}\\) . Addition Here is how the addition operation on two \\(256\\) -bit numbers is reduced to a byte-by-byte addition, and thus ready to use the byte-wise Plookup table. Observe that adding two bytes \\(a\\) and \\(b\\) (i.e., \\(a\\) and \\(b\\) are members of the set \\([0, 2^8-1]\\) ), may result in a sum \\(c\\) which cannot be expressed as a single byte. For example, if \\(a = \\mathtt{0xFF}\\) and \\(b = \\mathtt{0x01}\\) , then, $$ a + b = \\mathtt{0xFF} + \\mathtt{0x01} = \\mathtt{0x100}. $$ In byte-form, \\(c=\\mathtt{0x00}\\) and with \\(carry'=1\\) . This carry has to be taken care of when dealing with bytes. Consider now the process of adding two bytes. Example 2. Take for instance, \\(\\mathbf{a} = (a_1, a_0) = (\\mathtt{0xFF}, \\mathtt{0x01})\\) and \\(\\mathbf{b} = (b_1, b_0) = (\\mathtt{0xF0}, \\mathtt{0xFF})\\) . First add the less significant bytes: \\[ \\begin{aligned} a_1 + b_1 &= \\mathtt{0x01} + \\mathtt{0xFF} = c_1 = \\mathtt{0x00}, \\\\ carry_1 &= 1. \\end{aligned} \\] Then, add the next significant byte, \\[ \\begin{aligned} a_2 + b_2 + carry_1 &= \\mathtt{0xFF} + \\mathtt{0xF0} = c_2 = \\mathtt{0xF0}, \\\\ carry_2 &= 1. \\end{aligned} \\] The previous example shows is scheme depicts several cases that need to be treated separately; If \\(a_1 + b_1 < 2^8\\) and \\(a_2 + b_2 < 2^8\\) , then the sum \\(\\mathbf{a} + \\mathbf{b}\\) is simply, \\[ \\mathbf{a} + \\mathbf{b} = (a_2 + b_2, a_1 + b_1). \\] If \\(a_1 + b_1 < 2^8\\) but \\(a_2 + b_2 \\geq 2^8\\) , then \\(a_2 + b_2\\) does not fit in a single byte. Hence, the sum of \\(a_2\\) and \\(b_2\\) has to be written as, \\[ a_2 + b_2 = 1 \\cdot 2^8 + c_2, \\] \u200b for some byte \\(c_2\\) . The addition \\(\\mathbf{a} + \\mathbf{b}\\) is then computed as follows, $$ \\mathbf{a} + \\mathbf{b} = (1, c_2, a_1 + b_1). $$ If \\(a_1 + b_1 \\geq 2^8\\) , then we have that: \\[ a_1 + b_1 = 1 \\cdot 2^8 + c_1, \\] \u200b for some byte \\(c_1\\) . Then we can write, $$ \\mathbf{a} + \\mathbf{b} = (a_2 + b_2 + 1) \\cdot 2^8 + c_1. $$ Consider the following two scenarios: (a) If \\(a_2 + b_2 + 1 \\geq 2^8\\) , then the sum will take the form: $$ a_2 + b_2 + 1 = 1 \\cdot 2^8 + c_2. $$ \u200b Therefore, the byte decomposition of \\(\\mathbf{a} + \\mathbf{b}\\) is, $$ \\mathbf{a} + \\mathbf{b} = (1, c_2, c_1). $$ (b) If \\(a_2 + b_2 + 1 < 2^8\\) , then the byte decomposition of \\(\\mathbf{a} + \\mathbf{b}\\) is: $$ \\mathbf{a} + \\mathbf{b} = (c_2, c_1). $$ Observe that addition of \\(256\\) -bit numbers can be reduced to additions at byte-level by operating through the previous cases in an iterative manner. Subtraction Reducing Subtraction to byte-level turns out to be trickier than Addition case. Suppose \\(\\mathbf{a} = \\mathtt{0x0101}\\) and \\(\\mathbf{b} = \\mathtt{0x00FF}\\) . Observe that \\(\\mathtt{0xFF}\\) cannot be subtracted from \\(\\mathtt{0x01}\\) because \\(\\mathtt{0xFF} > \\mathtt{0x01}\\) . However, we know that the result is \\(\\mathbf{a} - \\mathbf{b} = \\mathbf{c} = \\mathtt{0x0002}\\) . In order to get this result, notice that the operation can be described as follows, \\[ \\begin{aligned} \\mathbf{a} - \\mathbf{b} & = (\\mathtt{0x01} - \\mathtt{0x00}) \\cdot 2^8 + (\\mathtt{0x01} - \\mathtt{0xFF}) \\\\ & = (\\mathtt{0x01} - \\mathtt{0x00}) \\cdot 2^8 - 2^8 + 2^8 + (\\mathtt{0x01} - \\mathtt{0xFF}) \\\\ & = (\\mathtt{0x01} - \\mathtt{0x00 - 0x01}) \\cdot 2^8 + \\mathtt{0xFF + 0x01} + \\mathtt{0x01} - \\mathtt{0xFF} \\\\ & = ( \\mathtt{0x00} ) \\cdot 2^8 + \\mathtt{0x02} \\end{aligned} \\] The output byte decomposition is \\(\\mathbf{a} = (c_1, c_0) = (\\mathtt{0x00}, \\mathtt{0x02})\\) . Nonetheless, it may be necessary to look at more examples so as to better understand how subtraction works at byte-level in a more general sense. Consider now subtraction of numbers with \\(3\\) bytes. Say, \\(a = \\mathtt{0x0001FE}\\) and \\(b = \\mathtt{0xFEFFFF}\\) . First analyse the first two bytes, as in the previous example, \\[ \\begin{aligned} (\\mathtt{0x01} - \\mathtt{0xFF}) \\cdot 2^8 + (\\mathtt{0xFE} - \\mathtt{0xFF}) &= (\\mathtt{0x01} - \\mathtt{0xFF} - \\mathtt{0x01} ) \\cdot 2^8 + (\\mathtt{2^8} + \\mathtt{0xFE} - \\mathtt{0xFF}) \\\\ & = (\\mathtt{0x01} - \\mathtt{0xFF - 0x01}) \\cdot 2^8 + \\mathtt{0xFF} \\end{aligned} \\] But now observe that \\(\\mathtt{0x01} - \\mathtt{0xFF} - \\mathtt{0x01}\\) is also a negative value. Hence, there is a need to repeat the strategy and keep a carry to the next byte, \\[ \\begin{aligned} &(\\mathtt{0x00} - \\mathtt{0xFE}) \\cdot 2^{16} + (\\mathtt{0x01} - \\mathtt{0xFF} - \\mathtt{0x01}) \\cdot 2^8 + \\mathtt{0xFF} = \\\\ &(\\mathtt{0x00} - \\mathtt{0xFE} - \\mathtt{0x01}) \\cdot 2^{16} + (\\mathtt{2^8} + \\mathtt{0x01} - \\mathtt{0xFF} - \\mathtt{0x01}) \\cdot 2^8 + \\mathtt{0xFF} = \\\\ &(\\mathtt{0x00} - \\mathtt{0xFE} - \\mathtt{0x01}) \\cdot 2^{16} + \\mathtt{0x01} \\cdot 2^8 + \\mathtt{0xFF}. \\end{aligned} \\] Observe that the previous example is included in this case. In general, let \\(a = (a_i)_i\\) and \\(b = (b_i)_i\\) , with \\(a_i, b_i\\) bytes, be the byte representations of \\(a\\) and \\(b\\) . Instead of checking if we can perform the subtraction \\(a_i - b_i\\) for some bytes \\(i\\) , we are checking if \\(a_i - b_i - \\texttt{carry} \\geq 0\\) . Equivalently, we are checking if \\(a_i - \\texttt{carry} \\geq b_i\\) . The previous case can be recovered by setting \\(\\texttt{carry} = 1\\) and the first case corresponds to setting \\(\\mathtt{carry = 0}\\) . We have two possible cases, If \\(a_i - \\texttt{carry} \\geq b_i\\) , then \\(a_i - b_i - \\texttt{carry}\\) provides the corresponding \\(i\\) -th byte of the representation of \\(a - b\\) . If \\(a_i - \\texttt{carry} < b_i\\) then we should compute the corresponding \\(i\\) -th byte of the representation of \\(a - b\\) as, \\[ 2^8 - b_i + a_i - \\texttt{carry} = 255 - b_i + a_i - \\texttt{carry} + 1. \\] However, we need to discuss the last step of our example. Observe that we can not perform the operation \\(\\mathtt{0x00} - \\mathtt{0xFE} - \\mathtt{0x01}\\) since it corresponds to a negative value. But as we are working with unsigned integers, we will do the two's complement and set the last byte to, $$ 2^8 - \\mathtt{0xFE} + \\mathtt{0x00} - \\mathtt{0x01} = 255 - \\mathtt{0xFE} + \\mathtt{0x00} - \\mathtt{0x01} + 1 = 255 - b_3 + a_3 - \\texttt{carry} + 1. $$ Observe that this is also included in the case when \\(a_i - \\texttt{carry} < b_i\\) , so we must not treat the last bit in a different manner. To end up with our example, we get the following byte representation of \\(a - b\\) , $$ c = (\\mathtt{0x01}, \\mathtt{0x01}, \\mathtt{0xFF}) = \\mathtt{0x01} \\cdot 2^{16} + \\mathtt{0x01} \\cdot 2^8 + \\mathtt{0xFF}. $$ Less Than We want to describe the less than comparator byte-wise. For \\(256\\) -bits integers, the operation \\(<\\) will output \\(c = 1\\) if \\(a < b\\) and \\(c = 0\\) otherwise. As we are working in the natural integers order, the most significant byte decide and, if they are equal, we should consider the previous one until we can decide. Let us propose the example with \\(a = \\mathtt{0xFF AE 09}\\) and \\(b = \\mathtt{0x FF AE 02}\\) . We know that \\(a > b\\) . Why? We should start at the most significant byte. We know that $$ a \\mathtt{>> 16} = \\mathtt{0x FF} = \\mathtt{0x FF} = b \\mathtt{>> 16}. $$ Hence, we can not decide with this byte. An the same happens with the second byte, they are both equal to \\(\\mathtt{0x AE}\\) . Hence, the less significant byte decides, $$ \\mathtt{0x 09} > \\mathtt{0x 02}. $$ However, the problem with our set up is that we must start with the less significant byte and climb up to the most significant byte. The strategy will be to use some kind of a carry in order to \"carry\" the decisions from previous bytes. Let us do an example step by step, now with \\(a = \\mathtt{0x FF AA 02}\\) and \\(b = \\mathtt{0x 01 AA 09}\\) . First of all, we will compare the less significant bytes. Since $$ \\mathtt{0x 02} < \\mathtt{0x 09}, $$ we will set up \\(\\mathtt{carry} = 1\\) . We will carry this decision until we finish to process all bytes or, alternatively, we should change to the complementary decision. Therefore, since the next two bytes are equal and we are not at the end, we maintain \\(\\mathtt{carry}\\) to \\(1\\) . The previous step is the last one. We compare the most significant bytes, $$ \\mathtt{0x FF} \\not < \\mathtt{0x 01}. $$ Henceforth, we should output a \\(0\\) , independently to the previous carry decision. But, let us suppose now that \\(b = \\mathtt{0x FF AA 09}\\) . Then, in this last step, we should output a \\(1\\) , since \\(a < b\\) . The idea is that, in the last step, if both bytes are equal, we should output the decision carry \\(\\mathtt{carry}\\) . In general, in the step \\(i\\) , comparing bytes \\(a_i\\) and \\(b_i\\) , we have \\(3\\) cases, If \\(a_i < b_i\\) , we set \\(\\mathtt{carry}\\) to \\(1\\) . If we are at the most significant byte, we output \\(1\\) . If \\(a_i = b_i\\) , we let \\(\\mathtt{carry}\\) unchanged in order to maintain the previous decision. If we are at the most significant byte, we output \\(\\mathtt{carry}\\) . If \\(a_i > b_i\\) , we set \\(\\mathtt{carry}\\) to \\(0\\) . If we are at the most significant byte, we output \\(0\\) . Signed Less Than In computer science, the most common method of representing signed integers on computers, is called \\textbf{two's complement}. When the most significant bit is a one, the number is signed as negative. The way to express a negative integer \\(x\\) into two's complement form is chosen so that, among integers of the same sign, the lexicographical order is maintained. That is, if \\(a < b\\) are signed integers of the same sign, then its two's complement representations preserve the same order. This will not be true if the signs are different. For example, it is not surprising that $$ 000\\dots0 > 111\\dots1 $$ using the two's complement encoding, because \\(111\\dots1\\) is negative and \\(000\\dots0\\) is positive. The two's complement form of negative integer \\(x\\) in a \\(N\\) -bits system is the binary representation of \\(2^N - x\\) . For example, let \\(x = -1\\) and \\(N = 4\\) . Then, $$ 10000 - 0001 = 1111. $$ Hence, \\(-1 = 1111\\) in this representation. It is easy to see that \\(-2 = 1110\\) because $$ 10000 - 0010 = 1110. $$ Hence, observe that \\(-1 > -2\\) because \\(1111 > 1110\\) and conversely: the order is preserved for integers of the same sign. We will describe a method to compare signed integers byte-wise. First of all, let us analyze the order among all the signed bytes, in order to understand how to compare them. Once we achieve this, the strategy will be very similar to the previous Less Than. Let \\(a = (a_{31}, a_{30}, \\dots, a_0)\\) and \\(b = (b_{31}, b_{30}, \\dots, b_0)\\) be the byte-representation of the 256-bits unsigned integers \\(a\\) and \\(b\\) . We will define \\(\\texttt{sgn}(a) = a_{31, 7}\\) , where $$ a_{31} = \\sum_{i = 0}^7 a_{31, i} \\cdot 2^i $$ is the binary representation of \\(a_{31}\\) . That is, \\(\\texttt{sgn}(a)\\) is the most significant bit of \\(a\\) or, equivalently, the \"sign\" of \\(a\\) . In a similar way, we define \\(\\texttt{sgn}(b)\\) . Observe that it is easy to compare \\(a\\) and \\(b\\) if \\(\\texttt{sgn}(a) \\neq \\texttt{sgn}(b)\\) . For example, $$ a = \\mathtt{0b11111111} = \\mathtt{0xFF} < \\mathtt{0x00} = \\mathtt{0b00000000} = b $$ because \\(\\texttt{sgn}(a) > \\texttt{sgn}(b)\\) i.e. \\(a\\) is negative and \\(b\\) is positive. If \\(\\texttt{sgn}(a) \\neq \\texttt{sgn}(b)\\) , we can simply compare \\(a\\) and \\(b\\) using the same strategy as before, because the natural lexicographic order is preserved in this case. Then, we have the following cases when comparing \\(a\\) and \\(b\\) : If \\(\\texttt{sgn}(a) = 1\\) and \\(\\texttt{sgn}(b) = 0\\) , then \\(a < b\\) . If \\(\\texttt{sgn}(a) = 0\\) and \\(\\texttt{sgn}(b) = 1\\) , then \\(a > b\\) . If \\(\\texttt{sgn}(a) = \\texttt{sgn}(b)\\) , the order is the usual one and hence, we already know how to compare \\(a\\) and \\(b\\) . \u200b Recall that we are processing the bytes of \\(a\\) and \\(b\\) from the less significant bytes to the most significant bytes. Hence, we need to adapt our strategy following this order. The strategy will be almost the same than in the unsigned operation. First of all, we start comparing \\(a_0\\) and \\(b_0\\) . \u200b (a) If \\(a_0 < b_0\\) , we set \\(\\texttt{carry} = 1\\) . \u200b (b) Otherwise we set \\(\\texttt{carry} = 0\\) . For all \\(0 < i < 31\\) , we compare \\(a_i\\) and \\(b_i\\) . \u200b (a) If \\(a_i < b_i\\) , we set \\(\\texttt{carry} = 1\\) . \u200b (b) If \\(a_i = b_i\\) , we leave \\(\\texttt{carry}\\) unchanged from the previous step. \u200b (c) Otherwise, we set \\(\\texttt{carry} = 0\\) . Now, we have to compare the last byte. We follow the described strategy of comparing the signs: \u200b (a) If \\(\\texttt{sgn}(a) > \\texttt{sgn}(b)\\) , we output a \\(1\\) , so \\(a < b\\) . \u200b (b) If \\(\\texttt{sgn}(a) < \\texttt{sgn}(b)\\) , we output a \\(0\\) , so \\(a < b\\) . \u200b (c) If \\(\\texttt{sgn}(a) = \\texttt{sgn}(b)\\) , we compare the last bytes \\(a_{31}\\) and \\(b_{31}\\) in the same way we have compare the previous bytes. We output \\(0\\) or \\(1\\) accordingly. \u200b (i) If \\(a_{31} < b_{31}\\) , we output a \\(1\\) , so \\(a < b\\) . \u200b (ii) If \\(a_{31} = b_{31}\\) , we output the previous \\(\\texttt{carry}\\) , maintaining the last decision. \u200b (iii) Otherwise, we output a \\(0\\) , so \\(a \\not < b\\) . Let us exemplify the previous procedure setting \\(a = \\mathtt{0xFF FF FF 00}\\) and \\(b = \\mathtt{0x00 FF FF FF}\\) . We know that \\(a < b\\) , so we should output a \\(1\\) . Observe that the less significant byte of \\(a\\) is leaser than the less significant byte of \\(b\\) . Hence, we should put \\(\\texttt{carry}\\) equal to \\(1\\) . The next two bytes of \\(a\\) and \\(b\\) are both equal to \\(\\mathtt{0xFF FF}\\) , therefore we maintain \\(\\texttt{carry}\\) unchanged equal to \\(1\\) . However, since \\(a\\) is negative and \\(b\\) is positive, we should change the decision and output a \\(1\\) , independently of the \\(\\texttt{carry}\\) . Equality We want to describe the equality comparator byte-wise. For unsigned \\(256\\) -bits integers, the operation \\(=\\) will output \\(c = 1\\) if \\(a = b\\) and \\(c = 0\\) otherwise. This operation is very simple to describe byte-wise, since \\(a = b\\) if and only if all its bytes coincide. Let us compare \\(a = \\mathtt{0xFF 00 a0 10}\\) and \\(b = \\mathtt{0xFF 00 00 10}\\) byte-wise. Observe that the first byte is the same \\(\\mathtt{0x10}\\) , however the next byte are different \\(\\mathtt{0xa0} \\neq \\mathtt{0x00}\\) . Hence, we can finish here and state that \\(a \\neq b\\) . We will describe an algorithm in order to proceed processing all the bytes. We will use a carry to mark up when a difference among bytes has \\(\\textbf{not}\\) been found (i.e. if \\(\\texttt{carry}\\) reach \\(0\\) , then \\(a\\) and \\(b\\) should differ). Hence, the algorithm to compare two \\(32\\) -bytes integers \\(a = (a_{31}, a_{30}, \\dots, a_{0})\\) and \\(b = (b_{31}, b_{30}, \\dots, b_0)\\) is the following: First of all, since no differences have been found up to this point, set \\(\\texttt{carry}\\) equal to \\(1\\) . Now, compare \\(a_0\\) and \\(b_0\\) , (a) If \\(a_0\\) and \\(b_0\\) are equal, then leave \\(\\texttt{carry}\\) unchanged equal to \\(1\\) . (b) If \\(a_0 \\neq b_0\\) , then set \\(\\texttt{carry}\\) equal to \\(0\\) , which will imply that \\(a \\neq b\\) . When comparing bytes \\(a_i\\) and \\(b_i\\) for \\(0 < i \\leq 31\\) . (a) If \\(a_i = b_i \\textbf{ and } \\texttt{carry} = 1\\) , we should leave \\(\\texttt{carry}\\) unchanged and, if \\(i = 31\\) , we should output a \\(1\\) because \\(a = b\\) . The reason of demanding \\(\\texttt{carry} = 1\\) in the enter condition is because we should ensure that, if \\(\\texttt{carry} = 0\\) in a previous step, we must never enter to this block and change the non-equality decision. This is because if \\(a_i \\neq b_i\\) for some \\(i\\) , then \\(a \\neq b\\) . (b) Hence, if \\(a_i \\neq b_i\\) , we should set \\(\\texttt{carry} = 0\\) and output a \\(0\\) if \\(i = 31\\) . \u200b Bitwise Operations We will describe all bitwise operations at once because they are the easiest ones, since we do not need to introduce carries. Now, the idea is to extend this operation bitwise. That is, if we have the following binary representations of \\(a = (a_{31}, a_{30}, \\dots, a_{0})\\) and \\(a = (b_{31}, b_{30}, \\dots, b_{0})\\) where \\(a_i, b_i \\in \\{0, 1\\}\\) , then we define, \\[ a \\star b = (a_i \\star b_i)_i = (a_{31} \\star b_{31}, a_{30} \\star b_{30}, \\dots, a_0 \\star b_0) \\] for \\(\\star\\) being \\(\\land, \\lor\\) or \\(\\oplus\\) . For example, if \\(a = \\mathtt{0xCB} = \\mathtt{0b11001011}\\) and \\(b = \\mathtt{0xEA} = \\mathtt{0b11101010}\\) then, \\[ \\begin{aligned} a \\land b &= \\mathtt{0b11001010} = \\mathtt{0xCA},\\\\ a \\lor b &= \\mathtt{0b11101011} = \\mathtt{0xEB},\\\\ a \\oplus b &= \\mathtt{0b00100001} = \\mathtt{0x21}. \\end{aligned} \\] The Binary SM In Summary The Binary SM has 8 registries, each with an 32-bit Input/Output capacity. i.e., A total of 256 bits. It carries out binary computations in accordance with instructions from the Main SM Executor. The binary operations it executes, together with their specific opcodes, are; The common operations; the No-Operation NOP , Addition ADD and Subtraction SUB . Their corresponding special opcodes are; 0 , 1 and 2 , respectively. The Boolean operations; \\(\\text{Less Than }\\) LT , \\(\\text{Greater Than }\\) GT , \\(\\text{Signed Less Than }\\) SLT , \\(\\text{Signed Greater Than }\\) SGT , \\(\\text{Equal }\\) EQ and \\(\\text{Is-Zero }\\) ISZERO . Their special opcodes are, 3 , 4 , 5 , 6 and 7 , respectively. The logical operations; AND , OR , XOR and NOT , each with its special opcode; 9 , 10 , 11 and 12 , respectively. The Nutshell Firstly, the Binary SM Executor translates the Binary Actions into the PIL language. Secondly, it executes the Binary Actions. And thirdly, it uses the Binary PIL program binary.pil , to check correct execution of the Binary Actions using Plookup . Translation to PIL Language It builds the constant polynomials, which are generated once-off at the beginning. These are; the 4 bits long operation code P_OPCODE , the 1-bit Carry-in P_CIN , the Last-byte P_LAST , the 1 byte input polynomials P_A and P_B , the 16-bit output polynomial P_C , the 1-bit Carry-out P_COUT . It also creates constants required in the Binary PIL program; RESET is used to reset registry values every time the state machine completes a cycle of state transitions, FACTOR , which is an array of size 8, is used for correct placement of output registry values. Execution of Binary Actions The crux of the Binary SM Executor is in the lines 371 to 636 of sm_binary.js . This is where it executes Binary Actions. It takes the committed polynomials A, B and C, breaks them into bytes (in little-endian form). It sequentially pushes each triplet of bytes ( freeInA , freeInB , freeInC ) into their corresponding registries ( ai , bi , ci ). i.e., It runs one for-loop for all committed polynomials (A, B, C), over all the bytes of the 8 registries, which are altogether 32 bytes per committed polynomial. Recall that LATCH_SIZE = REGISTERS_NUM * BYTES_PER_REGISTER = 8 registries * 4 bytes. It hence amounts to 32 bytes for each committed polynomial. Once the 256-bit LATCH is built, it checks the opcodes and then computes the required binary operations in accordance with the instructions of the Main SM. It also generates the final registries. The Binary PIL (Program) There are two types of inputs to the Binary PIL program: the constant polynomials and the committed polynomials. The program operates byte-wise to carry out 256-bit Plookup operations. Each row of the lookup table is a vector of the form; { P_LAST , P_OPCODE , P_A , P_B , P_CIN , P_C , P_COUT }, consisting of the constant polynomials created by the Binary SM Executor. As seen above, P_LAST is the Last-byte, P_OPCODE is the 4-bit operation code, P_A and P_B , are the 1-byte input polynomials, P_CIN is the 1-bit Carry-in, P_C is the 16-bit output polynomial, P_COUT is the 1-bit Carry-out. The Binary PIL program takes in byte-size inputs, as in the Binary SM Executor, each 256-bit input committed polynomial is first broken into 32 bytes. For each of the 32 triplets freeInA , freeInB and freeInC , tallying with the three 256-bit committed polynomials A,B and C, the Binary PIL program, Prepares a Plookup input vector of the form; { last , opcode , freeInA , freeInB , cIn , freeInC , cOut }, where each element is a byte. Runs Plookup, {last,opcode,freeInA,freeInB,cIn,freeInC,cOut} in {P_LAST,P_OPCODE,P_A,P_B,P_CIN,P_C,P_COUT}; Resets registry values at the end of the 32 cycles using RESET , and utilising FACTOR for correct placement of values. For e.g., a0' = a0 * (1 - RESET) + freeInA * FACTOR[0]; Special variables, useCarry and c0Temp , are used for managing updates and assignments of values, particularly for Boolean operations, where the output c0 registry value is either TRUE = 1 or FALSE = 0 . Hence the Lines 104 and 105 of code; Line 104. c0Temp' = c0Temp * (1 - RESET) + freeInC * FACTOR[0]; Line 105. c0' = useCarry * (cOut - c0Temp ) + c0Temp; For all non-Boolean operations; the default value for useCarry is zero, making c0' = c0Temp . The value of c0' is therefore of the same form as other ci' update values. The output of the Binary PIL program is therefore a report of either pass or fail .","title":"Binary"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#binary-state-machine","text":"The Binary State Machine (SM) is one of the six secondary state machines receiving instructions, called Binary Actions, from the Main State Machine Executor. It is responsible for the execution of all binary operations in the zkProver. As a secondary state machine, the Binary State Machine has the executor part (the Binary SM Executor) and an internal Binary PIL (program) which is a set of verification rules, written in the PIL language. The Binary SM Executor is written in two versions; Javascript and C/C++. The Polygon zkEVM Repo is here https://github.com/0xPolygonHermez Binary SM Executor : sm_binary.js Binary SM PIL : binary.pil Test Vectors : binary_test.js","title":"Binary State Machine"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#binary-operations-on-256-bit-strings","text":"The zkEVM (zero-knowledge Ethereum Virtual Machine) performs the following binary operations on 256-bit strings, \\(\\text{ADD }\\) ( \\(+\\) ), the addition operation adds two 256-bit numbers. \\(\\text{SUB }\\) ( \\(-\\) ), the subtraction operation computes the difference between two 256-bit numbers. \\(\\text{LT }\\) ( \\(<\\) ), the less-than operation checks if a 256-bit number is smaller than another 256-bit number, without considering the signs the numbers. \\(\\text{SLT }\\) ( \\(<\\) ), the signed less-than operation checks if a 256-bit number is smaller than another 256-bit number, but takes into consideration the respective signs of the numbers. \\(\\text{EQ }\\) ( \\(=\\) ), the 'equal' operation checks if two 256-bit numbers are equal. \\(\\text{AND }\\) ( \\(\\land\\) ), the operation that computes the bit-wise \"AND\" of two numbers. \\(\\text{OR }\\) ( \\(\\lor\\) ), the operation computes the bit-wise \"OR\" of two numbers. \\(\\text{XOR }\\) ( \\(\\oplus\\) ), the operation computes the bit-wise \"XOR\" of two numbers. \\(\\text{NOT }\\) ( \\(\\neg\\) ), the operation computes the bit-wise \"NOT\" of a binary number. In order to understand how the \\(\\text{ADD}\\) , \\(\\text{SUB}\\) , \\(\\text{LT}\\) and \\(\\text{SLT}\\) operations work, one needs to first understand how the zkEVM codes 256-bit strings to signed and unsigned integers. Figure 1 shows these codifications for 3-bit strings but the idea can be easily extended to 256-bit strings. Figure 1: Codifications of 3-bit strings for signed and unsigned integers as used by the EVM Adding two strings is performed bit-by-bit using the corresponding carry. For example, add the 3-bit strings \\(\\mathtt{0b001}\\) and \\(\\mathtt{0b101}\\) , where \\(\\mathtt{0b}\\) means binary, Start with an initial \\(carry=0\\) and add the least significant bits, \\(1+1+carry=1+1+0=0\\) , so the next carry becomes \\(carry'=1\\) . Next, add the the second least-significant bits using the previous carry, \\(0+0+carry = 0+0+1 = 1\\) , this time the next carry is \\(carry'=0\\) . Finally, add the most significant bits, \\(0+1+carry=0+1+0=1\\) , with the final carry being \\(carry'=0\\) . As a result: \\(\\mathtt{0b001}+\\mathtt{0b101} = \\mathtt{0b110}\\) with \\(carry=0\\) . The sum \\(\\mathtt{0b001}+\\mathtt{0b101} = \\mathtt{0b110}\\) , for unsigned integers is \\(1+5=6\\) , while for signed integers encoded with complement to two, this sum is \\(1+(-3) =(-2)\\) . In other words, the same binary sum can be done for both signed integers and for unsigned integers. The operations \\(\\text{LT}\\) and \\(\\text{SLT}\\) are different however. When comparing unsigned integers (using \\(\\text{LT}\\) ), the natural order for comparisons is applied. For example, \\(010 < 110\\) , i.e., \\(2 < 6\\) . When comparing signed integers (using \\(\\text{SLT}\\) ), one must take into account the most significant bit that acts as the sign. If the most-significant bits of the two strings being compared is the same, the the natural order applies. For example, \\(101 < 110\\) . i.e., \\(-3 < -2\\) However, if the most significant bits of strings being compared are different, then the order must be flipped (bigger numbers start with 0). For example, \\(110 < 001\\) . i.e., \\(-2 < 1\\) . Finally, notice that with unsigned integers, there is a caveat since 4 and -4 have the same codification. On the other hand, the \\(\\text{AND}\\) , \\(\\text{OR}\\) , \\(\\text{XOR}\\) and \\(\\text{NOT}\\) operations are bit-wise operations, that is to say, the operation is done bit-by-bit. As a result, there is no carry to be considered when operating a pair of bits. This makes the checks easier to implement for bit-wise operations. Table 1 depicts the truth tables of \\(\\text{AND}\\) , \\(\\text{OR}\\) and \\(\\text{XOR}\\) operators, respectively. Table 1: Truth Tables of bit-wise operations Notice that we do not consider the \\(\\text{NOT}\\) operation. This is because the \\(\\text{NOT}\\) operation can be easily implemented with the \\(\\text{XOR}\\) operation, by taking an \\(\\text{XOR}\\) of the 256-bit string and \\(\\texttt{0xff...ff}\\) .","title":"Binary Operations on 256-bit Strings"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#the-design-of-the-binary-sm","text":"The Executor of the Binary SM records the trace of each computation in the state machine, and this computational trace is used to prove correctness of computations. The execution trace is typically in the form of 256-bit strings. And the polynomial constraints, that every correct execution trace must satisfy, are described in a PIL file (or 'code'). For the Binary SM, these computations refers to the aforementioned binary operations, and uses special codes for each of the operations.","title":"The Design Of The Binary SM"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#codes-for-the-binary-operations","text":"Each operation that the Binary SM checks has a code as shown in Table 2, below. In instances where none of the defined binary operations is carried out, the Binary SM's operation is considered to be a \\(\\text{NOP}\\) (No Operation), in which case any code not in the defined list of codes can be used. Table 2: All Operations Checked by the Binary SM \\(\\textbf{Operation Name}\\) \\(\\textbf{Mnemonic}\\) \\(\\textbf{Symbol}\\) \\(\\textbf{BinOpCode}\\) \\(\\text{Addition}\\) \\(\\mathrm{ADD}\\) \\(+\\) \\(0\\) \\(\\text{Subtraction}\\) \\(\\mathrm{SUB}\\) \\(-\\) \\(1\\) \\(\\text{Less Than}\\) \\(\\mathrm{LT}\\) \\(<\\) \\(2\\) \\(\\text{Signed Less Than}\\) \\(\\mathrm{SLT}\\) \\(<\\) \\(3\\) \\(\\text{Equal To}\\) \\(\\mathrm{EQ}\\) \\(=\\) \\(4\\) \\(\\text{Bitwise AND}\\) \\(\\mathrm{AND}\\) \\(\\wedge\\) \\(5\\) \\(\\text{Bitwise OR}\\) \\(\\mathrm{OR}\\) \\(\\vee\\) \\(6\\) \\(\\text{Bitwise XOR}\\) \\(\\mathrm{XOR}\\) \\(\\oplus\\) \\(7\\) \\(\\text{No Operation}\\) \\(\\mathrm{NOP}\\) \\(\\mathrm{NOP}\\) \\(\\star\\)","title":"Codes for the Binary Operations"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#internal-byte-plookups","text":"The Binary SM is internally designed to use plookups of bytes for all the binary operations. That is, it uses plookups that contain all the possible input bytes and output byte combinations, \\[ \\text{byte}_{in_0} \\star \\text{byte}_{in_1} = \\text{byte}_{out}, \\] where \\(\\star\\) is one of the possible operations. When executing a binary operation between the 256-bit input strings, an execution trace is generated in cycles of \\(32\\) steps per operation. At each step, the corresponding byte-wise operation and any required extra information, such as 'carries' or auxiliary values, form part of the computation trace. Additionally, each \\(256\\) -bit string (the two inputs and the output) are expressed using \\(8\\) registers of \\(32\\) -bits.","title":"Internal Byte Plookups"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#connection-with-the-main-sm","text":"The constraint that connects the execution trace of the Main SM with the execution trace of the Binary SM is a Plookup, which is performed at each row of the Binary SM execution trace when the cycle is completed (this is when a register called \\(\\texttt{RESET}\\) is 1). The Plookup checks the operation code, the registries for the input and output 256-bit strings, and the final carry.","title":"Connection with the Main SM"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#operating-at-byte-level","text":"This section provides examples of how the byte-wise operations work. A \\(256\\) -bit integer \\(\\mathbf{a}\\) is herein denoted in vector form as \\((a_{31}, \\dots, a_1, a_0)\\) to indicate that, $$ \\mathbf{a} = a_{31}\\cdot (2^8)^{31} + a_{30}\\cdot (2^8)^{30} + \\cdots + a_1\\cdot2^8 + a_0 = \\sum_{i = {31}}^{0} a_i \\cdot (2^8)^i, $$ where each \\(a_i\\) is a byte that can take values between \\(0\\) and \\(2^8 - 1\\) . Example 1. If \\(\\mathbf{a} = 29967\\) , its byte decomposition can be written as \\(\\mathbf{a} = (\\mathtt{0x75}, \\mathtt{0x0F})\\) , because \\(\\mathbf{a} = 29967 = 117 \\cdot 2^8 + 15\\) , and in hexadecimal, \\(117 \\mapsto \\mathtt{0x75}\\) and \\(15 \\mapsto \\mathtt{0x0F}\\) .","title":"Operating At Byte-Level"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#addition","text":"Here is how the addition operation on two \\(256\\) -bit numbers is reduced to a byte-by-byte addition, and thus ready to use the byte-wise Plookup table. Observe that adding two bytes \\(a\\) and \\(b\\) (i.e., \\(a\\) and \\(b\\) are members of the set \\([0, 2^8-1]\\) ), may result in a sum \\(c\\) which cannot be expressed as a single byte. For example, if \\(a = \\mathtt{0xFF}\\) and \\(b = \\mathtt{0x01}\\) , then, $$ a + b = \\mathtt{0xFF} + \\mathtt{0x01} = \\mathtt{0x100}. $$ In byte-form, \\(c=\\mathtt{0x00}\\) and with \\(carry'=1\\) . This carry has to be taken care of when dealing with bytes. Consider now the process of adding two bytes. Example 2. Take for instance, \\(\\mathbf{a} = (a_1, a_0) = (\\mathtt{0xFF}, \\mathtt{0x01})\\) and \\(\\mathbf{b} = (b_1, b_0) = (\\mathtt{0xF0}, \\mathtt{0xFF})\\) . First add the less significant bytes: \\[ \\begin{aligned} a_1 + b_1 &= \\mathtt{0x01} + \\mathtt{0xFF} = c_1 = \\mathtt{0x00}, \\\\ carry_1 &= 1. \\end{aligned} \\] Then, add the next significant byte, \\[ \\begin{aligned} a_2 + b_2 + carry_1 &= \\mathtt{0xFF} + \\mathtt{0xF0} = c_2 = \\mathtt{0xF0}, \\\\ carry_2 &= 1. \\end{aligned} \\] The previous example shows is scheme depicts several cases that need to be treated separately; If \\(a_1 + b_1 < 2^8\\) and \\(a_2 + b_2 < 2^8\\) , then the sum \\(\\mathbf{a} + \\mathbf{b}\\) is simply, \\[ \\mathbf{a} + \\mathbf{b} = (a_2 + b_2, a_1 + b_1). \\] If \\(a_1 + b_1 < 2^8\\) but \\(a_2 + b_2 \\geq 2^8\\) , then \\(a_2 + b_2\\) does not fit in a single byte. Hence, the sum of \\(a_2\\) and \\(b_2\\) has to be written as, \\[ a_2 + b_2 = 1 \\cdot 2^8 + c_2, \\] \u200b for some byte \\(c_2\\) . The addition \\(\\mathbf{a} + \\mathbf{b}\\) is then computed as follows, $$ \\mathbf{a} + \\mathbf{b} = (1, c_2, a_1 + b_1). $$ If \\(a_1 + b_1 \\geq 2^8\\) , then we have that: \\[ a_1 + b_1 = 1 \\cdot 2^8 + c_1, \\] \u200b for some byte \\(c_1\\) . Then we can write, $$ \\mathbf{a} + \\mathbf{b} = (a_2 + b_2 + 1) \\cdot 2^8 + c_1. $$ Consider the following two scenarios: (a) If \\(a_2 + b_2 + 1 \\geq 2^8\\) , then the sum will take the form: $$ a_2 + b_2 + 1 = 1 \\cdot 2^8 + c_2. $$ \u200b Therefore, the byte decomposition of \\(\\mathbf{a} + \\mathbf{b}\\) is, $$ \\mathbf{a} + \\mathbf{b} = (1, c_2, c_1). $$ (b) If \\(a_2 + b_2 + 1 < 2^8\\) , then the byte decomposition of \\(\\mathbf{a} + \\mathbf{b}\\) is: $$ \\mathbf{a} + \\mathbf{b} = (c_2, c_1). $$ Observe that addition of \\(256\\) -bit numbers can be reduced to additions at byte-level by operating through the previous cases in an iterative manner.","title":"Addition"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#subtraction","text":"Reducing Subtraction to byte-level turns out to be trickier than Addition case. Suppose \\(\\mathbf{a} = \\mathtt{0x0101}\\) and \\(\\mathbf{b} = \\mathtt{0x00FF}\\) . Observe that \\(\\mathtt{0xFF}\\) cannot be subtracted from \\(\\mathtt{0x01}\\) because \\(\\mathtt{0xFF} > \\mathtt{0x01}\\) . However, we know that the result is \\(\\mathbf{a} - \\mathbf{b} = \\mathbf{c} = \\mathtt{0x0002}\\) . In order to get this result, notice that the operation can be described as follows, \\[ \\begin{aligned} \\mathbf{a} - \\mathbf{b} & = (\\mathtt{0x01} - \\mathtt{0x00}) \\cdot 2^8 + (\\mathtt{0x01} - \\mathtt{0xFF}) \\\\ & = (\\mathtt{0x01} - \\mathtt{0x00}) \\cdot 2^8 - 2^8 + 2^8 + (\\mathtt{0x01} - \\mathtt{0xFF}) \\\\ & = (\\mathtt{0x01} - \\mathtt{0x00 - 0x01}) \\cdot 2^8 + \\mathtt{0xFF + 0x01} + \\mathtt{0x01} - \\mathtt{0xFF} \\\\ & = ( \\mathtt{0x00} ) \\cdot 2^8 + \\mathtt{0x02} \\end{aligned} \\] The output byte decomposition is \\(\\mathbf{a} = (c_1, c_0) = (\\mathtt{0x00}, \\mathtt{0x02})\\) . Nonetheless, it may be necessary to look at more examples so as to better understand how subtraction works at byte-level in a more general sense. Consider now subtraction of numbers with \\(3\\) bytes. Say, \\(a = \\mathtt{0x0001FE}\\) and \\(b = \\mathtt{0xFEFFFF}\\) . First analyse the first two bytes, as in the previous example, \\[ \\begin{aligned} (\\mathtt{0x01} - \\mathtt{0xFF}) \\cdot 2^8 + (\\mathtt{0xFE} - \\mathtt{0xFF}) &= (\\mathtt{0x01} - \\mathtt{0xFF} - \\mathtt{0x01} ) \\cdot 2^8 + (\\mathtt{2^8} + \\mathtt{0xFE} - \\mathtt{0xFF}) \\\\ & = (\\mathtt{0x01} - \\mathtt{0xFF - 0x01}) \\cdot 2^8 + \\mathtt{0xFF} \\end{aligned} \\] But now observe that \\(\\mathtt{0x01} - \\mathtt{0xFF} - \\mathtt{0x01}\\) is also a negative value. Hence, there is a need to repeat the strategy and keep a carry to the next byte, \\[ \\begin{aligned} &(\\mathtt{0x00} - \\mathtt{0xFE}) \\cdot 2^{16} + (\\mathtt{0x01} - \\mathtt{0xFF} - \\mathtt{0x01}) \\cdot 2^8 + \\mathtt{0xFF} = \\\\ &(\\mathtt{0x00} - \\mathtt{0xFE} - \\mathtt{0x01}) \\cdot 2^{16} + (\\mathtt{2^8} + \\mathtt{0x01} - \\mathtt{0xFF} - \\mathtt{0x01}) \\cdot 2^8 + \\mathtt{0xFF} = \\\\ &(\\mathtt{0x00} - \\mathtt{0xFE} - \\mathtt{0x01}) \\cdot 2^{16} + \\mathtt{0x01} \\cdot 2^8 + \\mathtt{0xFF}. \\end{aligned} \\] Observe that the previous example is included in this case. In general, let \\(a = (a_i)_i\\) and \\(b = (b_i)_i\\) , with \\(a_i, b_i\\) bytes, be the byte representations of \\(a\\) and \\(b\\) . Instead of checking if we can perform the subtraction \\(a_i - b_i\\) for some bytes \\(i\\) , we are checking if \\(a_i - b_i - \\texttt{carry} \\geq 0\\) . Equivalently, we are checking if \\(a_i - \\texttt{carry} \\geq b_i\\) . The previous case can be recovered by setting \\(\\texttt{carry} = 1\\) and the first case corresponds to setting \\(\\mathtt{carry = 0}\\) . We have two possible cases, If \\(a_i - \\texttt{carry} \\geq b_i\\) , then \\(a_i - b_i - \\texttt{carry}\\) provides the corresponding \\(i\\) -th byte of the representation of \\(a - b\\) . If \\(a_i - \\texttt{carry} < b_i\\) then we should compute the corresponding \\(i\\) -th byte of the representation of \\(a - b\\) as, \\[ 2^8 - b_i + a_i - \\texttt{carry} = 255 - b_i + a_i - \\texttt{carry} + 1. \\] However, we need to discuss the last step of our example. Observe that we can not perform the operation \\(\\mathtt{0x00} - \\mathtt{0xFE} - \\mathtt{0x01}\\) since it corresponds to a negative value. But as we are working with unsigned integers, we will do the two's complement and set the last byte to, $$ 2^8 - \\mathtt{0xFE} + \\mathtt{0x00} - \\mathtt{0x01} = 255 - \\mathtt{0xFE} + \\mathtt{0x00} - \\mathtt{0x01} + 1 = 255 - b_3 + a_3 - \\texttt{carry} + 1. $$ Observe that this is also included in the case when \\(a_i - \\texttt{carry} < b_i\\) , so we must not treat the last bit in a different manner. To end up with our example, we get the following byte representation of \\(a - b\\) , $$ c = (\\mathtt{0x01}, \\mathtt{0x01}, \\mathtt{0xFF}) = \\mathtt{0x01} \\cdot 2^{16} + \\mathtt{0x01} \\cdot 2^8 + \\mathtt{0xFF}. $$","title":"Subtraction"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#less-than","text":"We want to describe the less than comparator byte-wise. For \\(256\\) -bits integers, the operation \\(<\\) will output \\(c = 1\\) if \\(a < b\\) and \\(c = 0\\) otherwise. As we are working in the natural integers order, the most significant byte decide and, if they are equal, we should consider the previous one until we can decide. Let us propose the example with \\(a = \\mathtt{0xFF AE 09}\\) and \\(b = \\mathtt{0x FF AE 02}\\) . We know that \\(a > b\\) . Why? We should start at the most significant byte. We know that $$ a \\mathtt{>> 16} = \\mathtt{0x FF} = \\mathtt{0x FF} = b \\mathtt{>> 16}. $$ Hence, we can not decide with this byte. An the same happens with the second byte, they are both equal to \\(\\mathtt{0x AE}\\) . Hence, the less significant byte decides, $$ \\mathtt{0x 09} > \\mathtt{0x 02}. $$ However, the problem with our set up is that we must start with the less significant byte and climb up to the most significant byte. The strategy will be to use some kind of a carry in order to \"carry\" the decisions from previous bytes. Let us do an example step by step, now with \\(a = \\mathtt{0x FF AA 02}\\) and \\(b = \\mathtt{0x 01 AA 09}\\) . First of all, we will compare the less significant bytes. Since $$ \\mathtt{0x 02} < \\mathtt{0x 09}, $$ we will set up \\(\\mathtt{carry} = 1\\) . We will carry this decision until we finish to process all bytes or, alternatively, we should change to the complementary decision. Therefore, since the next two bytes are equal and we are not at the end, we maintain \\(\\mathtt{carry}\\) to \\(1\\) . The previous step is the last one. We compare the most significant bytes, $$ \\mathtt{0x FF} \\not < \\mathtt{0x 01}. $$ Henceforth, we should output a \\(0\\) , independently to the previous carry decision. But, let us suppose now that \\(b = \\mathtt{0x FF AA 09}\\) . Then, in this last step, we should output a \\(1\\) , since \\(a < b\\) . The idea is that, in the last step, if both bytes are equal, we should output the decision carry \\(\\mathtt{carry}\\) . In general, in the step \\(i\\) , comparing bytes \\(a_i\\) and \\(b_i\\) , we have \\(3\\) cases, If \\(a_i < b_i\\) , we set \\(\\mathtt{carry}\\) to \\(1\\) . If we are at the most significant byte, we output \\(1\\) . If \\(a_i = b_i\\) , we let \\(\\mathtt{carry}\\) unchanged in order to maintain the previous decision. If we are at the most significant byte, we output \\(\\mathtt{carry}\\) . If \\(a_i > b_i\\) , we set \\(\\mathtt{carry}\\) to \\(0\\) . If we are at the most significant byte, we output \\(0\\) .","title":"Less Than"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#signed-less-than","text":"In computer science, the most common method of representing signed integers on computers, is called \\textbf{two's complement}. When the most significant bit is a one, the number is signed as negative. The way to express a negative integer \\(x\\) into two's complement form is chosen so that, among integers of the same sign, the lexicographical order is maintained. That is, if \\(a < b\\) are signed integers of the same sign, then its two's complement representations preserve the same order. This will not be true if the signs are different. For example, it is not surprising that $$ 000\\dots0 > 111\\dots1 $$ using the two's complement encoding, because \\(111\\dots1\\) is negative and \\(000\\dots0\\) is positive. The two's complement form of negative integer \\(x\\) in a \\(N\\) -bits system is the binary representation of \\(2^N - x\\) . For example, let \\(x = -1\\) and \\(N = 4\\) . Then, $$ 10000 - 0001 = 1111. $$ Hence, \\(-1 = 1111\\) in this representation. It is easy to see that \\(-2 = 1110\\) because $$ 10000 - 0010 = 1110. $$ Hence, observe that \\(-1 > -2\\) because \\(1111 > 1110\\) and conversely: the order is preserved for integers of the same sign. We will describe a method to compare signed integers byte-wise. First of all, let us analyze the order among all the signed bytes, in order to understand how to compare them. Once we achieve this, the strategy will be very similar to the previous Less Than. Let \\(a = (a_{31}, a_{30}, \\dots, a_0)\\) and \\(b = (b_{31}, b_{30}, \\dots, b_0)\\) be the byte-representation of the 256-bits unsigned integers \\(a\\) and \\(b\\) . We will define \\(\\texttt{sgn}(a) = a_{31, 7}\\) , where $$ a_{31} = \\sum_{i = 0}^7 a_{31, i} \\cdot 2^i $$ is the binary representation of \\(a_{31}\\) . That is, \\(\\texttt{sgn}(a)\\) is the most significant bit of \\(a\\) or, equivalently, the \"sign\" of \\(a\\) . In a similar way, we define \\(\\texttt{sgn}(b)\\) . Observe that it is easy to compare \\(a\\) and \\(b\\) if \\(\\texttt{sgn}(a) \\neq \\texttt{sgn}(b)\\) . For example, $$ a = \\mathtt{0b11111111} = \\mathtt{0xFF} < \\mathtt{0x00} = \\mathtt{0b00000000} = b $$ because \\(\\texttt{sgn}(a) > \\texttt{sgn}(b)\\) i.e. \\(a\\) is negative and \\(b\\) is positive. If \\(\\texttt{sgn}(a) \\neq \\texttt{sgn}(b)\\) , we can simply compare \\(a\\) and \\(b\\) using the same strategy as before, because the natural lexicographic order is preserved in this case. Then, we have the following cases when comparing \\(a\\) and \\(b\\) : If \\(\\texttt{sgn}(a) = 1\\) and \\(\\texttt{sgn}(b) = 0\\) , then \\(a < b\\) . If \\(\\texttt{sgn}(a) = 0\\) and \\(\\texttt{sgn}(b) = 1\\) , then \\(a > b\\) . If \\(\\texttt{sgn}(a) = \\texttt{sgn}(b)\\) , the order is the usual one and hence, we already know how to compare \\(a\\) and \\(b\\) . \u200b Recall that we are processing the bytes of \\(a\\) and \\(b\\) from the less significant bytes to the most significant bytes. Hence, we need to adapt our strategy following this order. The strategy will be almost the same than in the unsigned operation. First of all, we start comparing \\(a_0\\) and \\(b_0\\) . \u200b (a) If \\(a_0 < b_0\\) , we set \\(\\texttt{carry} = 1\\) . \u200b (b) Otherwise we set \\(\\texttt{carry} = 0\\) . For all \\(0 < i < 31\\) , we compare \\(a_i\\) and \\(b_i\\) . \u200b (a) If \\(a_i < b_i\\) , we set \\(\\texttt{carry} = 1\\) . \u200b (b) If \\(a_i = b_i\\) , we leave \\(\\texttt{carry}\\) unchanged from the previous step. \u200b (c) Otherwise, we set \\(\\texttt{carry} = 0\\) . Now, we have to compare the last byte. We follow the described strategy of comparing the signs: \u200b (a) If \\(\\texttt{sgn}(a) > \\texttt{sgn}(b)\\) , we output a \\(1\\) , so \\(a < b\\) . \u200b (b) If \\(\\texttt{sgn}(a) < \\texttt{sgn}(b)\\) , we output a \\(0\\) , so \\(a < b\\) . \u200b (c) If \\(\\texttt{sgn}(a) = \\texttt{sgn}(b)\\) , we compare the last bytes \\(a_{31}\\) and \\(b_{31}\\) in the same way we have compare the previous bytes. We output \\(0\\) or \\(1\\) accordingly. \u200b (i) If \\(a_{31} < b_{31}\\) , we output a \\(1\\) , so \\(a < b\\) . \u200b (ii) If \\(a_{31} = b_{31}\\) , we output the previous \\(\\texttt{carry}\\) , maintaining the last decision. \u200b (iii) Otherwise, we output a \\(0\\) , so \\(a \\not < b\\) . Let us exemplify the previous procedure setting \\(a = \\mathtt{0xFF FF FF 00}\\) and \\(b = \\mathtt{0x00 FF FF FF}\\) . We know that \\(a < b\\) , so we should output a \\(1\\) . Observe that the less significant byte of \\(a\\) is leaser than the less significant byte of \\(b\\) . Hence, we should put \\(\\texttt{carry}\\) equal to \\(1\\) . The next two bytes of \\(a\\) and \\(b\\) are both equal to \\(\\mathtt{0xFF FF}\\) , therefore we maintain \\(\\texttt{carry}\\) unchanged equal to \\(1\\) . However, since \\(a\\) is negative and \\(b\\) is positive, we should change the decision and output a \\(1\\) , independently of the \\(\\texttt{carry}\\) .","title":"Signed Less Than"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#equality","text":"We want to describe the equality comparator byte-wise. For unsigned \\(256\\) -bits integers, the operation \\(=\\) will output \\(c = 1\\) if \\(a = b\\) and \\(c = 0\\) otherwise. This operation is very simple to describe byte-wise, since \\(a = b\\) if and only if all its bytes coincide. Let us compare \\(a = \\mathtt{0xFF 00 a0 10}\\) and \\(b = \\mathtt{0xFF 00 00 10}\\) byte-wise. Observe that the first byte is the same \\(\\mathtt{0x10}\\) , however the next byte are different \\(\\mathtt{0xa0} \\neq \\mathtt{0x00}\\) . Hence, we can finish here and state that \\(a \\neq b\\) . We will describe an algorithm in order to proceed processing all the bytes. We will use a carry to mark up when a difference among bytes has \\(\\textbf{not}\\) been found (i.e. if \\(\\texttt{carry}\\) reach \\(0\\) , then \\(a\\) and \\(b\\) should differ). Hence, the algorithm to compare two \\(32\\) -bytes integers \\(a = (a_{31}, a_{30}, \\dots, a_{0})\\) and \\(b = (b_{31}, b_{30}, \\dots, b_0)\\) is the following: First of all, since no differences have been found up to this point, set \\(\\texttt{carry}\\) equal to \\(1\\) . Now, compare \\(a_0\\) and \\(b_0\\) , (a) If \\(a_0\\) and \\(b_0\\) are equal, then leave \\(\\texttt{carry}\\) unchanged equal to \\(1\\) . (b) If \\(a_0 \\neq b_0\\) , then set \\(\\texttt{carry}\\) equal to \\(0\\) , which will imply that \\(a \\neq b\\) . When comparing bytes \\(a_i\\) and \\(b_i\\) for \\(0 < i \\leq 31\\) . (a) If \\(a_i = b_i \\textbf{ and } \\texttt{carry} = 1\\) , we should leave \\(\\texttt{carry}\\) unchanged and, if \\(i = 31\\) , we should output a \\(1\\) because \\(a = b\\) . The reason of demanding \\(\\texttt{carry} = 1\\) in the enter condition is because we should ensure that, if \\(\\texttt{carry} = 0\\) in a previous step, we must never enter to this block and change the non-equality decision. This is because if \\(a_i \\neq b_i\\) for some \\(i\\) , then \\(a \\neq b\\) . (b) Hence, if \\(a_i \\neq b_i\\) , we should set \\(\\texttt{carry} = 0\\) and output a \\(0\\) if \\(i = 31\\) . \u200b","title":"Equality"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#bitwise-operations","text":"We will describe all bitwise operations at once because they are the easiest ones, since we do not need to introduce carries. Now, the idea is to extend this operation bitwise. That is, if we have the following binary representations of \\(a = (a_{31}, a_{30}, \\dots, a_{0})\\) and \\(a = (b_{31}, b_{30}, \\dots, b_{0})\\) where \\(a_i, b_i \\in \\{0, 1\\}\\) , then we define, \\[ a \\star b = (a_i \\star b_i)_i = (a_{31} \\star b_{31}, a_{30} \\star b_{30}, \\dots, a_0 \\star b_0) \\] for \\(\\star\\) being \\(\\land, \\lor\\) or \\(\\oplus\\) . For example, if \\(a = \\mathtt{0xCB} = \\mathtt{0b11001011}\\) and \\(b = \\mathtt{0xEA} = \\mathtt{0b11101010}\\) then, \\[ \\begin{aligned} a \\land b &= \\mathtt{0b11001010} = \\mathtt{0xCA},\\\\ a \\lor b &= \\mathtt{0b11101011} = \\mathtt{0xEB},\\\\ a \\oplus b &= \\mathtt{0b00100001} = \\mathtt{0x21}. \\end{aligned} \\]","title":"Bitwise Operations"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#the-binary-sm-in-summary","text":"The Binary SM has 8 registries, each with an 32-bit Input/Output capacity. i.e., A total of 256 bits. It carries out binary computations in accordance with instructions from the Main SM Executor. The binary operations it executes, together with their specific opcodes, are; The common operations; the No-Operation NOP , Addition ADD and Subtraction SUB . Their corresponding special opcodes are; 0 , 1 and 2 , respectively. The Boolean operations; \\(\\text{Less Than }\\) LT , \\(\\text{Greater Than }\\) GT , \\(\\text{Signed Less Than }\\) SLT , \\(\\text{Signed Greater Than }\\) SGT , \\(\\text{Equal }\\) EQ and \\(\\text{Is-Zero }\\) ISZERO . Their special opcodes are, 3 , 4 , 5 , 6 and 7 , respectively. The logical operations; AND , OR , XOR and NOT , each with its special opcode; 9 , 10 , 11 and 12 , respectively.","title":"The Binary SM In Summary"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#the-nutshell","text":"Firstly, the Binary SM Executor translates the Binary Actions into the PIL language. Secondly, it executes the Binary Actions. And thirdly, it uses the Binary PIL program binary.pil , to check correct execution of the Binary Actions using Plookup .","title":"The Nutshell"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#translation-to-pil-language","text":"It builds the constant polynomials, which are generated once-off at the beginning. These are; the 4 bits long operation code P_OPCODE , the 1-bit Carry-in P_CIN , the Last-byte P_LAST , the 1 byte input polynomials P_A and P_B , the 16-bit output polynomial P_C , the 1-bit Carry-out P_COUT . It also creates constants required in the Binary PIL program; RESET is used to reset registry values every time the state machine completes a cycle of state transitions, FACTOR , which is an array of size 8, is used for correct placement of output registry values.","title":"Translation to PIL Language"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#execution-of-binary-actions","text":"The crux of the Binary SM Executor is in the lines 371 to 636 of sm_binary.js . This is where it executes Binary Actions. It takes the committed polynomials A, B and C, breaks them into bytes (in little-endian form). It sequentially pushes each triplet of bytes ( freeInA , freeInB , freeInC ) into their corresponding registries ( ai , bi , ci ). i.e., It runs one for-loop for all committed polynomials (A, B, C), over all the bytes of the 8 registries, which are altogether 32 bytes per committed polynomial. Recall that LATCH_SIZE = REGISTERS_NUM * BYTES_PER_REGISTER = 8 registries * 4 bytes. It hence amounts to 32 bytes for each committed polynomial. Once the 256-bit LATCH is built, it checks the opcodes and then computes the required binary operations in accordance with the instructions of the Main SM. It also generates the final registries.","title":"Execution of Binary Actions"},{"location":"zkEVM/State-Machines/Binary/Binary-State-Machine-typ/#the-binary-pil-program","text":"There are two types of inputs to the Binary PIL program: the constant polynomials and the committed polynomials. The program operates byte-wise to carry out 256-bit Plookup operations. Each row of the lookup table is a vector of the form; { P_LAST , P_OPCODE , P_A , P_B , P_CIN , P_C , P_COUT }, consisting of the constant polynomials created by the Binary SM Executor. As seen above, P_LAST is the Last-byte, P_OPCODE is the 4-bit operation code, P_A and P_B , are the 1-byte input polynomials, P_CIN is the 1-bit Carry-in, P_C is the 16-bit output polynomial, P_COUT is the 1-bit Carry-out. The Binary PIL program takes in byte-size inputs, as in the Binary SM Executor, each 256-bit input committed polynomial is first broken into 32 bytes. For each of the 32 triplets freeInA , freeInB and freeInC , tallying with the three 256-bit committed polynomials A,B and C, the Binary PIL program, Prepares a Plookup input vector of the form; { last , opcode , freeInA , freeInB , cIn , freeInC , cOut }, where each element is a byte. Runs Plookup, {last,opcode,freeInA,freeInB,cIn,freeInC,cOut} in {P_LAST,P_OPCODE,P_A,P_B,P_CIN,P_C,P_COUT}; Resets registry values at the end of the 32 cycles using RESET , and utilising FACTOR for correct placement of values. For e.g., a0' = a0 * (1 - RESET) + freeInA * FACTOR[0]; Special variables, useCarry and c0Temp , are used for managing updates and assignments of values, particularly for Boolean operations, where the output c0 registry value is either TRUE = 1 or FALSE = 0 . Hence the Lines 104 and 105 of code; Line 104. c0Temp' = c0Temp * (1 - RESET) + freeInC * FACTOR[0]; Line 105. c0' = useCarry * (cOut - c0Temp ) + c0Temp; For all non-Boolean operations; the default value for useCarry is zero, making c0' = c0Temp . The value of c0' is therefore of the same form as other ci' update values. The output of the Binary PIL program is therefore a report of either pass or fail .","title":"The Binary PIL (Program)"},{"location":"zkEVM/State-Machines/Complementary/complementary-state-machines/","text":"Global The Global State Machine is a state machine that computes various constant polynomials used by some of the state machines of the zkEVM. These polynomials are typically used for the distinct lookup arguments that PIL is able to perform. At this moment, the Global SM used by the zkEVM is made of: include \"config.pil\"; namespace Global(%N); pol constant L1; pol constant BYTE; pol constant BYTE2; At this moment, the polynomials computed by the Global SM are showed in Table 1. Row L1 Row BYTE Row BYTE2 1 1 1 0 1 0 2 0 2 1 2 1 3 0 3 2 3 2 \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) 256 0 256 255 65536 65535 257 0 257 0 65537 0 258 0 258 1 65538 1 \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) N 0 N 255 N 65535 Table 1: Description of the polynomials computed by the Global State Machine. Byte4 The Byte4 State Machine takes as input two \\(16\\) -bit numbers and generates a \\(32\\) -bit number from them. This generation is obtained through the concatenation of the input numbers. A working example can be find in Table 2. row SET freeIn out out' 1 0 \\(\\textsf{0xba04}\\) \\(\\textsf{0x00000000}\\) \\(\\textsf{0x0000ba04}\\) 2 1 \\(\\textsf{0x3ff2}\\) \\(\\textsf{0x0000ba04}\\) \\(\\textsf{0xba043ff2}\\) 3 0 \\(\\textsf{0x4443}\\) \\(\\textsf{0xba043ff2}\\) \\(\\textsf{0x00004443}\\) 4 1 \\(\\textsf{0xc1d1}\\) \\(\\textsf{0x00004443}\\) \\(\\textsf{0x4443c1d1}\\) 5 0 \\(\\textsf{0xd11e}\\) \\(\\textsf{0x4443c1d1}\\) \\(\\textsf{0x0000d11e}\\) 6 1 \\(\\textsf{0x6ab9}\\) \\(\\textsf{0x0000d11e}\\) \\(\\textsf{0xd11e6ab9}\\) 7 0 \\(\\vdots\\) \\(\\textsf{0xd11e6ab9}\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) Table 2: Example of they Byte4 SM. The Byte4 SM works as follows. In one clock, the first input \\(x\\) is moved to the \\(\\textsf{out}\\) column. In the following clock, \\(x\\) is concatenated to the second input \\(y\\) and moved to the \\(\\textsf{out}\\) column. In order to make this \"moving\" possible, we introduce a constant polynomial, called \\(\\textsf{SET}\\) , defined as follows: \\[\\begin{aligned} \\textsf{SET} = \\begin{cases} 1, & \\text{if } \\textsf{row} \\text{ is even}\\\\ 0, & \\text{if } \\textsf{row} \\text{ is odd} \\end{cases} . \\end{aligned}\\] Once \\(\\textsf{SET}\\) is defined, the moving action is naturally enforced with the following constraint: \\[ \\textsf{out}' = (1 - \\textsf{SET}) \\cdot \\textsf{freeIn} + \\textsf{SET} \\cdot (2^{16} \\cdot \\textsf{out} + \\textsf{freeIn}). \\] Notice that when \\(\\textsf{SET} = 0\\) , then \\(\\textsf{out}' = \\textsf{freeIn}\\) , i.e., \\(\\textsf{out}\\) is set to be the first input. In contrast, when \\(\\textsf{SET} = 1\\) , then \\(\\textsf{out}' = 2^{16} \\cdot \\textsf{out} + \\textsf{freeIn}\\) , i.e., the previous input (stored in \\(\\textsf{out}\\) ) is set to be the upper part of \\(\\textsf{out}\\) , while the second input is set to be the lower part of \\(\\textsf{out}\\) . To achieve soundness, we must also check that both inputs are elements made at most of \\(2\\) bytes. The previous constraints are reflected in the PIL code for this SM: include \"config.pil\"; include \"global.pil\"; namespace Byte4(%N); // Constant Polynomials pol constant SET; // 0, 1, 0, 1, 0, 1, ... // Input Polynomials pol committed freeIn; // State Variables pol committed out; // Constraints freeIn in Global.Byte2; // Check that input is in [0,1,...,65535] out' = (1 - SET)*freeIn + SET*(2**16*out + freeIn);","title":"Complementaries"},{"location":"zkEVM/State-Machines/Complementary/complementary-state-machines/#global","text":"The Global State Machine is a state machine that computes various constant polynomials used by some of the state machines of the zkEVM. These polynomials are typically used for the distinct lookup arguments that PIL is able to perform. At this moment, the Global SM used by the zkEVM is made of: include \"config.pil\"; namespace Global(%N); pol constant L1; pol constant BYTE; pol constant BYTE2; At this moment, the polynomials computed by the Global SM are showed in Table 1. Row L1 Row BYTE Row BYTE2 1 1 1 0 1 0 2 0 2 1 2 1 3 0 3 2 3 2 \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) 256 0 256 255 65536 65535 257 0 257 0 65537 0 258 0 258 1 65538 1 \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) N 0 N 255 N 65535 Table 1: Description of the polynomials computed by the Global State Machine.","title":"Global"},{"location":"zkEVM/State-Machines/Complementary/complementary-state-machines/#byte4","text":"The Byte4 State Machine takes as input two \\(16\\) -bit numbers and generates a \\(32\\) -bit number from them. This generation is obtained through the concatenation of the input numbers. A working example can be find in Table 2. row SET freeIn out out' 1 0 \\(\\textsf{0xba04}\\) \\(\\textsf{0x00000000}\\) \\(\\textsf{0x0000ba04}\\) 2 1 \\(\\textsf{0x3ff2}\\) \\(\\textsf{0x0000ba04}\\) \\(\\textsf{0xba043ff2}\\) 3 0 \\(\\textsf{0x4443}\\) \\(\\textsf{0xba043ff2}\\) \\(\\textsf{0x00004443}\\) 4 1 \\(\\textsf{0xc1d1}\\) \\(\\textsf{0x00004443}\\) \\(\\textsf{0x4443c1d1}\\) 5 0 \\(\\textsf{0xd11e}\\) \\(\\textsf{0x4443c1d1}\\) \\(\\textsf{0x0000d11e}\\) 6 1 \\(\\textsf{0x6ab9}\\) \\(\\textsf{0x0000d11e}\\) \\(\\textsf{0xd11e6ab9}\\) 7 0 \\(\\vdots\\) \\(\\textsf{0xd11e6ab9}\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) Table 2: Example of they Byte4 SM. The Byte4 SM works as follows. In one clock, the first input \\(x\\) is moved to the \\(\\textsf{out}\\) column. In the following clock, \\(x\\) is concatenated to the second input \\(y\\) and moved to the \\(\\textsf{out}\\) column. In order to make this \"moving\" possible, we introduce a constant polynomial, called \\(\\textsf{SET}\\) , defined as follows: \\[\\begin{aligned} \\textsf{SET} = \\begin{cases} 1, & \\text{if } \\textsf{row} \\text{ is even}\\\\ 0, & \\text{if } \\textsf{row} \\text{ is odd} \\end{cases} . \\end{aligned}\\] Once \\(\\textsf{SET}\\) is defined, the moving action is naturally enforced with the following constraint: \\[ \\textsf{out}' = (1 - \\textsf{SET}) \\cdot \\textsf{freeIn} + \\textsf{SET} \\cdot (2^{16} \\cdot \\textsf{out} + \\textsf{freeIn}). \\] Notice that when \\(\\textsf{SET} = 0\\) , then \\(\\textsf{out}' = \\textsf{freeIn}\\) , i.e., \\(\\textsf{out}\\) is set to be the first input. In contrast, when \\(\\textsf{SET} = 1\\) , then \\(\\textsf{out}' = 2^{16} \\cdot \\textsf{out} + \\textsf{freeIn}\\) , i.e., the previous input (stored in \\(\\textsf{out}\\) ) is set to be the upper part of \\(\\textsf{out}\\) , while the second input is set to be the lower part of \\(\\textsf{out}\\) . To achieve soundness, we must also check that both inputs are elements made at most of \\(2\\) bytes. The previous constraints are reflected in the PIL code for this SM: include \"config.pil\"; include \"global.pil\"; namespace Byte4(%N); // Constant Polynomials pol constant SET; // 0, 1, 0, 1, 0, 1, ... // Input Polynomials pol committed freeIn; // State Variables pol committed out; // Constraints freeIn in Global.Byte2; // Check that input is in [0,1,...,65535] out' = (1 - SET)*freeIn + SET*(2**16*out + freeIn);","title":"Byte4"},{"location":"zkEVM/State-Machines/Complementary/configuration-file/","text":"The main purpose of this file is to provide configuration (e.g. global parameters) used across the different state machines that compose the same project. It is typically called config.pil and it is equivalent to the global configuration that is typically used in other languages and stored in the source directory of user's projects. For the shake of building the zkEVM, the configuration file is composed by: constant %N = 2**21; Here, \\(N\\) is the upper bound on the number of rows that the distinct state machines that give form to the zkEVM are limited to.","title":"Configuration File"},{"location":"zkEVM/State-Machines/Hashing/Hashing-State-Machine-typ/","text":"[ToC] The Hashing State Machine Sponge Construction The sponge construction is a simple iterated construction for building a function \\[ F: \\mathbb{Z}^* \\to \\mathbb{Z}^l \\] with variable-length input and arbitrary output length based on a fixed-length permutation $$ f: \\mathbb{Z}^b \\to \\mathbb{Z}^b $$ operating on a fixed number \\(b\\) of bits. Here \\(b\\) is called the width . The array of \\(b\\) bits that \\(f\\) keeps transforming is called the state . The state array is split in two chunks of \\(r\\) and \\(c\\) bits respectively. We call \\(r\\) the bitrate (or rate) and \\(c\\) the capacity . We will understand later on the motivation for this splitting. Let us describe how the sponge construction works: ( Init Phase ) First of all, the input string is padded with a reversible padding rule , in order to achieve a length divisible by \\(r\\) . Subsequently, it is cut into blocks of \\(r\\) bits. We also initialize the \\(b\\) bits of the state to zero. ( Absorbing Phase ) In this phase, the \\(r\\) -bit input blocks are XORed into the first \\(r\\) bits of the state, interleaved with applications of the function \\(f\\) . We proceed until processing all blocks of \\(r\\) -bits. Observe that the last \\(c\\) bits corresponding to the capacity value does not absorb any input from the outside. ( Squeezing Phase ) In this phase, the first \\(r\\) bits of the state are returned as output blocks, interleaved with applications of the function \\(f\\) . The number of output blocks is chosen at will by the user. Observe that the last \\(c\\) bits corresponding to the capacity value are never output during this phase. Actually, if the output exceeds the specified length, we will just truncate it in order to fit. We depict an schema of the sponge construction in the Figure 1 below: Figure 1: Sponge Function Construction The elements that completely describe a single instance of a sponge construction are: the fixed-length permutation \\(f\\) , the padding rule pad and the rate value \\(r\\) . zkEVM Specific Constructions The zkEVM uses two different hash functions. The main reason to do so is because the Storage of the EVM uses KECCAK-256 as the hash function used for constructing the corresponding Merkle Trees. However, for zkEVM internal hashes, a Poseidon hash will be used, in order to reduce the proving complexity. In this section, the specific instances of both hash functions will be defined: KECCAK-256 The EVM makes use of KECCAK-256 hash function, which is constructed using KECCAK \\([512]\\) sponge construction. Let us, therefore, define the KECCAK \\([c]\\) sponge construction. This sponge operates with a width of \\(1600\\) bits and a rate of \\(1600 - c\\) . In the case of KECCAK \\([512]\\) , the rate chunk is composed of \\(1088\\) bits (or equivalently, \\(136\\) bytes) and the capacity chunk has \\(512\\) bits (or equivalently, \\(64\\) bytes). The permutation used in KECCAK \\([c]\\) is KECCAK- \\(p[1600, 24]\\) (See NIST SHA-3 Standard ). The last ingredient we need to define in order to completely specify the hash function is the padding rule. In KECCAK \\([c]\\) , the padding pad10*1 is used. If we define \\(j = (-m-2) \\mod{r}\\) , where \\(m\\) is the length of the input in bits, then the padding we have to append to the original input message is \\[ P = 1 \\mid\\mid 0^j \\mid\\mid 1. \\] Thus, given an input bit string \\(M\\) and a output length \\(d\\) , KECCAK \\([c](M, d)\\) outputs a \\(d\\) bit string following the previous sponge construction description. It should be noted that this construction does not follow the FIPS-202 based standard (a.k.a SHA-3). According to the NIST specification,the SHA3 padding changed to \\[ \\text{SHA3-256}(M) = \\text{KECCAK}[512](M \\mid\\mid 01, 256). \\] The difference is the additional \\(01\\) bits appended to the original message, which were not present in the orignal KECCAK specification. Poseidon Poseidon (See Poseidon Paper ) is a hash function designed to minimize prover and verifier complexities when zero-knowledge proofs are generated and validated. The previously defined KECCAK-256 cryptographic hash require large circuits as they are not tailored to finite fields used in ZK proof systems (actually, KECCAK-256 works well in binary fields, and we will see later on that this fact introduces a lot of complexity in the constrain design). For this reason, zkEVM uses Poseidon hash as the main internal hash function. More concretely, we will now specify the specific instance of Poseidon that zkEVM uses. We will work over the field \\(\\mathbb{F}_p\\) where \\(p = 2^{64} - 2^{32} + 1\\) . The state width of the Poseidon permutation is of \\(8\\) field elements (observe that we are changing the paradigm, working with whole field elements instead of working bit-wise) meanwhile we will work with a capacity of \\(4\\) -field elements. The Poseidon S-box layer that we will use is the \\(7\\) -power S-Box, i.e. \\[ SB(x) = x^7, \\] The Poseidon instance also requires to specify the number of full and partial rounds of the permutation. In our case, we will use \\[ R_F = 8 \\text{ (number of full rounds) }, \\quad R_P = 22 \\text{ (number of partial rounds)} \\] Only one squeezing iteration will be effectuated, with an output of the first \\(4\\) field elements of the state (which consists of approximately \\(256\\) -bits, but no more than that). The Round Constants and the MDS matrix are completely specified using the previous parameters.","title":"Hashing"},{"location":"zkEVM/State-Machines/Hashing/Hashing-State-Machine-typ/#the-hashing-state-machine","text":"","title":"The Hashing State Machine"},{"location":"zkEVM/State-Machines/Hashing/Hashing-State-Machine-typ/#sponge-construction","text":"The sponge construction is a simple iterated construction for building a function \\[ F: \\mathbb{Z}^* \\to \\mathbb{Z}^l \\] with variable-length input and arbitrary output length based on a fixed-length permutation $$ f: \\mathbb{Z}^b \\to \\mathbb{Z}^b $$ operating on a fixed number \\(b\\) of bits. Here \\(b\\) is called the width . The array of \\(b\\) bits that \\(f\\) keeps transforming is called the state . The state array is split in two chunks of \\(r\\) and \\(c\\) bits respectively. We call \\(r\\) the bitrate (or rate) and \\(c\\) the capacity . We will understand later on the motivation for this splitting. Let us describe how the sponge construction works: ( Init Phase ) First of all, the input string is padded with a reversible padding rule , in order to achieve a length divisible by \\(r\\) . Subsequently, it is cut into blocks of \\(r\\) bits. We also initialize the \\(b\\) bits of the state to zero. ( Absorbing Phase ) In this phase, the \\(r\\) -bit input blocks are XORed into the first \\(r\\) bits of the state, interleaved with applications of the function \\(f\\) . We proceed until processing all blocks of \\(r\\) -bits. Observe that the last \\(c\\) bits corresponding to the capacity value does not absorb any input from the outside. ( Squeezing Phase ) In this phase, the first \\(r\\) bits of the state are returned as output blocks, interleaved with applications of the function \\(f\\) . The number of output blocks is chosen at will by the user. Observe that the last \\(c\\) bits corresponding to the capacity value are never output during this phase. Actually, if the output exceeds the specified length, we will just truncate it in order to fit. We depict an schema of the sponge construction in the Figure 1 below: Figure 1: Sponge Function Construction The elements that completely describe a single instance of a sponge construction are: the fixed-length permutation \\(f\\) , the padding rule pad and the rate value \\(r\\) .","title":"Sponge Construction"},{"location":"zkEVM/State-Machines/Hashing/Hashing-State-Machine-typ/#zkevm-specific-constructions","text":"The zkEVM uses two different hash functions. The main reason to do so is because the Storage of the EVM uses KECCAK-256 as the hash function used for constructing the corresponding Merkle Trees. However, for zkEVM internal hashes, a Poseidon hash will be used, in order to reduce the proving complexity. In this section, the specific instances of both hash functions will be defined:","title":"zkEVM Specific Constructions"},{"location":"zkEVM/State-Machines/Hashing/Hashing-State-Machine-typ/#keccak-256","text":"The EVM makes use of KECCAK-256 hash function, which is constructed using KECCAK \\([512]\\) sponge construction. Let us, therefore, define the KECCAK \\([c]\\) sponge construction. This sponge operates with a width of \\(1600\\) bits and a rate of \\(1600 - c\\) . In the case of KECCAK \\([512]\\) , the rate chunk is composed of \\(1088\\) bits (or equivalently, \\(136\\) bytes) and the capacity chunk has \\(512\\) bits (or equivalently, \\(64\\) bytes). The permutation used in KECCAK \\([c]\\) is KECCAK- \\(p[1600, 24]\\) (See NIST SHA-3 Standard ). The last ingredient we need to define in order to completely specify the hash function is the padding rule. In KECCAK \\([c]\\) , the padding pad10*1 is used. If we define \\(j = (-m-2) \\mod{r}\\) , where \\(m\\) is the length of the input in bits, then the padding we have to append to the original input message is \\[ P = 1 \\mid\\mid 0^j \\mid\\mid 1. \\] Thus, given an input bit string \\(M\\) and a output length \\(d\\) , KECCAK \\([c](M, d)\\) outputs a \\(d\\) bit string following the previous sponge construction description. It should be noted that this construction does not follow the FIPS-202 based standard (a.k.a SHA-3). According to the NIST specification,the SHA3 padding changed to \\[ \\text{SHA3-256}(M) = \\text{KECCAK}[512](M \\mid\\mid 01, 256). \\] The difference is the additional \\(01\\) bits appended to the original message, which were not present in the orignal KECCAK specification.","title":"KECCAK-256"},{"location":"zkEVM/State-Machines/Hashing/Hashing-State-Machine-typ/#poseidon","text":"Poseidon (See Poseidon Paper ) is a hash function designed to minimize prover and verifier complexities when zero-knowledge proofs are generated and validated. The previously defined KECCAK-256 cryptographic hash require large circuits as they are not tailored to finite fields used in ZK proof systems (actually, KECCAK-256 works well in binary fields, and we will see later on that this fact introduces a lot of complexity in the constrain design). For this reason, zkEVM uses Poseidon hash as the main internal hash function. More concretely, we will now specify the specific instance of Poseidon that zkEVM uses. We will work over the field \\(\\mathbb{F}_p\\) where \\(p = 2^{64} - 2^{32} + 1\\) . The state width of the Poseidon permutation is of \\(8\\) field elements (observe that we are changing the paradigm, working with whole field elements instead of working bit-wise) meanwhile we will work with a capacity of \\(4\\) -field elements. The Poseidon S-box layer that we will use is the \\(7\\) -power S-Box, i.e. \\[ SB(x) = x^7, \\] The Poseidon instance also requires to specify the number of full and partial rounds of the permutation. In our case, we will use \\[ R_F = 8 \\text{ (number of full rounds) }, \\quad R_P = 22 \\text{ (number of partial rounds)} \\] Only one squeezing iteration will be effectuated, with an output of the first \\(4\\) field elements of the state (which consists of approximately \\(256\\) -bits, but no more than that). The Round Constants and the MDS matrix are completely specified using the previous parameters.","title":"Poseidon"},{"location":"zkEVM/State-Machines/Memory/memory-state-machine/","text":"Memory State Machine As a secondary state machine, the Memory State Machine has the executor part (the Memory SM Executor) and an internal Memory PIL (program) which is a set of verification rules, written in the PIL language. The Memory SM Executor is written in two versions; Javascript and C/C++. The Polygon Hermez Repo is here https://github.com/0xPolygonHermez Memory SM Executor : sm_mem.js Memory SM PIL : mem.pil EVM Memory The memory of the EVM (Ethereum Virtual Machine) is a volatile read-write memory, and it is used to store temporary data during the execution of transactions of smart contract functions. That is, data in memory is populated during transaction's execution but it does not persist between transactions. The memory is an array of \\(256\\) -bit ( \\(32\\) bytes) words that can be accessed through addresses at byte level , that is to say, each byte in the memory has a different address. Memory has addresses of \\(32\\) bits, and initially, all memory locations are composed by bytes set to zero. Now, let's see the layout in memory of the following two words \\(\\texttt{0xc417...81a7}\\) and \\(\\texttt{0x88d1...b723}\\) . Table 1 displays this layout. \\(\\mathbf{ADDRESS}\\) \\(\\mathbf{BYTE}\\) \\(\\mathtt{0}\\) \\(\\mathtt{0xc4}\\) \\(\\mathtt{1}\\) \\(\\mathtt{0x17}\\) \\(\\mathtt{\\vdots}\\) \\(\\mathtt{\\vdots}\\) \\(\\mathtt{30}\\) \\(\\mathtt{0x81}\\) \\(\\mathtt{31}\\) \\(\\mathtt{0xa7}\\) \\(\\mathtt{32}\\) \\(\\mathtt{0x88}\\) \\(\\mathtt{33}\\) \\(\\mathtt{0xd1}\\) \\(\\mathtt{\\vdots}\\) \\(\\mathtt{\\vdots}\\) \\(\\mathtt{62}\\) \\(\\mathtt{0xb7}\\) \\(\\mathtt{63}\\) \\(\\mathtt{0x23}\\) Table 1: Layout in memory of 0xc417...81a7 and 0x88d1...b723. Observe that each word has 32 bytes and that the words are stored in Big-Endian form. i.e. The most significant bytes are set in the lower addresses. The EVM provides three opcodes to interact with the memory area. There is an opcode to read, and an opcode to write 32-byte words providing an offset: \\(\\texttt{MLOAD}\\) : It receives an offset and returns the 32 bytes in memory starting at that offset. \\(\\texttt{MSTORE}\\) : It receives an offset and saves 32 bytes from the offset address of the memory. Considering our previous memory contents, if we perform an \\(\\texttt{MLOAD}\\) with an offset of \\(\\texttt{1}\\) , we would obtain the following word: \\(\\texttt{0x17...a788}\\) . On the other hand, if we do an \\(\\texttt{MSTORE}\\) with an offset of \\(\\texttt{1}\\) with the word \\(\\texttt{0x74f0...ce92}\\) , we would modify the content of the memory as shown in Table 2. \\(\\mathbf{ADDRESS}\\) \\(\\mathbf{BYTE}\\) \\(\\mathtt{0}\\) \\(\\mathtt{0xc4}\\) \\(\\mathtt{1}\\) \\(\\mathtt{\\textbf{0x74}}\\) \\(\\mathtt{2}\\) \\(\\mathtt{\\textbf{0xf0}}\\) \\(\\mathtt{\\vdots}\\) \\(\\mathtt{\\vdots}\\) \\(\\mathtt{30}\\) \\(\\mathtt{\\textbf{0xce}}\\) \\(\\mathtt{31}\\) \\(\\mathtt{\\textbf{0x92}}\\) \\(\\mathtt{33}\\) \\(\\mathtt{0xd1}\\) \\(\\mathtt{\\vdots}\\) \\(\\mathtt{\\vdots}\\) \\(\\mathtt{62}\\) \\(\\mathtt{0xb7}\\) \\(\\mathtt{63}\\) \\(\\mathtt{0x23}\\) Table 2: Layout in memory after the introduction of 0x74f0...ce92. When the offset is not a multiple of 32 (or 0x20), as in the previous example, we have to use bytes from two different words when doing \\(\\texttt{MLOAD}\\) or \\(\\texttt{MSTORE}\\) . Finally, the EVM provides a write memory operation that just writes a byte: \\(\\texttt{MSTOREE}\\) : It receives an offset and saves one byte on that address of the memory. Notice that \\(\\texttt{MSTOREE}\\) always uses only one word. Layout The Memory SM is in charge of proving the memory operations in the execution trace. As mentioned, read and write operations use addresses at byte level in the EVM. However, doing the proofs byte-by-byte would consume many values in the trace of this state machine. Instead, in this machine, we operate addressing words (32 bytes). For example, if we have the memory layout from Table 1, then we would have the memory layout of Table 3 with addresses that point to 32-byte words. \\(\\textbf{ADDRESS}\\) \\(\\textbf{32-BYTE WORD}\\) \\(\\mathtt{0}\\) \\(\\mathtt{0xc417...81a7}\\) \\(\\mathtt{1}\\) \\(\\mathtt{0x88d1...b723}\\) Table 3: Layout in the memory state machine. The Memory SM uses this latter layout, the 32-byte word access, to check reads and writes. However, as previously mentioned, the EVM can read and write with offsets at a byte level. As a result, we will need to check the relationship between byte access and 32-byte word access. For these checks, we have another state machine called Memory Align SM. Design As with any state machine, the Memory SM has an executor to compute the trace that proves the correctness of memory reads and writes and a PIL description that enforces that the trace is correct. Execution Trace Design The Memory SM defines the design of the trace and the PIL description that checks that memory reads and writes aligned to 32-byte words are correct. The addresses, denoted as \\(\\texttt{addr}\\) , are represented through \\(32\\) bits ( \\(4\\) bytes) and point to 32-byte words. The value of words stored in memory, denoted as \\(\\texttt{val}\\) , are represented through \\(8\\) registers \\(\\texttt{val[0..7]}\\) of \\(4\\) bytes each, making a total of \\(32\\) bytes ( \\(256\\) bits). Table 4 shows an example with all the memory operations present at an execution trace of the Main SM. \\(\\texttt{step}\\) \\(\\texttt{mOp}\\) \\(\\texttt{mWr}\\) \\(\\texttt{addr}\\) \\(\\texttt{val[7]}\\) \\(\\texttt{val[6]}\\) \\(\\dots\\) \\(\\texttt{val[0]}\\) 11 1 1 6 2121 3782 \\(\\dots\\) 5432 31 1 1 4 3231 9326 \\(\\dots\\) 8012 55 1 0 6 2121 3782 \\(\\dots\\) 5432 63 1 1 6 4874 1725 \\(\\dots\\) 2074 72 1 0 4 3231 9326 \\(\\dots\\) 8012 89 1 1 2 9167 5291 \\(\\dots\\) 6001 Table 4: Memory Operations and an Execution Trace of the Main SM. The \\(\\texttt{step}\\) is the execution step number at the Main SM and in this case, we are showing only the steps that are performing a memory operation. The instruction to execute a memory operation is indicated by the \\(\\texttt{mOp}\\) selector. The \\(\\texttt{mWr}\\) is also a selector that shows whether the memory operation is a read or a write. In the previous trace, we can observe that the first memory operation is performed at step 11 and it is the write of the sixth 32-byte word. The eight registers \\(\\texttt{val[0..7]}\\) provide the bytes to be written in that word. It is worth to mention that for a specific word address, the first operation is always a write because it makes no sense to read a position that has not been previously written. Then, in this word address there can be a sequence of reads and writes. In the previous trace, we can observe that for the sixth word, there is a write at step 11, then a read at step \\(55\\) and finally another write at step \\(63\\) . \\(\\texttt{step}\\) \\(\\texttt{addr}\\) \\(\\texttt{mOp}\\) \\(\\texttt{mWr}\\) \\(\\texttt{val[7]}\\) \\(\\texttt{val[6]}\\) \\(\\dots\\) \\(\\texttt{val[0]}\\) 89 2 1 1 9167 5291 \\(\\dots\\) 6001 31 4 1 1 3231 9326 \\(\\dots\\) 8012 72 4 1 0 3231 9326 \\(\\dots\\) 8012 11 6 1 1 2121 3782 \\(\\dots\\) 5432 55 6 1 0 2121 3782 \\(\\dots\\) 5432 63 6 1 1 4674 1725 \\(\\dots\\) 2074 Table 5: Corresponding Memory SM Execution Trace. The trace of the Memory SM must check that the writes are done according to their step and that reads provide the correct words according also to their step. In order to implement these checks, the execution trace of the Memory SM sorts all the memory operations; firstly by \\(\\texttt{addr}\\) , and secondly by \\(\\texttt{step}\\) , as shown in Table 5. This ordering is referred to as the topology of the Memory SM. Finally, we will need to add a few more columns to ensure that the memory execution trace goes exactly across all the ordered writes and reads of the Main SM, with writes storing the provided values and with reads not changing the previous value of the word. In particular, we add three more columns. One these columns is called \\(\\texttt{INCS}\\) and it is used to provide an order for the values of the columns. Another column called \\(\\texttt{lastAccess}\\) is used to enable an address change when all the memory operations for this address have appeared at the trace. The last column is called \\(\\texttt{ISNOTLAST}\\) and it is used to make the checks pass when there are no more memory accesses. List of Columns The following columns (polynomials) are used by the Memory SM. We divide them between preprocessed and committed polynomials. Preprocessed : \\(\\texttt{INCS}\\) : Counter that goes from \\(1\\) up to \\(N\\) , where \\(N\\) is the number of rows in the computational trace, \\[ \\texttt{INCS} = (\\underbrace{1, 2, 3, \\dots,N-1, N}_{N}) \\] \u200b It is used to do a range check to prove the incremental order of other columns. \\(\\texttt{ISNOTLAST}\\) : Selector that is \\(1\\) in every row except in the \\(N\\) -th row, in which its value is \\(0\\) , \\[ \\texttt{ISNOTLAST} = (\\underbrace{1, 1, 1, \\dots,1, 0}_{N}) \\] Committed : \\(\\texttt{step}\\) : Position in which the memory operation was called in the Main SM. \\(\\texttt{mOp}\\) : Selector indicating whether it is being performed a memory operation or not. \\(\\texttt{mWr}\\) : Selector that is \\(1\\) if the memory operation is a write and \\(0\\) if it is a read operation. \\(\\texttt{addr}\\) : A \\(4\\) -byte (or \\(32\\) bit) integer indicating the address of a 32-byte word. \\(\\texttt{lastAccess}\\) : Selector indicating whether it has been reached the last memory access for a particular address or not. \\(\\texttt{val[0..7]}\\) : Vector containing \\(8\\) \\(4\\) -byte integer indicating the \\(256\\) -bit value associated to a given address. Complete Example Table 6 shows the complete Memory SM trace for our example in which the computational trace size \\(N\\) is \\(2^3\\) . There are various important details to remark from the point in which all memory accesses have been completed but the \\(2^3\\) -th row has not been reached yet: \\(\\texttt{mOp}\\) and \\(\\texttt{mWr}\\) are set to \\(0\\) until the last row. \\(\\texttt{addr}\\) is incremented by \\(1\\) to keep the incremental order of the addresses. This value is maintained until the last row. \\(\\texttt{lastAccess}\\) is also set to \\(0\\) except in the very last row, where it is set back to \\(1\\) to create the ciclycity behavior. \\(\\texttt{step}\\) is incremented by \\(1\\) in each row so that this column fulfills the constraints describing this state machine. \\(\\textbf{Remark}\\) . Notice that \\(\\texttt{step}\\) can take values beyond \\(N\\) and that the value of \\(\\texttt{step}\\) after the row of the last address can coincide with a previous value. As we will show in the next section, where we describe the constraints, these facts do not cause any issue. \\(\\texttt{val[0..7]}\\) are all set to \\(0\\) until the last row. Table 6: Complete Memory SM execution trace for our example. Constraints Topology Let's start with the set of constraints regarding the topology of the state machine. \\[ \\begin{align} &\\texttt{lastAccess} \\cdot (\\texttt{lastAccess} - 1) = 0, \\label{eq:lastAccessBin}\\tag{1}\\\\ &(1 - \\texttt{lastAccess}) \\cdot (\\texttt{addr}' - \\texttt{addr}) = 0, \\label{eqaddresSame}\\tag{2}\\\\ &\\texttt{ISNOTLAST}~\\left \\{ \\texttt{lastAccess} \\cdot \\left( \\texttt{addr}' - \\texttt{addr} - (\\texttt{step}' - \\texttt{step}) \\right) + (\\texttt{step}' - \\texttt{step}) \\right \\} \\subset \\texttt{INCS}. \\label{eq:topology}\\tag{3} \\end{align} \\] Equations (1) and (2) are straightforward. Equation (1) asserts that \\(\\texttt{lastAccess}\\) is a selector (i.e., a column whose values lie in the set \\(\\{0,1\\}\\) ), while Equation (2) confirms that \\(\\texttt{addr}\\) does not change until it is accessed for the last time. Note that Equation (2) implies that addresses are processed one-by-one in the Memory SM, but it does not guarantees that they are ordered incrementally. Equation (3) is a little bit more tricky. Let's do a case analysis on it. The curly braces notation in Equation (3) means that the inclusion is only checked at values such that the corresponding selector \\(\\texttt{ISNOTLAST}\\) is equal to \\(1\\) . Then, depending on value of the \\(\\texttt{lastAccess}\\) selector we have two cases: If \\(\\texttt{lastAccess} = 0\\) : \\[ \\texttt{step}' - \\texttt{step} \\subset \\texttt{INCS}. \\] Else: \\[ \\texttt{addr}' - \\texttt{addr} \\subset \\texttt{INCS}. \\] In words, whenever a transition do not change the address in question, verify that \\(\\texttt{step}' > \\texttt{step}\\) ; otherwise verify that \\(\\texttt{addr}' > \\texttt{addr}\\) . Therefore, Equation (3) ensures that both \\(\\texttt{step}\\) and \\(\\texttt{addr}\\) are ordered incrementally (first by \\(\\texttt{addr}\\) and then by \\(\\texttt{step}\\) ). A combination of Eqs. (2) and (3) gives the desired topology. Operation Selectors Let's continue with the operation selectors: \\(\\texttt{mOp}\\) and \\(\\texttt{mWr}\\) . \\[ \\begin{align} &\\texttt{mOp} \\cdot (\\texttt{mOp} - 1) = 0, \\tag{4}\\\\ &\\texttt{mWr} \\cdot (\\texttt{mWr} - 1) = 0, \\tag{5}\\\\ &\\left( 1 - \\texttt{mOp} \\right) \\cdot \\texttt{mWr} = 0. \\tag{6} \\end{align} \\] Eqs. (4) and (5) ensure that \\(\\texttt{mOp}\\) and \\(\\texttt{mWr}\\) are, effectively, selectors. Eq. (6) is imposing a restriction to \\(\\texttt{mWr}\\) (and binding it with \\(\\texttt{mOp}\\) ) in the following sense: \\(\\texttt{mWr}\\) can be set to \\(1\\) only if \\(\\texttt{mOp}\\) is also set to \\(1\\) . Similarly, if \\(\\texttt{mOp}\\) is set to \\(0\\) , then \\(\\texttt{mWr}\\) should be set to \\(0\\) as well. This restriction comes naturally from the definition of these selectors. Updating the Value Finally, we explain the constraints that deal with the value columns \\(\\texttt{val[0..7]}\\) . \\[ \\begin{align} &\\left( 1 - \\texttt{mOp}' \\cdot \\texttt{mWr}' \\right) \\cdot \\left(1 - \\texttt{lastAccess}\\right) \\cdot (\\texttt{val[0..7]}' - \\texttt{val[0..7]}) = 0, \\tag{7}\\\\ &\\left( 1 - \\texttt{mOp}' \\cdot \\texttt{mWr}' \\right) \\cdot \\texttt{lastAccess} \\cdot \\texttt{val[0..7]}' = 0. \\tag{8} \\end{align} \\] We analyze both Eqs. (7) and (8) at the same time. Notice that we simply discuss the feasible cases: \\(\\textbf{Maintain the same value when reading:}\\) If \\(\\texttt{mWr}' = 0\\) and \\(\\texttt{lastAccess} = 0\\) , then it should be the case that \\(\\texttt{val[0..7]}' = \\texttt{val[0..7]}\\) , since this means that we will perform a read in the next step. Eq. (7) ensures this case. \\(\\textbf{Filling the value with zeros when done:}\\) If \\(\\texttt{mOp}' = 1\\) , \\(\\texttt{mWr}' = 0\\) and \\(\\texttt{lastAccess} = 1\\) , then it should be the case that \\(\\texttt{val[0..7]}' = 0\\) , i.e., the register \\(\\texttt{val[0..7]}\\) is set to \\(0\\) in the forthcoming steps. More cases are not possible because for an address we always start with a write operation which limits the behavior of these constraints to these cases. For example, it cannot happen that \\(\\texttt{lastAccess = 1}\\) and some of \\(\\texttt{mOp}'\\) or \\(\\texttt{mWr}'\\) is 0; because the first operation that is always performed over a memory address is a write. However, notice that to be able reset \\(\\texttt{addr}\\) to its state in the first row (where it is the case that \\(\\texttt{addr}' < \\texttt{addr}\\) ) it should be the case that \\(\\texttt{lastAccess} = 1\\) in the last row of the computational case. If \\(\\texttt{lastAccess}\\) would have not been set to \\(1\\) , then Eq. (2) would not be satisfied. We obtain this condition by adding the following constraint: \\[ \\left(1 - \\texttt{lastAccess}\\right) \\cdot \\left(1 - \\texttt{ISNOTLAST}\\right) = 0. \\] Connection with the Main SM The last constraint that we need to add is to relate the execution trace of the Main SM with the execution trace of the Memory SM. The constraint has to check that all the rows in the trace of the Main SM that make memory operations (i.e. rows where \\(\\texttt{mOp} == 1\\) ) are a permutation (any permutation) of the rows of the Memory SM where \\(\\texttt{mOp} == 1\\) . The key point is that if both vectors would not be a permutation of each other, then that would mean that the Main SM is performing an incorrect memory action.","title":"Memory"},{"location":"zkEVM/State-Machines/Memory/memory-state-machine/#memory-state-machine","text":"As a secondary state machine, the Memory State Machine has the executor part (the Memory SM Executor) and an internal Memory PIL (program) which is a set of verification rules, written in the PIL language. The Memory SM Executor is written in two versions; Javascript and C/C++. The Polygon Hermez Repo is here https://github.com/0xPolygonHermez Memory SM Executor : sm_mem.js Memory SM PIL : mem.pil","title":"Memory State Machine"},{"location":"zkEVM/State-Machines/Memory/memory-state-machine/#evm-memory","text":"The memory of the EVM (Ethereum Virtual Machine) is a volatile read-write memory, and it is used to store temporary data during the execution of transactions of smart contract functions. That is, data in memory is populated during transaction's execution but it does not persist between transactions. The memory is an array of \\(256\\) -bit ( \\(32\\) bytes) words that can be accessed through addresses at byte level , that is to say, each byte in the memory has a different address. Memory has addresses of \\(32\\) bits, and initially, all memory locations are composed by bytes set to zero. Now, let's see the layout in memory of the following two words \\(\\texttt{0xc417...81a7}\\) and \\(\\texttt{0x88d1...b723}\\) . Table 1 displays this layout. \\(\\mathbf{ADDRESS}\\) \\(\\mathbf{BYTE}\\) \\(\\mathtt{0}\\) \\(\\mathtt{0xc4}\\) \\(\\mathtt{1}\\) \\(\\mathtt{0x17}\\) \\(\\mathtt{\\vdots}\\) \\(\\mathtt{\\vdots}\\) \\(\\mathtt{30}\\) \\(\\mathtt{0x81}\\) \\(\\mathtt{31}\\) \\(\\mathtt{0xa7}\\) \\(\\mathtt{32}\\) \\(\\mathtt{0x88}\\) \\(\\mathtt{33}\\) \\(\\mathtt{0xd1}\\) \\(\\mathtt{\\vdots}\\) \\(\\mathtt{\\vdots}\\) \\(\\mathtt{62}\\) \\(\\mathtt{0xb7}\\) \\(\\mathtt{63}\\) \\(\\mathtt{0x23}\\) Table 1: Layout in memory of 0xc417...81a7 and 0x88d1...b723. Observe that each word has 32 bytes and that the words are stored in Big-Endian form. i.e. The most significant bytes are set in the lower addresses. The EVM provides three opcodes to interact with the memory area. There is an opcode to read, and an opcode to write 32-byte words providing an offset: \\(\\texttt{MLOAD}\\) : It receives an offset and returns the 32 bytes in memory starting at that offset. \\(\\texttt{MSTORE}\\) : It receives an offset and saves 32 bytes from the offset address of the memory. Considering our previous memory contents, if we perform an \\(\\texttt{MLOAD}\\) with an offset of \\(\\texttt{1}\\) , we would obtain the following word: \\(\\texttt{0x17...a788}\\) . On the other hand, if we do an \\(\\texttt{MSTORE}\\) with an offset of \\(\\texttt{1}\\) with the word \\(\\texttt{0x74f0...ce92}\\) , we would modify the content of the memory as shown in Table 2. \\(\\mathbf{ADDRESS}\\) \\(\\mathbf{BYTE}\\) \\(\\mathtt{0}\\) \\(\\mathtt{0xc4}\\) \\(\\mathtt{1}\\) \\(\\mathtt{\\textbf{0x74}}\\) \\(\\mathtt{2}\\) \\(\\mathtt{\\textbf{0xf0}}\\) \\(\\mathtt{\\vdots}\\) \\(\\mathtt{\\vdots}\\) \\(\\mathtt{30}\\) \\(\\mathtt{\\textbf{0xce}}\\) \\(\\mathtt{31}\\) \\(\\mathtt{\\textbf{0x92}}\\) \\(\\mathtt{33}\\) \\(\\mathtt{0xd1}\\) \\(\\mathtt{\\vdots}\\) \\(\\mathtt{\\vdots}\\) \\(\\mathtt{62}\\) \\(\\mathtt{0xb7}\\) \\(\\mathtt{63}\\) \\(\\mathtt{0x23}\\) Table 2: Layout in memory after the introduction of 0x74f0...ce92. When the offset is not a multiple of 32 (or 0x20), as in the previous example, we have to use bytes from two different words when doing \\(\\texttt{MLOAD}\\) or \\(\\texttt{MSTORE}\\) . Finally, the EVM provides a write memory operation that just writes a byte: \\(\\texttt{MSTOREE}\\) : It receives an offset and saves one byte on that address of the memory. Notice that \\(\\texttt{MSTOREE}\\) always uses only one word.","title":"EVM Memory"},{"location":"zkEVM/State-Machines/Memory/memory-state-machine/#layout","text":"The Memory SM is in charge of proving the memory operations in the execution trace. As mentioned, read and write operations use addresses at byte level in the EVM. However, doing the proofs byte-by-byte would consume many values in the trace of this state machine. Instead, in this machine, we operate addressing words (32 bytes). For example, if we have the memory layout from Table 1, then we would have the memory layout of Table 3 with addresses that point to 32-byte words. \\(\\textbf{ADDRESS}\\) \\(\\textbf{32-BYTE WORD}\\) \\(\\mathtt{0}\\) \\(\\mathtt{0xc417...81a7}\\) \\(\\mathtt{1}\\) \\(\\mathtt{0x88d1...b723}\\) Table 3: Layout in the memory state machine. The Memory SM uses this latter layout, the 32-byte word access, to check reads and writes. However, as previously mentioned, the EVM can read and write with offsets at a byte level. As a result, we will need to check the relationship between byte access and 32-byte word access. For these checks, we have another state machine called Memory Align SM.","title":"Layout"},{"location":"zkEVM/State-Machines/Memory/memory-state-machine/#design","text":"As with any state machine, the Memory SM has an executor to compute the trace that proves the correctness of memory reads and writes and a PIL description that enforces that the trace is correct.","title":"Design"},{"location":"zkEVM/State-Machines/Memory/memory-state-machine/#execution-trace-design","text":"The Memory SM defines the design of the trace and the PIL description that checks that memory reads and writes aligned to 32-byte words are correct. The addresses, denoted as \\(\\texttt{addr}\\) , are represented through \\(32\\) bits ( \\(4\\) bytes) and point to 32-byte words. The value of words stored in memory, denoted as \\(\\texttt{val}\\) , are represented through \\(8\\) registers \\(\\texttt{val[0..7]}\\) of \\(4\\) bytes each, making a total of \\(32\\) bytes ( \\(256\\) bits). Table 4 shows an example with all the memory operations present at an execution trace of the Main SM. \\(\\texttt{step}\\) \\(\\texttt{mOp}\\) \\(\\texttt{mWr}\\) \\(\\texttt{addr}\\) \\(\\texttt{val[7]}\\) \\(\\texttt{val[6]}\\) \\(\\dots\\) \\(\\texttt{val[0]}\\) 11 1 1 6 2121 3782 \\(\\dots\\) 5432 31 1 1 4 3231 9326 \\(\\dots\\) 8012 55 1 0 6 2121 3782 \\(\\dots\\) 5432 63 1 1 6 4874 1725 \\(\\dots\\) 2074 72 1 0 4 3231 9326 \\(\\dots\\) 8012 89 1 1 2 9167 5291 \\(\\dots\\) 6001 Table 4: Memory Operations and an Execution Trace of the Main SM. The \\(\\texttt{step}\\) is the execution step number at the Main SM and in this case, we are showing only the steps that are performing a memory operation. The instruction to execute a memory operation is indicated by the \\(\\texttt{mOp}\\) selector. The \\(\\texttt{mWr}\\) is also a selector that shows whether the memory operation is a read or a write. In the previous trace, we can observe that the first memory operation is performed at step 11 and it is the write of the sixth 32-byte word. The eight registers \\(\\texttt{val[0..7]}\\) provide the bytes to be written in that word. It is worth to mention that for a specific word address, the first operation is always a write because it makes no sense to read a position that has not been previously written. Then, in this word address there can be a sequence of reads and writes. In the previous trace, we can observe that for the sixth word, there is a write at step 11, then a read at step \\(55\\) and finally another write at step \\(63\\) . \\(\\texttt{step}\\) \\(\\texttt{addr}\\) \\(\\texttt{mOp}\\) \\(\\texttt{mWr}\\) \\(\\texttt{val[7]}\\) \\(\\texttt{val[6]}\\) \\(\\dots\\) \\(\\texttt{val[0]}\\) 89 2 1 1 9167 5291 \\(\\dots\\) 6001 31 4 1 1 3231 9326 \\(\\dots\\) 8012 72 4 1 0 3231 9326 \\(\\dots\\) 8012 11 6 1 1 2121 3782 \\(\\dots\\) 5432 55 6 1 0 2121 3782 \\(\\dots\\) 5432 63 6 1 1 4674 1725 \\(\\dots\\) 2074 Table 5: Corresponding Memory SM Execution Trace. The trace of the Memory SM must check that the writes are done according to their step and that reads provide the correct words according also to their step. In order to implement these checks, the execution trace of the Memory SM sorts all the memory operations; firstly by \\(\\texttt{addr}\\) , and secondly by \\(\\texttt{step}\\) , as shown in Table 5. This ordering is referred to as the topology of the Memory SM. Finally, we will need to add a few more columns to ensure that the memory execution trace goes exactly across all the ordered writes and reads of the Main SM, with writes storing the provided values and with reads not changing the previous value of the word. In particular, we add three more columns. One these columns is called \\(\\texttt{INCS}\\) and it is used to provide an order for the values of the columns. Another column called \\(\\texttt{lastAccess}\\) is used to enable an address change when all the memory operations for this address have appeared at the trace. The last column is called \\(\\texttt{ISNOTLAST}\\) and it is used to make the checks pass when there are no more memory accesses.","title":"Execution Trace Design"},{"location":"zkEVM/State-Machines/Memory/memory-state-machine/#list-of-columns","text":"The following columns (polynomials) are used by the Memory SM. We divide them between preprocessed and committed polynomials. Preprocessed : \\(\\texttt{INCS}\\) : Counter that goes from \\(1\\) up to \\(N\\) , where \\(N\\) is the number of rows in the computational trace, \\[ \\texttt{INCS} = (\\underbrace{1, 2, 3, \\dots,N-1, N}_{N}) \\] \u200b It is used to do a range check to prove the incremental order of other columns. \\(\\texttt{ISNOTLAST}\\) : Selector that is \\(1\\) in every row except in the \\(N\\) -th row, in which its value is \\(0\\) , \\[ \\texttt{ISNOTLAST} = (\\underbrace{1, 1, 1, \\dots,1, 0}_{N}) \\] Committed : \\(\\texttt{step}\\) : Position in which the memory operation was called in the Main SM. \\(\\texttt{mOp}\\) : Selector indicating whether it is being performed a memory operation or not. \\(\\texttt{mWr}\\) : Selector that is \\(1\\) if the memory operation is a write and \\(0\\) if it is a read operation. \\(\\texttt{addr}\\) : A \\(4\\) -byte (or \\(32\\) bit) integer indicating the address of a 32-byte word. \\(\\texttt{lastAccess}\\) : Selector indicating whether it has been reached the last memory access for a particular address or not. \\(\\texttt{val[0..7]}\\) : Vector containing \\(8\\) \\(4\\) -byte integer indicating the \\(256\\) -bit value associated to a given address.","title":"List of Columns"},{"location":"zkEVM/State-Machines/Memory/memory-state-machine/#complete-example","text":"Table 6 shows the complete Memory SM trace for our example in which the computational trace size \\(N\\) is \\(2^3\\) . There are various important details to remark from the point in which all memory accesses have been completed but the \\(2^3\\) -th row has not been reached yet: \\(\\texttt{mOp}\\) and \\(\\texttt{mWr}\\) are set to \\(0\\) until the last row. \\(\\texttt{addr}\\) is incremented by \\(1\\) to keep the incremental order of the addresses. This value is maintained until the last row. \\(\\texttt{lastAccess}\\) is also set to \\(0\\) except in the very last row, where it is set back to \\(1\\) to create the ciclycity behavior. \\(\\texttt{step}\\) is incremented by \\(1\\) in each row so that this column fulfills the constraints describing this state machine. \\(\\textbf{Remark}\\) . Notice that \\(\\texttt{step}\\) can take values beyond \\(N\\) and that the value of \\(\\texttt{step}\\) after the row of the last address can coincide with a previous value. As we will show in the next section, where we describe the constraints, these facts do not cause any issue. \\(\\texttt{val[0..7]}\\) are all set to \\(0\\) until the last row. Table 6: Complete Memory SM execution trace for our example.","title":"Complete Example"},{"location":"zkEVM/State-Machines/Memory/memory-state-machine/#constraints","text":"","title":"Constraints"},{"location":"zkEVM/State-Machines/Memory/memory-state-machine/#topology","text":"Let's start with the set of constraints regarding the topology of the state machine. \\[ \\begin{align} &\\texttt{lastAccess} \\cdot (\\texttt{lastAccess} - 1) = 0, \\label{eq:lastAccessBin}\\tag{1}\\\\ &(1 - \\texttt{lastAccess}) \\cdot (\\texttt{addr}' - \\texttt{addr}) = 0, \\label{eqaddresSame}\\tag{2}\\\\ &\\texttt{ISNOTLAST}~\\left \\{ \\texttt{lastAccess} \\cdot \\left( \\texttt{addr}' - \\texttt{addr} - (\\texttt{step}' - \\texttt{step}) \\right) + (\\texttt{step}' - \\texttt{step}) \\right \\} \\subset \\texttt{INCS}. \\label{eq:topology}\\tag{3} \\end{align} \\] Equations (1) and (2) are straightforward. Equation (1) asserts that \\(\\texttt{lastAccess}\\) is a selector (i.e., a column whose values lie in the set \\(\\{0,1\\}\\) ), while Equation (2) confirms that \\(\\texttt{addr}\\) does not change until it is accessed for the last time. Note that Equation (2) implies that addresses are processed one-by-one in the Memory SM, but it does not guarantees that they are ordered incrementally. Equation (3) is a little bit more tricky. Let's do a case analysis on it. The curly braces notation in Equation (3) means that the inclusion is only checked at values such that the corresponding selector \\(\\texttt{ISNOTLAST}\\) is equal to \\(1\\) . Then, depending on value of the \\(\\texttt{lastAccess}\\) selector we have two cases: If \\(\\texttt{lastAccess} = 0\\) : \\[ \\texttt{step}' - \\texttt{step} \\subset \\texttt{INCS}. \\] Else: \\[ \\texttt{addr}' - \\texttt{addr} \\subset \\texttt{INCS}. \\] In words, whenever a transition do not change the address in question, verify that \\(\\texttt{step}' > \\texttt{step}\\) ; otherwise verify that \\(\\texttt{addr}' > \\texttt{addr}\\) . Therefore, Equation (3) ensures that both \\(\\texttt{step}\\) and \\(\\texttt{addr}\\) are ordered incrementally (first by \\(\\texttt{addr}\\) and then by \\(\\texttt{step}\\) ). A combination of Eqs. (2) and (3) gives the desired topology.","title":"Topology"},{"location":"zkEVM/State-Machines/Memory/memory-state-machine/#operation-selectors","text":"Let's continue with the operation selectors: \\(\\texttt{mOp}\\) and \\(\\texttt{mWr}\\) . \\[ \\begin{align} &\\texttt{mOp} \\cdot (\\texttt{mOp} - 1) = 0, \\tag{4}\\\\ &\\texttt{mWr} \\cdot (\\texttt{mWr} - 1) = 0, \\tag{5}\\\\ &\\left( 1 - \\texttt{mOp} \\right) \\cdot \\texttt{mWr} = 0. \\tag{6} \\end{align} \\] Eqs. (4) and (5) ensure that \\(\\texttt{mOp}\\) and \\(\\texttt{mWr}\\) are, effectively, selectors. Eq. (6) is imposing a restriction to \\(\\texttt{mWr}\\) (and binding it with \\(\\texttt{mOp}\\) ) in the following sense: \\(\\texttt{mWr}\\) can be set to \\(1\\) only if \\(\\texttt{mOp}\\) is also set to \\(1\\) . Similarly, if \\(\\texttt{mOp}\\) is set to \\(0\\) , then \\(\\texttt{mWr}\\) should be set to \\(0\\) as well. This restriction comes naturally from the definition of these selectors.","title":"Operation Selectors"},{"location":"zkEVM/State-Machines/Memory/memory-state-machine/#updating-the-value","text":"Finally, we explain the constraints that deal with the value columns \\(\\texttt{val[0..7]}\\) . \\[ \\begin{align} &\\left( 1 - \\texttt{mOp}' \\cdot \\texttt{mWr}' \\right) \\cdot \\left(1 - \\texttt{lastAccess}\\right) \\cdot (\\texttt{val[0..7]}' - \\texttt{val[0..7]}) = 0, \\tag{7}\\\\ &\\left( 1 - \\texttt{mOp}' \\cdot \\texttt{mWr}' \\right) \\cdot \\texttt{lastAccess} \\cdot \\texttt{val[0..7]}' = 0. \\tag{8} \\end{align} \\] We analyze both Eqs. (7) and (8) at the same time. Notice that we simply discuss the feasible cases: \\(\\textbf{Maintain the same value when reading:}\\) If \\(\\texttt{mWr}' = 0\\) and \\(\\texttt{lastAccess} = 0\\) , then it should be the case that \\(\\texttt{val[0..7]}' = \\texttt{val[0..7]}\\) , since this means that we will perform a read in the next step. Eq. (7) ensures this case. \\(\\textbf{Filling the value with zeros when done:}\\) If \\(\\texttt{mOp}' = 1\\) , \\(\\texttt{mWr}' = 0\\) and \\(\\texttt{lastAccess} = 1\\) , then it should be the case that \\(\\texttt{val[0..7]}' = 0\\) , i.e., the register \\(\\texttt{val[0..7]}\\) is set to \\(0\\) in the forthcoming steps. More cases are not possible because for an address we always start with a write operation which limits the behavior of these constraints to these cases. For example, it cannot happen that \\(\\texttt{lastAccess = 1}\\) and some of \\(\\texttt{mOp}'\\) or \\(\\texttt{mWr}'\\) is 0; because the first operation that is always performed over a memory address is a write. However, notice that to be able reset \\(\\texttt{addr}\\) to its state in the first row (where it is the case that \\(\\texttt{addr}' < \\texttt{addr}\\) ) it should be the case that \\(\\texttt{lastAccess} = 1\\) in the last row of the computational case. If \\(\\texttt{lastAccess}\\) would have not been set to \\(1\\) , then Eq. (2) would not be satisfied. We obtain this condition by adding the following constraint: \\[ \\left(1 - \\texttt{lastAccess}\\right) \\cdot \\left(1 - \\texttt{ISNOTLAST}\\right) = 0. \\]","title":"Updating the Value"},{"location":"zkEVM/State-Machines/Memory/memory-state-machine/#connection-with-the-main-sm","text":"The last constraint that we need to add is to relate the execution trace of the Main SM with the execution trace of the Memory SM. The constraint has to check that all the rows in the trace of the Main SM that make memory operations (i.e. rows where \\(\\texttt{mOp} == 1\\) ) are a permutation (any permutation) of the rows of the Memory SM where \\(\\texttt{mOp} == 1\\) . The key point is that if both vectors would not be a permutation of each other, then that would mean that the Main SM is performing an incorrect memory action.","title":"Connection with the Main SM"},{"location":"zkEVM/State-Machines/Memory-Align/memory-align-state-machine/","text":"Memory Align SM Introduction As a secondary state machine, the Memory Align State Machine has the executor part (the Memory Align SM Executor) and an internal Memory Align PIL (program) which is a set of verification rules, written in the PIL language. The Memory Align SM Executor is written in two versions; Javascript and C/C++. The Polygon Hermez Repo is here https://github.com/0xPolygonHermez Memory Align SM Executor : sm_mem_align.js Memory Align SM PIL : mem_align.pil Purpose of the State Machine The Memory SM checks memory reads and writes using a 32-byte word access, while the EVM can read and write 32-byte words with offsets at a byte level. Table 6 shows an example of possible byte-addressed and 32-byte-addressed memory layouts for the same content (three words). Table 7: Sample memory layouts for byte and 32-byte access. \\[ \\begin{array}{|c|c|} \\hline \\mathbf{ADDRESS} &\\mathbf{BYTE} \\\\ \\hline \\mathtt{0} &\\mathtt{0xc4} \\\\ \\mathtt{1} &\\mathtt{0x17} \\\\ \\mathtt{\\vdots} &\\mathtt{\\vdots} \\\\ \\mathtt{30} &\\mathtt{0x81} \\\\ \\mathtt{31} &\\mathtt{0xa7} \\\\ \\mathtt{32} &\\mathtt{0x88} \\\\ \\mathtt{33} &\\mathtt{0xd1} \\\\ \\mathtt{\\vdots} &\\mathtt{\\vdots} \\\\ \\mathtt{62} &\\mathtt{0xb7} \\\\ \\mathtt{63} &\\mathtt{0x23} \\\\ \\hline \\end{array} \\] \\[ \\begin{array}{|c|c|} \\hline \\textbf{ADDRESS} & \\textbf{32-BYTE WORD} \\\\ \\hline \\mathtt{0} &\\mathtt{0xc417...81a7} \\\\ \\mathtt{1} &\\mathtt{0x88d1...b723} \\\\ \\hline \\end{array} \\] The relationship between the 32-byte word addressable layout and the byte addressable layout is called \"memory alignment\" and the Memory Align SM is the state machine that checks the correctness of this relationship. In more detail, we have to check the following memory operations: \\(\\mathtt{MLOAD}\\) : It receives an offset and returns the 32 bytes in memory starting at that offset. \\(\\mathtt{MSTORE}\\) : It receives an offset and saves 32 bytes from the offset address of the memory. \\(\\mathtt{MSTORE8}\\) : It receives an offset and saves one byte on that address of the memory. Notice that, in the general case, \\(\\mathtt{MLOAD}\\) requires reading bytes of two different words. Considering that the content of the memory is the one shown at Table 6, since the EVM is addressed at a byte level, if we want to check a read from the EVM of a word starting at the address \\(\\mathtt{0x22}\\) , the value that we should obtain is the following: \\[ \\mathtt{val} = \\mathtt{0x1f \\cdots b7236e21}. \\] We denote the content of the words affected by an EVM memory read as \\(\\mathtt{m}_0\\) and \\(\\mathtt{m}_1\\) . In our example, these words are the following: \\[ \\mathtt{m}_0 = \\mathtt{0x} \\mathtt{88d11f} \\cdots \\mathtt{b723}, \\quad \\mathtt{m}_1 = \\mathtt{0x} \\mathtt{6e21ff} \\cdots \\mathtt{54f9}. \\] We define a read block as the string concatenating the content of the words affected by the read: \\(\\mathtt{m}_0 \\mid \\mathtt{m}_1\\) . Figure 7 shows the affected read words \\(\\mathtt{m}_0\\) and \\(\\mathtt{m}_1\\) that form the affected read block and the read value \\(\\mathtt{val}\\) for a read from the EVM at address \\(\\mathtt{0x22}\\) in our example memory of Table 6. Figure 1: Schema of MLOAD Example Let us now introduce the flow at the time of validating a read. Suppose that we want to validate that if we perform an \\(\\mathtt{MLOAD}\\) operation at the address \\(\\mathtt{0x22}\\) , we get the previous value \\(\\mathtt{0x1f\\dotsb7236e21}\\) . At this point, the main state machine will perform several operations. First of all, it will have to query for the values \\(\\mathtt{m}_0\\) and \\(\\mathtt{m}_1\\) . Henceforth, it must call the Memory SM in order to validate the previous queries. Observe that it is easy to extract the memory positions to query from the address \\(\\mathtt{0x22}\\) . In fact, if \\(a\\) is the memory position of the \\(\\mathtt{MLOAD}\\) operation, then \\(\\mathtt{m}_0\\) is always stored at the memory position \\(\\lfloor \\frac{a}{32} \\rfloor\\) and \\(\\mathtt{m}_1\\) is stored at the memory position \\(\\lfloor \\frac{a}{32} \\rfloor + 1\\) . In our example, \\(a = \\mathtt{0x22} = 34\\) . Hence, \\(\\mathtt{m}_0\\) is stored at the position \\(\\lfloor \\frac{32}{34} \\rfloor = \\mathtt{0x01}\\) and \\(\\mathtt{m}_1\\) is stored at the position \\(\\lfloor \\frac{32}{34} \\rfloor + 1= \\mathtt{0x02}\\) . Secondly, we should extract the correct \\(\\mathtt{offset}\\) . The \\(\\mathtt{offset}\\) represents an index between \\(0\\) and \\(31\\) indicating the number of bytes we should offset from the starting of \\(\\mathtt{m}_0\\) to correctly place \\(\\mathtt{val}\\) in the block. In our case, the \\(\\mathtt{offset}\\) is \\(2\\) . Similarly as before, it is easy to obtain the offset from \\(a\\) . In fact, the it is equal to \\(a\\) \\((\\mathrm{mod} \\ 32)\\) . Now, the Main SM will check via a Plookup to the Memory Align State Machine that \\val is a correct read given the affected words \\(\\mathtt{m}_0\\) and \\(\\mathtt{m}_1\\) and the \\(\\mathtt{offset}\\) . That is, we should check that the value \\(\\mathtt{val}\\) can be correctly split into \\(\\mathtt{m}_0\\) and \\(\\mathtt{m}_1\\) using the provided \\(\\mathtt{offset}\\) . Similarly, \\(\\mathtt{MSTORE}\\) instruction requires, in general, writing bytes in two words. The idea is very similar, but we are provided with a value \\val that we want to write into a specific location of the memory. We will denote by \\(\\mathtt{w}_0\\) and \\(\\mathtt{w}_1\\) the words that arise from \\(\\mathtt{m}_0\\) and \\(\\mathtt{m}_1\\) after the corresponding write. Following our previous example, suppose that we want to write \\[ \\mathtt{val} = \\mathtt{0xe201e6\\dots662b} \\] in the address \\(\\mathtt{0x22}\\) of the byte-addressed Ethereum memory. We are using the same \\(\\mathtt{m}_0\\) and \\(\\mathtt{m}_1\\) (and since we are writting into the same address as before) and they will transition into (see Figure 8 ): \\[ \\mathtt{w}_0 = \\mathtt{0x88d1}\\color{-red!75}\\mathtt{e201e6\\dots}\\color{black},\\quad \\mathtt{w}_1 = \\mathtt{0x}\\color{-red!75} \\mathtt{662b}\\color{black} \\mathtt{ff\\dots54f9}. \\] Figure 8: Schema of MSTORE example. Just as before, the main state machine will need to perform several operations. We will be given an address \\(\\mathtt{addr}\\) , an offset value \\(\\mathtt{offset}\\) and a value to be wrote \\(\\mathtt{val}\\) . Identically as before, the Main SM will be in charge of reading the zkEVM memory to find \\(\\mathtt{m}_0\\) and \\(\\mathtt{m}_1\\) from the given address and offset. Of course, the validity of this query should be performed with a specific Plookup into the Memory SM, just as before. Now, the Main SM can compute \\(\\mathtt{w}_0\\) and \\(\\mathtt{w}_1\\) from all the previous values in a uniquely way. The way of validating that we are providing the correct \\(\\mathtt{w}_0\\) and \\(\\mathtt{w}_1\\) is to perform a Plookup into the Memory Align SM. That is, we will check that the provided values \\(\\mathtt{w}_0\\) and \\(\\mathtt{w}_1\\) are correctly constructed from the provided \\(\\mathtt{val}\\) , \\(\\mathtt{m}_0\\) , \\(\\mathtt{m}_1\\) and \\(\\mathtt{offset}\\) values. Finally, the last opcode \\(\\mathtt{MSTOREE}\\) works similarly, but it only affects one word \\(\\mathtt{m}_0\\) . Moreover, we can only write one byte and hence, only the less significant byte of \\(\\mathtt{val}\\) will be considered into the write. Observe that, in this opcode, \\(\\mathtt{m}_1\\) and \\(\\mathtt{w}_1\\) are unconstrained.","title":"Memory Align"},{"location":"zkEVM/State-Machines/Memory-Align/memory-align-state-machine/#memory-align-sm","text":"","title":"Memory Align SM"},{"location":"zkEVM/State-Machines/Memory-Align/memory-align-state-machine/#introduction","text":"As a secondary state machine, the Memory Align State Machine has the executor part (the Memory Align SM Executor) and an internal Memory Align PIL (program) which is a set of verification rules, written in the PIL language. The Memory Align SM Executor is written in two versions; Javascript and C/C++. The Polygon Hermez Repo is here https://github.com/0xPolygonHermez Memory Align SM Executor : sm_mem_align.js Memory Align SM PIL : mem_align.pil","title":"Introduction"},{"location":"zkEVM/State-Machines/Memory-Align/memory-align-state-machine/#purpose-of-the-state-machine","text":"The Memory SM checks memory reads and writes using a 32-byte word access, while the EVM can read and write 32-byte words with offsets at a byte level. Table 6 shows an example of possible byte-addressed and 32-byte-addressed memory layouts for the same content (three words). Table 7: Sample memory layouts for byte and 32-byte access. \\[ \\begin{array}{|c|c|} \\hline \\mathbf{ADDRESS} &\\mathbf{BYTE} \\\\ \\hline \\mathtt{0} &\\mathtt{0xc4} \\\\ \\mathtt{1} &\\mathtt{0x17} \\\\ \\mathtt{\\vdots} &\\mathtt{\\vdots} \\\\ \\mathtt{30} &\\mathtt{0x81} \\\\ \\mathtt{31} &\\mathtt{0xa7} \\\\ \\mathtt{32} &\\mathtt{0x88} \\\\ \\mathtt{33} &\\mathtt{0xd1} \\\\ \\mathtt{\\vdots} &\\mathtt{\\vdots} \\\\ \\mathtt{62} &\\mathtt{0xb7} \\\\ \\mathtt{63} &\\mathtt{0x23} \\\\ \\hline \\end{array} \\] \\[ \\begin{array}{|c|c|} \\hline \\textbf{ADDRESS} & \\textbf{32-BYTE WORD} \\\\ \\hline \\mathtt{0} &\\mathtt{0xc417...81a7} \\\\ \\mathtt{1} &\\mathtt{0x88d1...b723} \\\\ \\hline \\end{array} \\] The relationship between the 32-byte word addressable layout and the byte addressable layout is called \"memory alignment\" and the Memory Align SM is the state machine that checks the correctness of this relationship. In more detail, we have to check the following memory operations: \\(\\mathtt{MLOAD}\\) : It receives an offset and returns the 32 bytes in memory starting at that offset. \\(\\mathtt{MSTORE}\\) : It receives an offset and saves 32 bytes from the offset address of the memory. \\(\\mathtt{MSTORE8}\\) : It receives an offset and saves one byte on that address of the memory. Notice that, in the general case, \\(\\mathtt{MLOAD}\\) requires reading bytes of two different words. Considering that the content of the memory is the one shown at Table 6, since the EVM is addressed at a byte level, if we want to check a read from the EVM of a word starting at the address \\(\\mathtt{0x22}\\) , the value that we should obtain is the following: \\[ \\mathtt{val} = \\mathtt{0x1f \\cdots b7236e21}. \\] We denote the content of the words affected by an EVM memory read as \\(\\mathtt{m}_0\\) and \\(\\mathtt{m}_1\\) . In our example, these words are the following: \\[ \\mathtt{m}_0 = \\mathtt{0x} \\mathtt{88d11f} \\cdots \\mathtt{b723}, \\quad \\mathtt{m}_1 = \\mathtt{0x} \\mathtt{6e21ff} \\cdots \\mathtt{54f9}. \\] We define a read block as the string concatenating the content of the words affected by the read: \\(\\mathtt{m}_0 \\mid \\mathtt{m}_1\\) . Figure 7 shows the affected read words \\(\\mathtt{m}_0\\) and \\(\\mathtt{m}_1\\) that form the affected read block and the read value \\(\\mathtt{val}\\) for a read from the EVM at address \\(\\mathtt{0x22}\\) in our example memory of Table 6. Figure 1: Schema of MLOAD Example Let us now introduce the flow at the time of validating a read. Suppose that we want to validate that if we perform an \\(\\mathtt{MLOAD}\\) operation at the address \\(\\mathtt{0x22}\\) , we get the previous value \\(\\mathtt{0x1f\\dotsb7236e21}\\) . At this point, the main state machine will perform several operations. First of all, it will have to query for the values \\(\\mathtt{m}_0\\) and \\(\\mathtt{m}_1\\) . Henceforth, it must call the Memory SM in order to validate the previous queries. Observe that it is easy to extract the memory positions to query from the address \\(\\mathtt{0x22}\\) . In fact, if \\(a\\) is the memory position of the \\(\\mathtt{MLOAD}\\) operation, then \\(\\mathtt{m}_0\\) is always stored at the memory position \\(\\lfloor \\frac{a}{32} \\rfloor\\) and \\(\\mathtt{m}_1\\) is stored at the memory position \\(\\lfloor \\frac{a}{32} \\rfloor + 1\\) . In our example, \\(a = \\mathtt{0x22} = 34\\) . Hence, \\(\\mathtt{m}_0\\) is stored at the position \\(\\lfloor \\frac{32}{34} \\rfloor = \\mathtt{0x01}\\) and \\(\\mathtt{m}_1\\) is stored at the position \\(\\lfloor \\frac{32}{34} \\rfloor + 1= \\mathtt{0x02}\\) . Secondly, we should extract the correct \\(\\mathtt{offset}\\) . The \\(\\mathtt{offset}\\) represents an index between \\(0\\) and \\(31\\) indicating the number of bytes we should offset from the starting of \\(\\mathtt{m}_0\\) to correctly place \\(\\mathtt{val}\\) in the block. In our case, the \\(\\mathtt{offset}\\) is \\(2\\) . Similarly as before, it is easy to obtain the offset from \\(a\\) . In fact, the it is equal to \\(a\\) \\((\\mathrm{mod} \\ 32)\\) . Now, the Main SM will check via a Plookup to the Memory Align State Machine that \\val is a correct read given the affected words \\(\\mathtt{m}_0\\) and \\(\\mathtt{m}_1\\) and the \\(\\mathtt{offset}\\) . That is, we should check that the value \\(\\mathtt{val}\\) can be correctly split into \\(\\mathtt{m}_0\\) and \\(\\mathtt{m}_1\\) using the provided \\(\\mathtt{offset}\\) . Similarly, \\(\\mathtt{MSTORE}\\) instruction requires, in general, writing bytes in two words. The idea is very similar, but we are provided with a value \\val that we want to write into a specific location of the memory. We will denote by \\(\\mathtt{w}_0\\) and \\(\\mathtt{w}_1\\) the words that arise from \\(\\mathtt{m}_0\\) and \\(\\mathtt{m}_1\\) after the corresponding write. Following our previous example, suppose that we want to write \\[ \\mathtt{val} = \\mathtt{0xe201e6\\dots662b} \\] in the address \\(\\mathtt{0x22}\\) of the byte-addressed Ethereum memory. We are using the same \\(\\mathtt{m}_0\\) and \\(\\mathtt{m}_1\\) (and since we are writting into the same address as before) and they will transition into (see Figure 8 ): \\[ \\mathtt{w}_0 = \\mathtt{0x88d1}\\color{-red!75}\\mathtt{e201e6\\dots}\\color{black},\\quad \\mathtt{w}_1 = \\mathtt{0x}\\color{-red!75} \\mathtt{662b}\\color{black} \\mathtt{ff\\dots54f9}. \\] Figure 8: Schema of MSTORE example. Just as before, the main state machine will need to perform several operations. We will be given an address \\(\\mathtt{addr}\\) , an offset value \\(\\mathtt{offset}\\) and a value to be wrote \\(\\mathtt{val}\\) . Identically as before, the Main SM will be in charge of reading the zkEVM memory to find \\(\\mathtt{m}_0\\) and \\(\\mathtt{m}_1\\) from the given address and offset. Of course, the validity of this query should be performed with a specific Plookup into the Memory SM, just as before. Now, the Main SM can compute \\(\\mathtt{w}_0\\) and \\(\\mathtt{w}_1\\) from all the previous values in a uniquely way. The way of validating that we are providing the correct \\(\\mathtt{w}_0\\) and \\(\\mathtt{w}_1\\) is to perform a Plookup into the Memory Align SM. That is, we will check that the provided values \\(\\mathtt{w}_0\\) and \\(\\mathtt{w}_1\\) are correctly constructed from the provided \\(\\mathtt{val}\\) , \\(\\mathtt{m}_0\\) , \\(\\mathtt{m}_1\\) and \\(\\mathtt{offset}\\) values. Finally, the last opcode \\(\\mathtt{MSTOREE}\\) works similarly, but it only affects one word \\(\\mathtt{m}_0\\) . Moreover, we can only write one byte and hence, only the less significant byte of \\(\\mathtt{val}\\) will be considered into the write. Observe that, in this opcode, \\(\\mathtt{m}_1\\) and \\(\\mathtt{w}_1\\) are unconstrained.","title":"Purpose of the State Machine"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/","text":"[ToC] The Storage State Machine The Storage State Machine (SM) is responsible for all operations on data stored in the zkProver's storage. It receives instructions from the Main State Machine, called Storage Actions . These Storage Actions are typical database operations; Create, Read, Update and Delete (CRUD). The Storage SM is in fact a micro-processor with the firm-ware and the hardware parts. It is in the firmware part of the Storage SM where the logic and rules are set up, expressed in JSON format and stored in a ROM. A novel language, called the zero-knowledge Assembly (zkASM), has been developed by the team. It is a language especially designed to map instructions from the zkProver's Main SM to other state machines, in this case, to the Storage SM's Executor. The Main SM's instructions, or Storage Actions, are parsed to the Storage SM Executor for execution in compliance with the rules and logic specified in the JSON-file. The hardware part uses another novel language, called Polynomial Identity Language (PIL), which is especially designed for the zkProver, because almost all state machines express computations in terms of polynomials. State transitions in state machines must satisfy computation-specific polynomial identities. The Storage SM's Executor carries out all Storage Actions (executes these operations), and also generates committed and constant polynomials. PIL codes, in the zkProver, are used to check correct execution of SM-specific Actions. They therefore take as inputs all committed and constant polynomials. In order to achieve zero-knowledge, all data is stored in the form of Merkle Trees, which means the Storage SM often makes requests of another state machine, the Poseidon SM , to perform hashing (referred to as \\(\\text{POSEIDON}\\) Actions). About this Document This document describes the Storage State Machine and the zkProver's Storage, which the Storage SM interacts with, by either reading or altering data stored in it. This document therefore entails; The basic design of the zkProver's Storage and some preliminaries. i.e., How the Sparse Merkle Trees (SMTs) are built. Explanations of each of the Basic Operations the Storage SM routinely performs. Specific parameters the Storage SM uses, such as, how keys and paths are created, and the two \\(\\text{POSEIDON}\\) Hashes used in the SMTs. As well as, the three main source-codes the Storage SM needs to function effectively. That is, the Storage Assembly code, the Storage Executor (both in C and JavaScript), and the PIL code, for all the polynomial constraints and proving correctness of execution. Introduction A generic state machine is characterised by; sets of states (as inputs) stored in registers, instructions to how the states should transition, and the resultant states (as outputs) stored as new values in the same registers. See Figure 1 below, for a standard state machine. A state machine can be monolithic, where it is a prototype of one particular computation, while others may specialise with certain types of computations. Depending on the computational algorithm, a state machine may have to run through a number of state transitions before producing the desired output. Iterations of the same sequence of operations may be required, to the extend that most common state machines are cyclic by nature. Figure 1: A Generic State Machine The Storage SM performs computations on the key-value data stored in special Merkle Trees, called Sparse Merkle Trees (SMTs). The basic operations it executes are; CREATE, READ, UPDATE and DELETE. In the Storage SM, keys and values are strings of 256 bits and, for convenience, can be interpreted as 256-bit unsigned integers The mechanics of the Storage SM and its basic operations are described in detail later in this document. For now, an example of the UPDATE Operation is given in order to illustrate the various components involved. Storage Design - Preliminaries Storage in the zkProver is designed in such a way that aggregators and verifiers can easily and efficiently interact with stored data. This is data needed for providing zero-knowledge proofs, or verifying state. Data is stored in the form of a special Sparse Merkle Tree (SMT), which is a tree that combines the concept of a Merkle Tree and that of a Patricia tree. What follows is an explanation of how the zkProver storage, as a database, is designed. This design is based on how the Sparse Merkle Trees are constructed and how they store keys and values . Merkle Trees A typical Merkle tree has leaves , branches and a root . A leaf is a node with no child-nodes, while a branch is a node with child-nodes. A root is therefore a node with no parent-node. See Figure 3 below, for an example of how a hash function \\(\\mathbf{H}\\) is used to create a Merkle tree to record eight (8) values; \\(\\text{V}_{\\mathbf{a}}, \\text{V}_{\\mathbf{b}}, \\text{V}_{\\mathbf{c}}, \\text{V}_{\\mathbf{d}}, \\text{V}_{\\mathbf{e}}, \\text{V}_{\\mathbf{f}}, \\text{V}_{\\mathbf{g}}, \\text{V}_{\\mathbf{h}}\\) ; Each leaf is nothing but the hash \\(\\mathbf{H}(\\text{V}_{\\mathbf{i}})\\) of a particular value \\(\\text{V}_{\\mathbf{i}}\\) , where \\(\\mathbf{ i} \\in \\{ \\mathbf{a}, \\mathbf{b}, \\mathbf{c}, \\mathbf{d}, \\mathbf{e}, \\mathbf{f}, \\mathbf{g}, \\mathbf{h} \\}\\) . The branches; \\(\\mathbf{B}_{\\mathbf{ab}} = \\mathbf{H} \\big( \\mathbf{H}(\\text{V}_{\\mathbf{a}})\\| \\mathbf{H}(\\text{V}_{\\mathbf{b}}) \\big)\\) , \\(\\mathbf{B}_{\\mathbf{cd}} = \\mathbf{H} \\big( \\mathbf{H}(\\text{V}_{\\mathbf{c}})\\| \\mathbf{H}(\\text{V}_{\\mathbf{d}}) \\big)\\) , \\(\\mathbf{B}_{\\mathbf{ef}} = \\mathbf{H} \\big( \\mathbf{H}(\\text{V}_{\\mathbf{e}})\\| \\mathbf{H}(\\text{V}_{\\mathbf{f}}) \\big)\\) , \\(\\mathbf{B}_{\\mathbf{gh}} = \\mathbf{H} \\big( \\mathbf{H}(\\text{V}_{\\mathbf{g}})\\| \\mathbf{H}(\\text{V}_{\\mathbf{h}}) \\big)\\) , \\(\\mathbf{B}_{\\mathbf{abcd}} = \\mathbf{H} \\big(\\mathbf{B}_{\\mathbf{ab}}\\| \\mathbf{B}_{\\mathbf{cd}} \\big)\\) and \\(\\mathbf{B}_{\\mathbf{efgh}} = \\mathbf{H} \\big( \\mathbf{B}_{\\mathbf{ef}}\\| \\mathbf{B}_{\\mathbf{gh}} \\big)\\) . The root is \\(\\mathbf{root}_{\\mathbf{a..h}} = \\mathbf{H} \\big(\\mathbf{B}_{\\mathbf{abcd}}\\| \\mathbf{B}_{\\mathbf{efgh}} \\big)\\) . Figure 3: A Merkle Tree Example Leaves that share a parent-node are called siblings . The same terminology applies to branches. For example, \\(\\mathbf{B}_{\\mathbf{ab}}\\) and \\(\\mathbf{B}_{\\mathbf{cd}}\\) are siblings because they are branches of the same parent, \\(\\mathbf{B}_{\\mathbf{abcd}}\\) . Similarly, \\(\\mathbf{B}_{\\mathbf{efgh}}\\) and \\(\\mathbf{B}_{\\mathbf{abcd}}\\) are siblings. Using Keys To Navigate A Merkle Tree Keys are used to navigate from the root to the leaves (and backwards). Reading the key starting from the left to the right , and when traversing the tree from the root downwards , a zero-key-bit \" \\(0\\) \" means \" follow the edge going to the left \", a key-bit \" \\(1\\) \" means \" follow the edge going to the right \". Consider the tree in Figure 1 above, as an example. Suppose one is given the key-value pair \\(( K_{\\mathbf{d}} , V_{\\mathbf{d}})\\) , where \\(K_{\\mathbf{d}} = 10010110\\) . The leaf \\(L_{\\mathbf{d}}\\) , storing the value \\(V_{\\mathbf{d}}\\) , is located uniquely by using the key, \\(K_{\\mathbf{d} } = 10010110\\) , as follows; Read the least-significant bit of \\(K_{\\mathbf{d}}\\) , which is \\(0\\) , hence traverse the tree to the left, and reach \\(\\mathbf{B_{abcd}}\\) . Then read the second significant key-bit, which is \" \\(1\\) \" in this case. So take the edge going to the right, reaching \\(\\mathbf{B_{cd}}\\) . Again, read the next key-bit, which is \" \\(1\\) \", hence follow the edge going to the right, reaching the leaf \\(\\mathbf{H}( V_{\\mathbf{d}} )\\) . Since \\(\\mathbf{H}( V_{\\mathbf{d}})\\) is a leaf and not a branch, and the navigation was correctly done with respect to the given key \\(K_{\\mathbf{d}}\\) , the \\(\\mathbf{H}( V_{\\mathbf{d}})\\) must be the leaf storing the value \\(V_{\\mathbf{d}}\\) . One can similarly \"climb\" the tree, going in the reverse direction, by using the key-bits of the given key in the reverse order. i.e., Starting with the last key-bit used to reach the leaf and ending with the least-significant bit of the key. The tree-address of the value \\(V_{\\mathbf{x}}\\) , herein refers to the position of the leaf \\(L_{\\mathbf{x}} := \\mathbf{H}( V_{\\mathbf{x}})\\) , denoted by the key-bits used to reach \\(L_{\\mathbf{d}}\\) but in the reverse order. In the above example (i.e., The tree in Figure 1), the tree-address of \\(V_{\\mathbf{d}}\\) is 011 . A Merkle Proof Example Merkle Trees can be used as commitment schemes. Here's an example that follows the (key,value)-pair approach used in the zkProver. Consider the Merkle Tree shown in Figure 3 above. If the prover has committed to a value \\(\\text{V}_{\\mathbf{f}}\\) by appending a new leaf \\(\\mathbf{H}(\\text{V}_{\\mathbf{f}})\\) to the Merkle Tree as in Figure 3 , he must then avail the following information, to enable verification of his claim; The Merkle root \\(\\mathbf{root}_{\\mathbf{a..h}}\\) , The value \\(\\text{V}_{\\mathbf{f}}\\) , The siblings; \\(\\mathbf{H}(\\text{V}_{\\mathbf{e}})\\) , \\(\\mathbf{B}_{\\mathbf{gh}}\\) and \\(\\mathbf{B}_{\\mathbf{abcd}}\\) . Instead of searching through all hash values stored in the tree, the verifier uses only a few hash values of relevant siblings. That is, three (3) in this case. The verifier then checks the prover's claim by computing the Merkle root as follows; \u200b (a) He computes \\(\\mathbf{H}(\\text{V}_{\\mathbf{f}})\\) , which is the hash of the value \\(\\text{V}_{\\mathbf{f}}\\) . \u200b (b) Then uses the sibling \\(\\mathbf{H}(\\text{V}_{\\mathbf{e}})\\) to compute \\(\\mathbf{H} \\big( \\mathbf{H}(\\text{V}_{\\mathbf{e}})\\|\\mathbf{H}(\\text{V}_{\\mathbf{f}}) \\big) =: \\tilde{ \\mathbf{B}}_{\\mathbf{ef}}\\) , which should be the same as the branch node \\(\\mathbf{B}_{\\mathbf{ef}}\\) . ( Note. The symbol, tilde \" \\(\\tilde{ }\\) \", is used throughout the document to indicate that the computed value, \\(\\tilde{\\Box}\\) , still needs to be checked, or tested to be true.) \u200b (c) Next, he computes \\(\\mathbf{H} \\big( \\tilde{ \\mathbf{B}}_{\\mathbf{ef}}\\|\\mathbf{B}_{\\mathbf{gh}} \\big) =: \\tilde{ \\mathbf{B}}_{\\mathbf{efgh}}\\) , corresponding to the branch node \\(\\mathbf{B}_{\\mathbf{efgh}}\\) . \u200b (d) Now, uses \\(\\mathbf{H} \\big( \\mathbf{B}_{\\mathbf{abcd}}\\| \\tilde{ \\mathbf{B}}_{\\mathbf{efgh}} \\big) =: \\tilde{ \\mathbf{root}}_{\\mathbf{a..h}}\\) . The Merkle proof is concluded by checking whether \\(\\tilde{ \\mathbf{root}}_{\\mathbf{a\\dots h}}\\) equals to the publicly known root \\(\\mathbf{root}_{\\mathbf{a..h}}\\) . Building Simplified Binary Sparse Merkle Trees Consider key-value pair based binary Sparse Merkle Trees (SMTs). The focus here is on explaining how to build an SMT that represents a given set of key-value pairs. And, for simplicity sake, key-lengths of 8 bits are assumed. A NULL or empty SMT has a zero root. That is, no key and no value recorded. Similarly, a zero node or NULL node refers to a node that carry no value. A Binary SMT With One Key-Value Pair A binary SMT with a single key-value pair \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) , is built as follows. Suppose that the key, \\(K_{\\mathbf{a}} = 11010110\\) . In order to build a binary SMT with this single key-value \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) , (a) One computes the hash \\(\\mathbf{H}( \\text{V}_{\\mathbf{a}})\\) of the value \\(\\text{V}_{\\mathbf{a}}\\) , (b) Sets the leaf \\(\\mathbf{L}_{\\mathbf{a}} := \\mathbf{H}( \\text{V}_{\\mathbf{a}})\\) , (c) Sets the sibling leaf as a NULL leaf, simply represented as \" \\(\\mathbf{0}\\) \", (d) Computes the root as \\(\\mathbf{root}_{a0} = \\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{0} )\\) , with the leaf \\(\\mathbf{L}_{\\mathbf{a}}\\) on the left because the \\(\\text{lsb}(K_{\\mathbf{a}}) = 0\\) . That is, between the two edges leading up to the root, the leaf \\(\\mathbf{L}_{\\mathbf{a}}\\) is on the left edge, while the NULL leaf \" \\(\\mathbf{0}\\) \" is on the right. See, Figure 4 below, for the SMT representing the single key-value pair \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) , where \\(K_{\\mathbf{a}} = 11010110\\) . Figure 4: A Single key-value pair SMT Note that the last nodes in binary SMT branches are generally either leaves or zero-nodes. In the case where the least-significant bit, lsb of \\(K_{\\mathbf{a}}\\) is \\(1\\) , the SMT with a single key-value pair \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) would be a mirror image of what is seen in Figure 3. And its root, \\(\\mathbf{root}_{0a} = \\mathbf{H}( \\mathbf{0}\\| \\mathbf{L}_{\\mathbf{a}} ) \\neq \\mathbf{root}_{a0}\\) because \\(\\mathbf{H}\\) is a collision-resistant hash function. This example also explains why we need a zero node. Since all trees used in our design are binary SMTs, a zero node is used as a default sibling for computing the parent node. This helps to differentiate between roots (also between parent nodes) because a root node actually identifies an SMT. Therefore, it is crucial to distinguish between \\(\\mathbf{root}_{a0} = \\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{0} )\\) and \\(\\mathbf{root}_{0a} = \\mathbf{H}( \\mathbf{0}\\| \\mathbf{L}_{\\mathbf{a}})\\) because they represent two distinct trees. Binary SMTs With Two Key-Value Pairs Consider now SMTs with two key-value pairs , \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) and \\((K_{\\mathbf{b}}, \\text{V}_{\\mathbf{b}})\\) . There are three distinct cases of how corresponding SMTs can be built, each determined by the keys, \\(K_{\\mathbf{a}}\\) and \\(K_{\\mathbf{b}}\\) . Case 1 : The keys are such that the \\(\\text{lsb}(K_{\\mathbf{a}}) = 0\\) and the \\(\\text{lsb}(K_{\\mathbf{b}}) = 1\\) . Suppose that the keys are given as, \\(K_{\\mathbf{a}} = 11010110\\) and \\(K_{\\mathbf{b}} = 11010101\\) . To build a binary SMT with this two key-values, \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) and \\((K_{\\mathbf{b}}, \\text{V}_{\\mathbf{b}})\\) , (a) One computes the hashes, \\(\\mathbf{H}(\\text{V}_{\\mathbf{a}})\\) and \\(\\mathbf{H}( \\text{V}_{\\mathbf{b}})\\) of the values, \\(\\text{V}_{\\mathbf{a}}\\) and \\(\\text{V}_{\\mathbf{b}}\\) , respectively, (b) Sets the leaves, \\(\\mathbf{L}_{\\mathbf{a}} := \\mathbf{H}( \\text{V}_{\\mathbf{a}})\\) and \\(\\mathbf{L}_{\\mathbf{b}} := \\mathbf{H}( \\text{V}_{\\mathbf{b}})\\) , (c) Checks if the \\(\\text{lsb}(K_{\\mathbf{a}})\\) differs from the \\(\\text{lsb}(K_{\\mathbf{b}})\\) , (d) Since the \\(\\text{lsb}(K_{\\mathbf{a}}) = 0\\) and the \\(\\text{lsb}(K_{\\mathbf{b}}) = 1\\) , it means the two leaves can be siblings , (e) One can then compute the root as, \\(\\mathbf{root}_{\\mathbf{ab}} = \\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{L}_{\\mathbf{b}})\\) . \u200b Note that, the leaf \\(\\mathbf{L}_{\\mathbf{a}}\\) is on the left because the \\(\\text{lsb}(K_{\\mathbf{a}}) = 0\\) , but \\(\\mathbf{L}_{\\mathbf{b}}\\) is on the right because the \\(\\text{lsb}(K_{\\mathbf{b}}) = 1\\) . That is, between the two edges leading up to the \\(\\mathbf{root}_{\\mathbf{ab}}\\) , the leaf \\(\\mathbf{L}_{\\mathbf{a}}\\) must be on the edge from the left, while \\(\\mathbf{L}_{\\mathbf{b}}\\) is on the edge from the right. See, Figure 5(a) below, for the SMT representing the two key-value pairs \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) and \\((K_{\\mathbf{b}}, \\text{V}_{\\mathbf{b}})\\) , where \\(K_{\\mathbf{a}} = 11010110\\) and \\(K_{\\mathbf{b}} = 11010101\\) . Figure 5(a): Two key-value pairs SMT - Case 1 Case 2 : Both keys end with the same key-bit. That is, the \\(\\text{lsb}(K_{\\mathbf{a}}) = \\text{lsb}(K_{\\mathbf{b}})\\) , but their second least-significant bits differ. Suppose that the two keys are given as, \\(K_{\\mathbf{a}} = 11010100\\) and \\(K_{\\mathbf{b}} = 11010110\\) . To build a binary SMT with this two key-values, \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) and \\((K_{\\mathbf{b}}, \\text{V}_{\\mathbf{b}})\\) ; (a) One computes the hashes, \\(\\mathbf{H}(\\text{V}_{\\mathbf{a}})\\) and \\(\\mathbf{H}( \\text{V}_{\\mathbf{b}})\\) of the values, \\(\\text{V}_{\\mathbf{a}}\\) and \\(\\text{V}_{\\mathbf{b}}\\) , respectively. (b) Sets the leaves, \\(\\mathbf{L}_{\\mathbf{a}} := \\mathbf{H}( \\text{V}_{\\mathbf{a}})\\) and \\(\\mathbf{L}_{\\mathbf{b}} := \\mathbf{H}( \\text{V}_{\\mathbf{b}})\\) . (c) Checks if the \\(\\text{lsb}(K_{\\mathbf{a}})\\) differs from the \\(\\text{lsb}(K_{\\mathbf{b}})\\) . Since the \\(\\text{lsb}(K_{\\mathbf{a}}) = 0\\) and the \\(\\text{lsb}(K_{\\mathbf{b}}) = 0\\) , it means the two leaves cannot be siblings at this position because it would otherwise mean they share the same tree-address 0 , which is not allowed. (d) One, therefore, continues to check if the second least-significant bits of \\(K_{\\mathbf{a}}\\) and \\(K_{\\mathbf{b}}\\) differ. Since the \\(\\text{second lsb}(K_{\\mathbf{a}}) = 0\\) and the \\(\\text{second lsb}(K_{\\mathbf{b}}) = 1\\) , it means the two leaves \\(\\mathbf{L}_{\\mathbf{a}}\\) and \\(\\mathbf{L}_{\\mathbf{b}}\\) can be siblings at their respective tree-addresses, 00 and 10 . (e) Next is to compute the hash \\(\\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{L}_{\\mathbf{b}})\\) and set it as the branch \\(\\mathbf{B}_{\\mathbf{ab}} := \\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{L}_{\\mathbf{b}})\\) at the tree-address 0 . Note that the leaf \\(\\mathbf{L}_{\\mathbf{a}}\\) is on the left because the \\(\\text{second lsb}(K_{\\mathbf{a}}) = 0\\) , while \\(\\mathbf{L}_{\\mathbf{b}}\\) is on the right because the \\(\\text{second lsb}(K_{\\mathbf{b}}) = 1\\) . (f) The branch \\(\\mathbf{B}_{\\mathbf{ab}} := \\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{L}_{\\mathbf{b}})\\) needs a sibling. Since all the values, \\(\\text{V}_{\\mathbf{a}}\\) and \\(\\text{V}_{\\mathbf{b}}\\) , are already represented in the tree at \\(\\mathbf{L}_{\\mathbf{a}}\\) and \\(\\mathbf{L}_{\\mathbf{b}}\\) , respectively, one therefore sets a NULL leaf \" \\(\\mathbf{0}\\) \" as the sibling leaf to \\(\\mathbf{B}_{\\mathbf{ab}}\\) . (g) As a result, it is possible to compute the root as, \\(\\mathbf{root}_{\\mathbf{ab0}} = \\mathbf{H}(\\mathbf{B}_{\\mathbf{ab}} \\| \\mathbf{0})\\) . Note that, the branch \\(\\mathbf{B}_{\\mathbf{ab}}\\) is on the left because the \\(\\text{lsb}(K_{\\mathbf{a}}) = 0\\) , and \\(\\mathbf{0}\\) must therefore be on the right. That is, between the two edges leading up to the \\(\\mathbf{root}_{\\mathbf{ab0}}\\) , the branch \\(\\mathbf{B}_{\\mathbf{ab}}\\) must be on the edge from the left, while \\(\\mathbf{0}\\) is on the edge from the right. See, Figure 5(b) below, depicting the SMT representing the two key-value pairs \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) and \\((K_{\\mathbf{b}}, \\text{V}_{\\mathbf{b}})\\) , where \\(K_{\\mathbf{a}} = 11010100\\) and \\(K_{\\mathbf{b}} = 11010110\\) . Figure 5(b): Two key-value pairs SMT - Case 2 Case 3 : The first two least-significant bits of both keys are the same, but their third least-significant bits differ. Suppose that the two keys are given as, \\(K_{\\mathbf{a}} = 11011000\\) and \\(K_{\\mathbf{b}} = 10010100\\) . The process for building a binary SMT with this two key-values, \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) and \\((K_{\\mathbf{b}}, \\text{V}_{\\mathbf{b}})\\) is the same as in Case 2; (a) One computes the hashes, \\(\\mathbf{H}(\\text{V}_{\\mathbf{a}})\\) and \\(\\mathbf{H}( \\text{V}_{\\mathbf{b}})\\) of the values, \\(\\text{V}_{\\mathbf{a}}\\) and \\(\\text{V}_{\\mathbf{b}}\\) , respectively. (b) Sets the leaves, \\(\\mathbf{L}_{\\mathbf{a}} := \\mathbf{H}( \\text{V}_{\\mathbf{a}})\\) and \\(\\mathbf{L}_{\\mathbf{b}} := \\mathbf{H}( \\text{V}_{\\mathbf{b}})\\) . (c) Checks if the \\(\\text{lsb}(K_{\\mathbf{a}})\\) differs from the \\(\\text{lsb}(K_{\\mathbf{b}})\\) . Since the \\(\\text{lsb}(K_{\\mathbf{a}}) = 0\\) and the \\(\\text{lsb}(K_{\\mathbf{b}}) = 0\\) , it means the two leaves cannot be siblings at this position as it would otherwise mean they share the same tree-address 0 , which is not allowed. (d) Next verifier coninues to check if the second least-significant bits of \\(K_{\\mathbf{a}}\\) and \\(K_{\\mathbf{b}}\\) differ. Since the \\(\\text{second lsb}(K_{\\mathbf{a}}) = 0\\) and the \\(\\text{second lsb}(K_{\\mathbf{b}}) = 0\\) , it means the two leaves cannot be siblings at this position, because it would otherwise mean they share the same tree-address 00 , which is not allowed. (e) Once again he checks if the third least-significant bits of \\(K_{\\mathbf{a}}\\) and \\(K_{\\mathbf{b}}\\) differ. Since the \\(\\text{third lsb}(K_{\\mathbf{a}}) = 0\\) and the \\(\\text{third lsb}(K_{\\mathbf{b}}) = 1\\) , it means the two leaves \\(\\mathbf{L}_{\\mathbf{a}}\\) and \\(\\mathbf{L}_{\\mathbf{b}}\\) can be siblings at their respective tree-addresses, 000 and 100 . (f) One then computes the hash \\(\\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{L}_{\\mathbf{b}})\\) , and sets it as the branch \\(\\mathbf{B}_{\\mathbf{ab}} := \\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{L}_{\\mathbf{b}})\\) at the tree-address 00 . The leaf \\(\\mathbf{L}_{\\mathbf{a}}\\) is on the left because the third \\(\\text{lsb}(K_{\\mathbf{a}}) = 0\\) , while \\(\\mathbf{L}_{\\mathbf{b}}\\) is on the right because the third \\(\\text{lsb}(K_{\\mathbf{b}}) = 1\\) . (g) The branch \\(\\mathbf{B}_{\\mathbf{ab}} := \\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{L}_{\\mathbf{b}})\\) needs a sibling. Since all the values, \\(\\text{V}_{\\mathbf{a}}\\) and \\(\\text{V}_{\\mathbf{b}}\\) , are already represented in the tree at \\(\\mathbf{L}_{\\mathbf{a}}\\) and \\(\\mathbf{L}_{\\mathbf{b}}\\) , respectively, one therefore sets a NULL leaf \" \\(\\mathbf{0}\\) \" as the sibling leaf to \\(\\mathbf{B}_{\\mathbf{ab}}\\) . (h) One can now compute the hash \\(\\mathbf{H}(\\mathbf{B}_{\\mathbf{ab}} \\| \\mathbf{0})\\) , and set it as the branch \\(\\mathbf{B}_{\\mathbf{ab0}} := \\mathbf{H}(\\mathbf{B}_{\\mathbf{ab}} \\| \\mathbf{0})\\) at the tree-address 0 . The hash is computed with the branch \\(\\mathbf{B}_{\\mathbf{ab}}\\) on the left because the second lsb of both keys, \\(K_{\\mathbf{a}}\\) and \\(K_{\\mathbf{b}}\\) , equals \\(0\\) . Therefore the NULL leaf \" \\(\\mathbf{0}\\) \" must be on the right as an argument to the hash. (i) The branch \\(\\mathbf{B}_{\\mathbf{ab0}} := \\mathbf{H}(\\mathbf{B}_{\\mathbf{ab}} \\| \\mathbf{0})\\) also needs a sibling. For the same reason given above, one sets a NULL leaf \" \\(\\mathbf{0}\\) \" as the sibling leaf to \\(\\mathbf{B}_{\\mathbf{ab0}}\\) . (j) Now, one is able to compute the root as, \\(\\mathbf{root}_{\\mathbf{ab00}} = \\mathbf{H}(\\mathbf{B}_{\\mathbf{ab0}} \\| \\mathbf{0})\\) . Note that the hash is computed with the branch \\(\\mathbf{B}_{\\mathbf{ab0}}\\) on the left because the lsb of both keys, \\(K_{\\mathbf{a}}\\) and \\(K_{\\mathbf{b}}\\) , equals \\(0\\) . That is, between the two edges leading up to the \\(\\mathbf{root}_{\\mathbf{ab00}}\\) , the branch \\(\\mathbf{B}_{\\mathbf{ab0}}\\) must be on the edge from the left, while \" \\(\\mathbf{0}\\) \" is on the edge from the right. See, Figure 5(c) below, depicting the SMT representing the two key-value pairs \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) and \\((K_{\\mathbf{b}}, \\text{V}_{\\mathbf{b}})\\) , where \\(K_{\\mathbf{a}} = 11011000\\) and \\(K_{\\mathbf{b}} = 10010100\\) . Figure 5(c): Two key-value pairs SMT - Case 3 There are several other SMTs of two key-value pairs \\((K_{\\mathbf{x}}, \\text{V}_{\\mathbf{x}})\\) and \\((K_{\\mathbf{z}}, \\text{V}_{\\mathbf{z}})\\) that can be constructed depending on how long are the strings of the common least-significant bits between \\(K_{\\mathbf{x}}\\) and \\(K_{\\mathbf{z}}\\) . In general, when building an SMT, leaves of key-value pairs with the same least-significant key-bits share the same \"navigational path\" only until any of the corresponding key-bits differ. These common strings of key-bits dictate where the leaf storing the corresponding value is located in the tree. A Few More Concepts About Binary SMTs In here are a few more concepts needed in understanding our specific design of the zkProver storage using binary SMTs. These concepts also help in elucidating how keys influence the shape of binary SMTs. First is the level of a leaf. The level of a leaf , \\(\\mathbf{L}_{\\mathbf{x}}\\) , in a binary SMT is defined as the number of edges one traverses when navigating from the root to the leaf. Denote the level of the leaf \\(\\mathbf{L_x}\\) by \\(\\text{lvl}(\\mathbf{L_x})\\) . Example 1. Leaf Levels Consider Figure 6 below, for an SMT storing seven (7) key-value pairs, built by following the principles explained in the foregoing subsection; \\[\\begin{aligned} (\\mathbf{K}_{\\mathbf{a}} , V_{\\mathbf{a}}),\\ \\ (\\mathbf{K}_{\\mathbf{b}} , V_{\\mathbf{b}}),\\ \\ (\\mathbf{K}_{\\mathbf{c}} , V_{\\mathbf{c}}),\\ \\ (\\mathbf{K}_{\\mathbf{c}}, V_{\\mathbf{c}}),\\\\ (\\mathbf{K}_{\\mathbf{d}}, V_{\\mathbf{d}}),\\ \\ (\\mathbf{K}_{\\mathbf{e}}, V_{\\mathbf{e}}),\\ \\ (\\mathbf{K}_{\\mathbf{f}}, V_{\\mathbf{f}})\\ \\ {\\text{and}}\\ \\ (\\mathbf{K}_{\\mathbf{g}} , V_{\\mathbf{g}}) \\end{aligned}\\] where the keys are, \\[\\begin{aligned} K_{\\mathbf{a}} = 10101100, K_{\\mathbf{b}} = 10010010, K_{\\mathbf{c}} = 10001010, &K_{\\mathbf{d}} = 11100110,\\\\ K_{\\mathbf{e}} = 11110101, K_{\\mathbf{f}} = 10001011, K_{\\mathbf{g}} = 00011111. \\end{aligned}\\] The leaf levels are as follows; \\(\\text{lvl}(\\mathbf{L}_{\\mathbf{a}}) = 2\\) , \\(\\text{lvl}(\\mathbf{L}_{\\mathbf{b}}) = 4\\) , \\(\\text{lvl}(\\mathbf{L}_{\\mathbf{c}}) = 4\\) , \\(\\text{lvl}(\\mathbf{L}_{\\mathbf{d}}) = 3\\) , \\(\\text{lvl}(\\mathbf{L}_{\\mathbf{e}}) = 2\\) , \\(\\text{lvl}(\\mathbf{L}_{\\mathbf{f}}) = 3\\) and \\(\\text{lvl}(\\mathbf{L}_{\\mathbf{g}}) = 3\\) . Figure 6: An SMT of 7 key-value pairs As illustrated, in the above subsections, keys basically determine the shape of the SMT. They dictate where respective leaves must be placed when building the SMT. The main determining factor of the SMT shape is in fact the common key-bits among the keys. For instance, the reason why the leaves \\(\\mathbf{L}_{\\mathbf{b}}\\) and \\(\\mathbf{L}_{\\mathbf{c}}\\) have the largest leaf level \\(4\\) is because the two leaves have the longest string of common key-bits \" \\(010\\) \" in the SMT of Figure 6 above. This explains why different leaves in SMTs can have different levels. The height of a Merkle Tree refers to the largest number of edges traversed when navigating from the root to any leaf. Since all leaves are of the same level in Merkle Trees, the concept of a height coincide with that of the level of a leaf for Merkle Trees. But this is not the case for SMTs. Since leaf levels differ from one leaf to another in SMTs, the height of an SMT is not the same as the leaf level. Rather, the height of an SMT is defined as the largest leaf level among the various leaf levels of leaves on the SMT. For instance, the height of the SMT depicted in Figure 6 above, is \\(4\\) . Now, since all keys have the same fixed key-length, they not only influence SMT leaf levels and shapes, but also restrict SMT heights to the fixed key-length. The maximum height of an SMT is the maximum key-length imposed on all keys. The Remaining Key In a general Sparse Merkle Tree (SMT) values are stored at their respective leaf-nodes. But a leaf node \\(\\mathbf{L}_{\\mathbf{x}}\\) not only stores a value, \\(V_{\\mathbf{x}}\\) , but also the key-bits that are left unused in the navigation from the root to \\(\\mathbf{L}_{\\mathbf{x}}\\) . These unused key-bits are called the remaining key , and are denoted by \\(\\text{RK}_{\\mathbf{x}}\\) for the leaf node \\(\\mathbf{L}_{\\mathbf{x}}\\) . Example 2. Remaining Keys Consider again the SMT of the 7 key-value pairs depicted in Figure 6 above. The remaining keys of each of the 7 leaves in the SMT are as follows; \\(\\text{RK}_{\\mathbf{a}} = 110101\\) , \\(\\text{RK}_{\\mathbf{b}} = 1001\\) , \\(\\text{RK}_{\\mathbf{c}} = 0001\\) , \\(\\text{RK}_{\\mathbf{d}} = 00111\\) , \\(\\text{RK}_{\\mathbf{e}} = 101111\\) , \\(\\text{RK}_{\\mathbf{f}} = 10001\\) and \\(\\text{RK}_{\\mathbf{g}} = 11000\\) . The Fake-Leaf Attack Note that the above simplified design of binary SMTs, based on key-value pairs, presents some problems. The characteristic of binary SMTs having leaves at different levels can be problematic to verifiers, especially when carrying out a simple Merkle proof. Scenario A: Fake SMT Leaf What if the verifier is presented with a fake leaf? Consider Figure 7 below, showing a binary SMT with a branch \\(\\mathbf{{B}_{ab}}\\) and its children \\(\\mathbf{L_{a}}\\) and \\(\\mathbf{L_{b}}\\) hidden from the verifier's sight. That is, suppose the verifier is provided with the following information; The key-value \\((K_{\\mathbf{fk}}, V_\\mathbf{{fk}})\\) , where \\(K_{\\mathbf{fk}} = 11010100\\) and \\(V_{\\mathbf{fk}} = \\mathbf{L_{a}} \\| \\mathbf{L_{b}}\\) . The root \\(\\mathbf{{root}_{ab..f}}\\) , the number of levels to root, and the siblings \\(\\mathbf{{S}_{\\mathbf{cd}}}\\) and \\(\\mathbf{{S}_{\\mathbf{ef}}}\\) . That is, the Attacker claims that some \\(V_{\\mathbf{fk}}\\) is stored at \\(\\mathbf{L_{fk}} := \\mathbf{{B}_{ab}}\\) . Verifier is unaware that \\(V_{\\mathbf{fk}}\\) is in fact the concatenated value of the hidden real leaves, \\(\\mathbf{L_{a}}\\) and \\(\\mathbf{L_{b}}\\) , that are children of the supposed leaf \\(\\mathbf{L_{fk}}\\) . i.e., Verifier does not know that leaf \\(\\mathbf{L_{fk}}\\) is in fact a branch. Figure 7: MPT - Fake Leaf Attack So then, the verifier being unaware that \\(\\mathbf{L_{fk}}\\) is not a properly constructed leaf, starts verification as follows; He uses the key \\(K_{\\mathbf{fk}}\\) to navigate the tree until locating the supposed leaf \\(\\mathbf{L_{fk}}\\) . He computes \\(\\mathbf{H}(V_{\\mathbf{fk}})\\) and sets it as \\(\\tilde{\\mathbf{L}}_{\\mathbf{fk}} := \\mathbf{H}(V_{\\mathbf{fk}})\\) . Then takes the sibling \\(\\mathbf{{S}_{\\mathbf{cd}}}\\) and calculates \\(\\tilde{ \\mathbf{B}}_{\\mathbf{fkcd}} = \\mathbf{H} \\big( \\tilde{\\mathbf{L}}_{\\mathbf{fk}} \\| \\mathbf{S}_{\\mathbf{cd}} \\big)\\) . And then, uses \\(\\tilde{ \\mathbf{B}}_{\\mathbf{fkcd}}\\) to compute the root, \\(\\tilde{ \\mathbf{root}}_{\\mathbf{ab..f}} = \\mathbf{H} \\big( \\tilde{ \\mathbf{B}}_{\\mathbf{fkcd}}\\| \\mathbf{S}_{\\mathbf{ef}} \\big)\\) . The question is: \"Does the fake leaf \\(\\mathbf{L_{fk}}\\) pass the verifier's Merkle proof or not?\" Or, equivalently: \"Is \\(\\tilde{ \\mathbf{root}}_{\\mathbf{ab..f}}\\) equal to \\(\\mathbf{root}_{\\mathbf{ab..f}}\\) ?\" Since the actual branch \\(\\mathbf{{B}_{ab}}\\) is by construction the hash, \\(\\mathbf{H}(\\mathbf{L_{a}} \\| \\mathbf{L_{b}})\\) , then \\(\\mathbf{{B}_{ab}} = \\tilde{\\mathbf{L}}_{\\mathbf{fk}}\\) . The parent branch \\({\\mathbf{B}}_{\\mathbf{abcd}}\\) also, being constructed as the hash, \\(\\mathbf{H} \\big( \\mathbf{B}_{\\mathbf{ab}}\\| { \\mathbf{S}}_{\\mathbf{cd}} \\big)\\) , should be equal to \\(\\mathbf{H} \\big( \\tilde{\\mathbf{L}}_{\\mathbf{fk}} \\| \\mathbf{S}_{\\mathbf{cd}} \\big) = \\tilde{ \\mathbf{B}}_{\\mathbf{fkcd}}\\) . As a result, \\(\\mathbf{root}_{\\mathbf{ab..f}} = \\mathbf{H} \\big( {\\mathbf{B}}_{\\mathbf{abcd}} \\| \\mathbf{S}_{\\mathbf{ef}} \\big) = \\mathbf{H} \\big( \\tilde{ \\mathbf{B}}_{\\mathbf{fkcd}}\\| \\mathbf{S}_{\\mathbf{ef}} \\big) = \\tilde{ \\mathbf{root}}_{\\mathbf{ab..f}}\\) . Therefore, the fake leaf \\(\\mathbf{L_{fk}}\\) passes the Merkle proof. Solution To The Fake-Leaf Attack In order to circumvent the Fake-Leaf Attack we modify how the binary SMTs are built. Here's the trick : When building binary SMTs, differentiate between how leaves are hashed and how branches are hashed. That is, use two different hash functions; one hash function to hash leaves, denote it by \\(\\mathbf{H}_{\\mathbf{leaf}}\\) , and the other function for hashing non-leaf nodes, denote it by \\(\\mathbf{H}_{\\mathbf{noleaf}}\\) . How does this prevent the Fake-Leaf Attack? Reconsider now, the Scenario A, given above. Recall that the Attacker provides the following; The key-value \\((K_{\\mathbf{fk}}, V_\\mathbf{{fk}})\\) , where \\(K_{\\mathbf{fk}} = 11010100\\) and \\(V_{\\mathbf{fk}} = \\mathbf{L_{a}} \\| \\mathbf{L_{b}}\\) . The root $ \\mathbf{{root}_{ab..f}}$ , the number of levels to root, and the siblings \\(\\mathbf{{S}_{\\mathbf{cd}}}\\) and \\(\\mathbf{{S}_{\\mathbf{ef}}}\\) . The verifier suspecting no foul, uses \\(K_{\\mathbf{fk}} = 11010100\\) to navigate the tree until he finds \\(V_{\\mathbf{fk}}\\) stored at \\(\\mathbf{L_{fk}} := \\mathbf{{B}_{ab}}\\) . He subsequently starts the Merkle proof by hashing the value \\(\\tilde{V}_{\\mathbf{fk}}\\) stored at the located leaf. Since, this computation amounts to forming a leaf, he uses the leaf-hash function, \\(\\mathbf{H}_{\\mathbf{leaf}}\\) . He then sets \\(\\tilde{\\mathbf{L}}_{\\mathbf{fk}} := \\mathbf{H}_{\\mathbf{leaf}} \\big( V_{\\mathbf{fk}} \\big) = \\mathbf{H}_{\\mathbf{leaf}} \\big( \\mathbf{L_{a}} \\| \\mathbf{L_{b}} \\big)\\) . And further computes \\(\\tilde{ \\mathbf{B}}_{\\mathbf{fkcd}} = \\mathbf{H}_{\\mathbf{noleaf}} \\big( \\tilde{\\mathbf{L}}_{\\mathbf{fk}} \\| \\mathbf{S}_{\\mathbf{cd}} \\big)\\) . Again, calculates the root, \\(\\tilde{ \\mathbf{root}}_{\\mathbf{ab..f}} = \\mathbf{H}_{\\mathbf{noleaf}} \\big( \\tilde{ \\mathbf{B}}_{\\mathbf{fkcd}}\\| \\mathbf{S}_{\\mathbf{ef}} \\big)\\) . But the actual branch \\(\\mathbf{{B}_{ab}}\\) was constructed with the no-leaf-hash function, \\(\\mathbf{H}_{\\mathbf{noleaf}}\\) . That is, \\[\\begin{aligned} \\mathbf{{B}_{ab}} = \\mathbf{H}_{\\mathbf{noleaf}} (\\mathbf{L_{a}} \\| \\mathbf{L_{b}}) \\neq \\mathbf{H}_{\\mathbf{leaf}} \\big(\\mathbf{L_{a}} \\| \\mathbf{L_{b}} \\big) = \\tilde{\\mathbf{L}}_{\\mathbf{fk}}. \\end{aligned}\\] The parent branch \\({\\mathbf{B}}_{\\mathbf{abcd}}\\) also, was constructed as, \\({\\mathbf{B}}_{\\mathbf{abcd}} = \\mathbf{H}_{\\mathbf{noleaf}} \\big( \\mathbf{B}_{\\mathbf{ab}}\\| { \\mathbf{S}}_{\\mathbf{cd}} \\big)\\) . Since the hash functions used are collision-resistant, \\({\\mathbf{B}}_{\\mathbf{abcd}}\\) cannot be equal to \\(\\mathbf{H}_{\\mathbf{noleaf}} \\big( \\tilde{\\mathbf{L}}_{\\mathbf{fk}} \\| \\mathbf{S}_{\\mathbf{cd}} \\big) = \\tilde{ \\mathbf{B}}_{\\mathbf{fkcd}}\\) . Consequently, \\(\\mathbf{root}_{\\mathbf{ab..f}} \\neq \\tilde{ \\mathbf{root}}_{\\mathbf{ab..f}}\\) . Therefore, the Merkle Proof fails. Non-Binding Key-Value Pairs Whenever the verifier needs to check inclusion of the given key-value pair \\((K_{\\mathbf{x}}, \\text{V}_{\\mathbf{x}})\\) in a binary SMT identified by the \\(\\mathbf{{root}_{a..x}}\\) , he first navigates the SMT in order to locate the leaf \\(\\mathbf{{L}_{x}}\\) storing \\(\\text{V}_{\\mathbf{x}}\\) , and thereafter carries out two computations. Both computations involve climbing the tree from the located leaf \\(\\mathbf{{L}_{x}}\\) back to the root, \\(\\mathbf{{root}_{a..x}}\\) . And the two computations are; Checking correctness of the key \\(K_{\\mathbf{x}}\\) . That is, verifier takes the Remaining Key, \\(\\text{RK}_{\\mathbf{x}}\\) , and reconstructs the key \\(K_{\\mathbf{x}}\\) by concatenating the key bits used to navigate to \\(\\mathbf{{L}_{x}}\\) from \\(\\mathbf{{root}_{a..x}}\\) , in the reverse order. Suppose the number of levels to root is 3, and the least-significant bits used for navigation are \\(\\text{kb}_\\mathbf{2}\\) , \\(\\text{kb}_\\mathbf{1}\\) and \\(\\text{kb}_\\mathbf{0}\\) . In order to check key-correctness, verifier the remaining key \\(\\text{RK}\\) and, (a) Concatenates \\(\\text{kb}_\\mathbf{2}\\) and gets \\(\\text{ } \\text{RK} \\| \\text{kb}_\\mathbf{2}\\) , (b) Concatenates \\(\\text{kb}_\\mathbf{1}\\) then gets \\(\\text{ } \\text{RK} \\| \\text{kb}_\\mathbf{2} \\| \\text{kb}_\\mathbf{1}\\) , (c) Concatenates \\(\\text{kb}_\\mathbf{0}\\) and gets \\(\\text{ } \\text{RK} \\| \\text{kb}_\\mathbf{2} \\| \\text{kb}_\\mathbf{1} \\| \\text{kb}_\\mathbf{0}\\) . He then sets \\(\\tilde{K}_{\\mathbf{x}} := \\text{RK} \\| \\text{kb}_\\mathbf{2} \\| \\text{kb}_\\mathbf{1} \\| \\text{kb}_\\mathbf{0}\\) , and checks if \\(\\tilde{K}_{\\mathbf{x}}\\) equals \\(K_{\\mathbf{x}}\\) . The Merkle proof : That is, checking whether the value stored at the located leaf \\(\\mathbf{{L}_{x}}\\) was indeed included in computing the root, \\(\\mathbf{{root}_{a..x}}\\) . This computation was illustrated several times in the above discussions. Note that the key-correctness and the Merkle proof are simultaneously carried out. Example 3. (Indistinguishable Leaves) Suppose a binary SMT contains a key-value pair \\((K_{\\mathbf{d}}, V_\\mathbf{{d}})\\) at the leaf \\(\\mathbf{L_{d}}\\) , where \\(K_{\\mathbf{d}} = 11100110\\) . That is, \\(\\mathbf{L_{d}} := \\mathbf{H_{leaf}}(V_\\mathbf{{d}})\\) . Note that, when building binary SMTs, it is permissible to have another key-value pair \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) in the same tree with \\(V_\\mathbf{{x}} = V_\\mathbf{{d}}\\) . An Attacker can pick the key-value pair \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) such that \\(V_\\mathbf{{x}} = V_\\mathbf{{d}}\\) and \\(K_{\\mathbf{x}} = 10100110\\) . And, with the above design, it means \\(\\mathbf{L_{x}} = \\mathbf{H_{leaf}}(V_\\mathbf{{x}}) = \\mathbf{H_{leaf}}(V_\\mathbf{{d}}) = \\mathbf{L_{d}}\\) . Consider Figure 8 below. And suppose the Attacker provides the following data; The key-value \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) , where \\(K_{\\mathbf{x}} = 10100110\\) and \\(V_{\\mathbf{x}} = V_\\mathbf{d}\\) . The root, \\(\\mathbf{{root}_{a..x}}\\) , the number of levels to root = 3, and the siblings \\(\\mathbf{{B}_{\\mathbf{bc}}}\\) , \\(\\mathbf{L_{a}}\\) and \\(\\mathbf{{S}_{\\mathbf{efg}}}\\) . The verifier uses the least-significant key bits; \\(\\text{kb}_\\mathbf{0} = 0\\) , \\(\\text{kb}_\\mathbf{1} = 0\\) and \\(\\text{kb}_\\mathbf{2} = 1\\) ; to navigate the tree and locate the leaf \\(\\mathbf{L_{x}}\\) which is positioned at \\(\\mathbf{L_{d}}\\) , see Figure 7 below. Figure 8: Non-binding Key-Value Pairs In order to ensure that \\(\\mathbf{L_{x}}\\) actually stores the value \\(V_\\mathbf{{x}}\\) ; The verifier first checks key-correctness. He takes the remaining key \\(\\text{RK} = 10100\\) and, \u200b(a) Concatenates \\(\\text{kb}_\\mathbf{2} = 1\\) , and gets \\(\\text{ } \\text{RK} \\| \\text{kb}_\\mathbf{2} = 10100 \\|1\\) , \u200b(b) Concatenates \\(\\text{kb}_\\mathbf{1} = 0\\) to get \\(\\text{ } \\text{RK} \\| \\text{kb}_\\mathbf{2} \\| \\text{kb}_\\mathbf{1} = 10100 \\|1\\|0\\) , \u200b(c) Concatenates \\(\\text{kb}_\\mathbf{0} = 0\\) , yielding \\(\\text{ } \\text{RK} \\| \\text{kb}_\\mathbf{2} \\| \\text{kb}_\\mathbf{1} \\| \\text{kb}_\\mathbf{0} = 10100 \\|1\\|0\\|0\\) . He sets \\(\\tilde{K}_{\\mathbf{x}} := 10100 \\|1\\|0\\|0 = 10100100\\) . Since \\(\\tilde{K}_{\\mathbf{x}}\\) equals \\(K_{\\mathbf{x}}\\) , the verifier concludes that the supplied key is correct. As the verifier 'climbs' the tree to test key-correctness, he concurrently checks if the value \\(V_\\mathbf{{x}}\\) is included in the SMT identified by the given root, \\(\\mathbf{{root}_{a..x}}\\) . That is, he executes the following computations; \u200b (a) He computes the hash of \\(V_\\mathbf{{x}}\\) and sets it as, \\(\\tilde{\\mathbf{L}}_\\mathbf{x}:= \\mathbf{H_{leaf}}(V_\\mathbf{{x}})\\) . \u200b (b) Then he uses \\(\\mathbf{{B}_{\\mathbf{bc}}}\\) to compute, \\(\\tilde{\\mathbf{B}}_{\\mathbf{bcd}} = \\mathbf{H_{noleaf}}(\\mathbf{{B}_{\\mathbf{bc}}} \\|\\tilde{\\mathbf{L}}_\\mathbf{x})\\) . \u200b (c) He also uses \\(\\mathbf{L_{a}}\\) to compute, \\(\\tilde{\\mathbf{B}}_{\\mathbf{abcd}} = \\mathbf{H_{noleaf}}(\\mathbf{L_{a}} \\| \\tilde{\\mathbf{B}}_{\\mathbf{bcd}})\\) . \u200b (d) He further calculates, \\(\\tilde{\\mathbf{root}}_{\\mathbf{abcd}} = \\mathbf{H_{noleaf}}(\\tilde{\\mathbf{B}}_{\\mathbf{abcd}} \\| \\mathbf{{S}_{\\mathbf{efg}}})\\) . Next, the verifier checks if \\(\\tilde{\\mathbf{root}}_{\\mathbf{abcd}}\\) equals \\(\\mathbf{root}_{\\mathbf{abcd}}\\) . Since \\(V_\\mathbf{{x}} = V_\\mathbf{{d}}\\) , it follows that all the corresponding intermediate values to the root are equal; \\(\\mathbf{L_{d}} = \\mathbf{H_{leaf}}(V_\\mathbf{{d}}) = \\mathbf{H_{leaf}}(V_\\mathbf{{x}}) = \\tilde{\\mathbf{L}}_\\mathbf{x}\\) , \\(\\mathbf{B}_{\\mathbf{bcd}} = \\mathbf{H_{noleaf}}(\\mathbf{{B}_{\\mathbf{bc}}} \\| \\mathbf{L}_\\mathbf{d}) = \\mathbf{H_{noleaf}}(\\mathbf{{B}_{\\mathbf{bc}}} \\|\\tilde{\\mathbf{L}}_\\mathbf{x}) = \\tilde{\\mathbf{B}}_{\\mathbf{bcd}}\\) , \\(\\mathbf{B}_{\\mathbf{abcd}} = \\mathbf{H_{noleaf}}(\\mathbf{L_{a}} \\| \\mathbf{B}_{\\mathbf{bcd}} ) = \\mathbf{H_{noleaf}}(\\mathbf{L_{a}} \\| \\tilde{\\mathbf{B}}_{\\mathbf{bcd}} ) = \\tilde{\\mathbf{B}}_{\\mathbf{abcd}}\\) , \\(\\mathbf{root}_{\\mathbf{abcd}} = \\mathbf{H_{noleaf}}(\\mathbf{B}_{\\mathbf{abcd}} \\| \\mathbf{{S}_{\\mathbf{efg}}} ) = \\mathbf{H_{noleaf}}(\\tilde{\\mathbf{B}}_{\\mathbf{abcd}} \\| \\mathbf{{S}_{\\mathbf{efg}}} ) = \\tilde{\\mathbf{root}}_{\\mathbf{abcd}}\\) . The verifier therefore concludes that the key-value pair \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) is in the SMT, when it is not. Why is this attack successful? Note that equality of values, \\(V_\\mathbf{{x}} = V_\\mathbf{{d}}\\) , associated with two distinct keys, has nothing to do with the efficacy of this attack. In fact, for all practical purposes, it should be permissible for distinct leaves to store any value, irrespective of whether other leaves store an equivalent value or not. The downfall of our binary SMTs design, thus far, is that it does not give the verifier any equation that relates or ties the keys to their associated values. In other words, the attack succeeds simply because the key-value pairs (as 'committed' values) are not binding. Solution To The Non-Binding Key-Value Problem The solution to this problem is straightforward, and it is to build the binary SMTs in such a way that the key-value pairs are binding. This means, create a relationship between the keys and their associated values, so that the verifier can simply check if this relationship holds true. In order to ensure that checking such a relationship blends with the usual proof machinery, one has two options. The na\u00efve solution, which involves the keys, is one option. The Na\u00efve Solution The na\u00efve solution is to simpy include keys in the argument of the hash function, when forming leaves. That is, when building a binary SMT, one includes a key-value pair \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) by setting the leaf \\(\\mathbf{L_{x}}\\) to be the hash of both the value and the key; \\[\\begin{aligned} \\mathbf{L_{x}} = \\mathbf{H_{leaf}}(K_{\\mathbf{x}} \\| V_\\mathbf{{x}} ) \\end{aligned}\\] Does this change remedy the non-binding problem? Suppose \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) and \\((K_{\\mathbf{z}}, V_\\mathbf{{z}})\\) are two key-value pairs such that \\(V_\\mathbf{{x}} = V_\\mathbf{{z}}\\) , while \\(K_\\mathbf{{x}}\\) and \\(K_\\mathbf{{z}}\\) differ only in one of the most-significant bits. Since the hash functions used are collision-resistant, it follows that \\[\\begin{aligned} \\mathbf{L_{x}} = \\mathbf{H_{leaf}}(K_{\\mathbf{x}} \\| V_\\mathbf{{x}}) \\neq \\mathbf{H_{leaf}}(K_{\\mathbf{z}} \\| V_\\mathbf{{z}}) = \\mathbf{L_{z}} \\end{aligned}\\] Consequently, although the key-value pairs \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) and \\((K_{\\mathbf{z}}, V_\\mathbf{{z}})\\) might falsely pass the key-correctness check, they will not pass the Merkle proof test. And this is because, collision-resistance also guarantees that the following series of inequalities hold true; \\[\\begin{aligned} \\mathbf{L_{x}} = \\mathbf{H_{leaf}}(K_{\\mathbf{x}} \\| V_\\mathbf{{x}}) \\neq \\mathbf{H_{leaf}}(K_{\\mathbf{z}} \\| V_\\mathbf{{z}}) = \\mathbf{L_{z}} \\\\ \\\\ \\mathbf{B_{bx}} = \\mathbf{H_{noleaf}}(\\mathbf{S}_\\mathbf{{b}} \\| \\mathbf{L}_{\\mathbf{x}}) \\neq \\mathbf{H_{noleaf}}(\\mathbf{S}'_\\mathbf{{b}} \\| \\mathbf{L}_{\\mathbf{z}}) = \\mathbf{B_{bz}} \\\\ \\\\ \\mathbf{B_{abx}} = \\mathbf{H_{noleaf}}(\\mathbf{S}_\\mathbf{{a}} \\| \\mathbf{B_{bx}} ) \\neq \\mathbf{H_{noleaf}}(\\mathbf{S}'_\\mathbf{{a}} \\| \\mathbf{B_{bz}}) = \\mathbf{B_{abz}} \\end{aligned}\\] where; \\(\\mathbf{S}_\\mathbf{{b}}\\) is a sibling to \\(\\mathbf{L}_{\\mathbf{x}}\\) , and \\(\\mathbf{S}_\\mathbf{{a}}\\) is a sibling to \\(\\mathbf{B_{bx}}\\) , making \\(\\mathbf{B_{bx}}\\) and \\(\\mathbf{B_{abx}}\\) branches traversed while climbing the tree from \\(\\mathbf{L_{x}}\\) to root; Similarly, \\(\\mathbf{S}'_\\mathbf{{b}}\\) is a sibling to \\(\\mathbf{L}_{\\mathbf{z}}\\) , while \\(\\mathbf{S}'_\\mathbf{{a}}\\) is a sibling to \\(\\mathbf{B_{bx}}\\) , also making \\(\\mathbf{B_{bz}}\\) and \\(\\mathbf{B_{abz}}\\) branches traversed while climbing the tree from \\(\\mathbf{L_{z}}\\) to root. The only chance for the Merkle proof to pass is if the key-value pairs \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) and \\((K_{\\mathbf{z}}, V_\\mathbf{{z}})\\) are distinct and are individually on the same SMT. The inclusion of keys, in the argument of the hash functions, therefore ensures that leaves \\(\\mathbf{L_{x}}\\) and \\(\\mathbf{L_{z}}\\) are distinguishable. And most importantly, that key-value pairs in our SMTs are now binding. A Better Solution The other solution, which is much more apt than the Na\u00efve option, utilises the remaining keys when forming leaves. Since levels to root is related to the Remaining Key ( \\(\\text{RK}\\) ) notion, a much more apt solution is to rather include the remaining key, \\(\\text{RK}_\\mathbf{x}\\) , as the argument to the hash function, instead of the whole key \\(K_{\\mathbf{x}}\\) . That is, for a key-value pair \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) , one sets the leaf \\(\\mathbf{L_{x}}\\) to be the hash of both the value and the remaining key; \\[\\begin{aligned} \\mathbf{L_{x}} = \\mathbf{H_{leaf}}( \\text{RK}_\\mathbf{x} \\| \\text{V}_\\mathbf{{x}}). \\end{aligned}\\] With this strategy, the verifier needs the remaining key \\(\\text{RK}_\\mathbf{{x}}\\) , instead of the whole key, in order to carry out a Merkle proof. So he adjusts the Merkle proof by; Firstly, picking the correct hash function \\(\\mathbf{H_{leaf}}\\) for leaves, Secondly, concatenating the value \\(V_{\\mathbf{x}}\\) stored at the leaf \\(L_{\\mathbf{x}}\\) and the remaining key \\(\\text{RK}_\\mathbf{{x}}\\) , instead of the whole key \\(K_{\\mathbf{x}}\\) , Thirdly, hashing the concatenation \\(\\mathbf{H_{leaf}}( \\text{RK}_\\mathbf{x} \\| \\text{V}_\\mathbf{{x}}) =: \\mathbf{L_{x}}\\) . This approach not only ensures that key-value pairs in our SMTs are now binding, but also implicitly 'encodes' the levels to root in the leaf. The strategy of using the \\(\\text{RK}_\\mathbf{x}\\) instead of the key \\(K_{\\mathbf{x}}\\) , coupled with hashing leaves and branches differently, yields sound verification. Introducing Zero-Knowledge It is often necessary to make sure that a proof-integrity system has the zero-knowledge property. In order to introduce zero-knowledge, instead of storing values as plaintexts in the leaves, one stores hashes of these values. A leaf therefore is henceforth constructed in two steps; Firstly, for a key-value pair \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) , compute the hash the value \\(V_\\mathbf{{x}}\\) , \\[\\begin{aligned} \\text{Hashed Value} = \\text{HV}_\\mathbf{{x}} = \\mathbf{H_{noleaf}}(V_\\mathbf{{x}}) \\end{aligned}\\] Secondly, form the leaf containing \\(V_\\mathbf{{x}}\\) , as follows, \\[\\begin{aligned} \\mathbf{L_{x}} = \\mathbf{H_{leaf}}( \\text{RK}_\\mathbf{x} \\| \\text{HV}_\\mathbf{{x}}) \\end{aligned}\\] Since it is infeasible to compute the preimage of the hash functions, \\(\\mathbf{H_{leaf}}\\) and \\(\\mathbf{H_{noleaf}}\\) , computing the hash of the value \\(V_\\mathbf{{x}}\\) amounts to 'encrypting'. The prover therefore achieves zero-knowledge by providing the pair, \\((K_{\\mathbf{x}}, \\text{HV}_\\mathbf{{x}})\\) , as the key-value pair instead of the explicit one, \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) . The verifier, on the other hand, has to adjust the Merkle proof by starting with; Firstly, picking the correct hash function \\(\\mathbf{H_{leaf}}\\) for leaf nodes, Secondly, concatenating the hashed-value \\(\\text{HV}_\\mathbf{{x}}\\) and the remaining key \\(\\text{RK}_\\mathbf{{x}}\\) , Thirdly, hashing the concatenation in order to form the leaf, \\(\\mathbf{L_{x}} := \\mathbf{H_{leaf}}( \\text{RK}_\\mathbf{x} \\| \\text{HV}_\\mathbf{{x}})\\) . Example 4. (Zero-Knowledge Merkle Proof) The following example illustrates a Merkle proof when the above strategy is applied. Consider an SMT where the keys are 8-bit long, and the prover commits to the key-value \\(( K_{\\mathbf{c}} , \\text{HV}_{\\mathbf{c}} )\\) with \\(K_{\\mathbf{c}} = 10010100\\) . See Figure 9 below. Figure 9 : ZK Merkle Proof Example Since the levels to root is 3, the prover provides; the least-significant key-bits, \\(\\text{kb}_0 = 0\\) , \\(\\text{kb}_1 = 0\\) , \\(\\text{kb}_2 = 1\\) , the stored hashed-value \\(\\text{HV}_{\\mathbf{c}}\\) , the root \\(\\mathbf{{root}_{a..f}}\\) , the Remaining Key \\(\\mathbf{ \\text{RK}_{\\mathbf{c}}} = 10010\\) , and the siblings \\(\\mathbf{{S}_{ab}}\\) , \\(\\mathbf{{L}_{d}}\\) and \\(\\mathbf{{S}_{\\mathbf{ef}}}\\) . The verifier first uses the least-significant bits of the key \\(K_{\\mathbf{c}} = 10010100\\) to navigate the SMT from the root, \\(\\mathbf{{root}_{a..f}}\\) , to the leaf \\(\\mathbf{L_c}\\) . Then, he executes the following computations; He computes, \\(\\mathbf{L_c} = \\mathbf{H_{leaf}}\\big( \\mathbf{ \\text{RK}_{\\mathbf{c}}} \\| \\text{HV}_{\\mathbf{c}} \\big) = \\mathbf{H_{leaf}}( 10010 \\| \\text{HV}_{\\mathbf{c}})\\) Then, he uses the sibling \\(\\mathbf{{S}_{ab}}\\) to compute, \\(\\tilde{ \\mathbf{B}}_{\\mathbf{abc}} := \\mathbf{H_{noleaf}} \\big( \\mathbf{{S}_{ab}}\\|\\mathbf{L}_{\\mathbf{c}} \\big)\\) . Next, he computes, \\(\\tilde{ \\mathbf{B}}_{\\mathbf{abcd}} := \\mathbf{H_{noleaf}} \\big( \\tilde{ \\mathbf{B}}_{\\mathbf{abc}} \\| \\mathbf{L}_{\\mathbf{d}} \\big)\\) . Now, verifier uses \\(\\tilde{ \\mathbf{B}}_{\\mathbf{abcd}}\\) to compute the supposed root, \\(\\tilde{ \\mathbf{root}}_{\\mathbf{ab..f}} := \\mathbf{H_{noleaf}} \\big( \\tilde{ \\mathbf{B}}_{\\mathbf{abcd}}\\| \\mathbf{S}_{\\mathbf{ef}} \\big)\\) . Checks if \\(\\tilde{ \\mathbf{root}}_{\\mathbf{ab..f}}\\) equals \\({ \\mathbf{root}}_{\\mathbf{ab..f}}\\) . The verifier accepts that the key-value pair \\(( K_{\\mathbf{c}} , V_{\\mathbf{c}} )\\) is in the SMT only if \\(\\tilde{ \\mathbf{root}}_{\\mathbf{ab..f}} = { \\mathbf{root}}_{\\mathbf{ab..f}}\\) . And he does this without any clue about the exact value \\(V_{\\mathbf{c}}\\) which is hidden as \\(\\text{HV}_{\\mathbf{c}}\\) . Basic Operations (Storage Actions) The previous sections have focused on the design of binary SMTs. The problems that cropped up with our initial design have assisted in refining and defining a secure design. While describing the design of binary SMTs, we have extensively utilised the READ or \"Get\" operation. Now that the basic design is established, the other operations can be delineated. The operations that the Storage State Machine performs, as per instructions of the Main SM Executor, are called Storage Actions . As mentioned above, these are; Create, Read, Update and Delete (CRUD). The READ Operation First, we illustrate the READ operation, which is in fact a \"Get\". The prover can commit to a key-value pair \\((K_{\\mathbf{x}}, \\text{HV}_{\\mathbf{x}})\\) where \\(\\text{HV}_{\\mathbf{x}}\\) is the hash of the value \\(V_{\\mathbf{x}}\\) . That is, he claims that he created a leaf \\(\\mathbf{L}_{\\mathbf{x}}\\) which contains the value \\(V_{\\mathbf{x}}\\) and it can be located using the key \\(K_{\\mathbf{x}}\\) . READ therefore means locating the leaf \\(\\mathbf{L}_{\\mathbf{x}}\\) and verifying that it contains the value \\(V_{\\mathbf{x}}\\) by using a Merkle proof. Hence, in addition to \\((K_{\\mathbf{x}}, \\text{HV}_{\\mathbf{x}})\\) , prover has to provide the rest of the information needed for completing the Merkle proof. That is, the root, the key-bits \\(\\text{kb}_\\mathbf{j}\\) for locating the leaf \\(\\mathbf{L}_{\\mathbf{x}}\\) , the Remaining Key \\(\\text{RK}_\\mathbf{x}\\) and all the necessary siblings. What if the key is not set? The next example demostrates the READ operation when a key is not set in the tree. That is, it illustrates how to check whether a value is not on a given SMT. There are two cases that can occur. The given key may lead either to a zero node or to an existing leaf. If the given key leads to a zero-node , then the verifier needs only prove the existence of the zero-node, and this would sufficiently prove that the key is not set. But if the given key leads to an existing leaf , the verifier has to prove the leaf exists in the SMT and show that the given key is not the same as the actual key associated with the value at the leaf. Example 5. When The Key Is Not Set Suppose the verifier needs to prove that the keys, \\(K_{\\mathbf{x}} = 11010101\\) and \\(K_{\\mathbf{z}} = 10101010\\) are not set in the SMT depicted in Figure 10 below. Case 1: When the key leads to a zero-node The verifier receives the key \\(K_{\\mathbf{x}}\\) , the remaining key \\(\\text{RK}_\\mathbf{x} = 1101010\\) , the least-significant key-bit \\(\\text{kb}_0 = 1\\) , and the sibling \\(\\mathbf{{S}_{1}} = \\mathbf{{B}_{\\mathbf{ab}}}\\) . Since the least-significant key-bit of the given key, \\(\\text{kb}_0 = 1\\) , navigation from the root leads to the right-side, to the zero-node. See the node circled in a green colour, in Figure 9 below. The task here is to verify that the node is indeed a zero-node. So the verifier computes the root as follows, \\(\\mathbf{{\\tilde{root}}_{ab0}} = \\mathbf{H_{noleaf}} (\\mathbf{{S}_{1}} \\| \\mathbf{0} ) = \\mathbf{H}( \\mathbf{{B}_{\\mathbf{ab}}} \\| \\mathbf{0} )\\) . Note that he concatenates \\(\\mathbf{{S}_{1}}\\) and \\(\\mathbf{0}\\) in the given ordering, because \\(\\text{kb}_0 = 1\\) . He then checks if \\(\\mathbf{{\\tilde{root}}_{ab0}} = \\mathbf{{root}_{ab0}}\\) . If this is true, then he concludes that the given key is not set. Figure 10: Key Not Set Example Case 2: When the key leads to an existing leaf Consider again the SMT depicted in Figure 10 above, and suppose that the prover claims that the key \\(K_{\\mathbf{z}} = 10101010\\) is set. The verifier is given; the key \\(K_{\\mathbf{z}} = 10101010\\) , the Remaining Key \\(\\text{RK}_{\\mathbf{z}} = 101010\\) , the least-significant key-bit \\(\\text{kb}_0 = 0\\) , the second least-significant key-bit \\(\\text{kb}_{\\mathbf{1}} = 1\\) , and the siblings \\(\\mathbf{{S}_{1}} = \\mathbf{L}_{a}\\) and \\(\\mathbf{{S}_{2}} = \\mathbf{0}\\) . When navigating the tree from \\(\\mathbf{{root}_{ab0}}\\) , using the key-bits \\(\\text{kb}_{\\mathbf{0}} = 0\\) and \\(\\text{kb}_{\\mathbf{1}} = 1\\) , and with reference to Figure 10 above, the key-bit \\(\\text{kb}_{\\mathbf{0}} = 0\\) leads to the branch \\(\\mathbf{{B}_{\\mathbf{ab}}}\\) , then from \\(\\mathbf{{B}_{\\mathbf{ab}}}\\) , the key-bit \\(\\text{kb}_{\\mathbf{1}} = 1\\) leads to the leaf \\(\\mathbf{L}_\\mathbf{b}\\) , which is the leaf circled in brown in Figure 9 above. Since the key navigates to a leaf, the verifier's task is to prove two things simultaneously; The leaf is in the SMT described in Figure 10, and The Remaining Key at the leaf \\(\\mathbf{L}_\\mathbf{b}\\) is different from the Remaining Key supplied by the prover. In proving that \\(\\mathbf{L}_{\\mathbf{b}}\\) is indeed in the tree, the verifier does the following; Checks the root : (a) Computes the hash of the hashed-value, \\(\\mathbf{ \\tilde{L} }_{\\mathbf{b}} = \\mathbf{H_{leaf}} ( \\text{RK}_{\\mathbf{b}} \\| \\text{HV}_{\\mathbf{b}} )\\) , (b) Uses the first sibling to compute, \\(\\mathbf{{\\tilde{B}}_{\\mathbf{ab}}} = \\mathbf{H_{noleaf}} \\big( \\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{ \\tilde{L}}_{\\mathbf{b}} \\big)\\) , (c) Then, uses the second sibling to compute the root, \\(\\mathbf{\\tilde{root}}_{ab0} = \\mathbf{H_{noleaf}} \\big( \\mathbf{{\\tilde{B}}_{\\mathbf{ab}}} \\| \\mathbf{0} \\big)\\) . (d) Completes the root-check by testing equality, \\(\\mathbf{\\tilde{root}}_{ab0} = \\mathbf{{root}}_{ab0}\\) . Simultaneously, Checks the keys : The verifier takes the two Remaining Keys \\(\\text{RK}_{\\mathbf{x}}\\) and \\(\\text{RK}_{\\mathbf{b}}\\) , and the key-bits \\(\\text{kb}_0\\) and \\(\\text{kb}_{\\mathbf{1}}\\) ; (a) Concatenates them as, \\(\\tilde{K}_{\\mathbf{x}} = \\text{RK}_{\\mathbf{x}} \\| \\text{kb}_0 \\| \\text{kb}_{\\mathbf{1}}\\) and \\(\\tilde{K}_{\\mathbf{b}} = \\text{RK}_{\\mathbf{b}} \\| \\text{kb}_0 \\| \\text{kb}_{\\mathbf{1}}\\) , (b) Checks \\(\\tilde{K}_{\\mathbf{x}} = K_{\\mathbf{x}}\\) and \\(\\tilde{K}_{\\mathbf{b}} = K_{\\mathbf{b}}\\) , and (c) Finally shows the inequality, \\(\\tilde{K}_{\\mathbf{x}} \\neq K_{\\mathbf{b}}\\) . This proves that the key \\(K_{\\mathbf{x}}\\) is not set. Remark : The last check, where the verifier checks inequality of keys, turns out to be very expensive to implement. A much more smarter method is used in the Storage State Machine. The UPDATE Operation The UPDATE operation does not change the topology of the tree. When carrying out the UPDATE, it is therefore important to retain all labels of nodes. The UPDATE process entails the following; First, the verifier needs to be provided with the following data; The remaining key \\(\\text{RK}\\) , the least-significant key-bits, the new value, the old value, the old root and the siblings. Step 1. Checking a READ of the current value with the old root. That is, checking that the leaf exists in the tree, and it was included in calculating the old root. Step 2. Recomputing (updating) all nodes along the path , from the leaf to the root, as well as computing the new root with the newly updated nodes. The verifier can continue with Step 2 only if all the checks in Step 1 pass verification. For the UPDATE operation, Step 1 is exactly the same as the READ operation. We therefore focus on illustrating Step 2 . Example 6. UPDATE - Step 2 Suppose the set key is \\(K_{\\mathbf{c}} = 10110100\\) corresponding to the old value \\(V_{\\mathbf{c}}\\) , and the new value is \\(V_\\mathbf{new}\\) . The verifier is provided with the following data; \u200b (a) the \\(\\text{RK}_{\\mathbf{c}} = 10110\\) , \u200b (b) the least-significant key-bit \\(\\text{kb}_0 = 0\\) , \u200b (c) the second least-significant key-bit \\(\\text{kb}_1 = 0\\) , \u200b (d) the third least-significant key-bit \\(\\text{kb}_2 = 1\\) , \u200b (e) the old hashed value \\(\\text{HV}_{\\mathbf{c}}\\) , \u200b (f) the old root \\(\\mathbf{{root}_{ab..f }}\\) , and \u200b (g) the siblings \\(\\mathbf{{S}_{1}} = \\mathbf{{S}_{\\mathbf{ab}}}\\) , \\(\\mathbf{{S}_{2}} = \\mathbf{{L}_{d}}\\) and \\(\\mathbf{{S}_{3}} = \\mathbf{{S}_{\\mathbf{ef}}}\\) . Consider the SMT given in Figure 11 below. Figure 11: Value UPDATE Example The required Step 2 of the UPDATE operation involves, (a) Computing the hash of the new value \\(V_\\mathbf{new}\\) as; \\(\\text{HV}_{\\mathbf{new}} = \\mathbf{H_{noleaf}}(V_\\mathbf{new})\\) , (b) Forming the new leaf by again hashing the hashed value \\(\\text{HV}_{\\mathbf{new}}\\) as; \\(\\mathbf{ \\tilde{L} }_{\\mathbf{new}} = \\mathbf{H_{leaf}}( \\text{RK}_{\\mathbf{new}} \\| \\text{HV}_{\\mathbf{new}} )\\) , (c) Using the first sibling \\(\\mathbf{{S}_{1}} = \\mathbf{{S}_{\\mathbf{ab}}}\\) to compute, \\(\\mathbf{{\\bar{B}}_{abc}} = \\mathbf{H_{noleaf}} \\big( \\mathbf{{S}_{\\mathbf{ab}}} \\| \\mathbf{ \\tilde{L}}_{\\mathbf{new}} \\big)\\) , (d) Again, using the second sibling \\(\\mathbf{{S}_{2}} = \\mathbf{{L}_{d}}\\) to compute, \\(\\mathbf{{\\bar{B}}_{\\mathbf{abcd}}} = \\mathbf{H_{noleaf}} \\big( \\mathbf{{\\bar{B}}_{abc}} \\| \\mathbf{{L}_{d}} \\big)\\) , (e) Then, uses the third sibling \\(\\mathbf{{S}_{3}} = \\mathbf{{S}_{\\mathbf{ef}}}\\) to compute the root, \\(\\mathbf{{{root}}_{\\mathbf{new}}} = \\mathbf{H_{noleaf}} \\big( \\mathbf{{\\bar{B}}_{\\mathbf{abcd}}} \\| \\mathbf{{S}_{\\mathbf{ef}}}\\big)\\) . Note that the key-bits are not changed. Therefore, replacing the following old values in the SMT, \\(\\text{HV}_\\mathbf{c}, \\mathbf{{B}_{abc}}, \\mathbf{{B}_{abcb}}, \\mathbf{{root}_{ab..f } }\\) , with the new ones, \\(\\text{HV}_\\mathbf{new}, \\mathbf{{\\bar{B}}_{abc}}, \\mathbf{{\\bar{B}}_{abcb}}, \\mathbf{{root}_{new } }\\) , respectively, completes the UPDATE operation. The CREATE Operation The CREATE Operation adds a new leaf \\(\\mathbf{L_{\\mathbf{new}}}\\) to the SMT in order to insert and store a new key-value pair \\(( \\mathbf{{K_{new}}} , \\mathbf{V_{\\mathbf{new}}} )\\) at \\(\\mathbf{L_{\\mathbf{new}}}\\) , where the key \\(\\mathbf{K_{new}}\\) was never used in the SMT and thus is uniquely associated with the leaf \\(\\mathbf{L_{new}}\\) . When navigating from the root, the new key \\(\\mathbf{K_{new}}\\) can lead to either a zero node or an existing leaf. This results in two scenarios. Case 1: New Key Navigates To A Zero Node That is, the first \\(l\\) least-significant bits of the key \\(\\mathbf{K_{new}}\\) leads to a zero node, where \\(l\\) is the levels to root of the zero node. The first step is to double-check that indeed the node is a zero node. That is, the verifier performs a Merkle proof starting with either \\(\\mathbf{H_{noleaf}} ( \\mathbf{S_1} \\| \\mathbf{0} )\\) or \\(\\mathbf{H_{noleaf}} ( \\mathbf{0} \\| \\mathbf{S_1} )\\) , depending on whether the sibling of the zero-node is on the right (the edge corresponding to a key-bit \\(1\\) ) or on the left (the edge corresponding to a key-bit \\(0\\) ), respectively. Once it is established that the new key \\(\\mathbf{K_{new}}\\) has led to a zero node, the verifier simply changes the zero node to the leaf \\(\\mathbf{L_{new}}\\) that stores the value \\(\\mathbf{V_{new}}\\) . The CREATE operation, in this case, therefore boils down to an UPDATE operation on the zero node. It amounts to; Computing the hash of the new value \\(V_\\mathbf{new}\\) as, \\(\\text{HV}_{\\mathbf{new}} = \\mathbf{H_{noleaf}}(V_\\mathbf{new})\\) , Then forming the new leaf, \\(\\mathbf{L_{new}} = \\mathbf{H_{leaf}}( \\text{RK}_{\\mathbf{new}} \\| \\text{HV}_{\\mathbf{new}})\\) , Recomputing all the nodes along the path climbing from the leaf \\(\\mathbf{L_{new}}\\) to the root, including computing the new root. Example 7. CREATE Operation at a Zero Node Suppose a new leaf with the key-value pair \\(\\big(K_{\\mathbf{new}}, \\text{V}_{\\mathbf{new}}\\big)\\) , where \\(K_{\\mathbf{new}} = 11010110\\) , needs to be created. As illustrated in Figure 12 below, the two least-significant key-bits \\(\\text{kb}_0 = 0\\) and \\(\\text{kb}_1 = 1\\) , lead to a zero node. That is, navigating from the root; \u200b (a) The lsb, \\(\\text{kb}_{0} = 0\\) leads to the node \\(\\mathbf{{B}_{ab0}}\\) , \u200b (b) Whilst the second lsb, \\(\\text{kb}_{1} = 1\\) leads to a zero node. At this stage the verifier checks if this is indeed a zero node; First he computes \\(\\mathbf{{\\tilde{B}}_{ab0}} = \\mathbf{H_{noleaf}} \\big( \\mathbf{{S}_{\\mathbf{ab}}} \\| \\mathbf{0} \\big)\\) . Then he computes \\(\\mathbf{{\\tilde{root}}_{ab0c}} = \\mathbf{H_{noleaf}} \\big( \\mathbf{{\\tilde{B}}_{ab0}} \\| \\mathbf{L_{c}} \\big)\\) . And, checks if \\(\\mathbf{{\\tilde{root}}_{ab0c}}\\) equals \\(\\mathbf{{root}_{ab0c}}\\) . Figure 12: CREATE Operation - Zero Node Once the zero-value is checked, the verifier now creates a non-zero leaf with the key-value pair \\(\\big( \\mathbf{K_{new}} , \\text{HV}_{\\mathbf{new}}\\big)\\) . He computes the hash of \\(\\text{V}_{\\mathbf{new}}\\) as, \\(\\text{HV}_{\\mathbf{new}} = \\mathbf{H_{noleaf}}(V_\\mathbf{new})\\) , He then forms the leaf \\(\\mathbf{L_{new}} = \\mathbf{H_{leaf}}( \\text{RK}_{\\mathbf{new}} \\| \\text{HV}_{\\mathbf{new}})\\) , Also computes \\(\\mathbf{B_{new}} = \\mathbf{H_{noleaf}} ( \\mathbf{{S}_{\\mathbf{ab}}} \\| \\mathbf{L_{new}})\\) , And computes \\(\\mathbf{{root}_{new}} = \\mathbf{H_{noleaf}} ( \\mathbf{B_{new}} \\| \\mathbf{L_{c}} )\\) . An UPDATE of these values; the branch \\(\\mathbf{B_{ab0}}\\) to \\(\\mathbf{B_{new}}\\) and the old root \\(\\mathbf{{root}_{ab0c}}\\) to \\(\\mathbf{{root}_{new}}\\) ; completes the CREATE operation. Note that inserting a new key-value pair at a zero node does not change the topology of the tree. Case 2: New Key Navigates To A Non-Zero Leaf That is, the first \\(\\mathbf{l}\\) least-significant bits of the key \\(\\mathbf{K_{new}}\\) leads to a non-zero leaf \\(\\mathbf{L_z}\\) , where \\(\\mathbf{l}\\) is \\(\\mathbf{L_z}\\) 's number of levels to root . This means, the keys \\(\\mathbf{K_{new}}\\) and \\(\\mathbf{K_{z}}\\) share a common string of least-significant key-bits, which is \\(\\mathbf{l}\\) bits long. Step 1: Checking Leaf Inclusion The first step is to double-check that indeed the value \\(V_\\mathbf{z}\\) stored at the leaf \\(\\mathbf{L_z}\\) is indeed included in the root. That is, the verifier performs a Merkle proof starting with either \\(\\mathbf{H_{noleaf}} ( \\mathbf{S_1} \\| \\mathbf{L_z} )\\) or \\(\\mathbf{H_{noleaf}} ( \\mathbf{L_z} \\| \\mathbf{S_1} )\\) , for some sibling \\(\\mathbf{S_1}\\) . The ordering of the hash arguments depends on whether the sibling of the leaf \\(\\mathbf{L_z}\\) is on the left (the edge corresponding to a key-bit \\(0\\) ) or on the right (the edge corresponding to a key-bit \\(1\\) ), respectively. The check of value-inclusion gets completed by climbing the tree as usual. Once it is established that the value \\(V_\\mathbf{z}\\) stored at the leaf \\(\\mathbf{L_z}\\) is included in the root, the new leaf \\(\\mathbf{L_{new}}\\) storing the key-value pair can now be created. Step 2: Extending The SMT Since it is not permissible for two distinct non-zero leaves, \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_z}\\) , to share a tree-address, a CREATE Operation at \\(\\mathbf{L_z}\\) results in extending the tree; by adding a new branch \\(\\mathbf{B_{ext1}}\\) at the tree-address where \\(\\mathbf{L_z}\\) has been positioned. As discussed earlier in this document, when building binary SMTs, the aim is to find a tree-address for the new leaf \\(\\mathbf{L_{new}}\\) which differs from the tree-address of any existing leaf \\(\\mathbf{L_z}\\) . So then, for as long as the next corresponding key-bits between \\(\\mathbf{K_{new}}\\) and \\(\\mathbf{K_{z}}\\) coincide, a new extension branch needs to be formed. Here's the general procedure; Start with the next least-significant key-bits, \\(\\text{kb}_\\mathbf{(l+1)new}\\) and \\(\\text{kb}_\\mathbf{(l+1)z}\\) , and check if \\(\\text{kb}_\\mathbf{(l+1)new} = \\text{kb}_\\mathbf{(l+1)z}\\) or not. If they are not the same (i.e., if \\(\\text{kb}_\\mathbf{(l+1)new} \\neq \\text{kb}_\\mathbf{(l+1)z}\\) ), then one new extension branch \\(\\mathbf{B_{ext1}}\\) with \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{z}}\\) as its child-nodes, suffices. But, if \\(\\text{kb}_\\mathbf{(l+1)new} = \\text{kb}_\\mathbf{(l+1)z}\\) , then another extension branch \\(\\mathbf{B_{ext2}}\\) needs to be formed. And, the first extension branch \\(\\mathbf{B_{ext1}}\\) is made a parent-node to both \\(\\mathbf{B_{ext2}}\\) and a NULL node \" \\(\\mathbf{0}\\) \". The key-bit \\(\\text{kb}_\\mathbf{(l+1)new}\\) determines whether the NULL node \" \\(\\mathbf{0}\\) \" is on the left or the right. One then continues with the next least-significant key-bits, \\(\\text{kb}_\\mathbf{(l+2)new}\\) and \\(\\text{kb}_\\mathbf{(l+2)z}\\) , and checks if \\(\\text{kb}_\\mathbf{(l+2)new} = \\text{kb}_\\mathbf{(l+2)z}\\) or not. If \\(\\text{kb}_\\mathbf{(l+2)new} \\neq \\text{kb}_\\mathbf{(l+2)z}\\) , then the second extension branch \\(\\mathbf{B_{ext2}}\\) , with \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{z}}\\) as its child-nodes, completes the CREATE operation. However, if \\(\\text{kb}_\\mathbf{(l+2)new} = \\text{kb}_\\mathbf{(l+2)z}\\) , then a third extension branch \\(\\mathbf{B_{ext3}}\\) is formed. And, as before, the second extension branch \\(\\mathbf{B_{ext2}}\\) is made a parent-node to both \\(\\mathbf{B_{ext3}}\\) and a NULL node \" \\(\\mathbf{0}\\) \". And similarly, the key-bit \\(\\text{kb}_\\mathbf{(l+2)new}\\) determines whether the NULL node \" \\(\\mathbf{0}\\) \" is on the left or the right. This procedure (of extending the tree) continues until, \\(\\text{kb}_\\mathbf{(l+j)new} \\neq \\text{kb}_\\mathbf{(l+j)z}\\) for some \\(j > 2\\) . In which case, the \\(\\mathbf{(l + j)}\\) -th extension branch \\(\\mathbf{B_{ext(l + j)}}\\) , with the \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{z}}\\) as its child-nodes, completes the CREATE operation. Step 3: UPDATE of Values The CREATE Operation is actually only complete once all the values on the navigation path from the new root to the new leaf are updated. Example 8. CREATE Operation with a Single Branch Extension Suppose a leaf needs to be created to store a new key-value pair \\(\\big({K_{\\mathbf{new}}\\ } , V_\\mathbf{{new}}\\big)\\) , where \\(K_{\\mathbf{new}} = 11010110\\) . Consider the SMT shown in Figure 13(a) below. In this example, navigation using the least-significant key-bits, \\(\\text{kb}_\\mathbf{0} = 0\\) and \\(\\text{kb}_\\mathbf{1} = 1\\) , leads to an existing leaf \\(\\mathbf{L_{\\mathbf{c}}}\\) . And the key-value pair \\((V_\\mathbf{\\mathbf{c}}, \\text{HV}_\\mathbf{\\mathbf{c}})\\) stored at \\(\\mathbf{L_{\\mathbf{c}}}\\) has the key \\(K_{\\mathbf{c}} = 11010010\\) . Value-Inclusion Check A value-inclusion check of \\(V_\\mathbf{\\mathbf{c}}\\) is performed before creating any new leaf. Since this amounts to a READ Operation, which has been illustrated in previous examples, we omit how this is done here. Once \\(V_\\mathbf{\\mathbf{c}}\\) passes the check, the CREATE Operation continues by inserting the new leaf. New Leaf Insertion In this example, the new leaf \\(\\mathbf{L_{new}}\\) cannot be inserted at the key-address 01 where \\(\\mathbf{L_{\\mathbf{c}}}\\) is positioned. A branch extension \\(\\mathbf{{B}_{ext}}\\) must therefore be done at the address 01 with the leaves \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{c}}\\) as child-nodes. Since the third least-significant key-bits of \\(K_{\\mathbf{new}}\\) and \\(K_{\\mathbf{c}}\\) are not the same, \\(\\text{kb}_\\mathbf{2new} = 1\\) and \\(\\text{kb}_\\mathbf{2c} = 0\\) , the addresses 110 and 010 of the leaves \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{c}}\\) , respectively, are distinct. Therefore, no further extension is necessary. And the CREATE Operation is complete by updating all the values on the navigation path. Figure 13(a): CREATE Operation - Non-zero Leaf Node The next process, after forming the branch extension, is to UPDATE all the nodes along the path from the root to the new leaf \\(\\mathbf{L_{new}}\\) . The verifier follows the steps of the UPDATE operation to accomplish this. UPDATE of SMT Values The verifier computes the following, The hashed value, \\(\\text{HV}_{\\mathbf{new}} = \\mathbf{H_{noleaf}}(V_\\mathbf{new})\\) , The new leaf, \\(\\mathbf{L_{new}} = \\mathbf{H_{leaf}} ( \\text{RK}_{\\mathbf{new}} \\| \\text{HV}_{\\mathbf{new}})\\) , Then, \\(\\mathbf{B_{ext}} = \\mathbf{H_{noleaf}} ( \\mathbf{L_{c}} \\| \\mathbf{L_{new}})\\) , Again, \\(\\mathbf{B_{new}} = \\mathbf{H_{noleaf}}( \\mathbf{S_{ab}} \\| \\mathbf{B_{ext}} )\\) , And finally computes, \\(\\mathbf{{root}_{new}} = \\mathbf{H_{noleaf}}( \\mathbf{B_{new}} \\| \\mathbf{L_{d}} )\\) . This illustrates how the CREATE Operation is performed at a non-zero leaf, when only one branch extension is required. Example 9. CREATE Operation with Multiple Branch Extensions This example provides an illustration of the CREATE Operation at a non-zero leaf, where more than one branch extensions are required. Suppose a leaf must be created to store a new key-value pair \\(\\big(K_{\\mathbf{new}}, V_\\mathbf{new}\\big)\\) , where \\(K_{\\mathbf{new}} = 11010110\\) . Consider the SMT shown in Figure 13(b) below. Navigating the tree by using the least-significant key-bits, \\(\\text{kb}_\\mathbf{0} = 0\\) and \\(\\text{kb}_\\mathbf{1} = 1\\) , leads to an existing leaf \\(\\mathbf{L_{\\mathbf{c}}}\\) . In this example, suppose the key-value pair \\((K_{\\mathbf{c}} , \\text{HV}_\\mathbf{\\mathbf{c}})\\) stored at \\(\\mathbf{L_{\\mathbf{c}}}\\) has the key \\(K_{\\mathbf{c}} = 11100110\\) . Value-Inclusion Check Before creating the new leaf, it is important to first check if \\(V_\\mathbf{\\mathbf{c}}\\) is indeed included in the root, \\(\\mathbf{root}_\\mathbf{abcd}\\) . Since this amounts to performing a READ Operation, which has been illustrated in previous examples, we omit here how this is done. Once \\(V_\\mathbf{\\mathbf{c}}\\) passes the value-inclusion check, the CREATE Operation proceeds with inserting the new leaf. New Leaf Insertion Note that the first and second least-significant key-bits for both \\(K_\\mathbf{new}\\) and \\(K_\\mathbf{c}\\) are the same. That is, \\(\\text{kb}_\\mathbf{0new} = 0 = \\text{kb}_\\mathbf{0c}\\) and \\(\\text{kb}_\\mathbf{1new} = 1 = \\text{kb}_\\mathbf{1c}\\) . As a result, the new leaf \\(\\mathbf{L_{new}}\\) cannot be inserted at the key-address 01 , where \\(\\mathbf{L_{\\mathbf{c}}}\\) is positioned. An extension branch \\(\\mathbf{{B}_{ext1}}\\) is formed at the tree-address 01 . But, can the leaves \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{c}}\\) be child-nodes to \\(\\mathbf{{B}_{ext1}}\\) ? Since the third least-significant key-bits of \\(K_\\mathbf{new}\\) and \\(K_\\mathbf{c}\\) are the same; that is, \\(\\text{kb}_\\mathbf{2new} = 1 = \\text{kb}_\\mathbf{2c}\\) ; leaves \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{c}}\\) cannot be child-nodes to \\(\\mathbf{{B}_{ext1}}\\) . Another extension branch \\(\\mathbf{{B}_{ext2}}\\) is formed at the tree-address 011 . Again, since the fourth least-significant key-bits of \\(K_\\mathbf{new}\\) and \\(K_\\mathbf{c}\\) are the same; \\(\\text{kb}_\\mathbf{3new} = 0 = \\text{kb}_\\mathbf{3c}\\) ; the leaves \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{c}}\\) cannot be child-nodes to \\(\\mathbf{{B}_{ext2}}\\) . A third extension branch \\(\\mathbf{{B}_{ext3}}\\) is needed at the tree-address 0110 . In this case, the fifth least-significant key-bits of \\(K_\\mathbf{new}\\) and \\(K_\\mathbf{c}\\) are different; i.e., \\(\\text{kb}_\\mathbf{4new} = 1\\) and \\(\\text{kb}_\\mathbf{4c} = 0\\) . The leaves \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{c}}\\) are now made child-nodes of the extension branch \\(\\mathbf{{B}_{ext3}}\\) . See Figure 13(b) below. Figure 13(b): CREATE Operation - Three Branch Extensions Once unique addresses for the key-value pairs \\(\\big( K_{\\mathbf{c}} , V_\\mathbf{c} \\big)\\) and \\(\\big( K_\\mathbf{{new}} , V_{\\mathbf{new}}\\big)\\) are reached, and the leaf \\(\\mathbf{L_{new}}\\) is inserted, all the nodes along the navigation path from the new leaf \\(\\mathbf{L_{new}}\\) to the root are updated as follows. The verifier computes, The hash of the new value, \\(\\text{HV}_\\mathbf{new} = \\mathbf{H_{noleaf}}(V_\\mathbf{new})\\) , The new leaf, \\(\\mathbf{L_{new}} = \\mathbf{H_{leaf}} ( \\text{RK}_{\\mathbf{new}} \\| \\text{HV}_{\\mathbf{new}})\\) , Then, \\(\\mathbf{B_{ext3}} = \\mathbf{H_{noleaf}}( \\mathbf{L_{c}} \\| \\mathbf{L_{new}})\\) , Followed by \\(\\mathbf{B_{ext2}} = \\mathbf{H_{noleaf}}( \\mathbf{B_{ext3}} \\| \\mathbf{0} )\\) , And, \\(\\mathbf{B_{ext1}} = \\mathbf{H_{noleaf}}( \\mathbf{0} \\| \\mathbf{B_{ext2}} )\\) , Again, \\(\\mathbf{B_{new}} = \\mathbf{H_{noleaf}}( \\mathbf{S_{ab}} \\| \\mathbf{B_{ext2}} )\\) , And finally computes, \\(\\mathbf{{root}_{new}} = \\mathbf{H_{noleaf}}( \\mathbf{B_{new}} \\| \\mathbf{L_{d}} )\\) . This completes the CREATE operation at an existing leaf where several branch extensions are needed. The CREATE operation at a non-leaf node clearly changes the topology of the tree. The DELETE/REMOVE Operation The DELETE Operation refers to a removal of a certain key-value pair from a binary SMT. It is in fact the reverse of the CREATE Operation. There are two types of scenarios that can occur when executing a DELETE Operation. There is a scenario where a DELETE Operation is equivalent to an UPDATE Operation of a non-zero leaf to a NULL leaf. In this case the topology of the SMT does not change. This occurs when the leaf being deleted has a non-zero sibling-node. On the other hand, a DELETE Operation can be tantamount to the reverse of a CREATE Operation where extension branches are removed from the tree. The topology of the SMT can drastically change. This scenario occurs when the leaf being removed has a zero sibling-node. A DELETE Operation involves two main steps; Step 1 : A READ of the value to be deleted is executed. That is; \u200b (a) Navigating to the value, \u200b (b) Checking if the value is included in the root, and \u200b (c) Checking if the given key (reconstructed from the given Remaining Key and the least-significant key-bits) matches the key at the leaf (reconstructed from the Remaining Key found at the leaf and the given key-bits). Step 2 : This step depends on whether the sibling of the leaf to be deleted is zero or not; \u200b (a) If the sibling is not a zero node , an UPDATE to a zero is performed. \u200b (b) If the sibling is a zero-node , an UPDATE to a zero is performed and the parent-node is turned into a NULL node with no child-nodes. Case 1: DELETE Operation - Leaves With Non-Zero Siblings Consider a DELETE of a key-value pair \\(\\big(K_{\\mathbf{b}} , V_\\mathbf{b} \\big)\\) where its leaf \\(\\mathbf{L_b}\\) has a non-zero node sibling. Suppose the data provided includes; the Remaining Key \\(\\tilde{\\text{RK}}_{\\mathbf{b}}\\) , the least-significant key-bits \\(\\text{kb}_0 = 0\\) and \\(\\text{kb}_1 = 1\\) , the root \\(\\mathbf{{root}_{abc}}\\) , and the sibling \\(\\mathbf{L_a}\\) which is not a zero node and the leaf \\(\\mathbf{L_c}\\) . With reference to Figure 14(a) below, navigation leads to the leaf \\(\\mathbf{L_b}\\) . Next, perform a Merkle proof to check if the hashed value \\(\\text{HV}_\\mathbf{b}\\) at \\(\\mathbf{L_b}\\) is included in the given root; Compute \\(\\tilde{\\mathbf{L}}_\\mathbf{b} = \\mathbf{H_{leaf}} ( \\text{RK}_{\\mathbf{b}} \\| \\text{HV}_\\mathbf{b} )\\) Then \\(\\tilde{\\mathbf{B}}_\\mathbf{ab} = \\mathbf{H_{noleaf}} ( \\mathbf{L_a} \\| \\tilde{\\mathbf{L}}_\\mathbf{b})\\) And, \\(\\tilde{\\mathbf{root}}_\\mathbf{abc} = \\mathbf{H_{noleaf}} ( \\tilde{\\mathbf{B}}_\\mathbf{ab} \\| \\mathbf{L_c} )\\) Check if \\(\\tilde{\\mathbf{root}}_\\mathbf{abc}\\) equals \\(\\mathbf{{root}_{abc}}\\) . Simultaneously, check if \\(\\tilde{K}_{\\mathbf{b}}\\) equals \\(\\text{K}_{\\mathbf{b}}\\) , where \\(\\tilde{K}_{\\mathbf{b}} = \\tilde{\\text{RK}}_{\\mathbf{b}} \\| \\text{kb}_1 \\| \\text{kb}_0\\) and \\(\\text{K}_{\\mathbf{b}} = \\text{RK}_{\\mathbf{b}} \\| \\text{kb}_1 \\| \\text{kb}_0\\) are keys reconstructed while climbing the tree. Since the sibling \\(\\mathbf{L_a}\\) is not a zero node, the hashed value \\(\\text{HV}_\\mathbf{b}\\) found at the leaf \\(\\mathbf{L_b}\\) is updated to a zero. And the values along the navigation path are also updated accordingly. That is, The leaf \\(\\mathbf{L_b}\\) is set to \" \\(\\mathbf{0}\\) \", a zero node. The parent-node is now, \\(\\mathbf{B_{a0}} = \\mathbf{H_{noleaf}} ( \\mathbf{L_a} \\| \\mathbf{0} )\\) . And, the new root, \\(\\mathbf{{root}_{abc}} = \\mathbf{H_{noleaf}}(\\mathbf{B_{a0}} \\| \\mathbf{L_a})\\) . See the above DELETE Operation illustrated in Figure 13(a) below, and notice how the SMT maintains its original shape. Figure 14(a): DELETE Operation - Non-Zero Sibling Case 2: DELETE Operation - Leaves With Zero Siblings Consider deleting a key-value pair \\(\\big(K_{\\mathbf{c}} , V_\\mathbf{c} \\big)\\) where its leaf \\(\\mathbf{L_c}\\) has a zero-node sibling. As in Case 1 above, suppose the data provided includes; the Remaining Key \\(\\tilde{\\text{RK}}_{\\mathbf{c}}\\) , the least-significant key-bits \\(\\text{kb}_0 = 0\\) , \\(\\text{kb}_1 = 1\\) and \\(\\text{kb}_2 = 1\\) , the root \\(\\mathbf{{root}_{a0cd}}\\) , and the sibling \" \\(\\mathbf{0}\\) \" which is a zero node, and the leaves \\(\\mathbf{L_a}\\) and \\(\\mathbf{L_d}\\) . With reference to Figure 14(b) below, navigation leads to the leaf \\(\\mathbf{L_c}\\) . The READ step in this case is similar to what is seen in Case 1. The UPDATE step depends on the sibling of \\(\\mathbf{L_c}\\) . Since the sibling is \" \\(\\mathbf{0}\\) \", an UPDATE of \\(\\mathbf{L_c}\\) to zero results in the branch \\(\\mathbf{B_{0c}}\\) having two zero nodes as child-nodes. Since \\(\\mathbf{H_{noleaf}} ( \\mathbf{0} \\| \\mathbf{0}) = 0\\) , it is therefore expedient to turn the branch \\(\\mathbf{B_{0c}}\\) into a zero node with no child-nodes. That is, the UPDATE step of this DELETE Operation concludes as follows; The original branch \\(\\mathbf{B_{0c}}\\) is now \" \\(\\mathbf{0}\\) \", a zero node. The parent-node is now, \\(\\mathbf{B_{a0}} = \\mathbf{H_{noleaf}} ( \\mathbf{L_a} \\| \\mathbf{0} )\\) . And, the new root, \\(\\mathbf{{root}_{a0d}} = \\mathbf{H_{noleaf}}(\\mathbf{B_{a0}} \\| \\mathbf{L_d})\\) . Notice that, in this example, the DELETE Operation alters the topology of the SMT, as seen in Figure 13(b) below. Figure 14(b): DELETE Operation - Zero Sibling Concluding Basic Operations The operations discussed in this section are in fact the very actions the Main State Machine will instruct the Storage State Machine to perform. The 'prover' and the 'verifier', as used in the above explanations, can loosely be interpreted as the Executor of the Storage State Machine and the Storage SM's PIL code, respectively. The zero-knowledge Assembly (zkASM) of the Storage SM plays the facilitator's role. The zkASM is the interpreter between the Storage SM and the Main State Machine, also between the Storage SM and the POSEIDON State Machine. The two hash functions used in building the Storage binary SMTs, are special versions of the POSEIDON family of hash functions. What's left is specifying parameters such as the actual key-length used in the Storage State Machine, how keys and paths are created, as well as cryptographic primitives utilised like the exact POSEIDON hash functions. zkProver Storage Parameters In the Storage SM, the keys and values are strings of 256 bits. Keys will henceforth be represented as 256-bit unsigned integers, which are quadruples of 64-bit field elements; e.g., \\(\\text{Key}_{\\mathbf{0123}} = \\big( \\text{Key}_{\\mathbf{0}} , \\text{Key}_{\\mathbf{1}} , \\text{Key}_{\\mathbf{2}} , \\text{Key}_{\\mathbf{3}} \\big)\\) , where each \\(\\text{Key}_{\\mathbf{i}} \\in \\mathbb{F}_p\\) , where \\(p = 2^{64} - 2^{32} + 1\\) . Although hashed-values are also 256-bit long and are used in quadruple form, 'committed' values are 256-bit long and are often expressed as octets. It is mainly due to the POSEIDON SM convention, where 256-bit committed values are input as, \\(\\text{V}_{\\mathbf{01..7}} = \\big( \\text{V}_{\\mathbf{0}} , \\text{V}_{\\mathbf{1}} , \\text{V}_{\\mathbf{2}} , \\dots , \\text{V}_{\\mathbf{7}} \\big)\\) , and each 32-bit \\(V_{\\mathbf{j}}\\) chunk of bits. In fact, almost every other 256-bit value in the Storage is expressed in the form of a quadruple of 64-bit field elements. Creating Keys And Paths How Keys Are Created In the key-value pair SMT context of our storage design, a key uniquely identifies a leaf. And it is because, although values can change, keys do not. Keys must consequently be generated deterministically, and in such a way that there are no collisions. That is, there must be a one-to-correspondence between keys and leaves. A collision-resistant hash function is therefore the best tool for generating keys. And the most convenient way to generate keys is by hashing some specific information so that the resultant hash uniquely identifies the leaf. The specific Information used for generating keys is the Ethereum Address and some constant. The \\(\\text{POSEIDON}\\) Hash is again used for this purpose. Constructing Navigation Paths A path refers to the edges traversed from the root to a leaf. Since the SMTs are binary, all edges can be thought of, as labelled with either a bit \"0\" or \"1\"; Edges to the left labelled with a bit \"0\", while edges to the right are labelled with a bit \"1\". Paths are therefore strings of bits, and are derived from keys in a very specific way. First of all, every key can be thought of as a quadruple, \\(\\text{Key}_{\\mathbf{0123}} = \\big( \\text{Key}_{\\mathbf{0}} , \\text{Key}_{\\mathbf{1}} , \\text{Key}_{\\mathbf{2}} , \\text{Key}_{\\mathbf{3}} \\big) \\in \\mathbb{F}_{p}^4\\) . Denote each key part \\(\\text{Key}_{\\mathbf{i}}\\) bit-wise as, \\[\\begin{aligned} \\text{Key}_{\\mathbf{0}} = k_{\\mathbf{0,63}\\ } k_{\\mathbf{0,62}\\ } \\dots k_{\\mathbf{0,2}\\ } k_{\\mathbf{0,1}\\ } k_{\\mathbf{0,0} },\\ \\ \\text{Key}_{\\mathbf{1}} = k_{\\mathbf{1,63}\\ } k_{\\mathbf{1,62}\\ } \\dots k_{\\mathbf{1,2}\\ } k_{\\mathbf{1,1}\\ } k_{\\mathbf{1,0} }, \\\\\\text{Key}_{\\mathbf{2}} = k_{\\mathbf{2,63}\\ } k_{\\mathbf{2,62}\\ } \\dots k_{\\mathbf{2,2}\\ } k_{\\mathbf{2,1}\\ } k_{\\mathbf{2,0} },\\ \\ \\text{Key}_{\\mathbf{3}} = k_{\\mathbf{3,63}\\ } k_{\\mathbf{3,62}\\ } \\dots k_{\\mathbf{3,2}\\ } k_{\\mathbf{3,1}\\ } k_{\\mathbf{3,0} }, \\end{aligned}\\] where the most-significant bit \\(\\text{MSB}(\\text{Key}_{\\mathbf{i}}) = k_{\\mathbf{i,63}\\ }\\) and the least-significant bit \\(\\text{LSB}(\\text{Key}_{\\mathbf{i}}) = k_{\\mathbf{i,0}}\\) , for each \\(\\mathbf{i} \\in \\{ \\mathbf{0}, \\mathbf{1}, \\mathbf{2}, \\mathbf{3} \\}\\) . The Navigation Path to the leaf corresponding to the key \\(\\text{Key}_{\\mathbf{0123}}\\) is defined as the following string of shuffled key-bits; \\[\\begin{aligned} k_{\\mathbf{0,0}\\ } k_{\\mathbf{1,0}\\ } k_{\\mathbf{2,0}\\ } k_{\\mathbf{3,0}\\ } k_{\\mathbf{0,1}\\ } k_{\\mathbf{1,1}\\ } k_{\\mathbf{2,1}\\ } k_{\\mathbf{3,1}\\ } k_{\\mathbf{0,2}\\ } k_{\\mathbf{1,2}\\ } k_{\\mathbf{2,2}\\ } k_{\\mathbf{3,2}\\ }\\\\ \\dots k_{\\mathbf{0,62}\\ } k_{\\mathbf{1,62}\\ } k_{\\mathbf{2,62}\\ } k_{\\mathbf{3,62}\\ } k_{\\mathbf{0,63}\\ } k_{\\mathbf{1,63}\\ } k_{\\mathbf{2,63}\\ } k_{\\mathbf{3,63} }. \\end{aligned}\\] That is, the Navigation Path to the leaf corresponding to \\(\\text{Key}_{\\mathbf{0123}}\\) is the string of bits composed of; The least-significant bits of the four key parts, \\(\\text{Key}_{\\mathbf{0}} , \\text{Key}_{\\mathbf{1}} , \\text{Key}_{\\mathbf{2}} , \\text{Key}_{\\mathbf{3}}\\) , appearing in the order of the key parts as: \\(k_{\\mathbf{0,0}\\ } k_{\\mathbf{1,0}\\ } k_{\\mathbf{2,0}\\ } k_{\\mathbf{3,0}}\\) . Followed by the second least-significant bits of the four key parts, \\(\\text{Key}_{\\mathbf{0}} , \\text{Key}_{\\mathbf{1}} , \\text{Key}_{\\mathbf{2}} , \\text{Key}_{\\mathbf{3}}\\) , appearing in the order of the key parts as: \\(k_{\\mathbf{0,1}\\ } k_{\\mathbf{1,1}\\ } k_{\\mathbf{2,1}\\ } k_{\\mathbf{3,1}}\\) . Then the third least-significant bits of the four key parts, \\(\\text{Key}_{\\mathbf{0}} , \\text{Key}_{\\mathbf{1}} , \\text{Key}_{\\mathbf{2}} , \\text{Key}_{\\mathbf{3}}\\) , appearing in the order of the key parts as: \\(k_{\\mathbf{0,2}\\ } k_{\\mathbf{1,2}\\ } k_{\\mathbf{2,2}\\ } k_{\\mathbf{3,2}}\\) . Up until the most-significant bits of the four key parts, \\(\\text{Key}_{\\mathbf{0}} , \\text{Key}_{\\mathbf{1}} , \\text{Key}_{\\mathbf{2}} , \\text{Key}_{\\mathbf{3}}\\) , appearing in the order of the key parts as: \\(k_{\\mathbf{0,63}\\ } k_{\\mathbf{1,63}\\ } k_{\\mathbf{2,63}\\ } k_{\\mathbf{3,63} }\\) . Figure 15 : Navigation Path Derivation Note that, this construction ensures that in every quadruplet of consecutive path-bits there is a one-to-one correspondence between the bits and the four parts of the key, \\(\\text{Key}_{\\mathbf{0}} , \\text{Key}_{\\mathbf{1}} , \\text{Key}_{\\mathbf{2}} , \\text{Key}_{\\mathbf{3}}\\) . Reconstructing The Key From Path-Bits When executing a basic operation such as an UPDATE of a value at a leaf, one has to reconstruct the key from the remaining key found at the leaf and the path-bits spent in navigating to the leaf. Denote the remaining key as a quadruple, \\(\\text{RKey}_{\\mathbf{0123}} = \\big( \\text{RKey}_{\\mathbf{0}} , \\text{RKey}_{\\mathbf{1}} , \\text{RKey}_{\\mathbf{2}} , \\text{RKey}_{\\mathbf{3}} \\big)\\) Since the Path was constructed by shuffling key-bits from the four parts, \\(\\text{Key}_{\\mathbf{0}}\\) , \\(\\text{Key}_{\\mathbf{1}}\\) , \\(\\text{Key}_{\\mathbf{2}}\\) , \\(\\text{Key}_{\\mathbf{3}}\\) , one would expect the reverse-process (going from the Path-bits to the original key) to work just as easily. Perhaps taking the level \\(\\text{lvl}\\) of a leaf and reducing it modulo 4 , should be sufficient to tell which part of the Remaining Key, \\(\\text{RKey}_{\\mathbf{i}}\\) , must the Path key-bit be appended to. Example. Key Reconstruction Suppose the leaf storing the key-value pair \\(\\big( \\text{Key}_{\\mathbf{0123}}, \\text{V}_{\\mathbf{01..7}} \\big)\\) is reached at level 7, the path-bits used are \\(0110101\\) , and the remaining key is \\(\\text{RKey}_{\\mathbf{0123}} = \\big( \\text{RKey}_{\\mathbf{0}} , \\text{RKey}_{\\mathbf{1}} , \\text{RKey}_{\\mathbf{2}} , \\text{RKey}_{\\mathbf{3}} \\big)\\) . That is, the path-bits are \\(\\text{path-bit}_6 = 1\\) , \\(\\text{path-bit}_5 = 0\\) , \\(\\text{path-bit}_4 = 1\\) , \\(\\text{path-bit}_3 = 0\\) , \\(\\text{path-bit}_2 = 1\\) , \\(\\text{path-bit}_1 = 1\\) and \\(\\text{path-bit}_0 = 0\\) . So, in order to place \\(\\text{path-bit}_6\\) , one first computes \\(7 \\text{ modulo } 4\\) to get \\(3\\) . Hence, the \\(\\text{key-bit}_6\\) must be appended to the third key part, \\(\\text{RKey}_{\\mathbf{2}}\\) . Next, one climbs the tree to level \\(6\\) , where \\(\\text{path-bit}_5 = 0\\) . One then computes \\(6 \\text{ modulo } 4\\) and gets \\(2\\) . The \\(\\text{path-bit}_5\\) must then be appended to the second key part, \\(\\text{RKey}_{\\mathbf{1}}\\) . Again, one climbs the tree to level \\(5\\) , where \\(\\text{path-bit}_4 = 1\\) . Computing \\(5 \\text{ modulo } 4\\) yields \\(1\\) . The \\(\\text{path-bit}_4\\) is thence appended to the first key part, \\(\\text{RKey}_{\\mathbf{0}}\\) . One then continues in the same fashion; \\(\\text{Climbs the tree to level } 4. \\text{ Computes }\\ 4 \\text{ modulo } 4 = 0. \\text{ Appends path-bit to the fourth part, } \\text{RKey}_{\\mathbf{3}}.\\) \\(\\text{Climbs the tree to level } 3. \\text{ Computes }\\ 3 \\text{ modulo } 4 = 3. \\text{ Appends path-bit to the third part, } \\text{RKey}_{\\mathbf{2}}.\\) \\(\\text{Climbs the tree to level } 2. \\text{ Computes }\\ 2 \\text{ modulo } 4 = 2. \\text{ Appends path-bit to the second part, } \\text{RKey}_{\\mathbf{1}}.\\) \\(\\text{Climbs the tree to level } 1. \\text{ Computes }\\ 1 \\text{ modulo } 4 = 1. \\text{ Appends path-bit to the first part, } \\text{RKey}_{\\mathbf{0}}.\\) The next climb is to the root. The navigation path-bits have been exhausted, and the last append has actually completed reconstruction of the key. Leaf Levels and Integers Modulo 4 It is clear, from the above example, that there is a one-to-one correspondence between the integers modulo 4 (i.e., Elements of the group \\(\\mathbb{Z}_4 = \\{ 0, 1, 2, 3 \\}\\) ) and remaining key parts \\(\\text{RKey}_{\\mathbf{0}} , \\text{RKey}_{\\mathbf{1}} , \\text{RKey}_{\\mathbf{2}} , \\text{RKey}_{\\mathbf{3}}\\) . That is, there is a mapping; \\[\\begin{aligned} 1 \\mapsto \\text{RKey}_{\\mathbf{0}},\\ \\ 2 \\mapsto \\text{RKey}_{\\mathbf{1}},\\ \\ 3 \\mapsto \\text{RKey}_{\\mathbf{2}} \\text{ and }\\ 0 \\mapsto \\text{RKey}_{\\mathbf{3}}. \\end{aligned}\\] The quadruple structure of the path bits and the level of leaves therefore have a homomorphic relationship that can be described in terms of the cyclic group of integers modulo 4, \\(\\mathbb{Z}_4 = \\{ 0, 1, 2, 3 \\}\\) . Since addition modulo n is an expensive computation in the state machine context, it is important to find a more efficient algorithm to achieve the same result. Alternate Cyclic Group Of Order 4 In order to explore cyclic groups of order 4, take the vector \\(\\mathbf{x} = (1,0,0,0)\\) , and rotate the components of \\(\\mathbf{x}\\) one position to the left. Note that, rotating \\(\\mathbf{x} = (1,0,0,0)\\) once, yields \\((0,0,0,1)\\) twice, one obtains \\((0,0,1,0)\\) thrice, one gets \\((0,1,0,0)\\) four times, and the result is \\(\\mathbf{x} = (1,0,0,0)\\) Continuously rotating \\(\\mathbf{x} = (1,0,0,0)\\) will not result in any other vector but the four vectors \\[ \\mathbf{G_4} = \\{ (1,0,0,0),\\ (0,0,0,1),\\ (0,0,1,0),\\ (0,1,0,0) \\}. \\] This set of four vectors \\(\\mathbf{G_4}\\) together with the described rotation , form an group. In fact, \\(\\mathbf{G_4}\\) is isomorphic (or homomorphically equivalent) to \\(\\mathbb{Z}_4\\) under \"addition modulo 4\". That is, there is a natural one-to-one correspondence between the elements of \\(\\mathbb{Z}_4\\) and those of \\(\\mathbf{G_4}\\) , as follows; $$ 0 \\mapsto (1,0,0,0),\\ \\ 1 \\mapsto (0,1,0,0),\\ \\ 2 \\mapsto (0,0,1,0)\\ \\text{ and }\\ 3 \\mapsto (0,0,0,1). $$ Note that the four numbers \\(0\\) , \\(1\\) , \\(2\\) and \\(3\\) can be expressed in their binary form with just two bits, and the same one-to-one correspondence holds as; \\[ \\text{00} \\mapsto (1,0,0,0),\\ \\ \\text{01} \\mapsto (0,1,0,0),\\ \\ \\text{10} \\mapsto (0,0,1,0)\\ \\text{ and }\\ \\text{11} \\mapsto (0,0,0,1). \\] A Special Cyclic Register For Leaf Levels Define a register called LEVEL which is vector of four bits, three \"0\" bits and one \"1\" bit. And the operation ROTATE_LEVEL which is the left rotation of LEVEL 's bits by one position. If LEVEL is initialised as \\((1,0,0,0)\\) , observe that applying ROTATE_LEVEL four times brings LEVEL back to \\((1,0,0,0)\\) . That is, $$ (1,0,0,0) \\to (0,0,0,1) \\to (0,0,1,0) \\to (0,1,0,0) \\to (1,0,0,0) $$ Therefore, LEVEL is cyclic under ROTATE_LEVEL , and is in fact algebraically the same as the cyclic group \\(\\mathbf{G_4}\\) described above. How is the LEVEL register used in key reconstruction? First note that, when navigating the tree, the leaf level can be indicated by one of the four possible states of the LEVEL register. And this works for all possible leaf levels because, for any positive integer \\(j\\) ; \\[\\begin{aligned} {\\text{LEVEL}} = (1,0,0,0)\\ \\text{indicates that the leaf level is one of the following};\\ 0, 4, 8, \\dots , 0 + 4j. \\ \\\\ {\\text{LEVEL}} = (0,1,0,0)\\ \\text{indicates that the leaf level is one of the following};\\ 1, 5, 9, \\dots , 1 + 4j. \\ \\\\ {\\text{LEVEL}} = (0,0,1,0)\\ \\text{indicates that the leaf level is one of the following};\\ 2, 6, 10, \\dots, 2 + 4j. \\\\ {\\text{LEVEL}} = (0,0,0,1)\\ \\text{indicates that the leaf level is one of the following};\\ 3, 7, 11, \\dots, 3 + 4j. \\end{aligned}\\] Second, the two least-significant bits of each of these number, when written in binary , are as follows; \\[\\begin{aligned} \\text{Each of these numbers};\\ 0, 4, 8, \\dots , 0 + 4j;\\ \\text{ends with } 00.\\ \\ \\\\ \\text{Each of these numbers};\\ 1, 5, 9, \\dots , 1 + 4j;\\ \\text{ends with } 01.\\ \\ \\\\ \\text{Each of these numbers};\\ 2, 6, 10, \\dots , 2 + 4j; \\text{ends with } 10.\\ \\\\ \\text{Each of these numbers};\\ 3, 7, 11, \\dots , 3 + 4j;\\ \\text{ends with } 11. \\end{aligned}\\] It suffices therefore to only read the two least-significant bits of the leaf level in order to determine the position of the bit \"1\" in the LEVEL register. Third, the position of the bit \"1\" in the LEVEL register tallies precisely with the part of the remaining key, \\(\\text{RKey}_{\\mathbf{i}}\\) , to which the last used path-bit came from. So then, when reconstructing the key, one needs only check where the bit \"1\" is in the LEVEL register, because \\[\\begin{aligned} {\\text{LEVEL}} = (1,0,0,0)\\ \\ \\text{means, the last used path bit must be appended to } \\mathbf{RKey_0}.\\\\ {\\text{LEVEL}} = (0,1,0,0)\\ \\ \\text{means, the last used path bit must be appended to } \\mathbf{RKey_1}.\\\\ { \\text{LEVEL}} = (0,0,1,0)\\ \\ \\text{means, the last used path bit must be appended to } \\mathbf{RKey_2}.\\\\ {\\text{LEVEL}} = (0,0,0,1)\\ \\ \\text{means, the last used path bit must be appended to } \\mathbf{RKey_3}. \\end{aligned}\\] Since things are rather mechanical in state machines, one or two more functions are needed. For instance, one for initialising the LEVEL register, and another for reading the position of the bit \"1\". The \\(\\text{POSEIDON}\\) HASH Poseidon SM is the most straight forward once one understands the internal mechanism of the original Poseidon hash function. The hash function's permutation process translates readily to the Poseidon SM states. The \\(\\text{POSEIDON}\\) State Machine carries out \\(\\text{POSEIDON}\\) Actions in accordance with instructions from the Main SM Executor and requests from the Storage SM. That is, it computes hashes of messages sent from any of the two SMs, and also checks if the hashes were correctly computed. The zkProver uses the goldilocks \\(\\text{POSEIDON}\\) which is defined over the field \\(\\mathbb{F}_p\\) , where \\(p = 2^{64} - 2^{32} + 1\\) . The states of the \\(\\text{POSEIDON}\\) SM coincide with the twelve (12) internal states of the \\(\\text{POSEIDON}^{\\pi}\\) permutation function. These are; in0 , in1 , ... , in7 , hashType , cap1 , cap2 and cap3 . \\(\\text{POSEIDON}^{\\pi}\\) runs 30 rounds, 3 times. Adding up to a total of 90 rounds. It outputs four (4) hash values; hash0 , hash1 , hash2 and hash3 . Figure 16 : POSEIDON HASH0 In the case of the zkProver storage, two slightly different \\(\\text{POSEIDON}\\) hashes are used; \\(\\text{HASH0}\\) is used when a branch node is created, whilst \\(\\text{HASH1}\\) is used when a leaf node is created. This depends on the hashType , which is a boolean. So \\(\\text{POSEIDON}\\) acts as \\(\\text{HASH1}\\) when hashType = 1, and \\(\\text{HASH0}\\) when hashType = 0. Since POSEIDON Hashes outputs \\(4 * \\lfloor(63.99)\\rfloor \\text{ bits} = 252\\) , and one bit is needed to encode each direction, the tree can therefore have a maximum of 252 levels. The Storage State Machine's Design and Mechanism The Storage SM is practically dual in that it is both a State Machine and a Storage, a database. So, instead of the Main SM having to query the Storage as a database itself (i.e., the Main SM itself carrying out the CRUD operations), the Storage has instead been automised to execute these queries (by turning it into a state machine). Since the design of the Storage part has been extensively described in the foregoing sections (in terms of SMTs), the design of the automation now follows. What follows next is the description of, how the State Machine part is designed, and how it works (i.e., explaining the internal mechanism of the Storage SM). The Storage SM is composed of three parts; Storage Assembly code, Storage Executor code, and the Storage PIL code. The Storage Assembly The Storage Assembly is the interpreter between the Main State Machine and its own Executor. It receives instructions from the Main SM and generates a JSON-file containing the corresponding rules and logic, which are stored in a special ROM for the Storage SM. The Storage SM has a primary Storage Assembly code , storage_sm.zkasm , that maps each instruction of the Main SM (i.e., each Storage Action) to the secondary Assembly code of the corresponding basic operation. These basic operations are mainly the CREATE, READ, UPDATE and DELETE, as discussed in previous sections. Considering some special cases, there are all-in-all eight (8) secondary Storage Assembly codes , each for a distinct basic operation; READ or Get, UPDATE, CREATE new value at a zero node, CREATE new value at found leaf, DELETE leaf with zero sibling, DELETE last non-zero node, DELETE leaf with non-zero sibling, and SET a zero node to zero. See Table 1, below, for the specific names of the secondary codes. Table 1: SMT Actions And Secondary zkASM Codes Storage Actions File Names Code Names Action Selectors In Primary zkASM Code READ Get Get isGet() UPDATE Set_Update SU isSetUpdate() CREATE new value at a found leaf Set_InsertFound SIF isSetInsertFound() CREATE new value at a zero node Set_InsertNotFound SINF isSetInsertNotFound() DELETE last non-zero node Set_DeleteLast SDL isSetDeleteLast() DELETE leaf with non-zero sibling Set_DeleteFound SDF isSetDeleteFound() DELETE leaf with zero sibling Set_DeleteNotFound SDNF isSetDeleteNotFound() SET a zero node to zero Set_ZeroToZero SZTZ isSetZeroToZero() Input and ouput states of the Storage SM are literally SMTs, given in the form of; the Merkle roots, the relevant siblings, as well as the key-value pairs. Note that state machines use registers in the place of variables. All values needed, for carrying out the basic operations, are stored by the primary Assembly code in the following registers; HASH_LEFT , HASH_RIGHT , OLD_ROOT , NEW_ROOT , VALUE_LOW , VALUE_HIGH , SIBLING_VALUE_HASH , RKEY , SIBLING_RKEY , RKEY_BIT , LEVEL . The SIBLING_VALUE_HASH and SIBLING_RKEY registers are only used by the Set_InsertFound and the Set_DeleteFound secondary Assembly codes. The rest of the registers are used in all the secondary Assembly codes. SMT Action Selectors In The Primary Assembly Code How does the primary Assembly code map the Main SM instructions to the relevant Storage Actions? It uses selectors. Like switches can either be ON or OFF, selectors can either be 1 or 0, where 1 means the action is selected for execution, while 0 means the instruction does not tally with the required action so a \"jump if zero\" JMPZ is applied. The primary Assembly code uses selectors by following the sequence in which these Storage Actions are listed in Table 1 above. That is, It first checks if the required action is a Get . If it is so, the storage_sm_get.zkasm code is fetched for execution. If not, it checks if the required action is Set_Update . If it is so, the storage_sm_set_update.zkasm code is fetched for execution. If not, it continues to check if the required action is Set_InsertFound . If it is so, the storage_sm_set_insert_found.zkasm code is fetched for execution. If not, it continues in the same way until the correct action is selected, in which case the corresponding code is fetched for execution. That's all the primary Storage Assembly code does, the details of how each if the SMT Actions are stipulated in the individual secondary Assembly codes. The primary and secondary Storage Assembly files are stored as JSON-files in the Storage ROM, ready to be fetched as \"function calls\" by the Storage Executor. The UPDATE zkASM Code Take as an example the Set_UPDATE zkASM code. The primary Storage Assembly code uses the selector isSetUpdate() for Set_UPDATE. Note that an UPDATE action involves, Reconstructs the corresponding key, from both the remaining key found at the leaf and key-bits used to navigate to the leaf. Ascertains that indeed the old value was included in the old root, Carries out the UPDATE of the old value with the new value, as well as updating all nodes along the path from the leaf to the root. There is only one Set_UPDATE Assembly code, storage_sm_set_update.zkasm , for all the above three computations. Key Reconstruction In zkASM Key Reconstruction is achieved in two steps; Positioning of the bit \"1\" in the LEVEL register, and using the LEVEL register to \"climb the RKey\". That is, append the path bit last used in navigation to the correct RKey part. Step 1. Positioning the bit \"1\" in the LEVEL register The Set_UPDATE zkASM code, first initialises the LEVEL register to (1,0,0,0) . Then uses the GetLevelBit() function to read the two least-significant bits of the leaf level, which happens in two cases, each with its own two subcases; Case 1 . If the least-significant bit of leaf level is 0 , then the GetLevelBit() function is used again to read the second least-significant bit of the leaf level. Subcase 1.1 : If the second least-significant bit of the leaf level is 0 , it means the leaf level is a multiple of 4, which is equivalent to 0 because leaf level works in modulo 4. So, the LEVEL register must remain as (1,0,0,0) . Subcase 1.2 : If the second least-significant bit of the leaf level is 1 , it means the leaf level in its binary form ends with a 10 . Hence, leaf level is a number of the form 2 + 4k , for some positive integer k . As a result, the LEVEL register must be rotated to the position, (0,0,1,0) . The code therefore applies ROTATE_LEVEL twice to LEVEL = (1,0,0,0) in order to bring it to (0,0,1,0) . Case 2 . If the least-significant bit of leaf level is 1 , then; The LEVEL register is rotated three times to the left, using ROTATE_LEVEL, and bringing the LEVEL register to (0,1,0,0) . Next, the GetLevelBit() function is used again to read the second least-significant bit of the leaf level. Subcase 2.1 : If the second least-significant bit of the leaf level is 0 , it means the leaf level in its binary form ends with a 01 . That is, leaf level is a number of the form 1 + 4k , for some positive integer k . And thus, the LEVEL register must remain in its current position, (0,1,0,0) . So it does not need to be rotated. Subcase 2.2 : Otherwise, the second least-significant bit of the leaf level is 1 , which means the leaf level in its binary form ends with a 11 . Hence, leaf level is a number of the form 3 + 4k , for some positive integer k . Consequently, the LEVEL register needs to be rotated from the current position (0,1,0,0) to the position (0,0,0,1) . Step 2. Using LEVEL to \"climb the RKey\" The Remaining Key is fetched using the GetRKey() function and stored in the RKEY register. When climbing the tree, there are two functions that are used in the code; the CLIMB_RKEY and the ROTATE_LEVEL. First, the LEVEL register is used to pinpoint the correct part of the Remaining Key to which the path-bit last used in the navigation must be appended. (See the previous subsection on \" A Special Cyclic Register For Leaf Levels \" for a one-to-one correspondence between the positions of \"1\" in LEVEL and the Rkey parts.) Second, the ROTATE_LEVEL is used to rotate the LEVEL register once. The CLIMB_RKEY is used; Firstly, to shift the value of the pinpointed RKey part one position to the left. Secondly, to insert the last used path bit to the least-significant position of the shifted-value of the pinpointed RKey part. The above two steps are repeated until all the path bits used in navigation have been appended. In which case, equality between the reconstructed key and the original key is checked. Checking Inclusion Of Old Value In Old Root The above key reconstruction, together with checking inclusion of the old value in the old root and updating the old value to the new value, are carried out simultaneously. Since checking inclusion of the old value in the old root follows the same steps as the update of the old value to the new value, the corresponding lines in the Assembly code are similar. It suffices therefore to explain only one of these two computations. Next is the discussion of the update of the old value to the new value. The Update Part Of Set_UPDATE All values, \\(\\text{V}_{0123}=\\big(\\text{V}_{0},\\text{V}_{1},\\text{V}_{2},\\text{V}_{3},\\text{V}_{4},\\text{V}_{5},\\text{V}_{6},\\text{V}_{7}\\big)\\) are 256-bit long and expressed as lower half and higher half as, VALUE_LOW \\(=\\big(\\text{V}_{0},\\text{V}_{1},\\text{V}_{2},\\text{V}_{3}\\big)\\) and VALUE_HIGH \\(=\\big(\\text{V}_{4},\\text{V}_{5},\\text{V}_{6},\\text{V}_{7} \\big)\\) . Step 1. Computing the new leaf value (a) The functions GetValueLow() and GetValueHigh() are used to fetch VALUE_LOW \\(=\\big(\\text{V}_{0},\\text{V}_{1},\\text{V}_{2},\\text{V}_{3}\\big)\\) and VALUE_HIGH \\(=\\big(\\text{V}_{4},\\text{V}_{5},\\text{V}_{6},\\text{V}_{7}\\big)\\) , respectively. (b) The VALUE_LOW \\(= \\big(\\text{V}_{0},\\text{V}_{1},\\text{V}_{2},\\text{V}_{3}\\big)\\) is stored in a register called HASH_LEFT , whilst VALUE_HIGH \\(=\\big(\\text{V}_{4},\\text{V}_{5},\\text{V}_{6},\\text{V}_{7}\\big)\\) is stored in another register called HASH_RIGHT . (c) The hashed value of \\(\\text{V}_{0123}\\) is computed using HASH0 as, \\(\\text{HASH0}\\big(\\text{HASH\\_LEFT}\\|\\text{HASH\\_RIGHT}\\big)\\) . Note that this is in fact, \\(\\text{POSEIDON}\\big(0\\|0\\|0\\|0\\|\\text{VALUE\\_LOW}\\|\\text{VALUE\\_HIGH}\\big)\\) . The hashed value is then stored in HASH_RIGHT . (This means the HASH_RIGHT and the HASH_LOW are 'make-shift' registers. Whenever a value is stored in it, the old value that was previously stored therein is simply pushed out. They hold values only for the next computation.) (d) Next the Rkey is copied into the HASH_LEFT register. And the leaf value is computed by using HASH1 as, \\(\\text{HASH1}\\big(\\text{HASH\\_LEFT}\\|\\text{HASH\\_RIGHT}\\big)\\) . i.e., The value of the leaf is, \\(\\text{HASH1}\\big( \\text{RKey}\\|\\text{HashedValue}\\big)\\) . The leaf value is then copied into another register called NEW_ROOT . Step 2. Climbing the SMT Check if the path bit that led to the leaf is 0 or 1, by using the GetNextKeyBit() function. Case 1 : If the path bit (called 'key bit' in the code) is 0, then the corresponding sibling is on the right. Therefore, using 'jump if zero' JMPZ , the code jumps to the SU_SiblingIsRight routine. (a) The leaf value in NEW_ROOT is pushed into the HASH_LEFT register. (b) The hash value of the sibling node is fetched, using the GetSiblingHash() function. And it is pushed into the HASH_RIGHT register. (c) The hash value of the parent node is computed using HASH0 as follows, \\(\\text{HASH0}\\big(\\text{HASH\\_LEFT}\\|\\text{HASH\\_RIGHT}\\big)\\) . i.e., The parent node is \\(\\text{POSEIDON}\\big(0\\|0\\|0\\|0\\|\\text{LeafValue}\\|\\text{SiblingHash}\\big)\\) . Case 2 : If the path bit is 1, then the corresponding sibling is on the left. The routine SU_SiblingIsRight is then executed. (a) The leaf value in NEW_ROOT is pushed into the HASH_RIGHT register. (b) The hash value of the sibling node is fetched, using the GetSiblingHash() function. And it is pushed into the HASH_LEFT register. (c) The hash value of the parent node is computed using HASH0 as follows, \\(\\text{HASH0}\\big(\\text{HASH\\_LEFT}\\|\\text{HASH\\_RIGHT}\\big)\\) . i.e., The parent node is \\(\\text{POSEIDON}\\big(0\\|0\\|0\\|0\\|\\text{SiblingHash}\\|\\text{LeafValue}\\big)\\) . Step 3. Check if tree top has been reached The code uses the function GetTopTree() to check is the top of the tree has been reached. Case 1 . If GetTopTree() returns 1, then Step 2 is repeated. But this time using the hash value of the corresponding sibling at the next level (i.e., at leaf level - 1 ). Case 2 . If GetTopTree() returns 0, then the code jumps to the SU_Latch routine. The SU_Latch is an overall routine for the entire Set_UPDATE Assembly code. It is here where, (a) Equality between the reconstructed key and the original key is checked. (b) Equality between the computed old root value and the original old root is checked. Once consistency is established both between the keys and the old roots, then all new values; the new root, the new hash value, and the new leaf value; are set using LATCH_SET . The Rest Of The Secondary Assembly Codes The Assembly codes for the other seven SMT Actions to a certain extent, follow a similar pattern except for a few cases where especially adjusted routines are used. Actions such as; The Set_InsertFound (or SIF ) may involve a change in the topology of the SMT by extending a branch once or several times. In cases where a branch has been extended, the SIF Assembly code, when computing the new root, uses another routine called SIF_ClimbBranch just for updating values along the newly extended branch. This is done in addition to the SIF_ClimbTree , which is the exact same routine as the aforementioned SU_ClimbTree of the Set_UPDATE case. It is for the same reason, SIF Assembly utilises special registers; the SIBLING_VALUE_HASH and SIBLING_RKEY . The opposite SMT Action, the Set_DeleteFound or SDF , may entail a previously extended branch being reserved. As in the SIF case, if a branch had been extended but now the extension needs to be reversed due to a deleted leaf value, a special routine called SDF_ClimbBranch is used when updating values of nodes along the newly shortened branch. This SDF_ClimbBranch routine is the exact same routine as the SIF_ClimbBranch . Similarly, the SDF Assembly code uses the SDF_ClimbTree as in the Set_UPDATE Assembly. Note also that there is only one Get Assembly code, for the READ SMT Action, and the rest of the secondary Assembly codes are Set_ Assembly codes differing according to their respective SMT Actions. So Get uses LATCH_GET at the end of a run, while the Set_ codes use LATCH_SET . The Storage Executor The Storage Executor like a slave-worker to the master, the Storage Assembly code, carries out all SMT Actions in accordance with rules and logic that the Assembly code has set out. As per instruction of the Main SM, the Storage Executor makes function calls to the Storage ROM for a specific secondary Assembly code stored as a JSON-file, by using the same aforementioned selectors of secondary Assembly codes. For example, if the Main SM requires a new leaf to be created at a found non-zero leaf, the Storage Executor uses isSetInsertFound as a function call for the Set_InsertFound (or SIF ) SMT Action. The Storage Executor then proceeds to build commited polynomials and executes the SIF SMT Action. As previously observed, in our very first UPDATE example in this document, all values are expressed as quadruplets of unsigned integers. For example, the Remaining Key looks like this, $$ \\text{RKey} = \\big( \\text{RKey}_0, \\text{RKey}_1, \\text{RKey}_2, \\text{RKey}_3 \\big) $$ The Executor therefore uses an internal 4-element register called op = [_,_,_,_] , for handling values from the Storage ROM, which are needed in the internal step-by-step evaluations of the SMT Action being executed. It is thus reset to 0 after every evaluation. All the function calls seen in the Assembly code; GetSibling() , GetValueLow() , GetValueHigh() , GetRKey() , GetSiblingRKey() , GetSiblingHash() , GetSiblingValueLow() , GetSiblingValueHigh() , GetOldValueLow() , GetOldValueHigh() , GetLevelBit() , GetTopTree() , GetTopBranch() and GetNextKeyBit() ; are actually performed by the Storage Executor. The values being fetched are carried with the op register. For instance, if the function call is GetRKey() then the Storage Executor gets the RKey from the rom.line file, carries it with op as; op[0] = ctx.rkey[0]; op[1] = ctx.rkey[1]; op[2] = ctx.rkey[2]; op[3] = ctx.rkey[3]; where ctx signifies an SMT Action. Also, since all SMT Actions require some hashing, the Storage SM delegates all hashing Actions to the \\(\\text{POSEIDON}\\) SM. However, from within the Storage SM, it is best to treat the \\(\\text{POSEIDON}\\) SM as a blackbox. The Storage Executor simply specifies the sets of twelve values to be digested. And the \\(\\text{POSEIDON}\\) SM then returns the required digests of the values. The Storage PIL All computations executed in the Storage SM must be verifiable. A special Polynomial Identity Language (PIL) code is therefore used to set up all the polynomial constraints the verifier needs to validate correctness of execution. The preparation for these polynomial constraints actually starts in the Storage Executor. In order to accomplish this, the Storage Executor uses; selectors, setters and instructions; which are in fact Boolean polynomials. See the list of these Boolean committed polynomials in Table 2, below. Table 2: Boolean Polynomials For Execution Tracing Selectors Setters Instructions selFree[i] setHashLeft[i] iHash selSiblingValueHash[i] setHashRight[i] iHashType selOldRoot[i] setOldRoot[i] iLatchSet selNewRoot[i] setNewRoot[i] iLatchGet selValueLow[i] setValueLow[i] iClimbRkey selValueHigh[i] setValueHigh[i] iClimbSiblingRkey selRkeyBit[i] setSiblingValueLow[i] iClimbSiblngRkeyN selSiblingRkey[i] setSiblingValueHigh[i] iRotateLevel selRkey[i] setRkey[i] iJmpz setSiblingRkey[i] iConst0 setRkeyBit[i] iConst1 setLevel[i] iConst2 iConst3 iAddress Everytime each of these Boolean polynomials are utilised or performed, a record of a \"1\" is kept in its register. This is called an execution trace . Therefore, instead of performing some expensive computations in order to verify correctness of execution (at times repeating the same computations being verified), the trace of execution is tested. The verifier takes the execution trace, and tests if it satisfies the polynomial constraints (or identities) in the PIL code. This technique helps the zkProver to achieve succintness as a zero-knowledge proof/verification system.","title":"Storage"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#the-storage-state-machine","text":"The Storage State Machine (SM) is responsible for all operations on data stored in the zkProver's storage. It receives instructions from the Main State Machine, called Storage Actions . These Storage Actions are typical database operations; Create, Read, Update and Delete (CRUD). The Storage SM is in fact a micro-processor with the firm-ware and the hardware parts. It is in the firmware part of the Storage SM where the logic and rules are set up, expressed in JSON format and stored in a ROM. A novel language, called the zero-knowledge Assembly (zkASM), has been developed by the team. It is a language especially designed to map instructions from the zkProver's Main SM to other state machines, in this case, to the Storage SM's Executor. The Main SM's instructions, or Storage Actions, are parsed to the Storage SM Executor for execution in compliance with the rules and logic specified in the JSON-file. The hardware part uses another novel language, called Polynomial Identity Language (PIL), which is especially designed for the zkProver, because almost all state machines express computations in terms of polynomials. State transitions in state machines must satisfy computation-specific polynomial identities. The Storage SM's Executor carries out all Storage Actions (executes these operations), and also generates committed and constant polynomials. PIL codes, in the zkProver, are used to check correct execution of SM-specific Actions. They therefore take as inputs all committed and constant polynomials. In order to achieve zero-knowledge, all data is stored in the form of Merkle Trees, which means the Storage SM often makes requests of another state machine, the Poseidon SM , to perform hashing (referred to as \\(\\text{POSEIDON}\\) Actions).","title":"The Storage State Machine"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#about-this-document","text":"This document describes the Storage State Machine and the zkProver's Storage, which the Storage SM interacts with, by either reading or altering data stored in it. This document therefore entails; The basic design of the zkProver's Storage and some preliminaries. i.e., How the Sparse Merkle Trees (SMTs) are built. Explanations of each of the Basic Operations the Storage SM routinely performs. Specific parameters the Storage SM uses, such as, how keys and paths are created, and the two \\(\\text{POSEIDON}\\) Hashes used in the SMTs. As well as, the three main source-codes the Storage SM needs to function effectively. That is, the Storage Assembly code, the Storage Executor (both in C and JavaScript), and the PIL code, for all the polynomial constraints and proving correctness of execution.","title":"About this Document"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#introduction","text":"A generic state machine is characterised by; sets of states (as inputs) stored in registers, instructions to how the states should transition, and the resultant states (as outputs) stored as new values in the same registers. See Figure 1 below, for a standard state machine. A state machine can be monolithic, where it is a prototype of one particular computation, while others may specialise with certain types of computations. Depending on the computational algorithm, a state machine may have to run through a number of state transitions before producing the desired output. Iterations of the same sequence of operations may be required, to the extend that most common state machines are cyclic by nature. Figure 1: A Generic State Machine The Storage SM performs computations on the key-value data stored in special Merkle Trees, called Sparse Merkle Trees (SMTs). The basic operations it executes are; CREATE, READ, UPDATE and DELETE. In the Storage SM, keys and values are strings of 256 bits and, for convenience, can be interpreted as 256-bit unsigned integers The mechanics of the Storage SM and its basic operations are described in detail later in this document. For now, an example of the UPDATE Operation is given in order to illustrate the various components involved.","title":"Introduction"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#storage-design-preliminaries","text":"Storage in the zkProver is designed in such a way that aggregators and verifiers can easily and efficiently interact with stored data. This is data needed for providing zero-knowledge proofs, or verifying state. Data is stored in the form of a special Sparse Merkle Tree (SMT), which is a tree that combines the concept of a Merkle Tree and that of a Patricia tree. What follows is an explanation of how the zkProver storage, as a database, is designed. This design is based on how the Sparse Merkle Trees are constructed and how they store keys and values .","title":"Storage Design - Preliminaries"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#merkle-trees","text":"A typical Merkle tree has leaves , branches and a root . A leaf is a node with no child-nodes, while a branch is a node with child-nodes. A root is therefore a node with no parent-node. See Figure 3 below, for an example of how a hash function \\(\\mathbf{H}\\) is used to create a Merkle tree to record eight (8) values; \\(\\text{V}_{\\mathbf{a}}, \\text{V}_{\\mathbf{b}}, \\text{V}_{\\mathbf{c}}, \\text{V}_{\\mathbf{d}}, \\text{V}_{\\mathbf{e}}, \\text{V}_{\\mathbf{f}}, \\text{V}_{\\mathbf{g}}, \\text{V}_{\\mathbf{h}}\\) ; Each leaf is nothing but the hash \\(\\mathbf{H}(\\text{V}_{\\mathbf{i}})\\) of a particular value \\(\\text{V}_{\\mathbf{i}}\\) , where \\(\\mathbf{ i} \\in \\{ \\mathbf{a}, \\mathbf{b}, \\mathbf{c}, \\mathbf{d}, \\mathbf{e}, \\mathbf{f}, \\mathbf{g}, \\mathbf{h} \\}\\) . The branches; \\(\\mathbf{B}_{\\mathbf{ab}} = \\mathbf{H} \\big( \\mathbf{H}(\\text{V}_{\\mathbf{a}})\\| \\mathbf{H}(\\text{V}_{\\mathbf{b}}) \\big)\\) , \\(\\mathbf{B}_{\\mathbf{cd}} = \\mathbf{H} \\big( \\mathbf{H}(\\text{V}_{\\mathbf{c}})\\| \\mathbf{H}(\\text{V}_{\\mathbf{d}}) \\big)\\) , \\(\\mathbf{B}_{\\mathbf{ef}} = \\mathbf{H} \\big( \\mathbf{H}(\\text{V}_{\\mathbf{e}})\\| \\mathbf{H}(\\text{V}_{\\mathbf{f}}) \\big)\\) , \\(\\mathbf{B}_{\\mathbf{gh}} = \\mathbf{H} \\big( \\mathbf{H}(\\text{V}_{\\mathbf{g}})\\| \\mathbf{H}(\\text{V}_{\\mathbf{h}}) \\big)\\) , \\(\\mathbf{B}_{\\mathbf{abcd}} = \\mathbf{H} \\big(\\mathbf{B}_{\\mathbf{ab}}\\| \\mathbf{B}_{\\mathbf{cd}} \\big)\\) and \\(\\mathbf{B}_{\\mathbf{efgh}} = \\mathbf{H} \\big( \\mathbf{B}_{\\mathbf{ef}}\\| \\mathbf{B}_{\\mathbf{gh}} \\big)\\) . The root is \\(\\mathbf{root}_{\\mathbf{a..h}} = \\mathbf{H} \\big(\\mathbf{B}_{\\mathbf{abcd}}\\| \\mathbf{B}_{\\mathbf{efgh}} \\big)\\) . Figure 3: A Merkle Tree Example Leaves that share a parent-node are called siblings . The same terminology applies to branches. For example, \\(\\mathbf{B}_{\\mathbf{ab}}\\) and \\(\\mathbf{B}_{\\mathbf{cd}}\\) are siblings because they are branches of the same parent, \\(\\mathbf{B}_{\\mathbf{abcd}}\\) . Similarly, \\(\\mathbf{B}_{\\mathbf{efgh}}\\) and \\(\\mathbf{B}_{\\mathbf{abcd}}\\) are siblings.","title":"Merkle Trees"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#using-keys-to-navigate-a-merkle-tree","text":"Keys are used to navigate from the root to the leaves (and backwards). Reading the key starting from the left to the right , and when traversing the tree from the root downwards , a zero-key-bit \" \\(0\\) \" means \" follow the edge going to the left \", a key-bit \" \\(1\\) \" means \" follow the edge going to the right \". Consider the tree in Figure 1 above, as an example. Suppose one is given the key-value pair \\(( K_{\\mathbf{d}} , V_{\\mathbf{d}})\\) , where \\(K_{\\mathbf{d}} = 10010110\\) . The leaf \\(L_{\\mathbf{d}}\\) , storing the value \\(V_{\\mathbf{d}}\\) , is located uniquely by using the key, \\(K_{\\mathbf{d} } = 10010110\\) , as follows; Read the least-significant bit of \\(K_{\\mathbf{d}}\\) , which is \\(0\\) , hence traverse the tree to the left, and reach \\(\\mathbf{B_{abcd}}\\) . Then read the second significant key-bit, which is \" \\(1\\) \" in this case. So take the edge going to the right, reaching \\(\\mathbf{B_{cd}}\\) . Again, read the next key-bit, which is \" \\(1\\) \", hence follow the edge going to the right, reaching the leaf \\(\\mathbf{H}( V_{\\mathbf{d}} )\\) . Since \\(\\mathbf{H}( V_{\\mathbf{d}})\\) is a leaf and not a branch, and the navigation was correctly done with respect to the given key \\(K_{\\mathbf{d}}\\) , the \\(\\mathbf{H}( V_{\\mathbf{d}})\\) must be the leaf storing the value \\(V_{\\mathbf{d}}\\) . One can similarly \"climb\" the tree, going in the reverse direction, by using the key-bits of the given key in the reverse order. i.e., Starting with the last key-bit used to reach the leaf and ending with the least-significant bit of the key. The tree-address of the value \\(V_{\\mathbf{x}}\\) , herein refers to the position of the leaf \\(L_{\\mathbf{x}} := \\mathbf{H}( V_{\\mathbf{x}})\\) , denoted by the key-bits used to reach \\(L_{\\mathbf{d}}\\) but in the reverse order. In the above example (i.e., The tree in Figure 1), the tree-address of \\(V_{\\mathbf{d}}\\) is 011 .","title":"Using Keys To Navigate A Merkle Tree"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#a-merkle-proof-example","text":"Merkle Trees can be used as commitment schemes. Here's an example that follows the (key,value)-pair approach used in the zkProver. Consider the Merkle Tree shown in Figure 3 above. If the prover has committed to a value \\(\\text{V}_{\\mathbf{f}}\\) by appending a new leaf \\(\\mathbf{H}(\\text{V}_{\\mathbf{f}})\\) to the Merkle Tree as in Figure 3 , he must then avail the following information, to enable verification of his claim; The Merkle root \\(\\mathbf{root}_{\\mathbf{a..h}}\\) , The value \\(\\text{V}_{\\mathbf{f}}\\) , The siblings; \\(\\mathbf{H}(\\text{V}_{\\mathbf{e}})\\) , \\(\\mathbf{B}_{\\mathbf{gh}}\\) and \\(\\mathbf{B}_{\\mathbf{abcd}}\\) . Instead of searching through all hash values stored in the tree, the verifier uses only a few hash values of relevant siblings. That is, three (3) in this case. The verifier then checks the prover's claim by computing the Merkle root as follows; \u200b (a) He computes \\(\\mathbf{H}(\\text{V}_{\\mathbf{f}})\\) , which is the hash of the value \\(\\text{V}_{\\mathbf{f}}\\) . \u200b (b) Then uses the sibling \\(\\mathbf{H}(\\text{V}_{\\mathbf{e}})\\) to compute \\(\\mathbf{H} \\big( \\mathbf{H}(\\text{V}_{\\mathbf{e}})\\|\\mathbf{H}(\\text{V}_{\\mathbf{f}}) \\big) =: \\tilde{ \\mathbf{B}}_{\\mathbf{ef}}\\) , which should be the same as the branch node \\(\\mathbf{B}_{\\mathbf{ef}}\\) . ( Note. The symbol, tilde \" \\(\\tilde{ }\\) \", is used throughout the document to indicate that the computed value, \\(\\tilde{\\Box}\\) , still needs to be checked, or tested to be true.) \u200b (c) Next, he computes \\(\\mathbf{H} \\big( \\tilde{ \\mathbf{B}}_{\\mathbf{ef}}\\|\\mathbf{B}_{\\mathbf{gh}} \\big) =: \\tilde{ \\mathbf{B}}_{\\mathbf{efgh}}\\) , corresponding to the branch node \\(\\mathbf{B}_{\\mathbf{efgh}}\\) . \u200b (d) Now, uses \\(\\mathbf{H} \\big( \\mathbf{B}_{\\mathbf{abcd}}\\| \\tilde{ \\mathbf{B}}_{\\mathbf{efgh}} \\big) =: \\tilde{ \\mathbf{root}}_{\\mathbf{a..h}}\\) . The Merkle proof is concluded by checking whether \\(\\tilde{ \\mathbf{root}}_{\\mathbf{a\\dots h}}\\) equals to the publicly known root \\(\\mathbf{root}_{\\mathbf{a..h}}\\) .","title":"A Merkle Proof Example"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#building-simplified-binary-sparse-merkle-trees","text":"Consider key-value pair based binary Sparse Merkle Trees (SMTs). The focus here is on explaining how to build an SMT that represents a given set of key-value pairs. And, for simplicity sake, key-lengths of 8 bits are assumed. A NULL or empty SMT has a zero root. That is, no key and no value recorded. Similarly, a zero node or NULL node refers to a node that carry no value.","title":"Building Simplified Binary Sparse Merkle Trees"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#a-binary-smt-with-one-key-value-pair","text":"A binary SMT with a single key-value pair \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) , is built as follows. Suppose that the key, \\(K_{\\mathbf{a}} = 11010110\\) . In order to build a binary SMT with this single key-value \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) , (a) One computes the hash \\(\\mathbf{H}( \\text{V}_{\\mathbf{a}})\\) of the value \\(\\text{V}_{\\mathbf{a}}\\) , (b) Sets the leaf \\(\\mathbf{L}_{\\mathbf{a}} := \\mathbf{H}( \\text{V}_{\\mathbf{a}})\\) , (c) Sets the sibling leaf as a NULL leaf, simply represented as \" \\(\\mathbf{0}\\) \", (d) Computes the root as \\(\\mathbf{root}_{a0} = \\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{0} )\\) , with the leaf \\(\\mathbf{L}_{\\mathbf{a}}\\) on the left because the \\(\\text{lsb}(K_{\\mathbf{a}}) = 0\\) . That is, between the two edges leading up to the root, the leaf \\(\\mathbf{L}_{\\mathbf{a}}\\) is on the left edge, while the NULL leaf \" \\(\\mathbf{0}\\) \" is on the right. See, Figure 4 below, for the SMT representing the single key-value pair \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) , where \\(K_{\\mathbf{a}} = 11010110\\) . Figure 4: A Single key-value pair SMT Note that the last nodes in binary SMT branches are generally either leaves or zero-nodes. In the case where the least-significant bit, lsb of \\(K_{\\mathbf{a}}\\) is \\(1\\) , the SMT with a single key-value pair \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) would be a mirror image of what is seen in Figure 3. And its root, \\(\\mathbf{root}_{0a} = \\mathbf{H}( \\mathbf{0}\\| \\mathbf{L}_{\\mathbf{a}} ) \\neq \\mathbf{root}_{a0}\\) because \\(\\mathbf{H}\\) is a collision-resistant hash function. This example also explains why we need a zero node. Since all trees used in our design are binary SMTs, a zero node is used as a default sibling for computing the parent node. This helps to differentiate between roots (also between parent nodes) because a root node actually identifies an SMT. Therefore, it is crucial to distinguish between \\(\\mathbf{root}_{a0} = \\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{0} )\\) and \\(\\mathbf{root}_{0a} = \\mathbf{H}( \\mathbf{0}\\| \\mathbf{L}_{\\mathbf{a}})\\) because they represent two distinct trees.","title":"A Binary SMT With One Key-Value Pair"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#binary-smts-with-two-key-value-pairs","text":"Consider now SMTs with two key-value pairs , \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) and \\((K_{\\mathbf{b}}, \\text{V}_{\\mathbf{b}})\\) . There are three distinct cases of how corresponding SMTs can be built, each determined by the keys, \\(K_{\\mathbf{a}}\\) and \\(K_{\\mathbf{b}}\\) . Case 1 : The keys are such that the \\(\\text{lsb}(K_{\\mathbf{a}}) = 0\\) and the \\(\\text{lsb}(K_{\\mathbf{b}}) = 1\\) . Suppose that the keys are given as, \\(K_{\\mathbf{a}} = 11010110\\) and \\(K_{\\mathbf{b}} = 11010101\\) . To build a binary SMT with this two key-values, \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) and \\((K_{\\mathbf{b}}, \\text{V}_{\\mathbf{b}})\\) , (a) One computes the hashes, \\(\\mathbf{H}(\\text{V}_{\\mathbf{a}})\\) and \\(\\mathbf{H}( \\text{V}_{\\mathbf{b}})\\) of the values, \\(\\text{V}_{\\mathbf{a}}\\) and \\(\\text{V}_{\\mathbf{b}}\\) , respectively, (b) Sets the leaves, \\(\\mathbf{L}_{\\mathbf{a}} := \\mathbf{H}( \\text{V}_{\\mathbf{a}})\\) and \\(\\mathbf{L}_{\\mathbf{b}} := \\mathbf{H}( \\text{V}_{\\mathbf{b}})\\) , (c) Checks if the \\(\\text{lsb}(K_{\\mathbf{a}})\\) differs from the \\(\\text{lsb}(K_{\\mathbf{b}})\\) , (d) Since the \\(\\text{lsb}(K_{\\mathbf{a}}) = 0\\) and the \\(\\text{lsb}(K_{\\mathbf{b}}) = 1\\) , it means the two leaves can be siblings , (e) One can then compute the root as, \\(\\mathbf{root}_{\\mathbf{ab}} = \\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{L}_{\\mathbf{b}})\\) . \u200b Note that, the leaf \\(\\mathbf{L}_{\\mathbf{a}}\\) is on the left because the \\(\\text{lsb}(K_{\\mathbf{a}}) = 0\\) , but \\(\\mathbf{L}_{\\mathbf{b}}\\) is on the right because the \\(\\text{lsb}(K_{\\mathbf{b}}) = 1\\) . That is, between the two edges leading up to the \\(\\mathbf{root}_{\\mathbf{ab}}\\) , the leaf \\(\\mathbf{L}_{\\mathbf{a}}\\) must be on the edge from the left, while \\(\\mathbf{L}_{\\mathbf{b}}\\) is on the edge from the right. See, Figure 5(a) below, for the SMT representing the two key-value pairs \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) and \\((K_{\\mathbf{b}}, \\text{V}_{\\mathbf{b}})\\) , where \\(K_{\\mathbf{a}} = 11010110\\) and \\(K_{\\mathbf{b}} = 11010101\\) . Figure 5(a): Two key-value pairs SMT - Case 1 Case 2 : Both keys end with the same key-bit. That is, the \\(\\text{lsb}(K_{\\mathbf{a}}) = \\text{lsb}(K_{\\mathbf{b}})\\) , but their second least-significant bits differ. Suppose that the two keys are given as, \\(K_{\\mathbf{a}} = 11010100\\) and \\(K_{\\mathbf{b}} = 11010110\\) . To build a binary SMT with this two key-values, \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) and \\((K_{\\mathbf{b}}, \\text{V}_{\\mathbf{b}})\\) ; (a) One computes the hashes, \\(\\mathbf{H}(\\text{V}_{\\mathbf{a}})\\) and \\(\\mathbf{H}( \\text{V}_{\\mathbf{b}})\\) of the values, \\(\\text{V}_{\\mathbf{a}}\\) and \\(\\text{V}_{\\mathbf{b}}\\) , respectively. (b) Sets the leaves, \\(\\mathbf{L}_{\\mathbf{a}} := \\mathbf{H}( \\text{V}_{\\mathbf{a}})\\) and \\(\\mathbf{L}_{\\mathbf{b}} := \\mathbf{H}( \\text{V}_{\\mathbf{b}})\\) . (c) Checks if the \\(\\text{lsb}(K_{\\mathbf{a}})\\) differs from the \\(\\text{lsb}(K_{\\mathbf{b}})\\) . Since the \\(\\text{lsb}(K_{\\mathbf{a}}) = 0\\) and the \\(\\text{lsb}(K_{\\mathbf{b}}) = 0\\) , it means the two leaves cannot be siblings at this position because it would otherwise mean they share the same tree-address 0 , which is not allowed. (d) One, therefore, continues to check if the second least-significant bits of \\(K_{\\mathbf{a}}\\) and \\(K_{\\mathbf{b}}\\) differ. Since the \\(\\text{second lsb}(K_{\\mathbf{a}}) = 0\\) and the \\(\\text{second lsb}(K_{\\mathbf{b}}) = 1\\) , it means the two leaves \\(\\mathbf{L}_{\\mathbf{a}}\\) and \\(\\mathbf{L}_{\\mathbf{b}}\\) can be siblings at their respective tree-addresses, 00 and 10 . (e) Next is to compute the hash \\(\\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{L}_{\\mathbf{b}})\\) and set it as the branch \\(\\mathbf{B}_{\\mathbf{ab}} := \\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{L}_{\\mathbf{b}})\\) at the tree-address 0 . Note that the leaf \\(\\mathbf{L}_{\\mathbf{a}}\\) is on the left because the \\(\\text{second lsb}(K_{\\mathbf{a}}) = 0\\) , while \\(\\mathbf{L}_{\\mathbf{b}}\\) is on the right because the \\(\\text{second lsb}(K_{\\mathbf{b}}) = 1\\) . (f) The branch \\(\\mathbf{B}_{\\mathbf{ab}} := \\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{L}_{\\mathbf{b}})\\) needs a sibling. Since all the values, \\(\\text{V}_{\\mathbf{a}}\\) and \\(\\text{V}_{\\mathbf{b}}\\) , are already represented in the tree at \\(\\mathbf{L}_{\\mathbf{a}}\\) and \\(\\mathbf{L}_{\\mathbf{b}}\\) , respectively, one therefore sets a NULL leaf \" \\(\\mathbf{0}\\) \" as the sibling leaf to \\(\\mathbf{B}_{\\mathbf{ab}}\\) . (g) As a result, it is possible to compute the root as, \\(\\mathbf{root}_{\\mathbf{ab0}} = \\mathbf{H}(\\mathbf{B}_{\\mathbf{ab}} \\| \\mathbf{0})\\) . Note that, the branch \\(\\mathbf{B}_{\\mathbf{ab}}\\) is on the left because the \\(\\text{lsb}(K_{\\mathbf{a}}) = 0\\) , and \\(\\mathbf{0}\\) must therefore be on the right. That is, between the two edges leading up to the \\(\\mathbf{root}_{\\mathbf{ab0}}\\) , the branch \\(\\mathbf{B}_{\\mathbf{ab}}\\) must be on the edge from the left, while \\(\\mathbf{0}\\) is on the edge from the right. See, Figure 5(b) below, depicting the SMT representing the two key-value pairs \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) and \\((K_{\\mathbf{b}}, \\text{V}_{\\mathbf{b}})\\) , where \\(K_{\\mathbf{a}} = 11010100\\) and \\(K_{\\mathbf{b}} = 11010110\\) . Figure 5(b): Two key-value pairs SMT - Case 2 Case 3 : The first two least-significant bits of both keys are the same, but their third least-significant bits differ. Suppose that the two keys are given as, \\(K_{\\mathbf{a}} = 11011000\\) and \\(K_{\\mathbf{b}} = 10010100\\) . The process for building a binary SMT with this two key-values, \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) and \\((K_{\\mathbf{b}}, \\text{V}_{\\mathbf{b}})\\) is the same as in Case 2; (a) One computes the hashes, \\(\\mathbf{H}(\\text{V}_{\\mathbf{a}})\\) and \\(\\mathbf{H}( \\text{V}_{\\mathbf{b}})\\) of the values, \\(\\text{V}_{\\mathbf{a}}\\) and \\(\\text{V}_{\\mathbf{b}}\\) , respectively. (b) Sets the leaves, \\(\\mathbf{L}_{\\mathbf{a}} := \\mathbf{H}( \\text{V}_{\\mathbf{a}})\\) and \\(\\mathbf{L}_{\\mathbf{b}} := \\mathbf{H}( \\text{V}_{\\mathbf{b}})\\) . (c) Checks if the \\(\\text{lsb}(K_{\\mathbf{a}})\\) differs from the \\(\\text{lsb}(K_{\\mathbf{b}})\\) . Since the \\(\\text{lsb}(K_{\\mathbf{a}}) = 0\\) and the \\(\\text{lsb}(K_{\\mathbf{b}}) = 0\\) , it means the two leaves cannot be siblings at this position as it would otherwise mean they share the same tree-address 0 , which is not allowed. (d) Next verifier coninues to check if the second least-significant bits of \\(K_{\\mathbf{a}}\\) and \\(K_{\\mathbf{b}}\\) differ. Since the \\(\\text{second lsb}(K_{\\mathbf{a}}) = 0\\) and the \\(\\text{second lsb}(K_{\\mathbf{b}}) = 0\\) , it means the two leaves cannot be siblings at this position, because it would otherwise mean they share the same tree-address 00 , which is not allowed. (e) Once again he checks if the third least-significant bits of \\(K_{\\mathbf{a}}\\) and \\(K_{\\mathbf{b}}\\) differ. Since the \\(\\text{third lsb}(K_{\\mathbf{a}}) = 0\\) and the \\(\\text{third lsb}(K_{\\mathbf{b}}) = 1\\) , it means the two leaves \\(\\mathbf{L}_{\\mathbf{a}}\\) and \\(\\mathbf{L}_{\\mathbf{b}}\\) can be siblings at their respective tree-addresses, 000 and 100 . (f) One then computes the hash \\(\\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{L}_{\\mathbf{b}})\\) , and sets it as the branch \\(\\mathbf{B}_{\\mathbf{ab}} := \\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{L}_{\\mathbf{b}})\\) at the tree-address 00 . The leaf \\(\\mathbf{L}_{\\mathbf{a}}\\) is on the left because the third \\(\\text{lsb}(K_{\\mathbf{a}}) = 0\\) , while \\(\\mathbf{L}_{\\mathbf{b}}\\) is on the right because the third \\(\\text{lsb}(K_{\\mathbf{b}}) = 1\\) . (g) The branch \\(\\mathbf{B}_{\\mathbf{ab}} := \\mathbf{H}(\\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{L}_{\\mathbf{b}})\\) needs a sibling. Since all the values, \\(\\text{V}_{\\mathbf{a}}\\) and \\(\\text{V}_{\\mathbf{b}}\\) , are already represented in the tree at \\(\\mathbf{L}_{\\mathbf{a}}\\) and \\(\\mathbf{L}_{\\mathbf{b}}\\) , respectively, one therefore sets a NULL leaf \" \\(\\mathbf{0}\\) \" as the sibling leaf to \\(\\mathbf{B}_{\\mathbf{ab}}\\) . (h) One can now compute the hash \\(\\mathbf{H}(\\mathbf{B}_{\\mathbf{ab}} \\| \\mathbf{0})\\) , and set it as the branch \\(\\mathbf{B}_{\\mathbf{ab0}} := \\mathbf{H}(\\mathbf{B}_{\\mathbf{ab}} \\| \\mathbf{0})\\) at the tree-address 0 . The hash is computed with the branch \\(\\mathbf{B}_{\\mathbf{ab}}\\) on the left because the second lsb of both keys, \\(K_{\\mathbf{a}}\\) and \\(K_{\\mathbf{b}}\\) , equals \\(0\\) . Therefore the NULL leaf \" \\(\\mathbf{0}\\) \" must be on the right as an argument to the hash. (i) The branch \\(\\mathbf{B}_{\\mathbf{ab0}} := \\mathbf{H}(\\mathbf{B}_{\\mathbf{ab}} \\| \\mathbf{0})\\) also needs a sibling. For the same reason given above, one sets a NULL leaf \" \\(\\mathbf{0}\\) \" as the sibling leaf to \\(\\mathbf{B}_{\\mathbf{ab0}}\\) . (j) Now, one is able to compute the root as, \\(\\mathbf{root}_{\\mathbf{ab00}} = \\mathbf{H}(\\mathbf{B}_{\\mathbf{ab0}} \\| \\mathbf{0})\\) . Note that the hash is computed with the branch \\(\\mathbf{B}_{\\mathbf{ab0}}\\) on the left because the lsb of both keys, \\(K_{\\mathbf{a}}\\) and \\(K_{\\mathbf{b}}\\) , equals \\(0\\) . That is, between the two edges leading up to the \\(\\mathbf{root}_{\\mathbf{ab00}}\\) , the branch \\(\\mathbf{B}_{\\mathbf{ab0}}\\) must be on the edge from the left, while \" \\(\\mathbf{0}\\) \" is on the edge from the right. See, Figure 5(c) below, depicting the SMT representing the two key-value pairs \\((K_{\\mathbf{a}}, \\text{V}_{\\mathbf{a}})\\) and \\((K_{\\mathbf{b}}, \\text{V}_{\\mathbf{b}})\\) , where \\(K_{\\mathbf{a}} = 11011000\\) and \\(K_{\\mathbf{b}} = 10010100\\) . Figure 5(c): Two key-value pairs SMT - Case 3 There are several other SMTs of two key-value pairs \\((K_{\\mathbf{x}}, \\text{V}_{\\mathbf{x}})\\) and \\((K_{\\mathbf{z}}, \\text{V}_{\\mathbf{z}})\\) that can be constructed depending on how long are the strings of the common least-significant bits between \\(K_{\\mathbf{x}}\\) and \\(K_{\\mathbf{z}}\\) . In general, when building an SMT, leaves of key-value pairs with the same least-significant key-bits share the same \"navigational path\" only until any of the corresponding key-bits differ. These common strings of key-bits dictate where the leaf storing the corresponding value is located in the tree.","title":"Binary SMTs With Two Key-Value Pairs"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#a-few-more-concepts-about-binary-smts","text":"In here are a few more concepts needed in understanding our specific design of the zkProver storage using binary SMTs. These concepts also help in elucidating how keys influence the shape of binary SMTs. First is the level of a leaf. The level of a leaf , \\(\\mathbf{L}_{\\mathbf{x}}\\) , in a binary SMT is defined as the number of edges one traverses when navigating from the root to the leaf. Denote the level of the leaf \\(\\mathbf{L_x}\\) by \\(\\text{lvl}(\\mathbf{L_x})\\) .","title":"A Few More Concepts About Binary SMTs"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#example-1-leaf-levels","text":"Consider Figure 6 below, for an SMT storing seven (7) key-value pairs, built by following the principles explained in the foregoing subsection; \\[\\begin{aligned} (\\mathbf{K}_{\\mathbf{a}} , V_{\\mathbf{a}}),\\ \\ (\\mathbf{K}_{\\mathbf{b}} , V_{\\mathbf{b}}),\\ \\ (\\mathbf{K}_{\\mathbf{c}} , V_{\\mathbf{c}}),\\ \\ (\\mathbf{K}_{\\mathbf{c}}, V_{\\mathbf{c}}),\\\\ (\\mathbf{K}_{\\mathbf{d}}, V_{\\mathbf{d}}),\\ \\ (\\mathbf{K}_{\\mathbf{e}}, V_{\\mathbf{e}}),\\ \\ (\\mathbf{K}_{\\mathbf{f}}, V_{\\mathbf{f}})\\ \\ {\\text{and}}\\ \\ (\\mathbf{K}_{\\mathbf{g}} , V_{\\mathbf{g}}) \\end{aligned}\\] where the keys are, \\[\\begin{aligned} K_{\\mathbf{a}} = 10101100, K_{\\mathbf{b}} = 10010010, K_{\\mathbf{c}} = 10001010, &K_{\\mathbf{d}} = 11100110,\\\\ K_{\\mathbf{e}} = 11110101, K_{\\mathbf{f}} = 10001011, K_{\\mathbf{g}} = 00011111. \\end{aligned}\\] The leaf levels are as follows; \\(\\text{lvl}(\\mathbf{L}_{\\mathbf{a}}) = 2\\) , \\(\\text{lvl}(\\mathbf{L}_{\\mathbf{b}}) = 4\\) , \\(\\text{lvl}(\\mathbf{L}_{\\mathbf{c}}) = 4\\) , \\(\\text{lvl}(\\mathbf{L}_{\\mathbf{d}}) = 3\\) , \\(\\text{lvl}(\\mathbf{L}_{\\mathbf{e}}) = 2\\) , \\(\\text{lvl}(\\mathbf{L}_{\\mathbf{f}}) = 3\\) and \\(\\text{lvl}(\\mathbf{L}_{\\mathbf{g}}) = 3\\) . Figure 6: An SMT of 7 key-value pairs As illustrated, in the above subsections, keys basically determine the shape of the SMT. They dictate where respective leaves must be placed when building the SMT. The main determining factor of the SMT shape is in fact the common key-bits among the keys. For instance, the reason why the leaves \\(\\mathbf{L}_{\\mathbf{b}}\\) and \\(\\mathbf{L}_{\\mathbf{c}}\\) have the largest leaf level \\(4\\) is because the two leaves have the longest string of common key-bits \" \\(010\\) \" in the SMT of Figure 6 above. This explains why different leaves in SMTs can have different levels. The height of a Merkle Tree refers to the largest number of edges traversed when navigating from the root to any leaf. Since all leaves are of the same level in Merkle Trees, the concept of a height coincide with that of the level of a leaf for Merkle Trees. But this is not the case for SMTs. Since leaf levels differ from one leaf to another in SMTs, the height of an SMT is not the same as the leaf level. Rather, the height of an SMT is defined as the largest leaf level among the various leaf levels of leaves on the SMT. For instance, the height of the SMT depicted in Figure 6 above, is \\(4\\) . Now, since all keys have the same fixed key-length, they not only influence SMT leaf levels and shapes, but also restrict SMT heights to the fixed key-length. The maximum height of an SMT is the maximum key-length imposed on all keys.","title":"Example 1. Leaf Levels"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#the-remaining-key","text":"In a general Sparse Merkle Tree (SMT) values are stored at their respective leaf-nodes. But a leaf node \\(\\mathbf{L}_{\\mathbf{x}}\\) not only stores a value, \\(V_{\\mathbf{x}}\\) , but also the key-bits that are left unused in the navigation from the root to \\(\\mathbf{L}_{\\mathbf{x}}\\) . These unused key-bits are called the remaining key , and are denoted by \\(\\text{RK}_{\\mathbf{x}}\\) for the leaf node \\(\\mathbf{L}_{\\mathbf{x}}\\) .","title":"The Remaining Key"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#example-2-remaining-keys","text":"Consider again the SMT of the 7 key-value pairs depicted in Figure 6 above. The remaining keys of each of the 7 leaves in the SMT are as follows; \\(\\text{RK}_{\\mathbf{a}} = 110101\\) , \\(\\text{RK}_{\\mathbf{b}} = 1001\\) , \\(\\text{RK}_{\\mathbf{c}} = 0001\\) , \\(\\text{RK}_{\\mathbf{d}} = 00111\\) , \\(\\text{RK}_{\\mathbf{e}} = 101111\\) , \\(\\text{RK}_{\\mathbf{f}} = 10001\\) and \\(\\text{RK}_{\\mathbf{g}} = 11000\\) .","title":"Example 2. Remaining Keys"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#the-fake-leaf-attack","text":"Note that the above simplified design of binary SMTs, based on key-value pairs, presents some problems. The characteristic of binary SMTs having leaves at different levels can be problematic to verifiers, especially when carrying out a simple Merkle proof.","title":"The Fake-Leaf Attack"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#scenario-a-fake-smt-leaf","text":"What if the verifier is presented with a fake leaf? Consider Figure 7 below, showing a binary SMT with a branch \\(\\mathbf{{B}_{ab}}\\) and its children \\(\\mathbf{L_{a}}\\) and \\(\\mathbf{L_{b}}\\) hidden from the verifier's sight. That is, suppose the verifier is provided with the following information; The key-value \\((K_{\\mathbf{fk}}, V_\\mathbf{{fk}})\\) , where \\(K_{\\mathbf{fk}} = 11010100\\) and \\(V_{\\mathbf{fk}} = \\mathbf{L_{a}} \\| \\mathbf{L_{b}}\\) . The root \\(\\mathbf{{root}_{ab..f}}\\) , the number of levels to root, and the siblings \\(\\mathbf{{S}_{\\mathbf{cd}}}\\) and \\(\\mathbf{{S}_{\\mathbf{ef}}}\\) . That is, the Attacker claims that some \\(V_{\\mathbf{fk}}\\) is stored at \\(\\mathbf{L_{fk}} := \\mathbf{{B}_{ab}}\\) . Verifier is unaware that \\(V_{\\mathbf{fk}}\\) is in fact the concatenated value of the hidden real leaves, \\(\\mathbf{L_{a}}\\) and \\(\\mathbf{L_{b}}\\) , that are children of the supposed leaf \\(\\mathbf{L_{fk}}\\) . i.e., Verifier does not know that leaf \\(\\mathbf{L_{fk}}\\) is in fact a branch. Figure 7: MPT - Fake Leaf Attack So then, the verifier being unaware that \\(\\mathbf{L_{fk}}\\) is not a properly constructed leaf, starts verification as follows; He uses the key \\(K_{\\mathbf{fk}}\\) to navigate the tree until locating the supposed leaf \\(\\mathbf{L_{fk}}\\) . He computes \\(\\mathbf{H}(V_{\\mathbf{fk}})\\) and sets it as \\(\\tilde{\\mathbf{L}}_{\\mathbf{fk}} := \\mathbf{H}(V_{\\mathbf{fk}})\\) . Then takes the sibling \\(\\mathbf{{S}_{\\mathbf{cd}}}\\) and calculates \\(\\tilde{ \\mathbf{B}}_{\\mathbf{fkcd}} = \\mathbf{H} \\big( \\tilde{\\mathbf{L}}_{\\mathbf{fk}} \\| \\mathbf{S}_{\\mathbf{cd}} \\big)\\) . And then, uses \\(\\tilde{ \\mathbf{B}}_{\\mathbf{fkcd}}\\) to compute the root, \\(\\tilde{ \\mathbf{root}}_{\\mathbf{ab..f}} = \\mathbf{H} \\big( \\tilde{ \\mathbf{B}}_{\\mathbf{fkcd}}\\| \\mathbf{S}_{\\mathbf{ef}} \\big)\\) . The question is: \"Does the fake leaf \\(\\mathbf{L_{fk}}\\) pass the verifier's Merkle proof or not?\" Or, equivalently: \"Is \\(\\tilde{ \\mathbf{root}}_{\\mathbf{ab..f}}\\) equal to \\(\\mathbf{root}_{\\mathbf{ab..f}}\\) ?\" Since the actual branch \\(\\mathbf{{B}_{ab}}\\) is by construction the hash, \\(\\mathbf{H}(\\mathbf{L_{a}} \\| \\mathbf{L_{b}})\\) , then \\(\\mathbf{{B}_{ab}} = \\tilde{\\mathbf{L}}_{\\mathbf{fk}}\\) . The parent branch \\({\\mathbf{B}}_{\\mathbf{abcd}}\\) also, being constructed as the hash, \\(\\mathbf{H} \\big( \\mathbf{B}_{\\mathbf{ab}}\\| { \\mathbf{S}}_{\\mathbf{cd}} \\big)\\) , should be equal to \\(\\mathbf{H} \\big( \\tilde{\\mathbf{L}}_{\\mathbf{fk}} \\| \\mathbf{S}_{\\mathbf{cd}} \\big) = \\tilde{ \\mathbf{B}}_{\\mathbf{fkcd}}\\) . As a result, \\(\\mathbf{root}_{\\mathbf{ab..f}} = \\mathbf{H} \\big( {\\mathbf{B}}_{\\mathbf{abcd}} \\| \\mathbf{S}_{\\mathbf{ef}} \\big) = \\mathbf{H} \\big( \\tilde{ \\mathbf{B}}_{\\mathbf{fkcd}}\\| \\mathbf{S}_{\\mathbf{ef}} \\big) = \\tilde{ \\mathbf{root}}_{\\mathbf{ab..f}}\\) . Therefore, the fake leaf \\(\\mathbf{L_{fk}}\\) passes the Merkle proof.","title":"Scenario A: Fake SMT Leaf"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#solution-to-the-fake-leaf-attack","text":"In order to circumvent the Fake-Leaf Attack we modify how the binary SMTs are built. Here's the trick : When building binary SMTs, differentiate between how leaves are hashed and how branches are hashed. That is, use two different hash functions; one hash function to hash leaves, denote it by \\(\\mathbf{H}_{\\mathbf{leaf}}\\) , and the other function for hashing non-leaf nodes, denote it by \\(\\mathbf{H}_{\\mathbf{noleaf}}\\) . How does this prevent the Fake-Leaf Attack? Reconsider now, the Scenario A, given above. Recall that the Attacker provides the following; The key-value \\((K_{\\mathbf{fk}}, V_\\mathbf{{fk}})\\) , where \\(K_{\\mathbf{fk}} = 11010100\\) and \\(V_{\\mathbf{fk}} = \\mathbf{L_{a}} \\| \\mathbf{L_{b}}\\) . The root $ \\mathbf{{root}_{ab..f}}$ , the number of levels to root, and the siblings \\(\\mathbf{{S}_{\\mathbf{cd}}}\\) and \\(\\mathbf{{S}_{\\mathbf{ef}}}\\) . The verifier suspecting no foul, uses \\(K_{\\mathbf{fk}} = 11010100\\) to navigate the tree until he finds \\(V_{\\mathbf{fk}}\\) stored at \\(\\mathbf{L_{fk}} := \\mathbf{{B}_{ab}}\\) . He subsequently starts the Merkle proof by hashing the value \\(\\tilde{V}_{\\mathbf{fk}}\\) stored at the located leaf. Since, this computation amounts to forming a leaf, he uses the leaf-hash function, \\(\\mathbf{H}_{\\mathbf{leaf}}\\) . He then sets \\(\\tilde{\\mathbf{L}}_{\\mathbf{fk}} := \\mathbf{H}_{\\mathbf{leaf}} \\big( V_{\\mathbf{fk}} \\big) = \\mathbf{H}_{\\mathbf{leaf}} \\big( \\mathbf{L_{a}} \\| \\mathbf{L_{b}} \\big)\\) . And further computes \\(\\tilde{ \\mathbf{B}}_{\\mathbf{fkcd}} = \\mathbf{H}_{\\mathbf{noleaf}} \\big( \\tilde{\\mathbf{L}}_{\\mathbf{fk}} \\| \\mathbf{S}_{\\mathbf{cd}} \\big)\\) . Again, calculates the root, \\(\\tilde{ \\mathbf{root}}_{\\mathbf{ab..f}} = \\mathbf{H}_{\\mathbf{noleaf}} \\big( \\tilde{ \\mathbf{B}}_{\\mathbf{fkcd}}\\| \\mathbf{S}_{\\mathbf{ef}} \\big)\\) . But the actual branch \\(\\mathbf{{B}_{ab}}\\) was constructed with the no-leaf-hash function, \\(\\mathbf{H}_{\\mathbf{noleaf}}\\) . That is, \\[\\begin{aligned} \\mathbf{{B}_{ab}} = \\mathbf{H}_{\\mathbf{noleaf}} (\\mathbf{L_{a}} \\| \\mathbf{L_{b}}) \\neq \\mathbf{H}_{\\mathbf{leaf}} \\big(\\mathbf{L_{a}} \\| \\mathbf{L_{b}} \\big) = \\tilde{\\mathbf{L}}_{\\mathbf{fk}}. \\end{aligned}\\] The parent branch \\({\\mathbf{B}}_{\\mathbf{abcd}}\\) also, was constructed as, \\({\\mathbf{B}}_{\\mathbf{abcd}} = \\mathbf{H}_{\\mathbf{noleaf}} \\big( \\mathbf{B}_{\\mathbf{ab}}\\| { \\mathbf{S}}_{\\mathbf{cd}} \\big)\\) . Since the hash functions used are collision-resistant, \\({\\mathbf{B}}_{\\mathbf{abcd}}\\) cannot be equal to \\(\\mathbf{H}_{\\mathbf{noleaf}} \\big( \\tilde{\\mathbf{L}}_{\\mathbf{fk}} \\| \\mathbf{S}_{\\mathbf{cd}} \\big) = \\tilde{ \\mathbf{B}}_{\\mathbf{fkcd}}\\) . Consequently, \\(\\mathbf{root}_{\\mathbf{ab..f}} \\neq \\tilde{ \\mathbf{root}}_{\\mathbf{ab..f}}\\) . Therefore, the Merkle Proof fails.","title":"Solution To The Fake-Leaf Attack"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#non-binding-key-value-pairs","text":"Whenever the verifier needs to check inclusion of the given key-value pair \\((K_{\\mathbf{x}}, \\text{V}_{\\mathbf{x}})\\) in a binary SMT identified by the \\(\\mathbf{{root}_{a..x}}\\) , he first navigates the SMT in order to locate the leaf \\(\\mathbf{{L}_{x}}\\) storing \\(\\text{V}_{\\mathbf{x}}\\) , and thereafter carries out two computations. Both computations involve climbing the tree from the located leaf \\(\\mathbf{{L}_{x}}\\) back to the root, \\(\\mathbf{{root}_{a..x}}\\) . And the two computations are; Checking correctness of the key \\(K_{\\mathbf{x}}\\) . That is, verifier takes the Remaining Key, \\(\\text{RK}_{\\mathbf{x}}\\) , and reconstructs the key \\(K_{\\mathbf{x}}\\) by concatenating the key bits used to navigate to \\(\\mathbf{{L}_{x}}\\) from \\(\\mathbf{{root}_{a..x}}\\) , in the reverse order. Suppose the number of levels to root is 3, and the least-significant bits used for navigation are \\(\\text{kb}_\\mathbf{2}\\) , \\(\\text{kb}_\\mathbf{1}\\) and \\(\\text{kb}_\\mathbf{0}\\) . In order to check key-correctness, verifier the remaining key \\(\\text{RK}\\) and, (a) Concatenates \\(\\text{kb}_\\mathbf{2}\\) and gets \\(\\text{ } \\text{RK} \\| \\text{kb}_\\mathbf{2}\\) , (b) Concatenates \\(\\text{kb}_\\mathbf{1}\\) then gets \\(\\text{ } \\text{RK} \\| \\text{kb}_\\mathbf{2} \\| \\text{kb}_\\mathbf{1}\\) , (c) Concatenates \\(\\text{kb}_\\mathbf{0}\\) and gets \\(\\text{ } \\text{RK} \\| \\text{kb}_\\mathbf{2} \\| \\text{kb}_\\mathbf{1} \\| \\text{kb}_\\mathbf{0}\\) . He then sets \\(\\tilde{K}_{\\mathbf{x}} := \\text{RK} \\| \\text{kb}_\\mathbf{2} \\| \\text{kb}_\\mathbf{1} \\| \\text{kb}_\\mathbf{0}\\) , and checks if \\(\\tilde{K}_{\\mathbf{x}}\\) equals \\(K_{\\mathbf{x}}\\) . The Merkle proof : That is, checking whether the value stored at the located leaf \\(\\mathbf{{L}_{x}}\\) was indeed included in computing the root, \\(\\mathbf{{root}_{a..x}}\\) . This computation was illustrated several times in the above discussions. Note that the key-correctness and the Merkle proof are simultaneously carried out.","title":"Non-Binding Key-Value Pairs"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#example-3-indistinguishable-leaves","text":"Suppose a binary SMT contains a key-value pair \\((K_{\\mathbf{d}}, V_\\mathbf{{d}})\\) at the leaf \\(\\mathbf{L_{d}}\\) , where \\(K_{\\mathbf{d}} = 11100110\\) . That is, \\(\\mathbf{L_{d}} := \\mathbf{H_{leaf}}(V_\\mathbf{{d}})\\) . Note that, when building binary SMTs, it is permissible to have another key-value pair \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) in the same tree with \\(V_\\mathbf{{x}} = V_\\mathbf{{d}}\\) . An Attacker can pick the key-value pair \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) such that \\(V_\\mathbf{{x}} = V_\\mathbf{{d}}\\) and \\(K_{\\mathbf{x}} = 10100110\\) . And, with the above design, it means \\(\\mathbf{L_{x}} = \\mathbf{H_{leaf}}(V_\\mathbf{{x}}) = \\mathbf{H_{leaf}}(V_\\mathbf{{d}}) = \\mathbf{L_{d}}\\) . Consider Figure 8 below. And suppose the Attacker provides the following data; The key-value \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) , where \\(K_{\\mathbf{x}} = 10100110\\) and \\(V_{\\mathbf{x}} = V_\\mathbf{d}\\) . The root, \\(\\mathbf{{root}_{a..x}}\\) , the number of levels to root = 3, and the siblings \\(\\mathbf{{B}_{\\mathbf{bc}}}\\) , \\(\\mathbf{L_{a}}\\) and \\(\\mathbf{{S}_{\\mathbf{efg}}}\\) . The verifier uses the least-significant key bits; \\(\\text{kb}_\\mathbf{0} = 0\\) , \\(\\text{kb}_\\mathbf{1} = 0\\) and \\(\\text{kb}_\\mathbf{2} = 1\\) ; to navigate the tree and locate the leaf \\(\\mathbf{L_{x}}\\) which is positioned at \\(\\mathbf{L_{d}}\\) , see Figure 7 below. Figure 8: Non-binding Key-Value Pairs In order to ensure that \\(\\mathbf{L_{x}}\\) actually stores the value \\(V_\\mathbf{{x}}\\) ; The verifier first checks key-correctness. He takes the remaining key \\(\\text{RK} = 10100\\) and, \u200b(a) Concatenates \\(\\text{kb}_\\mathbf{2} = 1\\) , and gets \\(\\text{ } \\text{RK} \\| \\text{kb}_\\mathbf{2} = 10100 \\|1\\) , \u200b(b) Concatenates \\(\\text{kb}_\\mathbf{1} = 0\\) to get \\(\\text{ } \\text{RK} \\| \\text{kb}_\\mathbf{2} \\| \\text{kb}_\\mathbf{1} = 10100 \\|1\\|0\\) , \u200b(c) Concatenates \\(\\text{kb}_\\mathbf{0} = 0\\) , yielding \\(\\text{ } \\text{RK} \\| \\text{kb}_\\mathbf{2} \\| \\text{kb}_\\mathbf{1} \\| \\text{kb}_\\mathbf{0} = 10100 \\|1\\|0\\|0\\) . He sets \\(\\tilde{K}_{\\mathbf{x}} := 10100 \\|1\\|0\\|0 = 10100100\\) . Since \\(\\tilde{K}_{\\mathbf{x}}\\) equals \\(K_{\\mathbf{x}}\\) , the verifier concludes that the supplied key is correct. As the verifier 'climbs' the tree to test key-correctness, he concurrently checks if the value \\(V_\\mathbf{{x}}\\) is included in the SMT identified by the given root, \\(\\mathbf{{root}_{a..x}}\\) . That is, he executes the following computations; \u200b (a) He computes the hash of \\(V_\\mathbf{{x}}\\) and sets it as, \\(\\tilde{\\mathbf{L}}_\\mathbf{x}:= \\mathbf{H_{leaf}}(V_\\mathbf{{x}})\\) . \u200b (b) Then he uses \\(\\mathbf{{B}_{\\mathbf{bc}}}\\) to compute, \\(\\tilde{\\mathbf{B}}_{\\mathbf{bcd}} = \\mathbf{H_{noleaf}}(\\mathbf{{B}_{\\mathbf{bc}}} \\|\\tilde{\\mathbf{L}}_\\mathbf{x})\\) . \u200b (c) He also uses \\(\\mathbf{L_{a}}\\) to compute, \\(\\tilde{\\mathbf{B}}_{\\mathbf{abcd}} = \\mathbf{H_{noleaf}}(\\mathbf{L_{a}} \\| \\tilde{\\mathbf{B}}_{\\mathbf{bcd}})\\) . \u200b (d) He further calculates, \\(\\tilde{\\mathbf{root}}_{\\mathbf{abcd}} = \\mathbf{H_{noleaf}}(\\tilde{\\mathbf{B}}_{\\mathbf{abcd}} \\| \\mathbf{{S}_{\\mathbf{efg}}})\\) . Next, the verifier checks if \\(\\tilde{\\mathbf{root}}_{\\mathbf{abcd}}\\) equals \\(\\mathbf{root}_{\\mathbf{abcd}}\\) . Since \\(V_\\mathbf{{x}} = V_\\mathbf{{d}}\\) , it follows that all the corresponding intermediate values to the root are equal; \\(\\mathbf{L_{d}} = \\mathbf{H_{leaf}}(V_\\mathbf{{d}}) = \\mathbf{H_{leaf}}(V_\\mathbf{{x}}) = \\tilde{\\mathbf{L}}_\\mathbf{x}\\) , \\(\\mathbf{B}_{\\mathbf{bcd}} = \\mathbf{H_{noleaf}}(\\mathbf{{B}_{\\mathbf{bc}}} \\| \\mathbf{L}_\\mathbf{d}) = \\mathbf{H_{noleaf}}(\\mathbf{{B}_{\\mathbf{bc}}} \\|\\tilde{\\mathbf{L}}_\\mathbf{x}) = \\tilde{\\mathbf{B}}_{\\mathbf{bcd}}\\) , \\(\\mathbf{B}_{\\mathbf{abcd}} = \\mathbf{H_{noleaf}}(\\mathbf{L_{a}} \\| \\mathbf{B}_{\\mathbf{bcd}} ) = \\mathbf{H_{noleaf}}(\\mathbf{L_{a}} \\| \\tilde{\\mathbf{B}}_{\\mathbf{bcd}} ) = \\tilde{\\mathbf{B}}_{\\mathbf{abcd}}\\) , \\(\\mathbf{root}_{\\mathbf{abcd}} = \\mathbf{H_{noleaf}}(\\mathbf{B}_{\\mathbf{abcd}} \\| \\mathbf{{S}_{\\mathbf{efg}}} ) = \\mathbf{H_{noleaf}}(\\tilde{\\mathbf{B}}_{\\mathbf{abcd}} \\| \\mathbf{{S}_{\\mathbf{efg}}} ) = \\tilde{\\mathbf{root}}_{\\mathbf{abcd}}\\) . The verifier therefore concludes that the key-value pair \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) is in the SMT, when it is not. Why is this attack successful? Note that equality of values, \\(V_\\mathbf{{x}} = V_\\mathbf{{d}}\\) , associated with two distinct keys, has nothing to do with the efficacy of this attack. In fact, for all practical purposes, it should be permissible for distinct leaves to store any value, irrespective of whether other leaves store an equivalent value or not. The downfall of our binary SMTs design, thus far, is that it does not give the verifier any equation that relates or ties the keys to their associated values. In other words, the attack succeeds simply because the key-value pairs (as 'committed' values) are not binding.","title":"Example 3. (Indistinguishable Leaves)"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#solution-to-the-non-binding-key-value-problem","text":"The solution to this problem is straightforward, and it is to build the binary SMTs in such a way that the key-value pairs are binding. This means, create a relationship between the keys and their associated values, so that the verifier can simply check if this relationship holds true. In order to ensure that checking such a relationship blends with the usual proof machinery, one has two options. The na\u00efve solution, which involves the keys, is one option.","title":"Solution To The Non-Binding Key-Value Problem"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#the-naive-solution","text":"The na\u00efve solution is to simpy include keys in the argument of the hash function, when forming leaves. That is, when building a binary SMT, one includes a key-value pair \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) by setting the leaf \\(\\mathbf{L_{x}}\\) to be the hash of both the value and the key; \\[\\begin{aligned} \\mathbf{L_{x}} = \\mathbf{H_{leaf}}(K_{\\mathbf{x}} \\| V_\\mathbf{{x}} ) \\end{aligned}\\] Does this change remedy the non-binding problem? Suppose \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) and \\((K_{\\mathbf{z}}, V_\\mathbf{{z}})\\) are two key-value pairs such that \\(V_\\mathbf{{x}} = V_\\mathbf{{z}}\\) , while \\(K_\\mathbf{{x}}\\) and \\(K_\\mathbf{{z}}\\) differ only in one of the most-significant bits. Since the hash functions used are collision-resistant, it follows that \\[\\begin{aligned} \\mathbf{L_{x}} = \\mathbf{H_{leaf}}(K_{\\mathbf{x}} \\| V_\\mathbf{{x}}) \\neq \\mathbf{H_{leaf}}(K_{\\mathbf{z}} \\| V_\\mathbf{{z}}) = \\mathbf{L_{z}} \\end{aligned}\\] Consequently, although the key-value pairs \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) and \\((K_{\\mathbf{z}}, V_\\mathbf{{z}})\\) might falsely pass the key-correctness check, they will not pass the Merkle proof test. And this is because, collision-resistance also guarantees that the following series of inequalities hold true; \\[\\begin{aligned} \\mathbf{L_{x}} = \\mathbf{H_{leaf}}(K_{\\mathbf{x}} \\| V_\\mathbf{{x}}) \\neq \\mathbf{H_{leaf}}(K_{\\mathbf{z}} \\| V_\\mathbf{{z}}) = \\mathbf{L_{z}} \\\\ \\\\ \\mathbf{B_{bx}} = \\mathbf{H_{noleaf}}(\\mathbf{S}_\\mathbf{{b}} \\| \\mathbf{L}_{\\mathbf{x}}) \\neq \\mathbf{H_{noleaf}}(\\mathbf{S}'_\\mathbf{{b}} \\| \\mathbf{L}_{\\mathbf{z}}) = \\mathbf{B_{bz}} \\\\ \\\\ \\mathbf{B_{abx}} = \\mathbf{H_{noleaf}}(\\mathbf{S}_\\mathbf{{a}} \\| \\mathbf{B_{bx}} ) \\neq \\mathbf{H_{noleaf}}(\\mathbf{S}'_\\mathbf{{a}} \\| \\mathbf{B_{bz}}) = \\mathbf{B_{abz}} \\end{aligned}\\] where; \\(\\mathbf{S}_\\mathbf{{b}}\\) is a sibling to \\(\\mathbf{L}_{\\mathbf{x}}\\) , and \\(\\mathbf{S}_\\mathbf{{a}}\\) is a sibling to \\(\\mathbf{B_{bx}}\\) , making \\(\\mathbf{B_{bx}}\\) and \\(\\mathbf{B_{abx}}\\) branches traversed while climbing the tree from \\(\\mathbf{L_{x}}\\) to root; Similarly, \\(\\mathbf{S}'_\\mathbf{{b}}\\) is a sibling to \\(\\mathbf{L}_{\\mathbf{z}}\\) , while \\(\\mathbf{S}'_\\mathbf{{a}}\\) is a sibling to \\(\\mathbf{B_{bx}}\\) , also making \\(\\mathbf{B_{bz}}\\) and \\(\\mathbf{B_{abz}}\\) branches traversed while climbing the tree from \\(\\mathbf{L_{z}}\\) to root. The only chance for the Merkle proof to pass is if the key-value pairs \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) and \\((K_{\\mathbf{z}}, V_\\mathbf{{z}})\\) are distinct and are individually on the same SMT. The inclusion of keys, in the argument of the hash functions, therefore ensures that leaves \\(\\mathbf{L_{x}}\\) and \\(\\mathbf{L_{z}}\\) are distinguishable. And most importantly, that key-value pairs in our SMTs are now binding.","title":"The Na\u00efve Solution"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#a-better-solution","text":"The other solution, which is much more apt than the Na\u00efve option, utilises the remaining keys when forming leaves. Since levels to root is related to the Remaining Key ( \\(\\text{RK}\\) ) notion, a much more apt solution is to rather include the remaining key, \\(\\text{RK}_\\mathbf{x}\\) , as the argument to the hash function, instead of the whole key \\(K_{\\mathbf{x}}\\) . That is, for a key-value pair \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) , one sets the leaf \\(\\mathbf{L_{x}}\\) to be the hash of both the value and the remaining key; \\[\\begin{aligned} \\mathbf{L_{x}} = \\mathbf{H_{leaf}}( \\text{RK}_\\mathbf{x} \\| \\text{V}_\\mathbf{{x}}). \\end{aligned}\\] With this strategy, the verifier needs the remaining key \\(\\text{RK}_\\mathbf{{x}}\\) , instead of the whole key, in order to carry out a Merkle proof. So he adjusts the Merkle proof by; Firstly, picking the correct hash function \\(\\mathbf{H_{leaf}}\\) for leaves, Secondly, concatenating the value \\(V_{\\mathbf{x}}\\) stored at the leaf \\(L_{\\mathbf{x}}\\) and the remaining key \\(\\text{RK}_\\mathbf{{x}}\\) , instead of the whole key \\(K_{\\mathbf{x}}\\) , Thirdly, hashing the concatenation \\(\\mathbf{H_{leaf}}( \\text{RK}_\\mathbf{x} \\| \\text{V}_\\mathbf{{x}}) =: \\mathbf{L_{x}}\\) . This approach not only ensures that key-value pairs in our SMTs are now binding, but also implicitly 'encodes' the levels to root in the leaf. The strategy of using the \\(\\text{RK}_\\mathbf{x}\\) instead of the key \\(K_{\\mathbf{x}}\\) , coupled with hashing leaves and branches differently, yields sound verification.","title":"A Better Solution"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#introducing-zero-knowledge","text":"It is often necessary to make sure that a proof-integrity system has the zero-knowledge property. In order to introduce zero-knowledge, instead of storing values as plaintexts in the leaves, one stores hashes of these values. A leaf therefore is henceforth constructed in two steps; Firstly, for a key-value pair \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) , compute the hash the value \\(V_\\mathbf{{x}}\\) , \\[\\begin{aligned} \\text{Hashed Value} = \\text{HV}_\\mathbf{{x}} = \\mathbf{H_{noleaf}}(V_\\mathbf{{x}}) \\end{aligned}\\] Secondly, form the leaf containing \\(V_\\mathbf{{x}}\\) , as follows, \\[\\begin{aligned} \\mathbf{L_{x}} = \\mathbf{H_{leaf}}( \\text{RK}_\\mathbf{x} \\| \\text{HV}_\\mathbf{{x}}) \\end{aligned}\\] Since it is infeasible to compute the preimage of the hash functions, \\(\\mathbf{H_{leaf}}\\) and \\(\\mathbf{H_{noleaf}}\\) , computing the hash of the value \\(V_\\mathbf{{x}}\\) amounts to 'encrypting'. The prover therefore achieves zero-knowledge by providing the pair, \\((K_{\\mathbf{x}}, \\text{HV}_\\mathbf{{x}})\\) , as the key-value pair instead of the explicit one, \\((K_{\\mathbf{x}}, V_\\mathbf{{x}})\\) . The verifier, on the other hand, has to adjust the Merkle proof by starting with; Firstly, picking the correct hash function \\(\\mathbf{H_{leaf}}\\) for leaf nodes, Secondly, concatenating the hashed-value \\(\\text{HV}_\\mathbf{{x}}\\) and the remaining key \\(\\text{RK}_\\mathbf{{x}}\\) , Thirdly, hashing the concatenation in order to form the leaf, \\(\\mathbf{L_{x}} := \\mathbf{H_{leaf}}( \\text{RK}_\\mathbf{x} \\| \\text{HV}_\\mathbf{{x}})\\) .","title":"Introducing Zero-Knowledge"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#example-4-zero-knowledge-merkle-proof","text":"The following example illustrates a Merkle proof when the above strategy is applied. Consider an SMT where the keys are 8-bit long, and the prover commits to the key-value \\(( K_{\\mathbf{c}} , \\text{HV}_{\\mathbf{c}} )\\) with \\(K_{\\mathbf{c}} = 10010100\\) . See Figure 9 below. Figure 9 : ZK Merkle Proof Example Since the levels to root is 3, the prover provides; the least-significant key-bits, \\(\\text{kb}_0 = 0\\) , \\(\\text{kb}_1 = 0\\) , \\(\\text{kb}_2 = 1\\) , the stored hashed-value \\(\\text{HV}_{\\mathbf{c}}\\) , the root \\(\\mathbf{{root}_{a..f}}\\) , the Remaining Key \\(\\mathbf{ \\text{RK}_{\\mathbf{c}}} = 10010\\) , and the siblings \\(\\mathbf{{S}_{ab}}\\) , \\(\\mathbf{{L}_{d}}\\) and \\(\\mathbf{{S}_{\\mathbf{ef}}}\\) . The verifier first uses the least-significant bits of the key \\(K_{\\mathbf{c}} = 10010100\\) to navigate the SMT from the root, \\(\\mathbf{{root}_{a..f}}\\) , to the leaf \\(\\mathbf{L_c}\\) . Then, he executes the following computations; He computes, \\(\\mathbf{L_c} = \\mathbf{H_{leaf}}\\big( \\mathbf{ \\text{RK}_{\\mathbf{c}}} \\| \\text{HV}_{\\mathbf{c}} \\big) = \\mathbf{H_{leaf}}( 10010 \\| \\text{HV}_{\\mathbf{c}})\\) Then, he uses the sibling \\(\\mathbf{{S}_{ab}}\\) to compute, \\(\\tilde{ \\mathbf{B}}_{\\mathbf{abc}} := \\mathbf{H_{noleaf}} \\big( \\mathbf{{S}_{ab}}\\|\\mathbf{L}_{\\mathbf{c}} \\big)\\) . Next, he computes, \\(\\tilde{ \\mathbf{B}}_{\\mathbf{abcd}} := \\mathbf{H_{noleaf}} \\big( \\tilde{ \\mathbf{B}}_{\\mathbf{abc}} \\| \\mathbf{L}_{\\mathbf{d}} \\big)\\) . Now, verifier uses \\(\\tilde{ \\mathbf{B}}_{\\mathbf{abcd}}\\) to compute the supposed root, \\(\\tilde{ \\mathbf{root}}_{\\mathbf{ab..f}} := \\mathbf{H_{noleaf}} \\big( \\tilde{ \\mathbf{B}}_{\\mathbf{abcd}}\\| \\mathbf{S}_{\\mathbf{ef}} \\big)\\) . Checks if \\(\\tilde{ \\mathbf{root}}_{\\mathbf{ab..f}}\\) equals \\({ \\mathbf{root}}_{\\mathbf{ab..f}}\\) . The verifier accepts that the key-value pair \\(( K_{\\mathbf{c}} , V_{\\mathbf{c}} )\\) is in the SMT only if \\(\\tilde{ \\mathbf{root}}_{\\mathbf{ab..f}} = { \\mathbf{root}}_{\\mathbf{ab..f}}\\) . And he does this without any clue about the exact value \\(V_{\\mathbf{c}}\\) which is hidden as \\(\\text{HV}_{\\mathbf{c}}\\) .","title":"Example 4. (Zero-Knowledge Merkle Proof)"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#basic-operations-storage-actions","text":"The previous sections have focused on the design of binary SMTs. The problems that cropped up with our initial design have assisted in refining and defining a secure design. While describing the design of binary SMTs, we have extensively utilised the READ or \"Get\" operation. Now that the basic design is established, the other operations can be delineated. The operations that the Storage State Machine performs, as per instructions of the Main SM Executor, are called Storage Actions . As mentioned above, these are; Create, Read, Update and Delete (CRUD).","title":"Basic Operations (Storage Actions)"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#the-read-operation","text":"First, we illustrate the READ operation, which is in fact a \"Get\". The prover can commit to a key-value pair \\((K_{\\mathbf{x}}, \\text{HV}_{\\mathbf{x}})\\) where \\(\\text{HV}_{\\mathbf{x}}\\) is the hash of the value \\(V_{\\mathbf{x}}\\) . That is, he claims that he created a leaf \\(\\mathbf{L}_{\\mathbf{x}}\\) which contains the value \\(V_{\\mathbf{x}}\\) and it can be located using the key \\(K_{\\mathbf{x}}\\) . READ therefore means locating the leaf \\(\\mathbf{L}_{\\mathbf{x}}\\) and verifying that it contains the value \\(V_{\\mathbf{x}}\\) by using a Merkle proof. Hence, in addition to \\((K_{\\mathbf{x}}, \\text{HV}_{\\mathbf{x}})\\) , prover has to provide the rest of the information needed for completing the Merkle proof. That is, the root, the key-bits \\(\\text{kb}_\\mathbf{j}\\) for locating the leaf \\(\\mathbf{L}_{\\mathbf{x}}\\) , the Remaining Key \\(\\text{RK}_\\mathbf{x}\\) and all the necessary siblings. What if the key is not set? The next example demostrates the READ operation when a key is not set in the tree. That is, it illustrates how to check whether a value is not on a given SMT. There are two cases that can occur. The given key may lead either to a zero node or to an existing leaf. If the given key leads to a zero-node , then the verifier needs only prove the existence of the zero-node, and this would sufficiently prove that the key is not set. But if the given key leads to an existing leaf , the verifier has to prove the leaf exists in the SMT and show that the given key is not the same as the actual key associated with the value at the leaf.","title":"The READ Operation"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#example-5-when-the-key-is-not-set","text":"Suppose the verifier needs to prove that the keys, \\(K_{\\mathbf{x}} = 11010101\\) and \\(K_{\\mathbf{z}} = 10101010\\) are not set in the SMT depicted in Figure 10 below.","title":"Example 5. When The Key Is Not Set"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#case-1-when-the-key-leads-to-a-zero-node","text":"The verifier receives the key \\(K_{\\mathbf{x}}\\) , the remaining key \\(\\text{RK}_\\mathbf{x} = 1101010\\) , the least-significant key-bit \\(\\text{kb}_0 = 1\\) , and the sibling \\(\\mathbf{{S}_{1}} = \\mathbf{{B}_{\\mathbf{ab}}}\\) . Since the least-significant key-bit of the given key, \\(\\text{kb}_0 = 1\\) , navigation from the root leads to the right-side, to the zero-node. See the node circled in a green colour, in Figure 9 below. The task here is to verify that the node is indeed a zero-node. So the verifier computes the root as follows, \\(\\mathbf{{\\tilde{root}}_{ab0}} = \\mathbf{H_{noleaf}} (\\mathbf{{S}_{1}} \\| \\mathbf{0} ) = \\mathbf{H}( \\mathbf{{B}_{\\mathbf{ab}}} \\| \\mathbf{0} )\\) . Note that he concatenates \\(\\mathbf{{S}_{1}}\\) and \\(\\mathbf{0}\\) in the given ordering, because \\(\\text{kb}_0 = 1\\) . He then checks if \\(\\mathbf{{\\tilde{root}}_{ab0}} = \\mathbf{{root}_{ab0}}\\) . If this is true, then he concludes that the given key is not set. Figure 10: Key Not Set Example","title":"Case 1: When the key leads to a zero-node"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#case-2-when-the-key-leads-to-an-existing-leaf","text":"Consider again the SMT depicted in Figure 10 above, and suppose that the prover claims that the key \\(K_{\\mathbf{z}} = 10101010\\) is set. The verifier is given; the key \\(K_{\\mathbf{z}} = 10101010\\) , the Remaining Key \\(\\text{RK}_{\\mathbf{z}} = 101010\\) , the least-significant key-bit \\(\\text{kb}_0 = 0\\) , the second least-significant key-bit \\(\\text{kb}_{\\mathbf{1}} = 1\\) , and the siblings \\(\\mathbf{{S}_{1}} = \\mathbf{L}_{a}\\) and \\(\\mathbf{{S}_{2}} = \\mathbf{0}\\) . When navigating the tree from \\(\\mathbf{{root}_{ab0}}\\) , using the key-bits \\(\\text{kb}_{\\mathbf{0}} = 0\\) and \\(\\text{kb}_{\\mathbf{1}} = 1\\) , and with reference to Figure 10 above, the key-bit \\(\\text{kb}_{\\mathbf{0}} = 0\\) leads to the branch \\(\\mathbf{{B}_{\\mathbf{ab}}}\\) , then from \\(\\mathbf{{B}_{\\mathbf{ab}}}\\) , the key-bit \\(\\text{kb}_{\\mathbf{1}} = 1\\) leads to the leaf \\(\\mathbf{L}_\\mathbf{b}\\) , which is the leaf circled in brown in Figure 9 above. Since the key navigates to a leaf, the verifier's task is to prove two things simultaneously; The leaf is in the SMT described in Figure 10, and The Remaining Key at the leaf \\(\\mathbf{L}_\\mathbf{b}\\) is different from the Remaining Key supplied by the prover. In proving that \\(\\mathbf{L}_{\\mathbf{b}}\\) is indeed in the tree, the verifier does the following; Checks the root : (a) Computes the hash of the hashed-value, \\(\\mathbf{ \\tilde{L} }_{\\mathbf{b}} = \\mathbf{H_{leaf}} ( \\text{RK}_{\\mathbf{b}} \\| \\text{HV}_{\\mathbf{b}} )\\) , (b) Uses the first sibling to compute, \\(\\mathbf{{\\tilde{B}}_{\\mathbf{ab}}} = \\mathbf{H_{noleaf}} \\big( \\mathbf{L}_{\\mathbf{a}} \\| \\mathbf{ \\tilde{L}}_{\\mathbf{b}} \\big)\\) , (c) Then, uses the second sibling to compute the root, \\(\\mathbf{\\tilde{root}}_{ab0} = \\mathbf{H_{noleaf}} \\big( \\mathbf{{\\tilde{B}}_{\\mathbf{ab}}} \\| \\mathbf{0} \\big)\\) . (d) Completes the root-check by testing equality, \\(\\mathbf{\\tilde{root}}_{ab0} = \\mathbf{{root}}_{ab0}\\) . Simultaneously, Checks the keys : The verifier takes the two Remaining Keys \\(\\text{RK}_{\\mathbf{x}}\\) and \\(\\text{RK}_{\\mathbf{b}}\\) , and the key-bits \\(\\text{kb}_0\\) and \\(\\text{kb}_{\\mathbf{1}}\\) ; (a) Concatenates them as, \\(\\tilde{K}_{\\mathbf{x}} = \\text{RK}_{\\mathbf{x}} \\| \\text{kb}_0 \\| \\text{kb}_{\\mathbf{1}}\\) and \\(\\tilde{K}_{\\mathbf{b}} = \\text{RK}_{\\mathbf{b}} \\| \\text{kb}_0 \\| \\text{kb}_{\\mathbf{1}}\\) , (b) Checks \\(\\tilde{K}_{\\mathbf{x}} = K_{\\mathbf{x}}\\) and \\(\\tilde{K}_{\\mathbf{b}} = K_{\\mathbf{b}}\\) , and (c) Finally shows the inequality, \\(\\tilde{K}_{\\mathbf{x}} \\neq K_{\\mathbf{b}}\\) . This proves that the key \\(K_{\\mathbf{x}}\\) is not set. Remark : The last check, where the verifier checks inequality of keys, turns out to be very expensive to implement. A much more smarter method is used in the Storage State Machine.","title":"Case 2: When the key leads to an existing leaf"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#the-update-operation","text":"The UPDATE operation does not change the topology of the tree. When carrying out the UPDATE, it is therefore important to retain all labels of nodes. The UPDATE process entails the following; First, the verifier needs to be provided with the following data; The remaining key \\(\\text{RK}\\) , the least-significant key-bits, the new value, the old value, the old root and the siblings. Step 1. Checking a READ of the current value with the old root. That is, checking that the leaf exists in the tree, and it was included in calculating the old root. Step 2. Recomputing (updating) all nodes along the path , from the leaf to the root, as well as computing the new root with the newly updated nodes. The verifier can continue with Step 2 only if all the checks in Step 1 pass verification. For the UPDATE operation, Step 1 is exactly the same as the READ operation. We therefore focus on illustrating Step 2 .","title":"The UPDATE Operation"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#example-6-update-step-2","text":"Suppose the set key is \\(K_{\\mathbf{c}} = 10110100\\) corresponding to the old value \\(V_{\\mathbf{c}}\\) , and the new value is \\(V_\\mathbf{new}\\) . The verifier is provided with the following data; \u200b (a) the \\(\\text{RK}_{\\mathbf{c}} = 10110\\) , \u200b (b) the least-significant key-bit \\(\\text{kb}_0 = 0\\) , \u200b (c) the second least-significant key-bit \\(\\text{kb}_1 = 0\\) , \u200b (d) the third least-significant key-bit \\(\\text{kb}_2 = 1\\) , \u200b (e) the old hashed value \\(\\text{HV}_{\\mathbf{c}}\\) , \u200b (f) the old root \\(\\mathbf{{root}_{ab..f }}\\) , and \u200b (g) the siblings \\(\\mathbf{{S}_{1}} = \\mathbf{{S}_{\\mathbf{ab}}}\\) , \\(\\mathbf{{S}_{2}} = \\mathbf{{L}_{d}}\\) and \\(\\mathbf{{S}_{3}} = \\mathbf{{S}_{\\mathbf{ef}}}\\) . Consider the SMT given in Figure 11 below. Figure 11: Value UPDATE Example The required Step 2 of the UPDATE operation involves, (a) Computing the hash of the new value \\(V_\\mathbf{new}\\) as; \\(\\text{HV}_{\\mathbf{new}} = \\mathbf{H_{noleaf}}(V_\\mathbf{new})\\) , (b) Forming the new leaf by again hashing the hashed value \\(\\text{HV}_{\\mathbf{new}}\\) as; \\(\\mathbf{ \\tilde{L} }_{\\mathbf{new}} = \\mathbf{H_{leaf}}( \\text{RK}_{\\mathbf{new}} \\| \\text{HV}_{\\mathbf{new}} )\\) , (c) Using the first sibling \\(\\mathbf{{S}_{1}} = \\mathbf{{S}_{\\mathbf{ab}}}\\) to compute, \\(\\mathbf{{\\bar{B}}_{abc}} = \\mathbf{H_{noleaf}} \\big( \\mathbf{{S}_{\\mathbf{ab}}} \\| \\mathbf{ \\tilde{L}}_{\\mathbf{new}} \\big)\\) , (d) Again, using the second sibling \\(\\mathbf{{S}_{2}} = \\mathbf{{L}_{d}}\\) to compute, \\(\\mathbf{{\\bar{B}}_{\\mathbf{abcd}}} = \\mathbf{H_{noleaf}} \\big( \\mathbf{{\\bar{B}}_{abc}} \\| \\mathbf{{L}_{d}} \\big)\\) , (e) Then, uses the third sibling \\(\\mathbf{{S}_{3}} = \\mathbf{{S}_{\\mathbf{ef}}}\\) to compute the root, \\(\\mathbf{{{root}}_{\\mathbf{new}}} = \\mathbf{H_{noleaf}} \\big( \\mathbf{{\\bar{B}}_{\\mathbf{abcd}}} \\| \\mathbf{{S}_{\\mathbf{ef}}}\\big)\\) . Note that the key-bits are not changed. Therefore, replacing the following old values in the SMT, \\(\\text{HV}_\\mathbf{c}, \\mathbf{{B}_{abc}}, \\mathbf{{B}_{abcb}}, \\mathbf{{root}_{ab..f } }\\) , with the new ones, \\(\\text{HV}_\\mathbf{new}, \\mathbf{{\\bar{B}}_{abc}}, \\mathbf{{\\bar{B}}_{abcb}}, \\mathbf{{root}_{new } }\\) , respectively, completes the UPDATE operation.","title":"Example 6. UPDATE - Step 2"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#the-create-operation","text":"The CREATE Operation adds a new leaf \\(\\mathbf{L_{\\mathbf{new}}}\\) to the SMT in order to insert and store a new key-value pair \\(( \\mathbf{{K_{new}}} , \\mathbf{V_{\\mathbf{new}}} )\\) at \\(\\mathbf{L_{\\mathbf{new}}}\\) , where the key \\(\\mathbf{K_{new}}\\) was never used in the SMT and thus is uniquely associated with the leaf \\(\\mathbf{L_{new}}\\) . When navigating from the root, the new key \\(\\mathbf{K_{new}}\\) can lead to either a zero node or an existing leaf. This results in two scenarios.","title":"The CREATE Operation"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#case-1-new-key-navigates-to-a-zero-node","text":"That is, the first \\(l\\) least-significant bits of the key \\(\\mathbf{K_{new}}\\) leads to a zero node, where \\(l\\) is the levels to root of the zero node. The first step is to double-check that indeed the node is a zero node. That is, the verifier performs a Merkle proof starting with either \\(\\mathbf{H_{noleaf}} ( \\mathbf{S_1} \\| \\mathbf{0} )\\) or \\(\\mathbf{H_{noleaf}} ( \\mathbf{0} \\| \\mathbf{S_1} )\\) , depending on whether the sibling of the zero-node is on the right (the edge corresponding to a key-bit \\(1\\) ) or on the left (the edge corresponding to a key-bit \\(0\\) ), respectively. Once it is established that the new key \\(\\mathbf{K_{new}}\\) has led to a zero node, the verifier simply changes the zero node to the leaf \\(\\mathbf{L_{new}}\\) that stores the value \\(\\mathbf{V_{new}}\\) . The CREATE operation, in this case, therefore boils down to an UPDATE operation on the zero node. It amounts to; Computing the hash of the new value \\(V_\\mathbf{new}\\) as, \\(\\text{HV}_{\\mathbf{new}} = \\mathbf{H_{noleaf}}(V_\\mathbf{new})\\) , Then forming the new leaf, \\(\\mathbf{L_{new}} = \\mathbf{H_{leaf}}( \\text{RK}_{\\mathbf{new}} \\| \\text{HV}_{\\mathbf{new}})\\) , Recomputing all the nodes along the path climbing from the leaf \\(\\mathbf{L_{new}}\\) to the root, including computing the new root.","title":"Case 1: New Key Navigates To A Zero Node"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#example-7-create-operation-at-a-zero-node","text":"Suppose a new leaf with the key-value pair \\(\\big(K_{\\mathbf{new}}, \\text{V}_{\\mathbf{new}}\\big)\\) , where \\(K_{\\mathbf{new}} = 11010110\\) , needs to be created. As illustrated in Figure 12 below, the two least-significant key-bits \\(\\text{kb}_0 = 0\\) and \\(\\text{kb}_1 = 1\\) , lead to a zero node. That is, navigating from the root; \u200b (a) The lsb, \\(\\text{kb}_{0} = 0\\) leads to the node \\(\\mathbf{{B}_{ab0}}\\) , \u200b (b) Whilst the second lsb, \\(\\text{kb}_{1} = 1\\) leads to a zero node. At this stage the verifier checks if this is indeed a zero node; First he computes \\(\\mathbf{{\\tilde{B}}_{ab0}} = \\mathbf{H_{noleaf}} \\big( \\mathbf{{S}_{\\mathbf{ab}}} \\| \\mathbf{0} \\big)\\) . Then he computes \\(\\mathbf{{\\tilde{root}}_{ab0c}} = \\mathbf{H_{noleaf}} \\big( \\mathbf{{\\tilde{B}}_{ab0}} \\| \\mathbf{L_{c}} \\big)\\) . And, checks if \\(\\mathbf{{\\tilde{root}}_{ab0c}}\\) equals \\(\\mathbf{{root}_{ab0c}}\\) . Figure 12: CREATE Operation - Zero Node Once the zero-value is checked, the verifier now creates a non-zero leaf with the key-value pair \\(\\big( \\mathbf{K_{new}} , \\text{HV}_{\\mathbf{new}}\\big)\\) . He computes the hash of \\(\\text{V}_{\\mathbf{new}}\\) as, \\(\\text{HV}_{\\mathbf{new}} = \\mathbf{H_{noleaf}}(V_\\mathbf{new})\\) , He then forms the leaf \\(\\mathbf{L_{new}} = \\mathbf{H_{leaf}}( \\text{RK}_{\\mathbf{new}} \\| \\text{HV}_{\\mathbf{new}})\\) , Also computes \\(\\mathbf{B_{new}} = \\mathbf{H_{noleaf}} ( \\mathbf{{S}_{\\mathbf{ab}}} \\| \\mathbf{L_{new}})\\) , And computes \\(\\mathbf{{root}_{new}} = \\mathbf{H_{noleaf}} ( \\mathbf{B_{new}} \\| \\mathbf{L_{c}} )\\) . An UPDATE of these values; the branch \\(\\mathbf{B_{ab0}}\\) to \\(\\mathbf{B_{new}}\\) and the old root \\(\\mathbf{{root}_{ab0c}}\\) to \\(\\mathbf{{root}_{new}}\\) ; completes the CREATE operation. Note that inserting a new key-value pair at a zero node does not change the topology of the tree.","title":"Example 7. CREATE Operation at a Zero Node"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#case-2-new-key-navigates-to-a-non-zero-leaf","text":"That is, the first \\(\\mathbf{l}\\) least-significant bits of the key \\(\\mathbf{K_{new}}\\) leads to a non-zero leaf \\(\\mathbf{L_z}\\) , where \\(\\mathbf{l}\\) is \\(\\mathbf{L_z}\\) 's number of levels to root . This means, the keys \\(\\mathbf{K_{new}}\\) and \\(\\mathbf{K_{z}}\\) share a common string of least-significant key-bits, which is \\(\\mathbf{l}\\) bits long. Step 1: Checking Leaf Inclusion The first step is to double-check that indeed the value \\(V_\\mathbf{z}\\) stored at the leaf \\(\\mathbf{L_z}\\) is indeed included in the root. That is, the verifier performs a Merkle proof starting with either \\(\\mathbf{H_{noleaf}} ( \\mathbf{S_1} \\| \\mathbf{L_z} )\\) or \\(\\mathbf{H_{noleaf}} ( \\mathbf{L_z} \\| \\mathbf{S_1} )\\) , for some sibling \\(\\mathbf{S_1}\\) . The ordering of the hash arguments depends on whether the sibling of the leaf \\(\\mathbf{L_z}\\) is on the left (the edge corresponding to a key-bit \\(0\\) ) or on the right (the edge corresponding to a key-bit \\(1\\) ), respectively. The check of value-inclusion gets completed by climbing the tree as usual. Once it is established that the value \\(V_\\mathbf{z}\\) stored at the leaf \\(\\mathbf{L_z}\\) is included in the root, the new leaf \\(\\mathbf{L_{new}}\\) storing the key-value pair can now be created. Step 2: Extending The SMT Since it is not permissible for two distinct non-zero leaves, \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_z}\\) , to share a tree-address, a CREATE Operation at \\(\\mathbf{L_z}\\) results in extending the tree; by adding a new branch \\(\\mathbf{B_{ext1}}\\) at the tree-address where \\(\\mathbf{L_z}\\) has been positioned. As discussed earlier in this document, when building binary SMTs, the aim is to find a tree-address for the new leaf \\(\\mathbf{L_{new}}\\) which differs from the tree-address of any existing leaf \\(\\mathbf{L_z}\\) . So then, for as long as the next corresponding key-bits between \\(\\mathbf{K_{new}}\\) and \\(\\mathbf{K_{z}}\\) coincide, a new extension branch needs to be formed. Here's the general procedure; Start with the next least-significant key-bits, \\(\\text{kb}_\\mathbf{(l+1)new}\\) and \\(\\text{kb}_\\mathbf{(l+1)z}\\) , and check if \\(\\text{kb}_\\mathbf{(l+1)new} = \\text{kb}_\\mathbf{(l+1)z}\\) or not. If they are not the same (i.e., if \\(\\text{kb}_\\mathbf{(l+1)new} \\neq \\text{kb}_\\mathbf{(l+1)z}\\) ), then one new extension branch \\(\\mathbf{B_{ext1}}\\) with \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{z}}\\) as its child-nodes, suffices. But, if \\(\\text{kb}_\\mathbf{(l+1)new} = \\text{kb}_\\mathbf{(l+1)z}\\) , then another extension branch \\(\\mathbf{B_{ext2}}\\) needs to be formed. And, the first extension branch \\(\\mathbf{B_{ext1}}\\) is made a parent-node to both \\(\\mathbf{B_{ext2}}\\) and a NULL node \" \\(\\mathbf{0}\\) \". The key-bit \\(\\text{kb}_\\mathbf{(l+1)new}\\) determines whether the NULL node \" \\(\\mathbf{0}\\) \" is on the left or the right. One then continues with the next least-significant key-bits, \\(\\text{kb}_\\mathbf{(l+2)new}\\) and \\(\\text{kb}_\\mathbf{(l+2)z}\\) , and checks if \\(\\text{kb}_\\mathbf{(l+2)new} = \\text{kb}_\\mathbf{(l+2)z}\\) or not. If \\(\\text{kb}_\\mathbf{(l+2)new} \\neq \\text{kb}_\\mathbf{(l+2)z}\\) , then the second extension branch \\(\\mathbf{B_{ext2}}\\) , with \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{z}}\\) as its child-nodes, completes the CREATE operation. However, if \\(\\text{kb}_\\mathbf{(l+2)new} = \\text{kb}_\\mathbf{(l+2)z}\\) , then a third extension branch \\(\\mathbf{B_{ext3}}\\) is formed. And, as before, the second extension branch \\(\\mathbf{B_{ext2}}\\) is made a parent-node to both \\(\\mathbf{B_{ext3}}\\) and a NULL node \" \\(\\mathbf{0}\\) \". And similarly, the key-bit \\(\\text{kb}_\\mathbf{(l+2)new}\\) determines whether the NULL node \" \\(\\mathbf{0}\\) \" is on the left or the right. This procedure (of extending the tree) continues until, \\(\\text{kb}_\\mathbf{(l+j)new} \\neq \\text{kb}_\\mathbf{(l+j)z}\\) for some \\(j > 2\\) . In which case, the \\(\\mathbf{(l + j)}\\) -th extension branch \\(\\mathbf{B_{ext(l + j)}}\\) , with the \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{z}}\\) as its child-nodes, completes the CREATE operation. Step 3: UPDATE of Values The CREATE Operation is actually only complete once all the values on the navigation path from the new root to the new leaf are updated.","title":"Case 2: New Key Navigates To A Non-Zero Leaf"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#example-8-create-operation-with-a-single-branch-extension","text":"Suppose a leaf needs to be created to store a new key-value pair \\(\\big({K_{\\mathbf{new}}\\ } , V_\\mathbf{{new}}\\big)\\) , where \\(K_{\\mathbf{new}} = 11010110\\) . Consider the SMT shown in Figure 13(a) below. In this example, navigation using the least-significant key-bits, \\(\\text{kb}_\\mathbf{0} = 0\\) and \\(\\text{kb}_\\mathbf{1} = 1\\) , leads to an existing leaf \\(\\mathbf{L_{\\mathbf{c}}}\\) . And the key-value pair \\((V_\\mathbf{\\mathbf{c}}, \\text{HV}_\\mathbf{\\mathbf{c}})\\) stored at \\(\\mathbf{L_{\\mathbf{c}}}\\) has the key \\(K_{\\mathbf{c}} = 11010010\\) . Value-Inclusion Check A value-inclusion check of \\(V_\\mathbf{\\mathbf{c}}\\) is performed before creating any new leaf. Since this amounts to a READ Operation, which has been illustrated in previous examples, we omit how this is done here. Once \\(V_\\mathbf{\\mathbf{c}}\\) passes the check, the CREATE Operation continues by inserting the new leaf. New Leaf Insertion In this example, the new leaf \\(\\mathbf{L_{new}}\\) cannot be inserted at the key-address 01 where \\(\\mathbf{L_{\\mathbf{c}}}\\) is positioned. A branch extension \\(\\mathbf{{B}_{ext}}\\) must therefore be done at the address 01 with the leaves \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{c}}\\) as child-nodes. Since the third least-significant key-bits of \\(K_{\\mathbf{new}}\\) and \\(K_{\\mathbf{c}}\\) are not the same, \\(\\text{kb}_\\mathbf{2new} = 1\\) and \\(\\text{kb}_\\mathbf{2c} = 0\\) , the addresses 110 and 010 of the leaves \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{c}}\\) , respectively, are distinct. Therefore, no further extension is necessary. And the CREATE Operation is complete by updating all the values on the navigation path. Figure 13(a): CREATE Operation - Non-zero Leaf Node The next process, after forming the branch extension, is to UPDATE all the nodes along the path from the root to the new leaf \\(\\mathbf{L_{new}}\\) . The verifier follows the steps of the UPDATE operation to accomplish this. UPDATE of SMT Values The verifier computes the following, The hashed value, \\(\\text{HV}_{\\mathbf{new}} = \\mathbf{H_{noleaf}}(V_\\mathbf{new})\\) , The new leaf, \\(\\mathbf{L_{new}} = \\mathbf{H_{leaf}} ( \\text{RK}_{\\mathbf{new}} \\| \\text{HV}_{\\mathbf{new}})\\) , Then, \\(\\mathbf{B_{ext}} = \\mathbf{H_{noleaf}} ( \\mathbf{L_{c}} \\| \\mathbf{L_{new}})\\) , Again, \\(\\mathbf{B_{new}} = \\mathbf{H_{noleaf}}( \\mathbf{S_{ab}} \\| \\mathbf{B_{ext}} )\\) , And finally computes, \\(\\mathbf{{root}_{new}} = \\mathbf{H_{noleaf}}( \\mathbf{B_{new}} \\| \\mathbf{L_{d}} )\\) . This illustrates how the CREATE Operation is performed at a non-zero leaf, when only one branch extension is required.","title":"Example 8. CREATE Operation with a Single Branch Extension"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#example-9-create-operation-with-multiple-branch-extensions","text":"This example provides an illustration of the CREATE Operation at a non-zero leaf, where more than one branch extensions are required. Suppose a leaf must be created to store a new key-value pair \\(\\big(K_{\\mathbf{new}}, V_\\mathbf{new}\\big)\\) , where \\(K_{\\mathbf{new}} = 11010110\\) . Consider the SMT shown in Figure 13(b) below. Navigating the tree by using the least-significant key-bits, \\(\\text{kb}_\\mathbf{0} = 0\\) and \\(\\text{kb}_\\mathbf{1} = 1\\) , leads to an existing leaf \\(\\mathbf{L_{\\mathbf{c}}}\\) . In this example, suppose the key-value pair \\((K_{\\mathbf{c}} , \\text{HV}_\\mathbf{\\mathbf{c}})\\) stored at \\(\\mathbf{L_{\\mathbf{c}}}\\) has the key \\(K_{\\mathbf{c}} = 11100110\\) . Value-Inclusion Check Before creating the new leaf, it is important to first check if \\(V_\\mathbf{\\mathbf{c}}\\) is indeed included in the root, \\(\\mathbf{root}_\\mathbf{abcd}\\) . Since this amounts to performing a READ Operation, which has been illustrated in previous examples, we omit here how this is done. Once \\(V_\\mathbf{\\mathbf{c}}\\) passes the value-inclusion check, the CREATE Operation proceeds with inserting the new leaf. New Leaf Insertion Note that the first and second least-significant key-bits for both \\(K_\\mathbf{new}\\) and \\(K_\\mathbf{c}\\) are the same. That is, \\(\\text{kb}_\\mathbf{0new} = 0 = \\text{kb}_\\mathbf{0c}\\) and \\(\\text{kb}_\\mathbf{1new} = 1 = \\text{kb}_\\mathbf{1c}\\) . As a result, the new leaf \\(\\mathbf{L_{new}}\\) cannot be inserted at the key-address 01 , where \\(\\mathbf{L_{\\mathbf{c}}}\\) is positioned. An extension branch \\(\\mathbf{{B}_{ext1}}\\) is formed at the tree-address 01 . But, can the leaves \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{c}}\\) be child-nodes to \\(\\mathbf{{B}_{ext1}}\\) ? Since the third least-significant key-bits of \\(K_\\mathbf{new}\\) and \\(K_\\mathbf{c}\\) are the same; that is, \\(\\text{kb}_\\mathbf{2new} = 1 = \\text{kb}_\\mathbf{2c}\\) ; leaves \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{c}}\\) cannot be child-nodes to \\(\\mathbf{{B}_{ext1}}\\) . Another extension branch \\(\\mathbf{{B}_{ext2}}\\) is formed at the tree-address 011 . Again, since the fourth least-significant key-bits of \\(K_\\mathbf{new}\\) and \\(K_\\mathbf{c}\\) are the same; \\(\\text{kb}_\\mathbf{3new} = 0 = \\text{kb}_\\mathbf{3c}\\) ; the leaves \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{c}}\\) cannot be child-nodes to \\(\\mathbf{{B}_{ext2}}\\) . A third extension branch \\(\\mathbf{{B}_{ext3}}\\) is needed at the tree-address 0110 . In this case, the fifth least-significant key-bits of \\(K_\\mathbf{new}\\) and \\(K_\\mathbf{c}\\) are different; i.e., \\(\\text{kb}_\\mathbf{4new} = 1\\) and \\(\\text{kb}_\\mathbf{4c} = 0\\) . The leaves \\(\\mathbf{L_{new}}\\) and \\(\\mathbf{L_{c}}\\) are now made child-nodes of the extension branch \\(\\mathbf{{B}_{ext3}}\\) . See Figure 13(b) below. Figure 13(b): CREATE Operation - Three Branch Extensions Once unique addresses for the key-value pairs \\(\\big( K_{\\mathbf{c}} , V_\\mathbf{c} \\big)\\) and \\(\\big( K_\\mathbf{{new}} , V_{\\mathbf{new}}\\big)\\) are reached, and the leaf \\(\\mathbf{L_{new}}\\) is inserted, all the nodes along the navigation path from the new leaf \\(\\mathbf{L_{new}}\\) to the root are updated as follows. The verifier computes, The hash of the new value, \\(\\text{HV}_\\mathbf{new} = \\mathbf{H_{noleaf}}(V_\\mathbf{new})\\) , The new leaf, \\(\\mathbf{L_{new}} = \\mathbf{H_{leaf}} ( \\text{RK}_{\\mathbf{new}} \\| \\text{HV}_{\\mathbf{new}})\\) , Then, \\(\\mathbf{B_{ext3}} = \\mathbf{H_{noleaf}}( \\mathbf{L_{c}} \\| \\mathbf{L_{new}})\\) , Followed by \\(\\mathbf{B_{ext2}} = \\mathbf{H_{noleaf}}( \\mathbf{B_{ext3}} \\| \\mathbf{0} )\\) , And, \\(\\mathbf{B_{ext1}} = \\mathbf{H_{noleaf}}( \\mathbf{0} \\| \\mathbf{B_{ext2}} )\\) , Again, \\(\\mathbf{B_{new}} = \\mathbf{H_{noleaf}}( \\mathbf{S_{ab}} \\| \\mathbf{B_{ext2}} )\\) , And finally computes, \\(\\mathbf{{root}_{new}} = \\mathbf{H_{noleaf}}( \\mathbf{B_{new}} \\| \\mathbf{L_{d}} )\\) . This completes the CREATE operation at an existing leaf where several branch extensions are needed. The CREATE operation at a non-leaf node clearly changes the topology of the tree.","title":"Example 9. CREATE Operation with Multiple Branch Extensions"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#the-deleteremove-operation","text":"The DELETE Operation refers to a removal of a certain key-value pair from a binary SMT. It is in fact the reverse of the CREATE Operation. There are two types of scenarios that can occur when executing a DELETE Operation. There is a scenario where a DELETE Operation is equivalent to an UPDATE Operation of a non-zero leaf to a NULL leaf. In this case the topology of the SMT does not change. This occurs when the leaf being deleted has a non-zero sibling-node. On the other hand, a DELETE Operation can be tantamount to the reverse of a CREATE Operation where extension branches are removed from the tree. The topology of the SMT can drastically change. This scenario occurs when the leaf being removed has a zero sibling-node. A DELETE Operation involves two main steps; Step 1 : A READ of the value to be deleted is executed. That is; \u200b (a) Navigating to the value, \u200b (b) Checking if the value is included in the root, and \u200b (c) Checking if the given key (reconstructed from the given Remaining Key and the least-significant key-bits) matches the key at the leaf (reconstructed from the Remaining Key found at the leaf and the given key-bits). Step 2 : This step depends on whether the sibling of the leaf to be deleted is zero or not; \u200b (a) If the sibling is not a zero node , an UPDATE to a zero is performed. \u200b (b) If the sibling is a zero-node , an UPDATE to a zero is performed and the parent-node is turned into a NULL node with no child-nodes.","title":"The DELETE/REMOVE Operation"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#case-1-delete-operation-leaves-with-non-zero-siblings","text":"Consider a DELETE of a key-value pair \\(\\big(K_{\\mathbf{b}} , V_\\mathbf{b} \\big)\\) where its leaf \\(\\mathbf{L_b}\\) has a non-zero node sibling. Suppose the data provided includes; the Remaining Key \\(\\tilde{\\text{RK}}_{\\mathbf{b}}\\) , the least-significant key-bits \\(\\text{kb}_0 = 0\\) and \\(\\text{kb}_1 = 1\\) , the root \\(\\mathbf{{root}_{abc}}\\) , and the sibling \\(\\mathbf{L_a}\\) which is not a zero node and the leaf \\(\\mathbf{L_c}\\) . With reference to Figure 14(a) below, navigation leads to the leaf \\(\\mathbf{L_b}\\) . Next, perform a Merkle proof to check if the hashed value \\(\\text{HV}_\\mathbf{b}\\) at \\(\\mathbf{L_b}\\) is included in the given root; Compute \\(\\tilde{\\mathbf{L}}_\\mathbf{b} = \\mathbf{H_{leaf}} ( \\text{RK}_{\\mathbf{b}} \\| \\text{HV}_\\mathbf{b} )\\) Then \\(\\tilde{\\mathbf{B}}_\\mathbf{ab} = \\mathbf{H_{noleaf}} ( \\mathbf{L_a} \\| \\tilde{\\mathbf{L}}_\\mathbf{b})\\) And, \\(\\tilde{\\mathbf{root}}_\\mathbf{abc} = \\mathbf{H_{noleaf}} ( \\tilde{\\mathbf{B}}_\\mathbf{ab} \\| \\mathbf{L_c} )\\) Check if \\(\\tilde{\\mathbf{root}}_\\mathbf{abc}\\) equals \\(\\mathbf{{root}_{abc}}\\) . Simultaneously, check if \\(\\tilde{K}_{\\mathbf{b}}\\) equals \\(\\text{K}_{\\mathbf{b}}\\) , where \\(\\tilde{K}_{\\mathbf{b}} = \\tilde{\\text{RK}}_{\\mathbf{b}} \\| \\text{kb}_1 \\| \\text{kb}_0\\) and \\(\\text{K}_{\\mathbf{b}} = \\text{RK}_{\\mathbf{b}} \\| \\text{kb}_1 \\| \\text{kb}_0\\) are keys reconstructed while climbing the tree. Since the sibling \\(\\mathbf{L_a}\\) is not a zero node, the hashed value \\(\\text{HV}_\\mathbf{b}\\) found at the leaf \\(\\mathbf{L_b}\\) is updated to a zero. And the values along the navigation path are also updated accordingly. That is, The leaf \\(\\mathbf{L_b}\\) is set to \" \\(\\mathbf{0}\\) \", a zero node. The parent-node is now, \\(\\mathbf{B_{a0}} = \\mathbf{H_{noleaf}} ( \\mathbf{L_a} \\| \\mathbf{0} )\\) . And, the new root, \\(\\mathbf{{root}_{abc}} = \\mathbf{H_{noleaf}}(\\mathbf{B_{a0}} \\| \\mathbf{L_a})\\) . See the above DELETE Operation illustrated in Figure 13(a) below, and notice how the SMT maintains its original shape. Figure 14(a): DELETE Operation - Non-Zero Sibling","title":"Case 1: DELETE Operation - Leaves With Non-Zero Siblings"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#case-2-delete-operation-leaves-with-zero-siblings","text":"Consider deleting a key-value pair \\(\\big(K_{\\mathbf{c}} , V_\\mathbf{c} \\big)\\) where its leaf \\(\\mathbf{L_c}\\) has a zero-node sibling. As in Case 1 above, suppose the data provided includes; the Remaining Key \\(\\tilde{\\text{RK}}_{\\mathbf{c}}\\) , the least-significant key-bits \\(\\text{kb}_0 = 0\\) , \\(\\text{kb}_1 = 1\\) and \\(\\text{kb}_2 = 1\\) , the root \\(\\mathbf{{root}_{a0cd}}\\) , and the sibling \" \\(\\mathbf{0}\\) \" which is a zero node, and the leaves \\(\\mathbf{L_a}\\) and \\(\\mathbf{L_d}\\) . With reference to Figure 14(b) below, navigation leads to the leaf \\(\\mathbf{L_c}\\) . The READ step in this case is similar to what is seen in Case 1. The UPDATE step depends on the sibling of \\(\\mathbf{L_c}\\) . Since the sibling is \" \\(\\mathbf{0}\\) \", an UPDATE of \\(\\mathbf{L_c}\\) to zero results in the branch \\(\\mathbf{B_{0c}}\\) having two zero nodes as child-nodes. Since \\(\\mathbf{H_{noleaf}} ( \\mathbf{0} \\| \\mathbf{0}) = 0\\) , it is therefore expedient to turn the branch \\(\\mathbf{B_{0c}}\\) into a zero node with no child-nodes. That is, the UPDATE step of this DELETE Operation concludes as follows; The original branch \\(\\mathbf{B_{0c}}\\) is now \" \\(\\mathbf{0}\\) \", a zero node. The parent-node is now, \\(\\mathbf{B_{a0}} = \\mathbf{H_{noleaf}} ( \\mathbf{L_a} \\| \\mathbf{0} )\\) . And, the new root, \\(\\mathbf{{root}_{a0d}} = \\mathbf{H_{noleaf}}(\\mathbf{B_{a0}} \\| \\mathbf{L_d})\\) . Notice that, in this example, the DELETE Operation alters the topology of the SMT, as seen in Figure 13(b) below. Figure 14(b): DELETE Operation - Zero Sibling","title":"Case 2: DELETE Operation - Leaves With Zero Siblings"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#concluding-basic-operations","text":"The operations discussed in this section are in fact the very actions the Main State Machine will instruct the Storage State Machine to perform. The 'prover' and the 'verifier', as used in the above explanations, can loosely be interpreted as the Executor of the Storage State Machine and the Storage SM's PIL code, respectively. The zero-knowledge Assembly (zkASM) of the Storage SM plays the facilitator's role. The zkASM is the interpreter between the Storage SM and the Main State Machine, also between the Storage SM and the POSEIDON State Machine. The two hash functions used in building the Storage binary SMTs, are special versions of the POSEIDON family of hash functions. What's left is specifying parameters such as the actual key-length used in the Storage State Machine, how keys and paths are created, as well as cryptographic primitives utilised like the exact POSEIDON hash functions.","title":"Concluding Basic Operations"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#zkprover-storage-parameters","text":"In the Storage SM, the keys and values are strings of 256 bits. Keys will henceforth be represented as 256-bit unsigned integers, which are quadruples of 64-bit field elements; e.g., \\(\\text{Key}_{\\mathbf{0123}} = \\big( \\text{Key}_{\\mathbf{0}} , \\text{Key}_{\\mathbf{1}} , \\text{Key}_{\\mathbf{2}} , \\text{Key}_{\\mathbf{3}} \\big)\\) , where each \\(\\text{Key}_{\\mathbf{i}} \\in \\mathbb{F}_p\\) , where \\(p = 2^{64} - 2^{32} + 1\\) . Although hashed-values are also 256-bit long and are used in quadruple form, 'committed' values are 256-bit long and are often expressed as octets. It is mainly due to the POSEIDON SM convention, where 256-bit committed values are input as, \\(\\text{V}_{\\mathbf{01..7}} = \\big( \\text{V}_{\\mathbf{0}} , \\text{V}_{\\mathbf{1}} , \\text{V}_{\\mathbf{2}} , \\dots , \\text{V}_{\\mathbf{7}} \\big)\\) , and each 32-bit \\(V_{\\mathbf{j}}\\) chunk of bits. In fact, almost every other 256-bit value in the Storage is expressed in the form of a quadruple of 64-bit field elements.","title":"zkProver Storage Parameters"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#creating-keys-and-paths","text":"","title":"Creating Keys And Paths"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#how-keys-are-created","text":"In the key-value pair SMT context of our storage design, a key uniquely identifies a leaf. And it is because, although values can change, keys do not. Keys must consequently be generated deterministically, and in such a way that there are no collisions. That is, there must be a one-to-correspondence between keys and leaves. A collision-resistant hash function is therefore the best tool for generating keys. And the most convenient way to generate keys is by hashing some specific information so that the resultant hash uniquely identifies the leaf. The specific Information used for generating keys is the Ethereum Address and some constant. The \\(\\text{POSEIDON}\\) Hash is again used for this purpose.","title":"How Keys Are Created"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#constructing-navigation-paths","text":"A path refers to the edges traversed from the root to a leaf. Since the SMTs are binary, all edges can be thought of, as labelled with either a bit \"0\" or \"1\"; Edges to the left labelled with a bit \"0\", while edges to the right are labelled with a bit \"1\". Paths are therefore strings of bits, and are derived from keys in a very specific way. First of all, every key can be thought of as a quadruple, \\(\\text{Key}_{\\mathbf{0123}} = \\big( \\text{Key}_{\\mathbf{0}} , \\text{Key}_{\\mathbf{1}} , \\text{Key}_{\\mathbf{2}} , \\text{Key}_{\\mathbf{3}} \\big) \\in \\mathbb{F}_{p}^4\\) . Denote each key part \\(\\text{Key}_{\\mathbf{i}}\\) bit-wise as, \\[\\begin{aligned} \\text{Key}_{\\mathbf{0}} = k_{\\mathbf{0,63}\\ } k_{\\mathbf{0,62}\\ } \\dots k_{\\mathbf{0,2}\\ } k_{\\mathbf{0,1}\\ } k_{\\mathbf{0,0} },\\ \\ \\text{Key}_{\\mathbf{1}} = k_{\\mathbf{1,63}\\ } k_{\\mathbf{1,62}\\ } \\dots k_{\\mathbf{1,2}\\ } k_{\\mathbf{1,1}\\ } k_{\\mathbf{1,0} }, \\\\\\text{Key}_{\\mathbf{2}} = k_{\\mathbf{2,63}\\ } k_{\\mathbf{2,62}\\ } \\dots k_{\\mathbf{2,2}\\ } k_{\\mathbf{2,1}\\ } k_{\\mathbf{2,0} },\\ \\ \\text{Key}_{\\mathbf{3}} = k_{\\mathbf{3,63}\\ } k_{\\mathbf{3,62}\\ } \\dots k_{\\mathbf{3,2}\\ } k_{\\mathbf{3,1}\\ } k_{\\mathbf{3,0} }, \\end{aligned}\\] where the most-significant bit \\(\\text{MSB}(\\text{Key}_{\\mathbf{i}}) = k_{\\mathbf{i,63}\\ }\\) and the least-significant bit \\(\\text{LSB}(\\text{Key}_{\\mathbf{i}}) = k_{\\mathbf{i,0}}\\) , for each \\(\\mathbf{i} \\in \\{ \\mathbf{0}, \\mathbf{1}, \\mathbf{2}, \\mathbf{3} \\}\\) . The Navigation Path to the leaf corresponding to the key \\(\\text{Key}_{\\mathbf{0123}}\\) is defined as the following string of shuffled key-bits; \\[\\begin{aligned} k_{\\mathbf{0,0}\\ } k_{\\mathbf{1,0}\\ } k_{\\mathbf{2,0}\\ } k_{\\mathbf{3,0}\\ } k_{\\mathbf{0,1}\\ } k_{\\mathbf{1,1}\\ } k_{\\mathbf{2,1}\\ } k_{\\mathbf{3,1}\\ } k_{\\mathbf{0,2}\\ } k_{\\mathbf{1,2}\\ } k_{\\mathbf{2,2}\\ } k_{\\mathbf{3,2}\\ }\\\\ \\dots k_{\\mathbf{0,62}\\ } k_{\\mathbf{1,62}\\ } k_{\\mathbf{2,62}\\ } k_{\\mathbf{3,62}\\ } k_{\\mathbf{0,63}\\ } k_{\\mathbf{1,63}\\ } k_{\\mathbf{2,63}\\ } k_{\\mathbf{3,63} }. \\end{aligned}\\] That is, the Navigation Path to the leaf corresponding to \\(\\text{Key}_{\\mathbf{0123}}\\) is the string of bits composed of; The least-significant bits of the four key parts, \\(\\text{Key}_{\\mathbf{0}} , \\text{Key}_{\\mathbf{1}} , \\text{Key}_{\\mathbf{2}} , \\text{Key}_{\\mathbf{3}}\\) , appearing in the order of the key parts as: \\(k_{\\mathbf{0,0}\\ } k_{\\mathbf{1,0}\\ } k_{\\mathbf{2,0}\\ } k_{\\mathbf{3,0}}\\) . Followed by the second least-significant bits of the four key parts, \\(\\text{Key}_{\\mathbf{0}} , \\text{Key}_{\\mathbf{1}} , \\text{Key}_{\\mathbf{2}} , \\text{Key}_{\\mathbf{3}}\\) , appearing in the order of the key parts as: \\(k_{\\mathbf{0,1}\\ } k_{\\mathbf{1,1}\\ } k_{\\mathbf{2,1}\\ } k_{\\mathbf{3,1}}\\) . Then the third least-significant bits of the four key parts, \\(\\text{Key}_{\\mathbf{0}} , \\text{Key}_{\\mathbf{1}} , \\text{Key}_{\\mathbf{2}} , \\text{Key}_{\\mathbf{3}}\\) , appearing in the order of the key parts as: \\(k_{\\mathbf{0,2}\\ } k_{\\mathbf{1,2}\\ } k_{\\mathbf{2,2}\\ } k_{\\mathbf{3,2}}\\) . Up until the most-significant bits of the four key parts, \\(\\text{Key}_{\\mathbf{0}} , \\text{Key}_{\\mathbf{1}} , \\text{Key}_{\\mathbf{2}} , \\text{Key}_{\\mathbf{3}}\\) , appearing in the order of the key parts as: \\(k_{\\mathbf{0,63}\\ } k_{\\mathbf{1,63}\\ } k_{\\mathbf{2,63}\\ } k_{\\mathbf{3,63} }\\) . Figure 15 : Navigation Path Derivation Note that, this construction ensures that in every quadruplet of consecutive path-bits there is a one-to-one correspondence between the bits and the four parts of the key, \\(\\text{Key}_{\\mathbf{0}} , \\text{Key}_{\\mathbf{1}} , \\text{Key}_{\\mathbf{2}} , \\text{Key}_{\\mathbf{3}}\\) .","title":"Constructing Navigation Paths"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#reconstructing-the-key-from-path-bits","text":"When executing a basic operation such as an UPDATE of a value at a leaf, one has to reconstruct the key from the remaining key found at the leaf and the path-bits spent in navigating to the leaf. Denote the remaining key as a quadruple, \\(\\text{RKey}_{\\mathbf{0123}} = \\big( \\text{RKey}_{\\mathbf{0}} , \\text{RKey}_{\\mathbf{1}} , \\text{RKey}_{\\mathbf{2}} , \\text{RKey}_{\\mathbf{3}} \\big)\\) Since the Path was constructed by shuffling key-bits from the four parts, \\(\\text{Key}_{\\mathbf{0}}\\) , \\(\\text{Key}_{\\mathbf{1}}\\) , \\(\\text{Key}_{\\mathbf{2}}\\) , \\(\\text{Key}_{\\mathbf{3}}\\) , one would expect the reverse-process (going from the Path-bits to the original key) to work just as easily. Perhaps taking the level \\(\\text{lvl}\\) of a leaf and reducing it modulo 4 , should be sufficient to tell which part of the Remaining Key, \\(\\text{RKey}_{\\mathbf{i}}\\) , must the Path key-bit be appended to.","title":"Reconstructing The Key From Path-Bits"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#example-key-reconstruction","text":"Suppose the leaf storing the key-value pair \\(\\big( \\text{Key}_{\\mathbf{0123}}, \\text{V}_{\\mathbf{01..7}} \\big)\\) is reached at level 7, the path-bits used are \\(0110101\\) , and the remaining key is \\(\\text{RKey}_{\\mathbf{0123}} = \\big( \\text{RKey}_{\\mathbf{0}} , \\text{RKey}_{\\mathbf{1}} , \\text{RKey}_{\\mathbf{2}} , \\text{RKey}_{\\mathbf{3}} \\big)\\) . That is, the path-bits are \\(\\text{path-bit}_6 = 1\\) , \\(\\text{path-bit}_5 = 0\\) , \\(\\text{path-bit}_4 = 1\\) , \\(\\text{path-bit}_3 = 0\\) , \\(\\text{path-bit}_2 = 1\\) , \\(\\text{path-bit}_1 = 1\\) and \\(\\text{path-bit}_0 = 0\\) . So, in order to place \\(\\text{path-bit}_6\\) , one first computes \\(7 \\text{ modulo } 4\\) to get \\(3\\) . Hence, the \\(\\text{key-bit}_6\\) must be appended to the third key part, \\(\\text{RKey}_{\\mathbf{2}}\\) . Next, one climbs the tree to level \\(6\\) , where \\(\\text{path-bit}_5 = 0\\) . One then computes \\(6 \\text{ modulo } 4\\) and gets \\(2\\) . The \\(\\text{path-bit}_5\\) must then be appended to the second key part, \\(\\text{RKey}_{\\mathbf{1}}\\) . Again, one climbs the tree to level \\(5\\) , where \\(\\text{path-bit}_4 = 1\\) . Computing \\(5 \\text{ modulo } 4\\) yields \\(1\\) . The \\(\\text{path-bit}_4\\) is thence appended to the first key part, \\(\\text{RKey}_{\\mathbf{0}}\\) . One then continues in the same fashion; \\(\\text{Climbs the tree to level } 4. \\text{ Computes }\\ 4 \\text{ modulo } 4 = 0. \\text{ Appends path-bit to the fourth part, } \\text{RKey}_{\\mathbf{3}}.\\) \\(\\text{Climbs the tree to level } 3. \\text{ Computes }\\ 3 \\text{ modulo } 4 = 3. \\text{ Appends path-bit to the third part, } \\text{RKey}_{\\mathbf{2}}.\\) \\(\\text{Climbs the tree to level } 2. \\text{ Computes }\\ 2 \\text{ modulo } 4 = 2. \\text{ Appends path-bit to the second part, } \\text{RKey}_{\\mathbf{1}}.\\) \\(\\text{Climbs the tree to level } 1. \\text{ Computes }\\ 1 \\text{ modulo } 4 = 1. \\text{ Appends path-bit to the first part, } \\text{RKey}_{\\mathbf{0}}.\\) The next climb is to the root. The navigation path-bits have been exhausted, and the last append has actually completed reconstruction of the key.","title":"Example. Key Reconstruction"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#leaf-levels-and-integers-modulo-4","text":"It is clear, from the above example, that there is a one-to-one correspondence between the integers modulo 4 (i.e., Elements of the group \\(\\mathbb{Z}_4 = \\{ 0, 1, 2, 3 \\}\\) ) and remaining key parts \\(\\text{RKey}_{\\mathbf{0}} , \\text{RKey}_{\\mathbf{1}} , \\text{RKey}_{\\mathbf{2}} , \\text{RKey}_{\\mathbf{3}}\\) . That is, there is a mapping; \\[\\begin{aligned} 1 \\mapsto \\text{RKey}_{\\mathbf{0}},\\ \\ 2 \\mapsto \\text{RKey}_{\\mathbf{1}},\\ \\ 3 \\mapsto \\text{RKey}_{\\mathbf{2}} \\text{ and }\\ 0 \\mapsto \\text{RKey}_{\\mathbf{3}}. \\end{aligned}\\] The quadruple structure of the path bits and the level of leaves therefore have a homomorphic relationship that can be described in terms of the cyclic group of integers modulo 4, \\(\\mathbb{Z}_4 = \\{ 0, 1, 2, 3 \\}\\) . Since addition modulo n is an expensive computation in the state machine context, it is important to find a more efficient algorithm to achieve the same result.","title":"Leaf Levels and Integers Modulo 4"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#alternate-cyclic-group-of-order-4","text":"In order to explore cyclic groups of order 4, take the vector \\(\\mathbf{x} = (1,0,0,0)\\) , and rotate the components of \\(\\mathbf{x}\\) one position to the left. Note that, rotating \\(\\mathbf{x} = (1,0,0,0)\\) once, yields \\((0,0,0,1)\\) twice, one obtains \\((0,0,1,0)\\) thrice, one gets \\((0,1,0,0)\\) four times, and the result is \\(\\mathbf{x} = (1,0,0,0)\\) Continuously rotating \\(\\mathbf{x} = (1,0,0,0)\\) will not result in any other vector but the four vectors \\[ \\mathbf{G_4} = \\{ (1,0,0,0),\\ (0,0,0,1),\\ (0,0,1,0),\\ (0,1,0,0) \\}. \\] This set of four vectors \\(\\mathbf{G_4}\\) together with the described rotation , form an group. In fact, \\(\\mathbf{G_4}\\) is isomorphic (or homomorphically equivalent) to \\(\\mathbb{Z}_4\\) under \"addition modulo 4\". That is, there is a natural one-to-one correspondence between the elements of \\(\\mathbb{Z}_4\\) and those of \\(\\mathbf{G_4}\\) , as follows; $$ 0 \\mapsto (1,0,0,0),\\ \\ 1 \\mapsto (0,1,0,0),\\ \\ 2 \\mapsto (0,0,1,0)\\ \\text{ and }\\ 3 \\mapsto (0,0,0,1). $$ Note that the four numbers \\(0\\) , \\(1\\) , \\(2\\) and \\(3\\) can be expressed in their binary form with just two bits, and the same one-to-one correspondence holds as; \\[ \\text{00} \\mapsto (1,0,0,0),\\ \\ \\text{01} \\mapsto (0,1,0,0),\\ \\ \\text{10} \\mapsto (0,0,1,0)\\ \\text{ and }\\ \\text{11} \\mapsto (0,0,0,1). \\]","title":"Alternate Cyclic Group Of Order 4"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#a-special-cyclic-register-for-leaf-levels","text":"Define a register called LEVEL which is vector of four bits, three \"0\" bits and one \"1\" bit. And the operation ROTATE_LEVEL which is the left rotation of LEVEL 's bits by one position. If LEVEL is initialised as \\((1,0,0,0)\\) , observe that applying ROTATE_LEVEL four times brings LEVEL back to \\((1,0,0,0)\\) . That is, $$ (1,0,0,0) \\to (0,0,0,1) \\to (0,0,1,0) \\to (0,1,0,0) \\to (1,0,0,0) $$ Therefore, LEVEL is cyclic under ROTATE_LEVEL , and is in fact algebraically the same as the cyclic group \\(\\mathbf{G_4}\\) described above. How is the LEVEL register used in key reconstruction? First note that, when navigating the tree, the leaf level can be indicated by one of the four possible states of the LEVEL register. And this works for all possible leaf levels because, for any positive integer \\(j\\) ; \\[\\begin{aligned} {\\text{LEVEL}} = (1,0,0,0)\\ \\text{indicates that the leaf level is one of the following};\\ 0, 4, 8, \\dots , 0 + 4j. \\ \\\\ {\\text{LEVEL}} = (0,1,0,0)\\ \\text{indicates that the leaf level is one of the following};\\ 1, 5, 9, \\dots , 1 + 4j. \\ \\\\ {\\text{LEVEL}} = (0,0,1,0)\\ \\text{indicates that the leaf level is one of the following};\\ 2, 6, 10, \\dots, 2 + 4j. \\\\ {\\text{LEVEL}} = (0,0,0,1)\\ \\text{indicates that the leaf level is one of the following};\\ 3, 7, 11, \\dots, 3 + 4j. \\end{aligned}\\] Second, the two least-significant bits of each of these number, when written in binary , are as follows; \\[\\begin{aligned} \\text{Each of these numbers};\\ 0, 4, 8, \\dots , 0 + 4j;\\ \\text{ends with } 00.\\ \\ \\\\ \\text{Each of these numbers};\\ 1, 5, 9, \\dots , 1 + 4j;\\ \\text{ends with } 01.\\ \\ \\\\ \\text{Each of these numbers};\\ 2, 6, 10, \\dots , 2 + 4j; \\text{ends with } 10.\\ \\\\ \\text{Each of these numbers};\\ 3, 7, 11, \\dots , 3 + 4j;\\ \\text{ends with } 11. \\end{aligned}\\] It suffices therefore to only read the two least-significant bits of the leaf level in order to determine the position of the bit \"1\" in the LEVEL register. Third, the position of the bit \"1\" in the LEVEL register tallies precisely with the part of the remaining key, \\(\\text{RKey}_{\\mathbf{i}}\\) , to which the last used path-bit came from. So then, when reconstructing the key, one needs only check where the bit \"1\" is in the LEVEL register, because \\[\\begin{aligned} {\\text{LEVEL}} = (1,0,0,0)\\ \\ \\text{means, the last used path bit must be appended to } \\mathbf{RKey_0}.\\\\ {\\text{LEVEL}} = (0,1,0,0)\\ \\ \\text{means, the last used path bit must be appended to } \\mathbf{RKey_1}.\\\\ { \\text{LEVEL}} = (0,0,1,0)\\ \\ \\text{means, the last used path bit must be appended to } \\mathbf{RKey_2}.\\\\ {\\text{LEVEL}} = (0,0,0,1)\\ \\ \\text{means, the last used path bit must be appended to } \\mathbf{RKey_3}. \\end{aligned}\\] Since things are rather mechanical in state machines, one or two more functions are needed. For instance, one for initialising the LEVEL register, and another for reading the position of the bit \"1\".","title":"A Special Cyclic Register For Leaf Levels"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#the-textposeidon-hash","text":"Poseidon SM is the most straight forward once one understands the internal mechanism of the original Poseidon hash function. The hash function's permutation process translates readily to the Poseidon SM states. The \\(\\text{POSEIDON}\\) State Machine carries out \\(\\text{POSEIDON}\\) Actions in accordance with instructions from the Main SM Executor and requests from the Storage SM. That is, it computes hashes of messages sent from any of the two SMs, and also checks if the hashes were correctly computed. The zkProver uses the goldilocks \\(\\text{POSEIDON}\\) which is defined over the field \\(\\mathbb{F}_p\\) , where \\(p = 2^{64} - 2^{32} + 1\\) . The states of the \\(\\text{POSEIDON}\\) SM coincide with the twelve (12) internal states of the \\(\\text{POSEIDON}^{\\pi}\\) permutation function. These are; in0 , in1 , ... , in7 , hashType , cap1 , cap2 and cap3 . \\(\\text{POSEIDON}^{\\pi}\\) runs 30 rounds, 3 times. Adding up to a total of 90 rounds. It outputs four (4) hash values; hash0 , hash1 , hash2 and hash3 . Figure 16 : POSEIDON HASH0 In the case of the zkProver storage, two slightly different \\(\\text{POSEIDON}\\) hashes are used; \\(\\text{HASH0}\\) is used when a branch node is created, whilst \\(\\text{HASH1}\\) is used when a leaf node is created. This depends on the hashType , which is a boolean. So \\(\\text{POSEIDON}\\) acts as \\(\\text{HASH1}\\) when hashType = 1, and \\(\\text{HASH0}\\) when hashType = 0. Since POSEIDON Hashes outputs \\(4 * \\lfloor(63.99)\\rfloor \\text{ bits} = 252\\) , and one bit is needed to encode each direction, the tree can therefore have a maximum of 252 levels.","title":"The \\(\\text{POSEIDON}\\) HASH"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#the-storage-state-machines-design-and-mechanism","text":"The Storage SM is practically dual in that it is both a State Machine and a Storage, a database. So, instead of the Main SM having to query the Storage as a database itself (i.e., the Main SM itself carrying out the CRUD operations), the Storage has instead been automised to execute these queries (by turning it into a state machine). Since the design of the Storage part has been extensively described in the foregoing sections (in terms of SMTs), the design of the automation now follows. What follows next is the description of, how the State Machine part is designed, and how it works (i.e., explaining the internal mechanism of the Storage SM). The Storage SM is composed of three parts; Storage Assembly code, Storage Executor code, and the Storage PIL code.","title":"The Storage State Machine's Design and Mechanism"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#the-storage-assembly","text":"The Storage Assembly is the interpreter between the Main State Machine and its own Executor. It receives instructions from the Main SM and generates a JSON-file containing the corresponding rules and logic, which are stored in a special ROM for the Storage SM. The Storage SM has a primary Storage Assembly code , storage_sm.zkasm , that maps each instruction of the Main SM (i.e., each Storage Action) to the secondary Assembly code of the corresponding basic operation. These basic operations are mainly the CREATE, READ, UPDATE and DELETE, as discussed in previous sections. Considering some special cases, there are all-in-all eight (8) secondary Storage Assembly codes , each for a distinct basic operation; READ or Get, UPDATE, CREATE new value at a zero node, CREATE new value at found leaf, DELETE leaf with zero sibling, DELETE last non-zero node, DELETE leaf with non-zero sibling, and SET a zero node to zero. See Table 1, below, for the specific names of the secondary codes. Table 1: SMT Actions And Secondary zkASM Codes Storage Actions File Names Code Names Action Selectors In Primary zkASM Code READ Get Get isGet() UPDATE Set_Update SU isSetUpdate() CREATE new value at a found leaf Set_InsertFound SIF isSetInsertFound() CREATE new value at a zero node Set_InsertNotFound SINF isSetInsertNotFound() DELETE last non-zero node Set_DeleteLast SDL isSetDeleteLast() DELETE leaf with non-zero sibling Set_DeleteFound SDF isSetDeleteFound() DELETE leaf with zero sibling Set_DeleteNotFound SDNF isSetDeleteNotFound() SET a zero node to zero Set_ZeroToZero SZTZ isSetZeroToZero() Input and ouput states of the Storage SM are literally SMTs, given in the form of; the Merkle roots, the relevant siblings, as well as the key-value pairs. Note that state machines use registers in the place of variables. All values needed, for carrying out the basic operations, are stored by the primary Assembly code in the following registers; HASH_LEFT , HASH_RIGHT , OLD_ROOT , NEW_ROOT , VALUE_LOW , VALUE_HIGH , SIBLING_VALUE_HASH , RKEY , SIBLING_RKEY , RKEY_BIT , LEVEL . The SIBLING_VALUE_HASH and SIBLING_RKEY registers are only used by the Set_InsertFound and the Set_DeleteFound secondary Assembly codes. The rest of the registers are used in all the secondary Assembly codes.","title":"The Storage Assembly"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#smt-action-selectors-in-the-primary-assembly-code","text":"How does the primary Assembly code map the Main SM instructions to the relevant Storage Actions? It uses selectors. Like switches can either be ON or OFF, selectors can either be 1 or 0, where 1 means the action is selected for execution, while 0 means the instruction does not tally with the required action so a \"jump if zero\" JMPZ is applied. The primary Assembly code uses selectors by following the sequence in which these Storage Actions are listed in Table 1 above. That is, It first checks if the required action is a Get . If it is so, the storage_sm_get.zkasm code is fetched for execution. If not, it checks if the required action is Set_Update . If it is so, the storage_sm_set_update.zkasm code is fetched for execution. If not, it continues to check if the required action is Set_InsertFound . If it is so, the storage_sm_set_insert_found.zkasm code is fetched for execution. If not, it continues in the same way until the correct action is selected, in which case the corresponding code is fetched for execution. That's all the primary Storage Assembly code does, the details of how each if the SMT Actions are stipulated in the individual secondary Assembly codes. The primary and secondary Storage Assembly files are stored as JSON-files in the Storage ROM, ready to be fetched as \"function calls\" by the Storage Executor.","title":"SMT Action Selectors In The Primary Assembly Code"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#the-update-zkasm-code","text":"Take as an example the Set_UPDATE zkASM code. The primary Storage Assembly code uses the selector isSetUpdate() for Set_UPDATE. Note that an UPDATE action involves, Reconstructs the corresponding key, from both the remaining key found at the leaf and key-bits used to navigate to the leaf. Ascertains that indeed the old value was included in the old root, Carries out the UPDATE of the old value with the new value, as well as updating all nodes along the path from the leaf to the root. There is only one Set_UPDATE Assembly code, storage_sm_set_update.zkasm , for all the above three computations.","title":"The UPDATE zkASM Code"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#key-reconstruction-in-zkasm","text":"Key Reconstruction is achieved in two steps; Positioning of the bit \"1\" in the LEVEL register, and using the LEVEL register to \"climb the RKey\". That is, append the path bit last used in navigation to the correct RKey part. Step 1. Positioning the bit \"1\" in the LEVEL register The Set_UPDATE zkASM code, first initialises the LEVEL register to (1,0,0,0) . Then uses the GetLevelBit() function to read the two least-significant bits of the leaf level, which happens in two cases, each with its own two subcases; Case 1 . If the least-significant bit of leaf level is 0 , then the GetLevelBit() function is used again to read the second least-significant bit of the leaf level. Subcase 1.1 : If the second least-significant bit of the leaf level is 0 , it means the leaf level is a multiple of 4, which is equivalent to 0 because leaf level works in modulo 4. So, the LEVEL register must remain as (1,0,0,0) . Subcase 1.2 : If the second least-significant bit of the leaf level is 1 , it means the leaf level in its binary form ends with a 10 . Hence, leaf level is a number of the form 2 + 4k , for some positive integer k . As a result, the LEVEL register must be rotated to the position, (0,0,1,0) . The code therefore applies ROTATE_LEVEL twice to LEVEL = (1,0,0,0) in order to bring it to (0,0,1,0) . Case 2 . If the least-significant bit of leaf level is 1 , then; The LEVEL register is rotated three times to the left, using ROTATE_LEVEL, and bringing the LEVEL register to (0,1,0,0) . Next, the GetLevelBit() function is used again to read the second least-significant bit of the leaf level. Subcase 2.1 : If the second least-significant bit of the leaf level is 0 , it means the leaf level in its binary form ends with a 01 . That is, leaf level is a number of the form 1 + 4k , for some positive integer k . And thus, the LEVEL register must remain in its current position, (0,1,0,0) . So it does not need to be rotated. Subcase 2.2 : Otherwise, the second least-significant bit of the leaf level is 1 , which means the leaf level in its binary form ends with a 11 . Hence, leaf level is a number of the form 3 + 4k , for some positive integer k . Consequently, the LEVEL register needs to be rotated from the current position (0,1,0,0) to the position (0,0,0,1) . Step 2. Using LEVEL to \"climb the RKey\" The Remaining Key is fetched using the GetRKey() function and stored in the RKEY register. When climbing the tree, there are two functions that are used in the code; the CLIMB_RKEY and the ROTATE_LEVEL. First, the LEVEL register is used to pinpoint the correct part of the Remaining Key to which the path-bit last used in the navigation must be appended. (See the previous subsection on \" A Special Cyclic Register For Leaf Levels \" for a one-to-one correspondence between the positions of \"1\" in LEVEL and the Rkey parts.) Second, the ROTATE_LEVEL is used to rotate the LEVEL register once. The CLIMB_RKEY is used; Firstly, to shift the value of the pinpointed RKey part one position to the left. Secondly, to insert the last used path bit to the least-significant position of the shifted-value of the pinpointed RKey part. The above two steps are repeated until all the path bits used in navigation have been appended. In which case, equality between the reconstructed key and the original key is checked.","title":"Key Reconstruction In zkASM"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#checking-inclusion-of-old-value-in-old-root","text":"The above key reconstruction, together with checking inclusion of the old value in the old root and updating the old value to the new value, are carried out simultaneously. Since checking inclusion of the old value in the old root follows the same steps as the update of the old value to the new value, the corresponding lines in the Assembly code are similar. It suffices therefore to explain only one of these two computations. Next is the discussion of the update of the old value to the new value.","title":"Checking Inclusion Of Old Value In Old Root"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#the-update-part-of-set_update","text":"All values, \\(\\text{V}_{0123}=\\big(\\text{V}_{0},\\text{V}_{1},\\text{V}_{2},\\text{V}_{3},\\text{V}_{4},\\text{V}_{5},\\text{V}_{6},\\text{V}_{7}\\big)\\) are 256-bit long and expressed as lower half and higher half as, VALUE_LOW \\(=\\big(\\text{V}_{0},\\text{V}_{1},\\text{V}_{2},\\text{V}_{3}\\big)\\) and VALUE_HIGH \\(=\\big(\\text{V}_{4},\\text{V}_{5},\\text{V}_{6},\\text{V}_{7} \\big)\\) . Step 1. Computing the new leaf value (a) The functions GetValueLow() and GetValueHigh() are used to fetch VALUE_LOW \\(=\\big(\\text{V}_{0},\\text{V}_{1},\\text{V}_{2},\\text{V}_{3}\\big)\\) and VALUE_HIGH \\(=\\big(\\text{V}_{4},\\text{V}_{5},\\text{V}_{6},\\text{V}_{7}\\big)\\) , respectively. (b) The VALUE_LOW \\(= \\big(\\text{V}_{0},\\text{V}_{1},\\text{V}_{2},\\text{V}_{3}\\big)\\) is stored in a register called HASH_LEFT , whilst VALUE_HIGH \\(=\\big(\\text{V}_{4},\\text{V}_{5},\\text{V}_{6},\\text{V}_{7}\\big)\\) is stored in another register called HASH_RIGHT . (c) The hashed value of \\(\\text{V}_{0123}\\) is computed using HASH0 as, \\(\\text{HASH0}\\big(\\text{HASH\\_LEFT}\\|\\text{HASH\\_RIGHT}\\big)\\) . Note that this is in fact, \\(\\text{POSEIDON}\\big(0\\|0\\|0\\|0\\|\\text{VALUE\\_LOW}\\|\\text{VALUE\\_HIGH}\\big)\\) . The hashed value is then stored in HASH_RIGHT . (This means the HASH_RIGHT and the HASH_LOW are 'make-shift' registers. Whenever a value is stored in it, the old value that was previously stored therein is simply pushed out. They hold values only for the next computation.) (d) Next the Rkey is copied into the HASH_LEFT register. And the leaf value is computed by using HASH1 as, \\(\\text{HASH1}\\big(\\text{HASH\\_LEFT}\\|\\text{HASH\\_RIGHT}\\big)\\) . i.e., The value of the leaf is, \\(\\text{HASH1}\\big( \\text{RKey}\\|\\text{HashedValue}\\big)\\) . The leaf value is then copied into another register called NEW_ROOT . Step 2. Climbing the SMT Check if the path bit that led to the leaf is 0 or 1, by using the GetNextKeyBit() function. Case 1 : If the path bit (called 'key bit' in the code) is 0, then the corresponding sibling is on the right. Therefore, using 'jump if zero' JMPZ , the code jumps to the SU_SiblingIsRight routine. (a) The leaf value in NEW_ROOT is pushed into the HASH_LEFT register. (b) The hash value of the sibling node is fetched, using the GetSiblingHash() function. And it is pushed into the HASH_RIGHT register. (c) The hash value of the parent node is computed using HASH0 as follows, \\(\\text{HASH0}\\big(\\text{HASH\\_LEFT}\\|\\text{HASH\\_RIGHT}\\big)\\) . i.e., The parent node is \\(\\text{POSEIDON}\\big(0\\|0\\|0\\|0\\|\\text{LeafValue}\\|\\text{SiblingHash}\\big)\\) . Case 2 : If the path bit is 1, then the corresponding sibling is on the left. The routine SU_SiblingIsRight is then executed. (a) The leaf value in NEW_ROOT is pushed into the HASH_RIGHT register. (b) The hash value of the sibling node is fetched, using the GetSiblingHash() function. And it is pushed into the HASH_LEFT register. (c) The hash value of the parent node is computed using HASH0 as follows, \\(\\text{HASH0}\\big(\\text{HASH\\_LEFT}\\|\\text{HASH\\_RIGHT}\\big)\\) . i.e., The parent node is \\(\\text{POSEIDON}\\big(0\\|0\\|0\\|0\\|\\text{SiblingHash}\\|\\text{LeafValue}\\big)\\) . Step 3. Check if tree top has been reached The code uses the function GetTopTree() to check is the top of the tree has been reached. Case 1 . If GetTopTree() returns 1, then Step 2 is repeated. But this time using the hash value of the corresponding sibling at the next level (i.e., at leaf level - 1 ). Case 2 . If GetTopTree() returns 0, then the code jumps to the SU_Latch routine. The SU_Latch is an overall routine for the entire Set_UPDATE Assembly code. It is here where, (a) Equality between the reconstructed key and the original key is checked. (b) Equality between the computed old root value and the original old root is checked. Once consistency is established both between the keys and the old roots, then all new values; the new root, the new hash value, and the new leaf value; are set using LATCH_SET .","title":"The Update Part Of Set_UPDATE"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#the-rest-of-the-secondary-assembly-codes","text":"The Assembly codes for the other seven SMT Actions to a certain extent, follow a similar pattern except for a few cases where especially adjusted routines are used. Actions such as; The Set_InsertFound (or SIF ) may involve a change in the topology of the SMT by extending a branch once or several times. In cases where a branch has been extended, the SIF Assembly code, when computing the new root, uses another routine called SIF_ClimbBranch just for updating values along the newly extended branch. This is done in addition to the SIF_ClimbTree , which is the exact same routine as the aforementioned SU_ClimbTree of the Set_UPDATE case. It is for the same reason, SIF Assembly utilises special registers; the SIBLING_VALUE_HASH and SIBLING_RKEY . The opposite SMT Action, the Set_DeleteFound or SDF , may entail a previously extended branch being reserved. As in the SIF case, if a branch had been extended but now the extension needs to be reversed due to a deleted leaf value, a special routine called SDF_ClimbBranch is used when updating values of nodes along the newly shortened branch. This SDF_ClimbBranch routine is the exact same routine as the SIF_ClimbBranch . Similarly, the SDF Assembly code uses the SDF_ClimbTree as in the Set_UPDATE Assembly. Note also that there is only one Get Assembly code, for the READ SMT Action, and the rest of the secondary Assembly codes are Set_ Assembly codes differing according to their respective SMT Actions. So Get uses LATCH_GET at the end of a run, while the Set_ codes use LATCH_SET .","title":"The Rest Of The Secondary Assembly Codes"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#the-storage-executor","text":"The Storage Executor like a slave-worker to the master, the Storage Assembly code, carries out all SMT Actions in accordance with rules and logic that the Assembly code has set out. As per instruction of the Main SM, the Storage Executor makes function calls to the Storage ROM for a specific secondary Assembly code stored as a JSON-file, by using the same aforementioned selectors of secondary Assembly codes. For example, if the Main SM requires a new leaf to be created at a found non-zero leaf, the Storage Executor uses isSetInsertFound as a function call for the Set_InsertFound (or SIF ) SMT Action. The Storage Executor then proceeds to build commited polynomials and executes the SIF SMT Action. As previously observed, in our very first UPDATE example in this document, all values are expressed as quadruplets of unsigned integers. For example, the Remaining Key looks like this, $$ \\text{RKey} = \\big( \\text{RKey}_0, \\text{RKey}_1, \\text{RKey}_2, \\text{RKey}_3 \\big) $$ The Executor therefore uses an internal 4-element register called op = [_,_,_,_] , for handling values from the Storage ROM, which are needed in the internal step-by-step evaluations of the SMT Action being executed. It is thus reset to 0 after every evaluation. All the function calls seen in the Assembly code; GetSibling() , GetValueLow() , GetValueHigh() , GetRKey() , GetSiblingRKey() , GetSiblingHash() , GetSiblingValueLow() , GetSiblingValueHigh() , GetOldValueLow() , GetOldValueHigh() , GetLevelBit() , GetTopTree() , GetTopBranch() and GetNextKeyBit() ; are actually performed by the Storage Executor. The values being fetched are carried with the op register. For instance, if the function call is GetRKey() then the Storage Executor gets the RKey from the rom.line file, carries it with op as; op[0] = ctx.rkey[0]; op[1] = ctx.rkey[1]; op[2] = ctx.rkey[2]; op[3] = ctx.rkey[3]; where ctx signifies an SMT Action. Also, since all SMT Actions require some hashing, the Storage SM delegates all hashing Actions to the \\(\\text{POSEIDON}\\) SM. However, from within the Storage SM, it is best to treat the \\(\\text{POSEIDON}\\) SM as a blackbox. The Storage Executor simply specifies the sets of twelve values to be digested. And the \\(\\text{POSEIDON}\\) SM then returns the required digests of the values.","title":"The Storage Executor"},{"location":"zkEVM/State-Machines/Storage/Storage-State-Machine-typ/#the-storage-pil","text":"All computations executed in the Storage SM must be verifiable. A special Polynomial Identity Language (PIL) code is therefore used to set up all the polynomial constraints the verifier needs to validate correctness of execution. The preparation for these polynomial constraints actually starts in the Storage Executor. In order to accomplish this, the Storage Executor uses; selectors, setters and instructions; which are in fact Boolean polynomials. See the list of these Boolean committed polynomials in Table 2, below. Table 2: Boolean Polynomials For Execution Tracing Selectors Setters Instructions selFree[i] setHashLeft[i] iHash selSiblingValueHash[i] setHashRight[i] iHashType selOldRoot[i] setOldRoot[i] iLatchSet selNewRoot[i] setNewRoot[i] iLatchGet selValueLow[i] setValueLow[i] iClimbRkey selValueHigh[i] setValueHigh[i] iClimbSiblingRkey selRkeyBit[i] setSiblingValueLow[i] iClimbSiblngRkeyN selSiblingRkey[i] setSiblingValueHigh[i] iRotateLevel selRkey[i] setRkey[i] iJmpz setSiblingRkey[i] iConst0 setRkeyBit[i] iConst1 setLevel[i] iConst2 iConst3 iAddress Everytime each of these Boolean polynomials are utilised or performed, a record of a \"1\" is kept in its register. This is called an execution trace . Therefore, instead of performing some expensive computations in order to verify correctness of execution (at times repeating the same computations being verified), the trace of execution is tested. The verifier takes the execution trace, and tests if it satisfies the polynomial constraints (or identities) in the PIL code. This technique helps the zkProver to achieve succintness as a zero-knowledge proof/verification system.","title":"The Storage PIL"},{"location":"zkEVM/tools-optimizations/merkle-tree/","text":"Merkle Tree Specification This document describes the Merkle Tree that is used. Basic understanding on how Merkle trees and Merkle proofs work is assumed. Glossary Key : position of a leaf in the tree. Branch : node of the tree that have children insted of data, e.g: a non-leaf node. Leaf : node of the tree that stores data. Topology Hexary (16 child per branch, could be 8 if deemed necessary to reduce complexity in zk circuits). Number of levels doesn't have to be fixed, because STARK allows to compute it dynamically. Max levels is 64 due to key size. At least 32 levels (we may consider using more levels to avoid collisions. Amount of leafs = 16**levels . 32 levels ~= 3.4e38). Sparse. Keys and Paths A key is the index of a leaf. They've to be generated in a way that there are no collisions and are deterministic (same leaf always have the same key). Therefore a convinient way to generate keys is by hashing some content of the leaf that uniquely identifies it. Poseidon hash will be used for that purpose (could be changed). A path is a list of directions that enable navigation from root to a given leaf. Paths are derived from keys by taking the last 4bits * (Levels-1) , each 4 bit group will represent a number (values 0 to 15) that indicates which is the child of the branch that follows the path to the leaf. Since poseidon hashes output 253,59 bits, and 4 bits are needed to encode each direction, the tree can have a maximum of 64 levels: 253.59bits / 4bits = Levels-1 . Keys are Finite Field Elements. Values are numbers between \\(0\\) and \\(2^{256}-1\\) (uint256). Example Given a tree with 8 levels (for example purposes, the actual implementation will have at least 32 levels), and the following key, the path will be this: Key (in Little Endian encoding): 0x21665a9251173584a82d950b0ea5f3c19297fdce2383ef325d3c01cb30191d10 Path: direction used bits Root => L1 0x0 252:256 L1 => L2 0x1 248:252 L2 => L3 0xd 244:248 L3 => L4 0x1 240:244 L4 => L5 0x9 236:240 L5 => L6 0x1 232:236 L6 => L7 0x0 228:232 Graphical representation: Reference Implementation Jordi has done js implementation here: 0xPolygonHermez/zkevm-proverjs Example of MT Creation Initially we have an empty MT, that has zero value as a root hash. For the example purpose it has 5 levels and keys are 2 bytes long (4 bits * 4). Step 1 Adding first leaf to sparse MT: Key: 0x4321 Value: 0x66 Leafs: Key (LE) Path Value Real Path Hash 4321 1234 66 - H[1,1234,66,0,0,0,0,0..0] Merkle root hash equals to the hash of the leaf node, which is H[1,1234,66,0,0..0] , since there's no other leaves in the tree. keyPrime equals to Path. Graphical representation: Yellow nodes need (re)calculation Step 2 Adding second leaf: Key: 0x4421 Value: 0x77 Leafs: Path Value Real Path Hash 1234 66 123 H[1,4,66,0,0,0,0..0] 1244 77 124 H[1,4,77,0,0,0,0..0] Graphical representation: Yellow nodes need (re)calculation Step 3 Adding third leaf: Key: 0x6541 Value: 0x88 Leafs: Path Value Real Path Hash 1234 66 123 H[1,4,66,0,0,0,0..0] 1244 77 124 H[1,4,77,0,0,0,0..0] 1456 88 14 H[1,56,88,0,0,0,0..0] Graphical representation: Yellow nodes need (re)calculation Step 4 Adding fourth leaf: Key: 0x5541 Value: 0x99 Leafs: Path Value Real Path Hash 1234 66 123 H[1,4,66,0,0,0,0..0] 1244 77 124 H[1,4,77,0,0,0,0..0] 1455 99 145 H[1,5,99,0,0,0,0..0] 1456 88 145 H[1,6,88,0,0,0,0..0] Graphical representation: Yellow nodes need (re)calculation Nodes Polygon Hermez 1.5 has 2 categories of nodes: Leafs : node of the tree that instead of pointing to other nodes, it holds data. There is 4 types of leafs: Nonce: Counter of transactions made by an account Balance: amount of Ether holded by an account SC code: code of a smart contract SC storage: persistent data stored by a smart contract Branches : node of the tree that point to other nodes. Leafs Generic schema to generate node hash: poseidon.Hash(1, keyPrime, V0, V1, V2, V3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) where: keyPrime - is a remaining part of the key, depends on a position of the Leaf in the Tree V0, V1, V2, V3 - parts of Value split in 64 bit chunks Value, 256 bits MSB LSB 64 bits 64 bits 64 bits 64 bits V3 V2 V1 V0 0 ... 0 - zero padding to get 16 inputs to poseidon hash in total, in this case 10 additional zero values Branches Value: array of 16 poseidon hashes Key: - Hash: poseidon.Hash(hashChild0, hashChild1, ..., hashChild15) Proofs Proofs are very similar to the implementation used in Polygon Hermez 1.0. Proof of Leaf Inclusion in Merkle Tree This type of proof is needed to prove that a key in Merkle Tree has specific value. Structure of the proof from a reference implementation: { root: root, key: key, value: value, siblings: siblings, isOld0: isOld0, // true if leaf hash is 0 insKey: insKey, insValue: insValue, } Proof of Leaf Update This type of proof is needed as an input for the ZKP, to prove the transiction from one state state A to the next one state B . Structure of the proof from a reference implementation: { oldRoot: oldRoot, newRoot: newRoot, key: key, siblings: siblings, // array [level][keys[level]] bytes, insKey: insKey, insValue: insValue, isOld0: isOld0, // true if previous leaf hash was 0 oldValue: oldValue, newValue: value, } Polygon zkEVM specific Leaf Types Balance Value: unsigned integer of 256 bits Key: key is generated by hashing the Ethereum address and a constant with value 0 using Poseidon: key = poseidon.Hash(ethAddrBytes[0:8], ethAddrBytes[8:16], ethAddrBytes[16:24], 0, 0..0) Hash: poseidon.Hash(1, keyPrime, balanceBytes[0:8], balanceBytes[8:16], balanceBytes[16:24], balanceBytes[24:32], 0..0) Nonce Value: unsigned integer of 256 bits Key: key is generated by hashing the Ethereum address and a constant with value 1 using Poseidon: key = poseidon.Hash(ethAddrBytes[0:8], ethAddrBytes[8:16], ethAddrBytes[16:24], 1, 0..0) Hash: poseidon.Hash(1, keyPrime, nonceBytes[0:8], nonceBytes[8:16], nonceBytes[16:24], nonceBytes[24:32], 0..0) SC Code Value: byte array that represents the compiled code Key: key is generated by hashing the Ethereum address and a constant with value 2 using Poseidon: key = poseidon.Hash(1, keyPrime, ethAddrBytes[0:8], ethAddrBytes[8:16], ethAddrBytes[16:24], 2, 0..0) Hash: TBD probably by splitting the code into chunks of 15 elements, and hashing the 15 elements and the hash of the previous chunk SC storage Value: 256 bits that will be interpreted by the SC Key: key is generated by hashing the Ethereum address and a constant with value 3 and the position of the storage that is being accessed: key = poseidon.Hash(ethAddrBytes[0:8], ethAddrBytes[8:16], ethAddrBytes[16:24], 3, storagePositionBytes[0:8], storagePositionBytes[8:16], storagePositionBytes[16:24], storagePositionBytes[24:32], 0..0) Hash: poseidon.Hash(1, keyPrime, valueBytes[0:8], valueBytes[8:16], valueBytes[16:24], valueBytes[24:32], 0..0)","title":"Merkle Tree Specification"},{"location":"zkEVM/tools-optimizations/merkle-tree/#merkle-tree-specification","text":"This document describes the Merkle Tree that is used. Basic understanding on how Merkle trees and Merkle proofs work is assumed.","title":"Merkle Tree Specification"},{"location":"zkEVM/tools-optimizations/merkle-tree/#glossary","text":"Key : position of a leaf in the tree. Branch : node of the tree that have children insted of data, e.g: a non-leaf node. Leaf : node of the tree that stores data.","title":"Glossary"},{"location":"zkEVM/tools-optimizations/merkle-tree/#topology","text":"Hexary (16 child per branch, could be 8 if deemed necessary to reduce complexity in zk circuits). Number of levels doesn't have to be fixed, because STARK allows to compute it dynamically. Max levels is 64 due to key size. At least 32 levels (we may consider using more levels to avoid collisions. Amount of leafs = 16**levels . 32 levels ~= 3.4e38). Sparse.","title":"Topology"},{"location":"zkEVM/tools-optimizations/merkle-tree/#keys-and-paths","text":"A key is the index of a leaf. They've to be generated in a way that there are no collisions and are deterministic (same leaf always have the same key). Therefore a convinient way to generate keys is by hashing some content of the leaf that uniquely identifies it. Poseidon hash will be used for that purpose (could be changed). A path is a list of directions that enable navigation from root to a given leaf. Paths are derived from keys by taking the last 4bits * (Levels-1) , each 4 bit group will represent a number (values 0 to 15) that indicates which is the child of the branch that follows the path to the leaf. Since poseidon hashes output 253,59 bits, and 4 bits are needed to encode each direction, the tree can have a maximum of 64 levels: 253.59bits / 4bits = Levels-1 . Keys are Finite Field Elements. Values are numbers between \\(0\\) and \\(2^{256}-1\\) (uint256).","title":"Keys and Paths"},{"location":"zkEVM/tools-optimizations/merkle-tree/#example","text":"Given a tree with 8 levels (for example purposes, the actual implementation will have at least 32 levels), and the following key, the path will be this: Key (in Little Endian encoding): 0x21665a9251173584a82d950b0ea5f3c19297fdce2383ef325d3c01cb30191d10 Path: direction used bits Root => L1 0x0 252:256 L1 => L2 0x1 248:252 L2 => L3 0xd 244:248 L3 => L4 0x1 240:244 L4 => L5 0x9 236:240 L5 => L6 0x1 232:236 L6 => L7 0x0 228:232 Graphical representation:","title":"Example"},{"location":"zkEVM/tools-optimizations/merkle-tree/#reference-implementation","text":"Jordi has done js implementation here: 0xPolygonHermez/zkevm-proverjs","title":"Reference Implementation"},{"location":"zkEVM/tools-optimizations/merkle-tree/#example-of-mt-creation","text":"Initially we have an empty MT, that has zero value as a root hash. For the example purpose it has 5 levels and keys are 2 bytes long (4 bits * 4).","title":"Example of MT Creation"},{"location":"zkEVM/tools-optimizations/merkle-tree/#step-1","text":"Adding first leaf to sparse MT: Key: 0x4321 Value: 0x66 Leafs: Key (LE) Path Value Real Path Hash 4321 1234 66 - H[1,1234,66,0,0,0,0,0..0] Merkle root hash equals to the hash of the leaf node, which is H[1,1234,66,0,0..0] , since there's no other leaves in the tree. keyPrime equals to Path. Graphical representation: Yellow nodes need (re)calculation","title":"Step 1"},{"location":"zkEVM/tools-optimizations/merkle-tree/#step-2","text":"Adding second leaf: Key: 0x4421 Value: 0x77 Leafs: Path Value Real Path Hash 1234 66 123 H[1,4,66,0,0,0,0..0] 1244 77 124 H[1,4,77,0,0,0,0..0] Graphical representation: Yellow nodes need (re)calculation","title":"Step 2"},{"location":"zkEVM/tools-optimizations/merkle-tree/#step-3","text":"Adding third leaf: Key: 0x6541 Value: 0x88 Leafs: Path Value Real Path Hash 1234 66 123 H[1,4,66,0,0,0,0..0] 1244 77 124 H[1,4,77,0,0,0,0..0] 1456 88 14 H[1,56,88,0,0,0,0..0] Graphical representation: Yellow nodes need (re)calculation","title":"Step 3"},{"location":"zkEVM/tools-optimizations/merkle-tree/#step-4","text":"Adding fourth leaf: Key: 0x5541 Value: 0x99 Leafs: Path Value Real Path Hash 1234 66 123 H[1,4,66,0,0,0,0..0] 1244 77 124 H[1,4,77,0,0,0,0..0] 1455 99 145 H[1,5,99,0,0,0,0..0] 1456 88 145 H[1,6,88,0,0,0,0..0] Graphical representation: Yellow nodes need (re)calculation","title":"Step 4"},{"location":"zkEVM/tools-optimizations/merkle-tree/#nodes","text":"Polygon Hermez 1.5 has 2 categories of nodes: Leafs : node of the tree that instead of pointing to other nodes, it holds data. There is 4 types of leafs: Nonce: Counter of transactions made by an account Balance: amount of Ether holded by an account SC code: code of a smart contract SC storage: persistent data stored by a smart contract Branches : node of the tree that point to other nodes.","title":"Nodes"},{"location":"zkEVM/tools-optimizations/merkle-tree/#leafs","text":"Generic schema to generate node hash: poseidon.Hash(1, keyPrime, V0, V1, V2, V3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) where: keyPrime - is a remaining part of the key, depends on a position of the Leaf in the Tree V0, V1, V2, V3 - parts of Value split in 64 bit chunks Value, 256 bits MSB LSB 64 bits 64 bits 64 bits 64 bits V3 V2 V1 V0 0 ... 0 - zero padding to get 16 inputs to poseidon hash in total, in this case 10 additional zero values","title":"Leafs"},{"location":"zkEVM/tools-optimizations/merkle-tree/#branches","text":"Value: array of 16 poseidon hashes Key: - Hash: poseidon.Hash(hashChild0, hashChild1, ..., hashChild15)","title":"Branches"},{"location":"zkEVM/tools-optimizations/merkle-tree/#proofs","text":"Proofs are very similar to the implementation used in Polygon Hermez 1.0.","title":"Proofs"},{"location":"zkEVM/tools-optimizations/merkle-tree/#proof-of-leaf-inclusion-in-merkle-tree","text":"This type of proof is needed to prove that a key in Merkle Tree has specific value. Structure of the proof from a reference implementation: { root: root, key: key, value: value, siblings: siblings, isOld0: isOld0, // true if leaf hash is 0 insKey: insKey, insValue: insValue, }","title":"Proof of Leaf Inclusion in Merkle Tree"},{"location":"zkEVM/tools-optimizations/merkle-tree/#proof-of-leaf-update","text":"This type of proof is needed as an input for the ZKP, to prove the transiction from one state state A to the next one state B . Structure of the proof from a reference implementation: { oldRoot: oldRoot, newRoot: newRoot, key: key, siblings: siblings, // array [level][keys[level]] bytes, insKey: insKey, insValue: insValue, isOld0: isOld0, // true if previous leaf hash was 0 oldValue: oldValue, newValue: value, }","title":"Proof of Leaf Update"},{"location":"zkEVM/tools-optimizations/merkle-tree/#polygon-zkevm-specific-leaf-types","text":"","title":"Polygon zkEVM specific Leaf Types"},{"location":"zkEVM/tools-optimizations/merkle-tree/#balance","text":"Value: unsigned integer of 256 bits Key: key is generated by hashing the Ethereum address and a constant with value 0 using Poseidon: key = poseidon.Hash(ethAddrBytes[0:8], ethAddrBytes[8:16], ethAddrBytes[16:24], 0, 0..0) Hash: poseidon.Hash(1, keyPrime, balanceBytes[0:8], balanceBytes[8:16], balanceBytes[16:24], balanceBytes[24:32], 0..0)","title":"Balance"},{"location":"zkEVM/tools-optimizations/merkle-tree/#nonce","text":"Value: unsigned integer of 256 bits Key: key is generated by hashing the Ethereum address and a constant with value 1 using Poseidon: key = poseidon.Hash(ethAddrBytes[0:8], ethAddrBytes[8:16], ethAddrBytes[16:24], 1, 0..0) Hash: poseidon.Hash(1, keyPrime, nonceBytes[0:8], nonceBytes[8:16], nonceBytes[16:24], nonceBytes[24:32], 0..0)","title":"Nonce"},{"location":"zkEVM/tools-optimizations/merkle-tree/#sc-code","text":"Value: byte array that represents the compiled code Key: key is generated by hashing the Ethereum address and a constant with value 2 using Poseidon: key = poseidon.Hash(1, keyPrime, ethAddrBytes[0:8], ethAddrBytes[8:16], ethAddrBytes[16:24], 2, 0..0) Hash: TBD probably by splitting the code into chunks of 15 elements, and hashing the 15 elements and the hash of the previous chunk","title":"SC Code"},{"location":"zkEVM/tools-optimizations/merkle-tree/#sc-storage","text":"Value: 256 bits that will be interpreted by the SC Key: key is generated by hashing the Ethereum address and a constant with value 3 and the position of the storage that is being accessed: key = poseidon.Hash(ethAddrBytes[0:8], ethAddrBytes[8:16], ethAddrBytes[16:24], 3, storagePositionBytes[0:8], storagePositionBytes[8:16], storagePositionBytes[16:24], storagePositionBytes[24:32], 0..0) Hash: poseidon.Hash(1, keyPrime, valueBytes[0:8], valueBytes[8:16], valueBytes[16:24], valueBytes[24:32], 0..0)","title":"SC storage"},{"location":"zkEVM/zkASM/basic-syntax/","text":"This section is devoted to explain the basic syntax of zkASM from a high-level point of view. Advanced syntax is totally dependendant of the use case (e.g. the design of a zkEVM) and will be explained in more detail with more complete examples in a latter section. It is important to remark that each instruction of the zkASM is executed sequentially (the exception being the execution of a jump) one after the other. Instructions are depicted line by line and are divided in two parts. The left side part includes the part of the code that is actually gets executed in the corresponding file, while the right part is related to the execution of opcodes, jumps and subrutines, which is indicated by the colon \" \\(:\\) \" symbol. Comments and Modules Comments are made with the semicolon \" \\(;\\) \" symbol. ; This a totally useful comment At this moment, only one-line comments are available. One can subdivide the zkASM code into multiple files and import code with the INCLUDE keyword. This is what we refer to as the modularity of the zkASM. ; File: main.zkasm INCLUDE \"utils.zkasm\" INCLUDE \"constants.zkasm\" ; -- code -- Storing Values on Registers There are many ways in which values can be stored into registers: Assign a constant into one or more registers is made using the arrow operator \"=>\". 0 => A,B Similarly, we can store the value of a register into other registers. A => B,C More generally, we can store the value of a function \\(f\\) of registers. f(A,B) => C,D We can also store a global variable into some register. %GLOBAL_VAR => A,B The result of executing an executor method can also be stored into one or more registers. The indication of such an execution is done with the dollar \"$\" sign, which should be treated as a free input. ${ExecutorMethod(params)} => A,B Notice that the method ExecutorMethod does not necessarily depends on the registers. An good example of such a method is SHA256 . If a method gets executed (with the dollar sign) by its own, its main purpose is generating log information. ${ExecutorMethod(params)} Apart from executor methods, one can also use inline functions. This functions, which are also instantiated by the executor, are simply \"short\" and non-reused executor methods. ${A >> 2} => B ${A & 0x03} => C Introducing Opcodes Until this point, every instruction consisted in a direct interaction with the registers. Now, we move one step forward and we obtain interaction with other parts of the ROM thank to the introduction of the zkEVM opcodes. To assign the output of a zkEVM opcode into some register we use the following syntax: $ => A,B :OPCODE(param) A clear example of such situation is when using the memory load opcode: $ => A,B :MLOAD(param) When a registers appear at the side of an opcode, it is typically used to indicate that the value of the register A is the input of the memory store opcode: A :MSTORE(param) Similarly, we can assign a free input into a register and later on execute several zkEVM opcodes using the following syntax: ${ExecutorMethod(params)} => A :OPCODE1 :OPCODE2 :OPCODE3 ... When a executor method with a register to store its result gets combined with a jump opcode is typically to handle some unexpected situation, such as running out of gas: ${ExecutorMethod(params)} => A :JMP(param) It is also typicall to encounter negative jumps to check appropiate situations in which carry on forthcoming operations: SP - 2 :JMPN(stackUnderflow) Code Injection Inline javascript-based instruction can be injected in plain by using the doble dollar \"$\" symbol. $${CODE} The main difference between the single dollar sign and the doble dollar sign is that while the methods inside the single dollar sign come from the Executor, the doble dollar ones do not: its is plain javascript code that is executed by the ROM. Asserts Asserts work by comparing what is being asserting with what the value on register A . So, for instance, the following instructions compares the value inside register B with the value inside register A : B :ASSERT","title":"Basic Syntax"},{"location":"zkEVM/zkASM/basic-syntax/#comments-and-modules","text":"Comments are made with the semicolon \" \\(;\\) \" symbol. ; This a totally useful comment At this moment, only one-line comments are available. One can subdivide the zkASM code into multiple files and import code with the INCLUDE keyword. This is what we refer to as the modularity of the zkASM. ; File: main.zkasm INCLUDE \"utils.zkasm\" INCLUDE \"constants.zkasm\" ; -- code --","title":"Comments and Modules"},{"location":"zkEVM/zkASM/basic-syntax/#storing-values-on-registers","text":"There are many ways in which values can be stored into registers: Assign a constant into one or more registers is made using the arrow operator \"=>\". 0 => A,B Similarly, we can store the value of a register into other registers. A => B,C More generally, we can store the value of a function \\(f\\) of registers. f(A,B) => C,D We can also store a global variable into some register. %GLOBAL_VAR => A,B The result of executing an executor method can also be stored into one or more registers. The indication of such an execution is done with the dollar \"$\" sign, which should be treated as a free input. ${ExecutorMethod(params)} => A,B Notice that the method ExecutorMethod does not necessarily depends on the registers. An good example of such a method is SHA256 . If a method gets executed (with the dollar sign) by its own, its main purpose is generating log information. ${ExecutorMethod(params)} Apart from executor methods, one can also use inline functions. This functions, which are also instantiated by the executor, are simply \"short\" and non-reused executor methods. ${A >> 2} => B ${A & 0x03} => C","title":"Storing Values on Registers"},{"location":"zkEVM/zkASM/basic-syntax/#introducing-opcodes","text":"Until this point, every instruction consisted in a direct interaction with the registers. Now, we move one step forward and we obtain interaction with other parts of the ROM thank to the introduction of the zkEVM opcodes. To assign the output of a zkEVM opcode into some register we use the following syntax: $ => A,B :OPCODE(param) A clear example of such situation is when using the memory load opcode: $ => A,B :MLOAD(param) When a registers appear at the side of an opcode, it is typically used to indicate that the value of the register A is the input of the memory store opcode: A :MSTORE(param) Similarly, we can assign a free input into a register and later on execute several zkEVM opcodes using the following syntax: ${ExecutorMethod(params)} => A :OPCODE1 :OPCODE2 :OPCODE3 ... When a executor method with a register to store its result gets combined with a jump opcode is typically to handle some unexpected situation, such as running out of gas: ${ExecutorMethod(params)} => A :JMP(param) It is also typicall to encounter negative jumps to check appropiate situations in which carry on forthcoming operations: SP - 2 :JMPN(stackUnderflow)","title":"Introducing Opcodes"},{"location":"zkEVM/zkASM/basic-syntax/#code-injection","text":"Inline javascript-based instruction can be injected in plain by using the doble dollar \"$\" symbol. $${CODE} The main difference between the single dollar sign and the doble dollar sign is that while the methods inside the single dollar sign come from the Executor, the doble dollar ones do not: its is plain javascript code that is executed by the ROM.","title":"Code Injection"},{"location":"zkEVM/zkASM/basic-syntax/#asserts","text":"Asserts work by comparing what is being asserting with what the value on register A . So, for instance, the following instructions compares the value inside register B with the value inside register A : B :ASSERT","title":"Asserts"},{"location":"zkEVM/zkASM/introduction/","text":"Ethereum is a state machine that transition from an old state to a new state by reading a series of transactions. It is a natural choice, in order to interpret the set of EVM opcodes, to design another state machine as for the interpreter. One should think of it as building a state machine inside another state machine, or more concretely, building an Ethereum inside the Ethereum itself. The distinction here is that the former contains a virtual machine, the zkEVM, that is zero-knowledge friendly. The zkEVM as a Microprocessor Following the previous discussion, it is good to see the outer state machine as a microprocessor. What we have done is creating a microprocessor, composed by a series of assembly instructions and its associate program (i.e., the ROM) running on top of it, that interprets the EVM opcodes. Figure 1: Block diagram of a basic uniprocessor-CPU computer. Black lines indicate data flow, whereas red lines indicate control flow; arrows indicate flow directions. As in input, the microprocessor will take the transactions that we want to process and the old state. After fetching the input, the ROM is used to interpret the transactions and generate a new state (the output) from them. Figure 2: Block diagram of a basic machine cycle. The Role of the zkASM The zero-knowledge Assembly (zkASM) is the language used to describe, in a more abstract way, the ROM of our processor. Specifically, this ROM will tell the Executor how to interpret the distinct types of transactions that it could possibly receive as an input. From this point, the Executor will be capable of generating a set of polynomials will describe the state transition and will be later on used by the STARK generator to generate a prove of correctness of this transition. Figure 3: Big picture of the Prover in the zkEVM project, with focus in the zkASM part.","title":"Introduction"},{"location":"zkEVM/zkASM/introduction/#the-zkevm-as-a-microprocessor","text":"Following the previous discussion, it is good to see the outer state machine as a microprocessor. What we have done is creating a microprocessor, composed by a series of assembly instructions and its associate program (i.e., the ROM) running on top of it, that interprets the EVM opcodes. Figure 1: Block diagram of a basic uniprocessor-CPU computer. Black lines indicate data flow, whereas red lines indicate control flow; arrows indicate flow directions. As in input, the microprocessor will take the transactions that we want to process and the old state. After fetching the input, the ROM is used to interpret the transactions and generate a new state (the output) from them. Figure 2: Block diagram of a basic machine cycle.","title":"The zkEVM as a Microprocessor"},{"location":"zkEVM/zkASM/introduction/#the-role-of-the-zkasm","text":"The zero-knowledge Assembly (zkASM) is the language used to describe, in a more abstract way, the ROM of our processor. Specifically, this ROM will tell the Executor how to interpret the distinct types of transactions that it could possibly receive as an input. From this point, the Executor will be capable of generating a set of polynomials will describe the state transition and will be later on used by the STARK generator to generate a prove of correctness of this transition. Figure 3: Big picture of the Prover in the zkEVM project, with focus in the zkASM part.","title":"The Role of the zkASM"},{"location":"zkEVM/zkASM/related-repos/","text":"The ROM for the EVM can be found at this repository . A compiler that compiles the zkASM program to a JSON file that can be read by the executor can be found at this repository . The assembly for the EC Recover can be found at this repository .","title":"Related Repositories"},{"location":"zkEVM/zkASM/some-examples/","text":"This section serves as a compendium of useful examples. EVM ADD Let's take the EVM ADD opcode as our first introductional example: opADD: SP - 2 :JMPN(stackUnderflow) SP - 1 => SP $ => A :MLOAD(SP--) $ => C :MLOAD(SP) ; Add operation with Arith A :MSTORE(arithA) C :MSTORE(arithB) :CALL(addARITH) $ => E :MLOAD(arithRes1) E :MSTORE(SP++) 1024 - SP :JMPN(stackOverflow) GAS-3 => GAS :JMPN(outOfGas) :JMP(readCode) Let us explain in detail how the ADD opcode gets interpreted by us. Recall that at the beginning the stack pointer is pointing to the next \"empty\" address in the stack: First, we check if the stack is filled \"properly\" in order to carry on the ADD operation. This means that, as the ADD opcode needs two elements to operate, it is checked that these two elements are actually in the stack: SP - 2 :JMPN(stackUnderflow) If less than two elements are present, then the stackUnderflow function gets executed. Next, we move the stack pointer to the first operand, load its value and place the result in the A register. Similarly, we move the stack pointer to the next operated, load its value and place the result in the C register. SP - 1 => SP $ => A :MLOAD(SP--) $ => C :MLOAD(SP) Now its when the operation takes place. We perform the addition operation by storing the value of the registers A and C into the variables arithA and arithB and then we call the subrutine addARITH that is the one in charge of actually performing the addition. A :MSTORE(arithA) C :MSTORE(arithB) :CALL(addARITH) $ => E :MLOAD(arithRes1) E :MSTORE(SP++) Finally, the result of the addition gets placed into the register E and the corresponding value gets placed into the stack pointer location; moving it forward afterwise. A bunch of checks are performed. It is first checked that after the operation the stack is not full and then that we do not run out of gas. 1024 - SP :JMPN(stackOverflow) GAS-3 => GAS :JMPN(outOfGas) :JMP(readCode) Last but not least, there is an instruction indicating to move forward to the next intruction.","title":"Some Examples"},{"location":"zkEVM/zkASM/some-examples/#evm-add","text":"Let's take the EVM ADD opcode as our first introductional example: opADD: SP - 2 :JMPN(stackUnderflow) SP - 1 => SP $ => A :MLOAD(SP--) $ => C :MLOAD(SP) ; Add operation with Arith A :MSTORE(arithA) C :MSTORE(arithB) :CALL(addARITH) $ => E :MLOAD(arithRes1) E :MSTORE(SP++) 1024 - SP :JMPN(stackOverflow) GAS-3 => GAS :JMPN(outOfGas) :JMP(readCode) Let us explain in detail how the ADD opcode gets interpreted by us. Recall that at the beginning the stack pointer is pointing to the next \"empty\" address in the stack: First, we check if the stack is filled \"properly\" in order to carry on the ADD operation. This means that, as the ADD opcode needs two elements to operate, it is checked that these two elements are actually in the stack: SP - 2 :JMPN(stackUnderflow) If less than two elements are present, then the stackUnderflow function gets executed. Next, we move the stack pointer to the first operand, load its value and place the result in the A register. Similarly, we move the stack pointer to the next operated, load its value and place the result in the C register. SP - 1 => SP $ => A :MLOAD(SP--) $ => C :MLOAD(SP) Now its when the operation takes place. We perform the addition operation by storing the value of the registers A and C into the variables arithA and arithB and then we call the subrutine addARITH that is the one in charge of actually performing the addition. A :MSTORE(arithA) C :MSTORE(arithB) :CALL(addARITH) $ => E :MLOAD(arithRes1) E :MSTORE(SP++) Finally, the result of the addition gets placed into the register E and the corresponding value gets placed into the stack pointer location; moving it forward afterwise. A bunch of checks are performed. It is first checked that after the operation the stack is not full and then that we do not run out of gas. 1024 - SP :JMPN(stackOverflow) GAS-3 => GAS :JMPN(outOfGas) :JMP(readCode) Last but not least, there is an instruction indicating to move forward to the next intruction.","title":"EVM ADD"}]}